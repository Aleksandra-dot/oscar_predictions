{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-Oscar Prediction with AutoML\n",
    "After out dataframe has been assemlbed (see scraping and table_assembling) notebooks we have the data we need to make predictions on the Best Picture winner. [AutoML](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html) represents a quick, but powerful route though the Machine Learning process. H2O's AutoML runs many models through the dataset and using cross-validation, picks the best one. For my purposes I use it to confirm/compare to the Preferential Balloting Random Forest model I created.\n",
    "If you are gunning to win your office's Oscar pool, scroll down to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators import H2OXGBoostEstimator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Using h2o Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>film</th>\n",
       "      <th>wiki</th>\n",
       "      <th>winner</th>\n",
       "      <th>rating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>worldwide_box_office</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>animation</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_pga</th>\n",
       "      <th>winner_pga</th>\n",
       "      <th>nom_bafta</th>\n",
       "      <th>winner_bafta</th>\n",
       "      <th>nom_dga</th>\n",
       "      <th>winner_dga</th>\n",
       "      <th>nom_sag</th>\n",
       "      <th>winner_sag</th>\n",
       "      <th>nom_cannes</th>\n",
       "      <th>winner_cannes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1927</td>\n",
       "      <td>Wings</td>\n",
       "      <td>/wiki/Wings_(1927_film)</td>\n",
       "      <td>True</td>\n",
       "      <td>7.3</td>\n",
       "      <td>13576.0</td>\n",
       "      <td>$746</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1927</td>\n",
       "      <td>7th Heaven</td>\n",
       "      <td>/wiki/7th_Heaven_(1927_film)</td>\n",
       "      <td>False</td>\n",
       "      <td>5.2</td>\n",
       "      <td>26223.0</td>\n",
       "      <td>$79,808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1927</td>\n",
       "      <td>The Racket</td>\n",
       "      <td>/wiki/The_Racket_(1928_film)</td>\n",
       "      <td>False</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3149.0</td>\n",
       "      <td>$21,733,230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1928</td>\n",
       "      <td>The Broadway Melody</td>\n",
       "      <td>/wiki/The_Broadway_Melody</td>\n",
       "      <td>True</td>\n",
       "      <td>5.6</td>\n",
       "      <td>7605.0</td>\n",
       "      <td>$223,723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1928</td>\n",
       "      <td>Alibi</td>\n",
       "      <td>/wiki/Alibi_(1929_film)</td>\n",
       "      <td>False</td>\n",
       "      <td>7.4</td>\n",
       "      <td>391.0</td>\n",
       "      <td>$42,915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2022</td>\n",
       "      <td>The Fabelmans</td>\n",
       "      <td>/wiki/The_Fabelmans</td>\n",
       "      <td>False</td>\n",
       "      <td>7.6</td>\n",
       "      <td>85709.0</td>\n",
       "      <td>$45,164,110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2022</td>\n",
       "      <td>Tár</td>\n",
       "      <td>/wiki/T%C3%A1r</td>\n",
       "      <td>False</td>\n",
       "      <td>7.5</td>\n",
       "      <td>69684.0</td>\n",
       "      <td>$27,541,681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>2022</td>\n",
       "      <td>Top Gun: Maverick</td>\n",
       "      <td>/wiki/Top_Gun:_Maverick</td>\n",
       "      <td>False</td>\n",
       "      <td>8.3</td>\n",
       "      <td>577408.0</td>\n",
       "      <td>$1,493,491,858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>2022</td>\n",
       "      <td>Triangle of Sadness</td>\n",
       "      <td>/wiki/Triangle_of_Sadness</td>\n",
       "      <td>False</td>\n",
       "      <td>7.3</td>\n",
       "      <td>128812.0</td>\n",
       "      <td>$25,615,870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>2022</td>\n",
       "      <td>Women Talking</td>\n",
       "      <td>/wiki/Women_Talking_(film)</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>29341.0</td>\n",
       "      <td>$8,954,708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year                 film                          wiki  winner  rating  \\\n",
       "0    1927               Wings        /wiki/Wings_(1927_film)    True     7.3   \n",
       "1    1927          7th Heaven   /wiki/7th_Heaven_(1927_film)   False     5.2   \n",
       "2    1927          The Racket   /wiki/The_Racket_(1928_film)   False     6.7   \n",
       "3    1928  The Broadway Melody     /wiki/The_Broadway_Melody    True     5.6   \n",
       "4    1928               Alibi        /wiki/Alibi_(1929_film)   False     7.4   \n",
       "..    ...                  ...                           ...     ...     ...   \n",
       "546  2022        The Fabelmans           /wiki/The_Fabelmans   False     7.6   \n",
       "547  2022                  Tár                /wiki/T%C3%A1r   False     7.5   \n",
       "548  2022    Top Gun: Maverick       /wiki/Top_Gun:_Maverick   False     8.3   \n",
       "549  2022  Triangle of Sadness     /wiki/Triangle_of_Sadness   False     7.3   \n",
       "550  2022       Women Talking     /wiki/Women_Talking_(film)   False     6.9   \n",
       "\n",
       "     numVotes worldwide_box_office  action  adventure  animation  ...  \\\n",
       "0     13576.0                 $746       1          0          0  ...   \n",
       "1     26223.0              $79,808       0          0          0  ...   \n",
       "2      3149.0          $21,733,230       0          0          0  ...   \n",
       "3      7605.0             $223,723       0          0          0  ...   \n",
       "4       391.0              $42,915       0          0          0  ...   \n",
       "..        ...                  ...     ...        ...        ...  ...   \n",
       "546   85709.0          $45,164,110       0          0          0  ...   \n",
       "547   69684.0          $27,541,681       0          0          0  ...   \n",
       "548  577408.0       $1,493,491,858       0          0          0  ...   \n",
       "549  128812.0          $25,615,870       0          0          0  ...   \n",
       "550   29341.0           $8,954,708       0          0          0  ...   \n",
       "\n",
       "     nom_pga  winner_pga  nom_bafta  winner_bafta  nom_dga  winner_dga  \\\n",
       "0          0           0          0             0        0           0   \n",
       "1          0           0          0             0        0           0   \n",
       "2          0           0          0             0        0           0   \n",
       "3          0           0          0             0        0           0   \n",
       "4          0           0          0             0        0           0   \n",
       "..       ...         ...        ...           ...      ...         ...   \n",
       "546        1           0          0             0        1           0   \n",
       "547        1           0          1             0        1           0   \n",
       "548        1           0          0             0        1           0   \n",
       "549        0           0          0             0        0           0   \n",
       "550        0           0          0             0        0           0   \n",
       "\n",
       "     nom_sag  winner_sag  nom_cannes  winner_cannes  \n",
       "0          0           0           0              0  \n",
       "1          0           0           0              0  \n",
       "2          0           0           0              0  \n",
       "3          0           0           0              0  \n",
       "4          0           0           0              0  \n",
       "..       ...         ...         ...            ...  \n",
       "546        1           0           0              0  \n",
       "547        0           0           0              0  \n",
       "548        0           0           0              0  \n",
       "549        0           0           1              1  \n",
       "550        0           0           0              0  \n",
       "\n",
       "[551 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_table = pd.read_csv('../data/processed_results/extended_df.csv')\n",
    "full_table=full_table.drop('Unnamed: 0', axis=1)\n",
    "full_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode)\n",
      "  Starting server from C:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmp0g3__ksz\n",
      "  JVM stdout: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmp0g3__ksz\\h2o_Aleksandra_Czaplak_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmp0g3__ksz\\h2o_Aleksandra_Czaplak_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>07 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Berlin</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>22 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Aleksandra_Czaplak_8vsa57</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.761 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.2 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------------------\n",
       "H2O_cluster_uptime:         07 secs\n",
       "H2O_cluster_timezone:       Europe/Berlin\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    22 days\n",
       "H2O_cluster_name:           H2O_from_python_Aleksandra_Czaplak_8vsa57\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.761 Gb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.2 final\n",
       "--------------------------  -----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Year of Existance. This data will be used below\n",
    "- golden_globes 1943\n",
    "- pga 1989\n",
    "- bafta 1960\n",
    "- dga 1948\n",
    "- sag 1995\n",
    "- cannes 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I pick a min_year where the awards shows will be relevant\n",
    "min_year = 1995"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O's Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set contains: 184 movies\n"
     ]
    }
   ],
   "source": [
    "# Auto ML uses Cross Validation, so we do not specifiy a validation set\n",
    "train = full_table.loc[((full_table['year'] < 2022) & (full_table['year'] >= min_year))]\n",
    "\n",
    "print('training set contains:', train.shape[0], 'movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'film', 'wiki', 'winner', 'rating', 'numVotes',\n",
       "       'worldwide_box_office', 'action', 'adventure', 'animation', 'biography',\n",
       "       'comedy', 'crime', 'documentary', 'drama', 'family', 'fantasy',\n",
       "       'film-noir', 'history', 'horror', 'music', 'musical', 'mystery',\n",
       "       'romance', 'sci-fi', 'sport', 'thriller', 'war', 'western',\n",
       "       'nominations', 'Oscar_win', 'nom_gg_drama', 'winner_gg_drama',\n",
       "       'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga', 'winner_pga',\n",
       "       'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga', 'nom_sag',\n",
       "       'winner_sag', 'nom_cannes', 'winner_cannes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train = train.drop(['index', '[]'], axis=1)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "14:45:14.508: AutoML: XGBoost is not available; skipping it.\n",
      "14:45:14.719: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, worldwide_box_office, documentary]\n",
      "\n",
      "\n",
      "14:45:16.395: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, worldwide_box_office, documentary]\n",
      "14:45:16.396: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 184.0.\n",
      "14:45:16.405: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, worldwide_box_office, documentary]\n",
      "\n",
      "██\n",
      "14:45:18.631: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, worldwide_box_office, documentary]\n",
      "14:45:19.866: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, worldwide_box_office, documentary]\n",
      "\n",
      "██\n",
      "14:45:21.74: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, worldwide_box_office, documentary]\n",
      "14:45:22.0: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, worldwide_box_office, documentary]\n",
      "\n",
      "██\n",
      "14:45:23.149: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, worldwide_box_office, documentary]\n",
      "14:45:24.32: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, worldwide_box_office, documentary]\n",
      "\n",
      "█████████████████████████████████████████████████████████\n",
      "18:07:27.833: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, worldwide_box_office, documentary]\n",
      "\n",
      "| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                             </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">    aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th><th style=\"text-align: right;\">  training_time_ms</th><th style=\"text-align: right;\">  predict_time_per_row_ms</th><th>algo        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_15</td><td style=\"text-align: right;\">0.791106</td><td style=\"text-align: right;\"> 1.09683 </td><td style=\"text-align: right;\">0.433063 </td><td style=\"text-align: right;\">              0.259023</td><td style=\"text-align: right;\">0.418761</td><td style=\"text-align: right;\">0.175361</td><td style=\"text-align: right;\">              2607</td><td style=\"text-align: right;\">                 1.49015 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_1 </td><td style=\"text-align: right;\">0.772588</td><td style=\"text-align: right;\"> 0.597379</td><td style=\"text-align: right;\">0.423092 </td><td style=\"text-align: right;\">              0.23732 </td><td style=\"text-align: right;\">0.340284</td><td style=\"text-align: right;\">0.115794</td><td style=\"text-align: right;\">             10574</td><td style=\"text-align: right;\">                 0.40056 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_3 </td><td style=\"text-align: right;\">0.747818</td><td style=\"text-align: right;\"> 1.73519 </td><td style=\"text-align: right;\">0.285581 </td><td style=\"text-align: right;\">              0.29087 </td><td style=\"text-align: right;\">0.44639 </td><td style=\"text-align: right;\">0.199264</td><td style=\"text-align: right;\">              2600</td><td style=\"text-align: right;\">                 0.247966</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_4 </td><td style=\"text-align: right;\">0.740269</td><td style=\"text-align: right;\"> 0.563238</td><td style=\"text-align: right;\">0.56181  </td><td style=\"text-align: right;\">              0.296886</td><td style=\"text-align: right;\">0.34356 </td><td style=\"text-align: right;\">0.118033</td><td style=\"text-align: right;\">              5737</td><td style=\"text-align: right;\">                 0.207271</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_14</td><td style=\"text-align: right;\">0.717622</td><td style=\"text-align: right;\"> 0.544596</td><td style=\"text-align: right;\">0.288007 </td><td style=\"text-align: right;\">              0.299835</td><td style=\"text-align: right;\">0.376135</td><td style=\"text-align: right;\">0.141477</td><td style=\"text-align: right;\">             10366</td><td style=\"text-align: right;\">                 0.264486</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_22</td><td style=\"text-align: right;\">0.713966</td><td style=\"text-align: right;\"> 1.13228 </td><td style=\"text-align: right;\">0.364345 </td><td style=\"text-align: right;\">              0.322364</td><td style=\"text-align: right;\">0.39171 </td><td style=\"text-align: right;\">0.153437</td><td style=\"text-align: right;\">              3805</td><td style=\"text-align: right;\">                 0.256387</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_1_20230520_144514              </td><td style=\"text-align: right;\">0.704647</td><td style=\"text-align: right;\"> 0.550712</td><td style=\"text-align: right;\">0.321968 </td><td style=\"text-align: right;\">              0.349847</td><td style=\"text-align: right;\">0.399602</td><td style=\"text-align: right;\">0.159682</td><td style=\"text-align: right;\">               175</td><td style=\"text-align: right;\">                 0.267711</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_8 </td><td style=\"text-align: right;\">0.704411</td><td style=\"text-align: right;\"> 0.751851</td><td style=\"text-align: right;\">0.278718 </td><td style=\"text-align: right;\">              0.289691</td><td style=\"text-align: right;\">0.393847</td><td style=\"text-align: right;\">0.155116</td><td style=\"text-align: right;\">              9067</td><td style=\"text-align: right;\">                 0.258215</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_21</td><td style=\"text-align: right;\">0.686954</td><td style=\"text-align: right;\"> 0.634938</td><td style=\"text-align: right;\">0.239659 </td><td style=\"text-align: right;\">              0.30243 </td><td style=\"text-align: right;\">0.399271</td><td style=\"text-align: right;\">0.159417</td><td style=\"text-align: right;\">              2917</td><td style=\"text-align: right;\">                 0.105547</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_20</td><td style=\"text-align: right;\">0.68318 </td><td style=\"text-align: right;\"> 0.604861</td><td style=\"text-align: right;\">0.26804  </td><td style=\"text-align: right;\">              0.343241</td><td style=\"text-align: right;\">0.370924</td><td style=\"text-align: right;\">0.137585</td><td style=\"text-align: right;\">              2724</td><td style=\"text-align: right;\">                 0.287551</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_16</td><td style=\"text-align: right;\">0.678226</td><td style=\"text-align: right;\"> 1.41355 </td><td style=\"text-align: right;\">0.241218 </td><td style=\"text-align: right;\">              0.320948</td><td style=\"text-align: right;\">0.408268</td><td style=\"text-align: right;\">0.166682</td><td style=\"text-align: right;\">              5448</td><td style=\"text-align: right;\">                 0.323083</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_13</td><td style=\"text-align: right;\">0.670441</td><td style=\"text-align: right;\"> 0.771527</td><td style=\"text-align: right;\">0.256752 </td><td style=\"text-align: right;\">              0.325902</td><td style=\"text-align: right;\">0.424014</td><td style=\"text-align: right;\">0.179788</td><td style=\"text-align: right;\">              5080</td><td style=\"text-align: right;\">                 0.211703</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_20</td><td style=\"text-align: right;\">0.670205</td><td style=\"text-align: right;\"> 0.476129</td><td style=\"text-align: right;\">0.279178 </td><td style=\"text-align: right;\">              0.317174</td><td style=\"text-align: right;\">0.357521</td><td style=\"text-align: right;\">0.127821</td><td style=\"text-align: right;\">              2997</td><td style=\"text-align: right;\">                 0.425244</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_12</td><td style=\"text-align: right;\">0.666667</td><td style=\"text-align: right;\"> 0.718853</td><td style=\"text-align: right;\">0.221536 </td><td style=\"text-align: right;\">              0.379099</td><td style=\"text-align: right;\">0.405866</td><td style=\"text-align: right;\">0.164727</td><td style=\"text-align: right;\">              2780</td><td style=\"text-align: right;\">                 0.168446</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_8 </td><td style=\"text-align: right;\">0.664544</td><td style=\"text-align: right;\"> 0.734381</td><td style=\"text-align: right;\">0.25456  </td><td style=\"text-align: right;\">              0.329913</td><td style=\"text-align: right;\">0.395121</td><td style=\"text-align: right;\">0.156121</td><td style=\"text-align: right;\">             10398</td><td style=\"text-align: right;\">                 0.270638</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_6 </td><td style=\"text-align: right;\">0.66242 </td><td style=\"text-align: right;\"> 0.843433</td><td style=\"text-align: right;\">0.253341 </td><td style=\"text-align: right;\">              0.349611</td><td style=\"text-align: right;\">0.406499</td><td style=\"text-align: right;\">0.165241</td><td style=\"text-align: right;\">              3922</td><td style=\"text-align: right;\">                 0.401375</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_5 </td><td style=\"text-align: right;\">0.657466</td><td style=\"text-align: right;\"> 0.668942</td><td style=\"text-align: right;\">0.318385 </td><td style=\"text-align: right;\">              0.35716 </td><td style=\"text-align: right;\">0.369685</td><td style=\"text-align: right;\">0.136667</td><td style=\"text-align: right;\">              5360</td><td style=\"text-align: right;\">                 0.193583</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_1 </td><td style=\"text-align: right;\">0.65723 </td><td style=\"text-align: right;\"> 0.782803</td><td style=\"text-align: right;\">0.243232 </td><td style=\"text-align: right;\">              0.327672</td><td style=\"text-align: right;\">0.423014</td><td style=\"text-align: right;\">0.178941</td><td style=\"text-align: right;\">              4246</td><td style=\"text-align: right;\">                 0.161024</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_12</td><td style=\"text-align: right;\">0.655815</td><td style=\"text-align: right;\"> 0.908319</td><td style=\"text-align: right;\">0.341523 </td><td style=\"text-align: right;\">              0.377919</td><td style=\"text-align: right;\">0.384756</td><td style=\"text-align: right;\">0.148037</td><td style=\"text-align: right;\">              5406</td><td style=\"text-align: right;\">                 0.181291</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_15</td><td style=\"text-align: right;\">0.645435</td><td style=\"text-align: right;\"> 0.928507</td><td style=\"text-align: right;\">0.204954 </td><td style=\"text-align: right;\">              0.357749</td><td style=\"text-align: right;\">0.408156</td><td style=\"text-align: right;\">0.166592</td><td style=\"text-align: right;\">              2703</td><td style=\"text-align: right;\">                 0.25721 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_16</td><td style=\"text-align: right;\">0.644492</td><td style=\"text-align: right;\"> 1.40899 </td><td style=\"text-align: right;\">0.343914 </td><td style=\"text-align: right;\">              0.36577 </td><td style=\"text-align: right;\">0.398147</td><td style=\"text-align: right;\">0.158521</td><td style=\"text-align: right;\">              2829</td><td style=\"text-align: right;\">                 0.266683</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_23</td><td style=\"text-align: right;\">0.640953</td><td style=\"text-align: right;\"> 0.852414</td><td style=\"text-align: right;\">0.179103 </td><td style=\"text-align: right;\">              0.321892</td><td style=\"text-align: right;\">0.462824</td><td style=\"text-align: right;\">0.214206</td><td style=\"text-align: right;\">              4117</td><td style=\"text-align: right;\">                 0.149978</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_10</td><td style=\"text-align: right;\">0.640717</td><td style=\"text-align: right;\"> 0.701027</td><td style=\"text-align: right;\">0.268394 </td><td style=\"text-align: right;\">              0.339467</td><td style=\"text-align: right;\">0.415325</td><td style=\"text-align: right;\">0.172495</td><td style=\"text-align: right;\">              4063</td><td style=\"text-align: right;\">                 0.125547</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_7 </td><td style=\"text-align: right;\">0.63482 </td><td style=\"text-align: right;\"> 0.79982 </td><td style=\"text-align: right;\">0.325836 </td><td style=\"text-align: right;\">              0.37733 </td><td style=\"text-align: right;\">0.401832</td><td style=\"text-align: right;\">0.161469</td><td style=\"text-align: right;\">              5126</td><td style=\"text-align: right;\">                 0.185359</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_10</td><td style=\"text-align: right;\">0.634584</td><td style=\"text-align: right;\"> 0.644333</td><td style=\"text-align: right;\">0.23265  </td><td style=\"text-align: right;\">              0.334867</td><td style=\"text-align: right;\">0.40487 </td><td style=\"text-align: right;\">0.16392 </td><td style=\"text-align: right;\">              5560</td><td style=\"text-align: right;\">                 0.335382</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_12</td><td style=\"text-align: right;\">0.633876</td><td style=\"text-align: right;\"> 0.900836</td><td style=\"text-align: right;\">0.306766 </td><td style=\"text-align: right;\">              0.335456</td><td style=\"text-align: right;\">0.373964</td><td style=\"text-align: right;\">0.139849</td><td style=\"text-align: right;\">              5721</td><td style=\"text-align: right;\">                 0.244858</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_5 </td><td style=\"text-align: right;\">0.627742</td><td style=\"text-align: right;\"> 0.87895 </td><td style=\"text-align: right;\">0.215641 </td><td style=\"text-align: right;\">              0.376504</td><td style=\"text-align: right;\">0.401213</td><td style=\"text-align: right;\">0.160972</td><td style=\"text-align: right;\">              2599</td><td style=\"text-align: right;\">                 0.679321</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_19</td><td style=\"text-align: right;\">0.621255</td><td style=\"text-align: right;\"> 1.09009 </td><td style=\"text-align: right;\">0.287351 </td><td style=\"text-align: right;\">              0.379925</td><td style=\"text-align: right;\">0.406938</td><td style=\"text-align: right;\">0.165599</td><td style=\"text-align: right;\">              4270</td><td style=\"text-align: right;\">                 0.26994 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_9 </td><td style=\"text-align: right;\">0.617363</td><td style=\"text-align: right;\"> 0.89096 </td><td style=\"text-align: right;\">0.222011 </td><td style=\"text-align: right;\">              0.397971</td><td style=\"text-align: right;\">0.433341</td><td style=\"text-align: right;\">0.187784</td><td style=\"text-align: right;\">              2610</td><td style=\"text-align: right;\">                 0.095389</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_21</td><td style=\"text-align: right;\">0.615711</td><td style=\"text-align: right;\"> 1.109   </td><td style=\"text-align: right;\">0.189947 </td><td style=\"text-align: right;\">              0.364709</td><td style=\"text-align: right;\">0.438902</td><td style=\"text-align: right;\">0.192635</td><td style=\"text-align: right;\">              2660</td><td style=\"text-align: right;\">                 0.18464 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_3 </td><td style=\"text-align: right;\">0.614532</td><td style=\"text-align: right;\"> 0.770595</td><td style=\"text-align: right;\">0.182326 </td><td style=\"text-align: right;\">              0.358103</td><td style=\"text-align: right;\">0.418797</td><td style=\"text-align: right;\">0.175391</td><td style=\"text-align: right;\">              2607</td><td style=\"text-align: right;\">                 0.444548</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_7 </td><td style=\"text-align: right;\">0.613352</td><td style=\"text-align: right;\"> 0.717247</td><td style=\"text-align: right;\">0.236867 </td><td style=\"text-align: right;\">              0.384643</td><td style=\"text-align: right;\">0.404008</td><td style=\"text-align: right;\">0.163222</td><td style=\"text-align: right;\">             10679</td><td style=\"text-align: right;\">                 0.255378</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_2 </td><td style=\"text-align: right;\">0.612173</td><td style=\"text-align: right;\"> 1.04132 </td><td style=\"text-align: right;\">0.208603 </td><td style=\"text-align: right;\">              0.327318</td><td style=\"text-align: right;\">0.409493</td><td style=\"text-align: right;\">0.167684</td><td style=\"text-align: right;\">              2576</td><td style=\"text-align: right;\">                 0.190902</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_14</td><td style=\"text-align: right;\">0.610993</td><td style=\"text-align: right;\"> 0.907117</td><td style=\"text-align: right;\">0.175602 </td><td style=\"text-align: right;\">              0.327672</td><td style=\"text-align: right;\">0.432305</td><td style=\"text-align: right;\">0.186888</td><td style=\"text-align: right;\">              3921</td><td style=\"text-align: right;\">                 0.100759</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DRF_1_AutoML_1_20230520_144514                       </td><td style=\"text-align: right;\">0.591767</td><td style=\"text-align: right;\"> 0.50409 </td><td style=\"text-align: right;\">0.171124 </td><td style=\"text-align: right;\">              0.400684</td><td style=\"text-align: right;\">0.377107</td><td style=\"text-align: right;\">0.14221 </td><td style=\"text-align: right;\">               203</td><td style=\"text-align: right;\">                 0.206978</td><td>DRF         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_24</td><td style=\"text-align: right;\">0.586931</td><td style=\"text-align: right;\"> 0.781671</td><td style=\"text-align: right;\">0.210054 </td><td style=\"text-align: right;\">              0.412361</td><td style=\"text-align: right;\">0.396223</td><td style=\"text-align: right;\">0.156992</td><td style=\"text-align: right;\">              2592</td><td style=\"text-align: right;\">                 0.068889</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230520_144514_model_17         </td><td style=\"text-align: right;\">0.574192</td><td style=\"text-align: right;\"> 0.490394</td><td style=\"text-align: right;\">0.173738 </td><td style=\"text-align: right;\">              0.389597</td><td style=\"text-align: right;\">0.379875</td><td style=\"text-align: right;\">0.144305</td><td style=\"text-align: right;\">                71</td><td style=\"text-align: right;\">                 0.217282</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_8 </td><td style=\"text-align: right;\">0.568059</td><td style=\"text-align: right;\"> 0.932845</td><td style=\"text-align: right;\">0.189217 </td><td style=\"text-align: right;\">              0.372729</td><td style=\"text-align: right;\">0.42151 </td><td style=\"text-align: right;\">0.177671</td><td style=\"text-align: right;\">             10836</td><td style=\"text-align: right;\">                 0.26796 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_4 </td><td style=\"text-align: right;\">0.563105</td><td style=\"text-align: right;\"> 0.940011</td><td style=\"text-align: right;\">0.170284 </td><td style=\"text-align: right;\">              0.411654</td><td style=\"text-align: right;\">0.432767</td><td style=\"text-align: right;\">0.187288</td><td style=\"text-align: right;\">              7071</td><td style=\"text-align: right;\">                 0.143872</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_11</td><td style=\"text-align: right;\">0.562633</td><td style=\"text-align: right;\"> 0.927883</td><td style=\"text-align: right;\">0.168648 </td><td style=\"text-align: right;\">              0.433947</td><td style=\"text-align: right;\">0.419657</td><td style=\"text-align: right;\">0.176112</td><td style=\"text-align: right;\">              2505</td><td style=\"text-align: right;\">                 0.205526</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_18</td><td style=\"text-align: right;\">0.556735</td><td style=\"text-align: right;\"> 0.714357</td><td style=\"text-align: right;\">0.281507 </td><td style=\"text-align: right;\">              0.386294</td><td style=\"text-align: right;\">0.37023 </td><td style=\"text-align: right;\">0.13707 </td><td style=\"text-align: right;\">              3737</td><td style=\"text-align: right;\">                 0.102698</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_2_AutoML_1_20230520_144514                       </td><td style=\"text-align: right;\">0.556027</td><td style=\"text-align: right;\"> 0.469792</td><td style=\"text-align: right;\">0.165365 </td><td style=\"text-align: right;\">              0.378863</td><td style=\"text-align: right;\">0.372084</td><td style=\"text-align: right;\">0.138447</td><td style=\"text-align: right;\">               124</td><td style=\"text-align: right;\">                 0.090993</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_3 </td><td style=\"text-align: right;\">0.555084</td><td style=\"text-align: right;\"> 1.17468 </td><td style=\"text-align: right;\">0.172302 </td><td style=\"text-align: right;\">              0.425572</td><td style=\"text-align: right;\">0.407718</td><td style=\"text-align: right;\">0.166234</td><td style=\"text-align: right;\">              2771</td><td style=\"text-align: right;\">                 0.115716</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_10</td><td style=\"text-align: right;\">0.55013 </td><td style=\"text-align: right;\"> 1.15267 </td><td style=\"text-align: right;\">0.18414  </td><td style=\"text-align: right;\">              0.391838</td><td style=\"text-align: right;\">0.421649</td><td style=\"text-align: right;\">0.177788</td><td style=\"text-align: right;\">              5347</td><td style=\"text-align: right;\">                 0.182336</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_22</td><td style=\"text-align: right;\">0.549658</td><td style=\"text-align: right;\"> 0.954656</td><td style=\"text-align: right;\">0.169077 </td><td style=\"text-align: right;\">              0.42168 </td><td style=\"text-align: right;\">0.405907</td><td style=\"text-align: right;\">0.164761</td><td style=\"text-align: right;\">              3773</td><td style=\"text-align: right;\">                 0.105225</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_16</td><td style=\"text-align: right;\">0.545883</td><td style=\"text-align: right;\"> 1.38915 </td><td style=\"text-align: right;\">0.239691 </td><td style=\"text-align: right;\">              0.384879</td><td style=\"text-align: right;\">0.404739</td><td style=\"text-align: right;\">0.163814</td><td style=\"text-align: right;\">              3973</td><td style=\"text-align: right;\">                 0.093709</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_2 </td><td style=\"text-align: right;\">0.545648</td><td style=\"text-align: right;\"> 0.779308</td><td style=\"text-align: right;\">0.177494 </td><td style=\"text-align: right;\">              0.374499</td><td style=\"text-align: right;\">0.391586</td><td style=\"text-align: right;\">0.153339</td><td style=\"text-align: right;\">              2607</td><td style=\"text-align: right;\">                 0.086839</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230520_144514_model_9          </td><td style=\"text-align: right;\">0.542817</td><td style=\"text-align: right;\"> 0.478362</td><td style=\"text-align: right;\">0.159707 </td><td style=\"text-align: right;\">              0.382048</td><td style=\"text-align: right;\">0.376034</td><td style=\"text-align: right;\">0.141401</td><td style=\"text-align: right;\">                91</td><td style=\"text-align: right;\">                 0.085379</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_19</td><td style=\"text-align: right;\">0.524888</td><td style=\"text-align: right;\"> 1.01194 </td><td style=\"text-align: right;\">0.175946 </td><td style=\"text-align: right;\">              0.413541</td><td style=\"text-align: right;\">0.400133</td><td style=\"text-align: right;\">0.160106</td><td style=\"text-align: right;\">              5339</td><td style=\"text-align: right;\">                 0.307078</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_14</td><td style=\"text-align: right;\">0.521113</td><td style=\"text-align: right;\"> 0.988961</td><td style=\"text-align: right;\">0.170751 </td><td style=\"text-align: right;\">              0.403987</td><td style=\"text-align: right;\">0.418164</td><td style=\"text-align: right;\">0.174861</td><td style=\"text-align: right;\">              5312</td><td style=\"text-align: right;\">                 0.22933 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_3_AutoML_1_20230520_144514                       </td><td style=\"text-align: right;\">0.514036</td><td style=\"text-align: right;\"> 0.503552</td><td style=\"text-align: right;\">0.149511 </td><td style=\"text-align: right;\">              0.422859</td><td style=\"text-align: right;\">0.380986</td><td style=\"text-align: right;\">0.145151</td><td style=\"text-align: right;\">               150</td><td style=\"text-align: right;\">                 0.118172</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_20</td><td style=\"text-align: right;\">0.496579</td><td style=\"text-align: right;\"> 1.34578 </td><td style=\"text-align: right;\">0.18461  </td><td style=\"text-align: right;\">              0.4251  </td><td style=\"text-align: right;\">0.427892</td><td style=\"text-align: right;\">0.183092</td><td style=\"text-align: right;\">              2777</td><td style=\"text-align: right;\">                 0.214069</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_13</td><td style=\"text-align: right;\">0.490446</td><td style=\"text-align: right;\"> 0.955715</td><td style=\"text-align: right;\">0.197408 </td><td style=\"text-align: right;\">              0.414367</td><td style=\"text-align: right;\">0.371351</td><td style=\"text-align: right;\">0.137901</td><td style=\"text-align: right;\">              5702</td><td style=\"text-align: right;\">                 0.115386</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230520_144514_model_12         </td><td style=\"text-align: right;\">0.488087</td><td style=\"text-align: right;\"> 0.544913</td><td style=\"text-align: right;\">0.147385 </td><td style=\"text-align: right;\">              0.457891</td><td style=\"text-align: right;\">0.38516 </td><td style=\"text-align: right;\">0.148348</td><td style=\"text-align: right;\">                99</td><td style=\"text-align: right;\">                 0.464566</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_17</td><td style=\"text-align: right;\">0.4862  </td><td style=\"text-align: right;\"> 0.943723</td><td style=\"text-align: right;\">0.137739 </td><td style=\"text-align: right;\">              0.474522</td><td style=\"text-align: right;\">0.43227 </td><td style=\"text-align: right;\">0.186857</td><td style=\"text-align: right;\">              4972</td><td style=\"text-align: right;\">                 0.3465  </td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230520_144514_model_2          </td><td style=\"text-align: right;\">0.484548</td><td style=\"text-align: right;\"> 0.510504</td><td style=\"text-align: right;\">0.145818 </td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.381722</td><td style=\"text-align: right;\">0.145712</td><td style=\"text-align: right;\">                68</td><td style=\"text-align: right;\">                 0.150157</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_4_AutoML_1_20230520_144514                       </td><td style=\"text-align: right;\">0.484076</td><td style=\"text-align: right;\"> 0.506161</td><td style=\"text-align: right;\">0.142245 </td><td style=\"text-align: right;\">              0.439372</td><td style=\"text-align: right;\">0.380888</td><td style=\"text-align: right;\">0.145076</td><td style=\"text-align: right;\">               146</td><td style=\"text-align: right;\">                 0.086061</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_6 </td><td style=\"text-align: right;\">0.48101 </td><td style=\"text-align: right;\"> 0.626453</td><td style=\"text-align: right;\">0.13975  </td><td style=\"text-align: right;\">              0.45624 </td><td style=\"text-align: right;\">0.375273</td><td style=\"text-align: right;\">0.14083 </td><td style=\"text-align: right;\">              5906</td><td style=\"text-align: right;\">                 0.186101</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230520_144514_model_3          </td><td style=\"text-align: right;\">0.479594</td><td style=\"text-align: right;\"> 0.48901 </td><td style=\"text-align: right;\">0.13289  </td><td style=\"text-align: right;\">              0.433593</td><td style=\"text-align: right;\">0.376328</td><td style=\"text-align: right;\">0.141623</td><td style=\"text-align: right;\">                98</td><td style=\"text-align: right;\">                 0.092972</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_5_AutoML_1_20230520_144514                       </td><td style=\"text-align: right;\">0.477707</td><td style=\"text-align: right;\"> 0.550701</td><td style=\"text-align: right;\">0.156918 </td><td style=\"text-align: right;\">              0.46025 </td><td style=\"text-align: right;\">0.384483</td><td style=\"text-align: right;\">0.147827</td><td style=\"text-align: right;\">               102</td><td style=\"text-align: right;\">                 0.107294</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_1 </td><td style=\"text-align: right;\">0.475112</td><td style=\"text-align: right;\"> 1.21026 </td><td style=\"text-align: right;\">0.190023 </td><td style=\"text-align: right;\">              0.418141</td><td style=\"text-align: right;\">0.420409</td><td style=\"text-align: right;\">0.176744</td><td style=\"text-align: right;\">             10535</td><td style=\"text-align: right;\">                 0.36495 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20230520_144514                       </td><td style=\"text-align: right;\">0.472517</td><td style=\"text-align: right;\"> 0.469563</td><td style=\"text-align: right;\">0.136594 </td><td style=\"text-align: right;\">              0.489856</td><td style=\"text-align: right;\">0.374698</td><td style=\"text-align: right;\">0.140399</td><td style=\"text-align: right;\">                85</td><td style=\"text-align: right;\">                 0.368636</td><td>GLM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230520_144514_model_8          </td><td style=\"text-align: right;\">0.471102</td><td style=\"text-align: right;\"> 0.576258</td><td style=\"text-align: right;\">0.144268 </td><td style=\"text-align: right;\">              0.477707</td><td style=\"text-align: right;\">0.385866</td><td style=\"text-align: right;\">0.148893</td><td style=\"text-align: right;\">               164</td><td style=\"text-align: right;\">                 0.13285 </td><td>GBM         </td></tr>\n",
       "<tr><td>XRT_1_AutoML_1_20230520_144514                       </td><td style=\"text-align: right;\">0.470866</td><td style=\"text-align: right;\"> 0.448103</td><td style=\"text-align: right;\">0.125463 </td><td style=\"text-align: right;\">              0.424982</td><td style=\"text-align: right;\">0.371358</td><td style=\"text-align: right;\">0.137907</td><td style=\"text-align: right;\">               112</td><td style=\"text-align: right;\">                 0.409729</td><td>DRF         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_11</td><td style=\"text-align: right;\">0.462609</td><td style=\"text-align: right;\"> 1.33253 </td><td style=\"text-align: right;\">0.161454 </td><td style=\"text-align: right;\">              0.427695</td><td style=\"text-align: right;\">0.392972</td><td style=\"text-align: right;\">0.154427</td><td style=\"text-align: right;\">              2920</td><td style=\"text-align: right;\">                 0.603855</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_2 </td><td style=\"text-align: right;\">0.458835</td><td style=\"text-align: right;\"> 0.73953 </td><td style=\"text-align: right;\">0.149011 </td><td style=\"text-align: right;\">              0.470748</td><td style=\"text-align: right;\">0.389648</td><td style=\"text-align: right;\">0.151826</td><td style=\"text-align: right;\">              3887</td><td style=\"text-align: right;\">                 0.262328</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230520_144514_model_1          </td><td style=\"text-align: right;\">0.455532</td><td style=\"text-align: right;\"> 0.496254</td><td style=\"text-align: right;\">0.13156  </td><td style=\"text-align: right;\">              0.480538</td><td style=\"text-align: right;\">0.378475</td><td style=\"text-align: right;\">0.143243</td><td style=\"text-align: right;\">               114</td><td style=\"text-align: right;\">                 0.112655</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_23</td><td style=\"text-align: right;\">0.455296</td><td style=\"text-align: right;\"> 0.749162</td><td style=\"text-align: right;\">0.164976 </td><td style=\"text-align: right;\">              0.423095</td><td style=\"text-align: right;\">0.384016</td><td style=\"text-align: right;\">0.147468</td><td style=\"text-align: right;\">              7565</td><td style=\"text-align: right;\">                 0.333271</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230520_144514_model_13         </td><td style=\"text-align: right;\">0.449398</td><td style=\"text-align: right;\"> 0.596311</td><td style=\"text-align: right;\">0.130139 </td><td style=\"text-align: right;\">              0.467563</td><td style=\"text-align: right;\">0.391421</td><td style=\"text-align: right;\">0.153211</td><td style=\"text-align: right;\">               154</td><td style=\"text-align: right;\">                 0.321965</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230520_144514_model_15         </td><td style=\"text-align: right;\">0.448927</td><td style=\"text-align: right;\"> 0.505406</td><td style=\"text-align: right;\">0.124347 </td><td style=\"text-align: right;\">              0.470158</td><td style=\"text-align: right;\">0.381077</td><td style=\"text-align: right;\">0.14522 </td><td style=\"text-align: right;\">               105</td><td style=\"text-align: right;\">                 0.156436</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230520_144514_model_5          </td><td style=\"text-align: right;\">0.44645 </td><td style=\"text-align: right;\"> 0.516604</td><td style=\"text-align: right;\">0.132279 </td><td style=\"text-align: right;\">              0.440198</td><td style=\"text-align: right;\">0.382355</td><td style=\"text-align: right;\">0.146195</td><td style=\"text-align: right;\">                98</td><td style=\"text-align: right;\">                 0.093302</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_22</td><td style=\"text-align: right;\">0.441614</td><td style=\"text-align: right;\"> 1.05545 </td><td style=\"text-align: right;\">0.127064 </td><td style=\"text-align: right;\">              0.479122</td><td style=\"text-align: right;\">0.394707</td><td style=\"text-align: right;\">0.155793</td><td style=\"text-align: right;\">              4000</td><td style=\"text-align: right;\">                 1.51169 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_17</td><td style=\"text-align: right;\">0.440198</td><td style=\"text-align: right;\"> 0.867081</td><td style=\"text-align: right;\">0.265436 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.368414</td><td style=\"text-align: right;\">0.135729</td><td style=\"text-align: right;\">              6134</td><td style=\"text-align: right;\">                 0.221694</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_23</td><td style=\"text-align: right;\">0.433121</td><td style=\"text-align: right;\"> 0.730648</td><td style=\"text-align: right;\">0.171008 </td><td style=\"text-align: right;\">              0.417551</td><td style=\"text-align: right;\">0.375017</td><td style=\"text-align: right;\">0.140637</td><td style=\"text-align: right;\">              7687</td><td style=\"text-align: right;\">                 0.235495</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230520_144514_model_10         </td><td style=\"text-align: right;\">0.430762</td><td style=\"text-align: right;\"> 0.50172 </td><td style=\"text-align: right;\">0.127761 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.376721</td><td style=\"text-align: right;\">0.141919</td><td style=\"text-align: right;\">                85</td><td style=\"text-align: right;\">                 0.087732</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_18</td><td style=\"text-align: right;\">0.428403</td><td style=\"text-align: right;\"> 0.662137</td><td style=\"text-align: right;\">0.186515 </td><td style=\"text-align: right;\">              0.411182</td><td style=\"text-align: right;\">0.375526</td><td style=\"text-align: right;\">0.14102 </td><td style=\"text-align: right;\">              8140</td><td style=\"text-align: right;\">                 0.112904</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_5 </td><td style=\"text-align: right;\">0.408823</td><td style=\"text-align: right;\"> 1.33097 </td><td style=\"text-align: right;\">0.140334 </td><td style=\"text-align: right;\">              0.496226</td><td style=\"text-align: right;\">0.421076</td><td style=\"text-align: right;\">0.177305</td><td style=\"text-align: right;\">              4385</td><td style=\"text-align: right;\">                 0.179457</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230520_144514_model_7          </td><td style=\"text-align: right;\">0.406464</td><td style=\"text-align: right;\"> 0.511829</td><td style=\"text-align: right;\">0.120972 </td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.383697</td><td style=\"text-align: right;\">0.147223</td><td style=\"text-align: right;\">                90</td><td style=\"text-align: right;\">                 0.080965</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_21</td><td style=\"text-align: right;\">0.40151 </td><td style=\"text-align: right;\"> 1.02192 </td><td style=\"text-align: right;\">0.115148 </td><td style=\"text-align: right;\">              0.493631</td><td style=\"text-align: right;\">0.449315</td><td style=\"text-align: right;\">0.201884</td><td style=\"text-align: right;\">              2702</td><td style=\"text-align: right;\">                 0.173128</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_24</td><td style=\"text-align: right;\">0.396792</td><td style=\"text-align: right;\"> 1.02873 </td><td style=\"text-align: right;\">0.124267 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.397233</td><td style=\"text-align: right;\">0.157794</td><td style=\"text-align: right;\">              3844</td><td style=\"text-align: right;\">                 0.101642</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_7 </td><td style=\"text-align: right;\">0.39632 </td><td style=\"text-align: right;\"> 1.04239 </td><td style=\"text-align: right;\">0.116107 </td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.443815</td><td style=\"text-align: right;\">0.196971</td><td style=\"text-align: right;\">              5474</td><td style=\"text-align: right;\">                 0.177297</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_19</td><td style=\"text-align: right;\">0.385232</td><td style=\"text-align: right;\"> 1.34339 </td><td style=\"text-align: right;\">0.113248 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.4141  </td><td style=\"text-align: right;\">0.171479</td><td style=\"text-align: right;\">              8555</td><td style=\"text-align: right;\">                 0.185122</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_9 </td><td style=\"text-align: right;\">0.380042</td><td style=\"text-align: right;\"> 1.3236  </td><td style=\"text-align: right;\">0.110154 </td><td style=\"text-align: right;\">              0.474522</td><td style=\"text-align: right;\">0.425378</td><td style=\"text-align: right;\">0.180947</td><td style=\"text-align: right;\">              3645</td><td style=\"text-align: right;\">                 0.09766 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_17</td><td style=\"text-align: right;\">0.377919</td><td style=\"text-align: right;\"> 0.87513 </td><td style=\"text-align: right;\">0.113222 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.384211</td><td style=\"text-align: right;\">0.147618</td><td style=\"text-align: right;\">              3750</td><td style=\"text-align: right;\">                 0.094977</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_9 </td><td style=\"text-align: right;\">0.368247</td><td style=\"text-align: right;\"> 0.913062</td><td style=\"text-align: right;\">0.146506 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.399298</td><td style=\"text-align: right;\">0.159438</td><td style=\"text-align: right;\">              3309</td><td style=\"text-align: right;\">                 0.430531</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_11</td><td style=\"text-align: right;\">0.367304</td><td style=\"text-align: right;\"> 0.879895</td><td style=\"text-align: right;\">0.114125 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.40577 </td><td style=\"text-align: right;\">0.16465 </td><td style=\"text-align: right;\">              1782</td><td style=\"text-align: right;\">                 0.116497</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_6 </td><td style=\"text-align: right;\">0.335456</td><td style=\"text-align: right;\"> 0.885943</td><td style=\"text-align: right;\">0.110314 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.389979</td><td style=\"text-align: right;\">0.152084</td><td style=\"text-align: right;\">              6879</td><td style=\"text-align: right;\">                 0.240109</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_13</td><td style=\"text-align: right;\">0.333569</td><td style=\"text-align: right;\"> 0.931643</td><td style=\"text-align: right;\">0.105104 </td><td style=\"text-align: right;\">              0.496226</td><td style=\"text-align: right;\">0.384408</td><td style=\"text-align: right;\">0.147769</td><td style=\"text-align: right;\">              8312</td><td style=\"text-align: right;\">                 0.098348</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230520_144514_model_4          </td><td style=\"text-align: right;\">0.326846</td><td style=\"text-align: right;\"> 0.495726</td><td style=\"text-align: right;\">0.104367 </td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.377999</td><td style=\"text-align: right;\">0.142883</td><td style=\"text-align: right;\">                78</td><td style=\"text-align: right;\">                 0.079623</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230520_144514_model_18</td><td style=\"text-align: right;\">0.299363</td><td style=\"text-align: right;\"> 1.3671  </td><td style=\"text-align: right;\">0.0994666</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.421977</td><td style=\"text-align: right;\">0.178065</td><td style=\"text-align: right;\">              4005</td><td style=\"text-align: right;\">                 0.103742</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230520_144514_model_15</td><td style=\"text-align: right;\">0.297712</td><td style=\"text-align: right;\"> 1.34066 </td><td style=\"text-align: right;\">0.0995702</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.384765</td><td style=\"text-align: right;\">0.148044</td><td style=\"text-align: right;\">              1712</td><td style=\"text-align: right;\">                 0.140139</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230520_144514_model_4 </td><td style=\"text-align: right;\">0.285445</td><td style=\"text-align: right;\"> 2.0805  </td><td style=\"text-align: right;\">0.0997169</td><td style=\"text-align: right;\">              0.493631</td><td style=\"text-align: right;\">0.435478</td><td style=\"text-align: right;\">0.189641</td><td style=\"text-align: right;\">              4225</td><td style=\"text-align: right;\">                 0.124166</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230520_144514_model_11         </td><td style=\"text-align: right;\">0.269521</td><td style=\"text-align: right;\"> 0.498139</td><td style=\"text-align: right;\">0.105927 </td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.375321</td><td style=\"text-align: right;\">0.140866</td><td style=\"text-align: right;\">                81</td><td style=\"text-align: right;\">                 0.144041</td><td>GBM         </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[93 rows x 10 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                    auc    logloss      aucpr    mean_per_class_error      rmse       mse    training_time_ms    predict_time_per_row_ms  algo\n",
       "-----------------------------------------------------  --------  ---------  ---------  ----------------------  --------  --------  ------------------  -------------------------  ------------\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_15  0.791106   1.09683   0.433063                 0.259023  0.418761  0.175361                2607                   1.49015   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_1   0.772588   0.597379  0.423092                 0.23732   0.340284  0.115794               10574                   0.40056   DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_3   0.747818   1.73519   0.285581                 0.29087   0.44639   0.199264                2600                   0.247966  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_4   0.740269   0.563238  0.56181                  0.296886  0.34356   0.118033                5737                   0.207271  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_14  0.717622   0.544596  0.288007                 0.299835  0.376135  0.141477               10366                   0.264486  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_22  0.713966   1.13228   0.364345                 0.322364  0.39171   0.153437                3805                   0.256387  DeepLearning\n",
       "DeepLearning_1_AutoML_1_20230520_144514                0.704647   0.550712  0.321968                 0.349847  0.399602  0.159682                 175                   0.267711  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_8   0.704411   0.751851  0.278718                 0.289691  0.393847  0.155116                9067                   0.258215  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_21  0.686954   0.634938  0.239659                 0.30243   0.399271  0.159417                2917                   0.105547  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_20  0.68318    0.604861  0.26804                  0.343241  0.370924  0.137585                2724                   0.287551  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_16  0.678226   1.41355   0.241218                 0.320948  0.408268  0.166682                5448                   0.323083  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_13  0.670441   0.771527  0.256752                 0.325902  0.424014  0.179788                5080                   0.211703  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_20  0.670205   0.476129  0.279178                 0.317174  0.357521  0.127821                2997                   0.425244  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_12  0.666667   0.718853  0.221536                 0.379099  0.405866  0.164727                2780                   0.168446  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_8   0.664544   0.734381  0.25456                  0.329913  0.395121  0.156121               10398                   0.270638  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_6   0.66242    0.843433  0.253341                 0.349611  0.406499  0.165241                3922                   0.401375  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_5   0.657466   0.668942  0.318385                 0.35716   0.369685  0.136667                5360                   0.193583  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_1   0.65723    0.782803  0.243232                 0.327672  0.423014  0.178941                4246                   0.161024  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_12  0.655815   0.908319  0.341523                 0.377919  0.384756  0.148037                5406                   0.181291  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_15  0.645435   0.928507  0.204954                 0.357749  0.408156  0.166592                2703                   0.25721   DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_16  0.644492   1.40899   0.343914                 0.36577   0.398147  0.158521                2829                   0.266683  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_23  0.640953   0.852414  0.179103                 0.321892  0.462824  0.214206                4117                   0.149978  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_10  0.640717   0.701027  0.268394                 0.339467  0.415325  0.172495                4063                   0.125547  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_7   0.63482    0.79982   0.325836                 0.37733   0.401832  0.161469                5126                   0.185359  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_10  0.634584   0.644333  0.23265                  0.334867  0.40487   0.16392                 5560                   0.335382  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_12  0.633876   0.900836  0.306766                 0.335456  0.373964  0.139849                5721                   0.244858  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_5   0.627742   0.87895   0.215641                 0.376504  0.401213  0.160972                2599                   0.679321  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_19  0.621255   1.09009   0.287351                 0.379925  0.406938  0.165599                4270                   0.26994   DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_9   0.617363   0.89096   0.222011                 0.397971  0.433341  0.187784                2610                   0.095389  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_21  0.615711   1.109     0.189947                 0.364709  0.438902  0.192635                2660                   0.18464   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_3   0.614532   0.770595  0.182326                 0.358103  0.418797  0.175391                2607                   0.444548  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_7   0.613352   0.717247  0.236867                 0.384643  0.404008  0.163222               10679                   0.255378  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_2   0.612173   1.04132   0.208603                 0.327318  0.409493  0.167684                2576                   0.190902  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_14  0.610993   0.907117  0.175602                 0.327672  0.432305  0.186888                3921                   0.100759  DeepLearning\n",
       "DRF_1_AutoML_1_20230520_144514                         0.591767   0.50409   0.171124                 0.400684  0.377107  0.14221                  203                   0.206978  DRF\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_24  0.586931   0.781671  0.210054                 0.412361  0.396223  0.156992                2592                   0.068889  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230520_144514_model_17           0.574192   0.490394  0.173738                 0.389597  0.379875  0.144305                  71                   0.217282  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_8   0.568059   0.932845  0.189217                 0.372729  0.42151   0.177671               10836                   0.26796   DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_4   0.563105   0.940011  0.170284                 0.411654  0.432767  0.187288                7071                   0.143872  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_11  0.562633   0.927883  0.168648                 0.433947  0.419657  0.176112                2505                   0.205526  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_18  0.556735   0.714357  0.281507                 0.386294  0.37023   0.13707                 3737                   0.102698  DeepLearning\n",
       "GBM_2_AutoML_1_20230520_144514                         0.556027   0.469792  0.165365                 0.378863  0.372084  0.138447                 124                   0.090993  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_3   0.555084   1.17468   0.172302                 0.425572  0.407718  0.166234                2771                   0.115716  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_10  0.55013    1.15267   0.18414                  0.391838  0.421649  0.177788                5347                   0.182336  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_22  0.549658   0.954656  0.169077                 0.42168   0.405907  0.164761                3773                   0.105225  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_16  0.545883   1.38915   0.239691                 0.384879  0.404739  0.163814                3973                   0.093709  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_2   0.545648   0.779308  0.177494                 0.374499  0.391586  0.153339                2607                   0.086839  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230520_144514_model_9            0.542817   0.478362  0.159707                 0.382048  0.376034  0.141401                  91                   0.085379  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_19  0.524888   1.01194   0.175946                 0.413541  0.400133  0.160106                5339                   0.307078  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_14  0.521113   0.988961  0.170751                 0.403987  0.418164  0.174861                5312                   0.22933   DeepLearning\n",
       "GBM_3_AutoML_1_20230520_144514                         0.514036   0.503552  0.149511                 0.422859  0.380986  0.145151                 150                   0.118172  GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_20  0.496579   1.34578   0.18461                  0.4251    0.427892  0.183092                2777                   0.214069  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_13  0.490446   0.955715  0.197408                 0.414367  0.371351  0.137901                5702                   0.115386  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230520_144514_model_12           0.488087   0.544913  0.147385                 0.457891  0.38516   0.148348                  99                   0.464566  GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_17  0.4862     0.943723  0.137739                 0.474522  0.43227   0.186857                4972                   0.3465    DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230520_144514_model_2            0.484548   0.510504  0.145818                 0.496815  0.381722  0.145712                  68                   0.150157  GBM\n",
       "GBM_4_AutoML_1_20230520_144514                         0.484076   0.506161  0.142245                 0.439372  0.380888  0.145076                 146                   0.086061  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_6   0.48101    0.626453  0.13975                  0.45624   0.375273  0.14083                 5906                   0.186101  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230520_144514_model_3            0.479594   0.48901   0.13289                  0.433593  0.376328  0.141623                  98                   0.092972  GBM\n",
       "GBM_5_AutoML_1_20230520_144514                         0.477707   0.550701  0.156918                 0.46025   0.384483  0.147827                 102                   0.107294  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_1   0.475112   1.21026   0.190023                 0.418141  0.420409  0.176744               10535                   0.36495   DeepLearning\n",
       "GLM_1_AutoML_1_20230520_144514                         0.472517   0.469563  0.136594                 0.489856  0.374698  0.140399                  85                   0.368636  GLM\n",
       "GBM_grid_1_AutoML_1_20230520_144514_model_8            0.471102   0.576258  0.144268                 0.477707  0.385866  0.148893                 164                   0.13285   GBM\n",
       "XRT_1_AutoML_1_20230520_144514                         0.470866   0.448103  0.125463                 0.424982  0.371358  0.137907                 112                   0.409729  DRF\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_11  0.462609   1.33253   0.161454                 0.427695  0.392972  0.154427                2920                   0.603855  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_2   0.458835   0.73953   0.149011                 0.470748  0.389648  0.151826                3887                   0.262328  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230520_144514_model_1            0.455532   0.496254  0.13156                  0.480538  0.378475  0.143243                 114                   0.112655  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_23  0.455296   0.749162  0.164976                 0.423095  0.384016  0.147468                7565                   0.333271  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230520_144514_model_13           0.449398   0.596311  0.130139                 0.467563  0.391421  0.153211                 154                   0.321965  GBM\n",
       "GBM_grid_1_AutoML_1_20230520_144514_model_15           0.448927   0.505406  0.124347                 0.470158  0.381077  0.14522                  105                   0.156436  GBM\n",
       "GBM_grid_1_AutoML_1_20230520_144514_model_5            0.44645    0.516604  0.132279                 0.440198  0.382355  0.146195                  98                   0.093302  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_22  0.441614   1.05545   0.127064                 0.479122  0.394707  0.155793                4000                   1.51169   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_17  0.440198   0.867081  0.265436                 0.5       0.368414  0.135729                6134                   0.221694  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_23  0.433121   0.730648  0.171008                 0.417551  0.375017  0.140637                7687                   0.235495  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230520_144514_model_10           0.430762   0.50172   0.127761                 0.5       0.376721  0.141919                  85                   0.087732  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_18  0.428403   0.662137  0.186515                 0.411182  0.375526  0.14102                 8140                   0.112904  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_5   0.408823   1.33097   0.140334                 0.496226  0.421076  0.177305                4385                   0.179457  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230520_144514_model_7            0.406464   0.511829  0.120972                 0.496815  0.383697  0.147223                  90                   0.080965  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_21  0.40151    1.02192   0.115148                 0.493631  0.449315  0.201884                2702                   0.173128  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_24  0.396792   1.02873   0.124267                 0.5       0.397233  0.157794                3844                   0.101642  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_7   0.39632    1.04239   0.116107                 0.496815  0.443815  0.196971                5474                   0.177297  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_19  0.385232   1.34339   0.113248                 0.5       0.4141    0.171479                8555                   0.185122  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_9   0.380042   1.3236    0.110154                 0.474522  0.425378  0.180947                3645                   0.09766   DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_17  0.377919   0.87513   0.113222                 0.5       0.384211  0.147618                3750                   0.094977  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_9   0.368247   0.913062  0.146506                 0.5       0.399298  0.159438                3309                   0.430531  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_11  0.367304   0.879895  0.114125                 0.5       0.40577   0.16465                 1782                   0.116497  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_6   0.335456   0.885943  0.110314                 0.5       0.389979  0.152084                6879                   0.240109  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_13  0.333569   0.931643  0.105104                 0.496226  0.384408  0.147769                8312                   0.098348  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230520_144514_model_4            0.326846   0.495726  0.104367                 0.496815  0.377999  0.142883                  78                   0.079623  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230520_144514_model_18  0.299363   1.3671    0.0994666                0.5       0.421977  0.178065                4005                   0.103742  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230520_144514_model_15  0.297712   1.34066   0.0995702                0.5       0.384765  0.148044                1712                   0.140139  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230520_144514_model_4   0.285445   2.0805    0.0997169                0.493631  0.435478  0.189641                4225                   0.124166  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230520_144514_model_11           0.269521   0.498139  0.105927                 0.496815  0.375321  0.140866                  81                   0.144041  GBM\n",
       "[93 rows x 10 columns]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.automl import H2OAutoML, get_leaderboard\n",
    "\n",
    "# Import a sample binary outcome train/test set into H2O\n",
    "train1 = h2o.H2OFrame(train)\n",
    "\n",
    "# Identify predictors and response\n",
    "predictors = ['year', 'rating', 'numVotes',\n",
    "       'worldwide_box_office', 'action', 'adventure',\n",
    "       'animation', 'biography', 'comedy', 'crime', 'documentary', 'drama',\n",
    "       'family', 'fantasy', 'film-noir', 'history', 'horror', 'music',\n",
    "       'musical', 'mystery', 'romance', 'sci-fi', 'sport', 'thriller', 'war',\n",
    "       'western', 'nominations', 'nom_gg_drama',\n",
    "       'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga',\n",
    "       'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga',\n",
    "       'nom_sag', 'winner_sag', 'nom_cannes', 'winner_cannes']\n",
    "\n",
    "x = predictors\n",
    "y = 'Oscar_win'\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train1[y] = train1[y].asfactor()\n",
    "\n",
    "# Run AutoML for 100 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=100, seed=1\n",
    "                , keep_cross_validation_predictions= True\n",
    "               , exclude_algos = ['StackedEnsemble'])\n",
    "\n",
    "aml.train(x=x, y=y, training_frame=train1)\n",
    "\n",
    "# AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "\n",
    "# Optionally edd extra model information to the leaderboard\n",
    "lb = get_leaderboard(aml, extra_columns='ALL')\n",
    "\n",
    "# Print all rows (instead of default 10 rows)\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a sample binary outcome train/test set into H2O\n",
    "train1 = h2o.H2OFrame(train)\n",
    "\n",
    "# Identify predictors and response\n",
    "predictors = ['year', 'rating', 'numVotes',\n",
    "       'worldwide_box_office', 'action', 'adventure',\n",
    "       'animation', 'biography', 'comedy', 'crime', 'documentary', 'drama',\n",
    "       'family', 'fantasy', 'film-noir', 'history', 'horror', 'music',\n",
    "       'musical', 'mystery', 'romance', 'sci-fi', 'sport', 'thriller', 'war',\n",
    "       'western', 'nominations', 'nom_gg_drama',\n",
    "       'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga',\n",
    "       'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga',\n",
    "       'nom_sag', 'winner_sag', 'nom_cannes', 'winner_cannes']\n",
    "\n",
    "x = predictors\n",
    "y = 'Oscar_win'\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train1[y] = train1[y].asfactor()\n",
    "\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train1, test = train1.split_frame(ratios=[0.8])\n",
    "\n",
    "# Define the XGBoost estimator\n",
    "xgboost = H2OXGBoostEstimator()\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgboost.train(x=x, y=y, training_frame=train1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "performance = xgboost.model_performance(test_data=test)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_1_AutoML_1_20230520_144514_model_15\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 782 weights/biases, 16,4 KB, 257 600 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>36</td>\n",
       "<td>Input</td>\n",
       "<td>5.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>20</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>10.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0022078</td>\n",
       "<td>0.0031235</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0902923</td>\n",
       "<td>0.2605822</td>\n",
       "<td>0.2456089</td>\n",
       "<td>0.2100096</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0018783</td>\n",
       "<td>0.0037211</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0555285</td>\n",
       "<td>1.3402414</td>\n",
       "<td>-0.0333103</td>\n",
       "<td>0.5842199</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.0015749634753609823\n",
       "RMSE: 0.03968580949610304\n",
       "LogLoss: 0.010643031295491859\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7357392318050676</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>157.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/157.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/27.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>157.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/184.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.7357392</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.7357392</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7357392</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7357392</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.7357392</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.7357392</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.7357392</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.7357392</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>157.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>25.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>157.0</td>\n",
       "<td>182.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.7357392</td>\n",
       "<td>27.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9259259</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>182.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.7357392</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,67 %, avg score: 14,62 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0108696</td>\n",
       "<td>0.9999994</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.0740741</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.0740741</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0217391</td>\n",
       "<td>0.9999876</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999959</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999980</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.1481481</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.1481481</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0326087</td>\n",
       "<td>0.9998911</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999738</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999899</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2222222</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.2222222</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0434783</td>\n",
       "<td>0.9995140</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997669</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999342</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2962963</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.2962963</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0543478</td>\n",
       "<td>0.9988889</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9990493</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997572</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.3703704</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.3703704</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1032609</td>\n",
       "<td>0.9845878</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9933574</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9967257</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.7037037</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.7037037</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1521739</td>\n",
       "<td>0.2450068</td>\n",
       "<td>6.0576132</td>\n",
       "<td>6.5714286</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.8225314</td>\n",
       "<td>0.9642857</td>\n",
       "<td>0.9407347</td>\n",
       "<td>0.2962963</td>\n",
       "<td>1.0</td>\n",
       "<td>505.7613169</td>\n",
       "<td>557.1428571</td>\n",
       "<td>0.9936306</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2010870</td>\n",
       "<td>0.0128189</td>\n",
       "<td>0.0</td>\n",
       "<td>4.9729730</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0486563</td>\n",
       "<td>0.7297297</td>\n",
       "<td>0.7237426</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>397.2972973</td>\n",
       "<td>0.9363057</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989130</td>\n",
       "<td>0.0018014</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3454545</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0057404</td>\n",
       "<td>0.4909091</td>\n",
       "<td>0.4887601</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>234.5454545</td>\n",
       "<td>0.8216561</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4021739</td>\n",
       "<td>0.0001637</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4864865</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0006189</td>\n",
       "<td>0.3648649</td>\n",
       "<td>0.3634265</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>148.6486486</td>\n",
       "<td>0.7006369</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0000398</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000882</td>\n",
       "<td>0.2934783</td>\n",
       "<td>0.2923386</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td>\n",
       "<td>0.5859873</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5978261</td>\n",
       "<td>0.0000130</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6727273</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000254</td>\n",
       "<td>0.2454545</td>\n",
       "<td>0.2445055</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2727273</td>\n",
       "<td>0.4713376</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010870</td>\n",
       "<td>0.0000034</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4263566</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000080</td>\n",
       "<td>0.2093023</td>\n",
       "<td>0.2084943</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6356589</td>\n",
       "<td>0.3503185</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7989130</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2517007</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000011</td>\n",
       "<td>0.1836735</td>\n",
       "<td>0.1829645</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1700680</td>\n",
       "<td>0.2356688</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8967391</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1151515</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1636364</td>\n",
       "<td>0.1630047</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.5151515</td>\n",
       "<td>0.1210191</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1467391</td>\n",
       "<td>0.1461727</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.17536099202568806\n",
       "RMSE: 0.4187612589837891\n",
       "LogLoss: 1.0968279650321282\n",
       "Mean Per-Class Error: 0.25902335456475584\n",
       "AUC: 0.7911063930172211\n",
       "AUCPR: 0.43306267605736654\n",
       "Gini: 0.5822127860344422</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.12780196671204258</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>128.0</td>\n",
       "<td>29.0</td>\n",
       "<td>0.1847</td>\n",
       "<td> (29.0/157.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>9.0</td>\n",
       "<td>18.0</td>\n",
       "<td>0.3333</td>\n",
       "<td> (9.0/27.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>137.0</td>\n",
       "<td>47.0</td>\n",
       "<td>0.2065</td>\n",
       "<td> (38.0/184.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.1278020</td>\n",
       "<td>0.4864865</td>\n",
       "<td>41.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0091372</td>\n",
       "<td>0.625</td>\n",
       "<td>70.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9999998</td>\n",
       "<td>0.5454545</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9999998</td>\n",
       "<td>0.8804348</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999998</td>\n",
       "<td>0.8571429</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>166.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9936306</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9999998</td>\n",
       "<td>0.3992581</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0221843</td>\n",
       "<td>0.7197452</td>\n",
       "<td>58.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0091372</td>\n",
       "<td>0.7571361</td>\n",
       "<td>70.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>156.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>22.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>157.0</td>\n",
       "<td>178.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>27.0</td>\n",
       "<td>166.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9936306</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>178.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>166.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,67 %, avg score: 20,09 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0271739</td>\n",
       "<td>1.0</td>\n",
       "<td>5.4518519</td>\n",
       "<td>5.4518519</td>\n",
       "<td>0.8</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1481481</td>\n",
       "<td>0.1481481</td>\n",
       "<td>445.1851852</td>\n",
       "<td>445.1851852</td>\n",
       "<td>0.1417787</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0326087</td>\n",
       "<td>0.9999999</td>\n",
       "<td>6.8148148</td>\n",
       "<td>5.6790123</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.8333333</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.1851852</td>\n",
       "<td>581.4814815</td>\n",
       "<td>467.9012346</td>\n",
       "<td>0.1788158</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0434783</td>\n",
       "<td>0.9999927</td>\n",
       "<td>3.4074074</td>\n",
       "<td>5.1111111</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9999996</td>\n",
       "<td>0.75</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.2222222</td>\n",
       "<td>240.7407407</td>\n",
       "<td>411.1111111</td>\n",
       "<td>0.2094834</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0543478</td>\n",
       "<td>0.9998611</td>\n",
       "<td>0.0</td>\n",
       "<td>4.0888889</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9999705</td>\n",
       "<td>0.6</td>\n",
       "<td>0.9999940</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2222222</td>\n",
       "<td>-100.0</td>\n",
       "<td>308.8888889</td>\n",
       "<td>0.1967445</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.1032609</td>\n",
       "<td>0.9348846</td>\n",
       "<td>0.7572016</td>\n",
       "<td>2.5107212</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.9677367</td>\n",
       "<td>0.3684211</td>\n",
       "<td>0.9847142</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.2592593</td>\n",
       "<td>-24.2798354</td>\n",
       "<td>151.0721248</td>\n",
       "<td>0.1828261</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1521739</td>\n",
       "<td>0.8413253</td>\n",
       "<td>1.5144033</td>\n",
       "<td>2.1904762</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.8966317</td>\n",
       "<td>0.3214286</td>\n",
       "<td>0.9564020</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.3333333</td>\n",
       "<td>51.4403292</td>\n",
       "<td>119.0476190</td>\n",
       "<td>0.2123142</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.2010870</td>\n",
       "<td>0.4432983</td>\n",
       "<td>3.0288066</td>\n",
       "<td>2.3943944</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.6893892</td>\n",
       "<td>0.3513514</td>\n",
       "<td>0.8914529</td>\n",
       "<td>0.1481481</td>\n",
       "<td>0.4814815</td>\n",
       "<td>202.8806584</td>\n",
       "<td>139.4394394</td>\n",
       "<td>0.3286152</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2989130</td>\n",
       "<td>0.0442015</td>\n",
       "<td>2.2716049</td>\n",
       "<td>2.3542088</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.1914701</td>\n",
       "<td>0.3454545</td>\n",
       "<td>0.6623676</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.7037037</td>\n",
       "<td>127.1604938</td>\n",
       "<td>135.4208754</td>\n",
       "<td>0.4744043</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.4021739</td>\n",
       "<td>0.0099159</td>\n",
       "<td>1.0760234</td>\n",
       "<td>2.0260260</td>\n",
       "<td>0.1578947</td>\n",
       "<td>0.0234602</td>\n",
       "<td>0.2972973</td>\n",
       "<td>0.4983238</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.8148148</td>\n",
       "<td>7.6023392</td>\n",
       "<td>102.6026026</td>\n",
       "<td>0.4836046</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0012273</td>\n",
       "<td>0.3786008</td>\n",
       "<td>1.7037037</td>\n",
       "<td>0.0555556</td>\n",
       "<td>0.0039189</td>\n",
       "<td>0.25</td>\n",
       "<td>0.4015924</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.8518519</td>\n",
       "<td>-62.1399177</td>\n",
       "<td>70.3703704</td>\n",
       "<td>0.4123614</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5978261</td>\n",
       "<td>0.0001552</td>\n",
       "<td>0.7572016</td>\n",
       "<td>1.5488215</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.0005590</td>\n",
       "<td>0.2272727</td>\n",
       "<td>0.3359688</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.9259259</td>\n",
       "<td>-24.2798354</td>\n",
       "<td>54.8821549</td>\n",
       "<td>0.3845247</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.7010870</td>\n",
       "<td>0.0000209</td>\n",
       "<td>0.0</td>\n",
       "<td>1.3207005</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000673</td>\n",
       "<td>0.1937984</td>\n",
       "<td>0.2864949</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9259259</td>\n",
       "<td>-100.0</td>\n",
       "<td>32.0700546</td>\n",
       "<td>0.2635055</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7989130</td>\n",
       "<td>0.0000024</td>\n",
       "<td>0.3786008</td>\n",
       "<td>1.2053414</td>\n",
       "<td>0.0555556</td>\n",
       "<td>0.0000100</td>\n",
       "<td>0.1768707</td>\n",
       "<td>0.2514151</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.9629630</td>\n",
       "<td>-62.1399177</td>\n",
       "<td>20.5341396</td>\n",
       "<td>0.1922623</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8967391</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0738496</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000007</td>\n",
       "<td>0.1575758</td>\n",
       "<td>0.2239881</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9629630</td>\n",
       "<td>-100.0</td>\n",
       "<td>7.3849607</td>\n",
       "<td>0.0776126</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3586745</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1467391</td>\n",
       "<td>0.2008589</td>\n",
       "<td>0.0370370</td>\n",
       "<td>1.0</td>\n",
       "<td>-64.1325536</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.6900901</td>\n",
       "<td>0.1279787</td>\n",
       "<td>0.5405405</td>\n",
       "<td>0.6486486</td>\n",
       "<td>0.8918919</td>\n",
       "<td>0.7027027</td>\n",
       "<td>0.6666667</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.6488293</td>\n",
       "<td>0.1947449</td>\n",
       "<td>0.5277778</td>\n",
       "<td>0.4142857</td>\n",
       "<td>0.9264706</td>\n",
       "<td>0.6568627</td>\n",
       "<td>0.71875</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.3099099</td>\n",
       "<td>0.1279787</td>\n",
       "<td>0.4594594</td>\n",
       "<td>0.3513514</td>\n",
       "<td>0.1081081</td>\n",
       "<td>0.2972973</td>\n",
       "<td>0.3333333</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>11.4</td>\n",
       "<td>4.7222877</td>\n",
       "<td>17.0</td>\n",
       "<td>13.0</td>\n",
       "<td>4.0</td>\n",
       "<td>11.0</td>\n",
       "<td>12.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.2985732</td>\n",
       "<td>0.3165244</td>\n",
       "<td>0.0684932</td>\n",
       "<td>0.0925926</td>\n",
       "<td>0.8415841</td>\n",
       "<td>0.1960784</td>\n",
       "<td>0.2941177</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.36</td>\n",
       "<td>0.3211399</td>\n",
       "<td>0.1052632</td>\n",
       "<td>0.1333333</td>\n",
       "<td>0.8947368</td>\n",
       "<td>0.2666667</td>\n",
       "<td>0.4</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.4924182</td>\n",
       "<td>0.3050952</td>\n",
       "<td>0.2272727</td>\n",
       "<td>0.2380952</td>\n",
       "<td>0.9550562</td>\n",
       "<td>0.4166667</td>\n",
       "<td>0.625</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>0.4352941</td>\n",
       "<td>0.9733472</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.1764705</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>1.0956588</td>\n",
       "<td>0.4838913</td>\n",
       "<td>1.4017993</td>\n",
       "<td>0.8229704</td>\n",
       "<td>0.5924769</td>\n",
       "<td>1.7805276</td>\n",
       "<td>0.8805193</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.3761111</td>\n",
       "<td>0.1198250</td>\n",
       "<td>0.4722222</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.375</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.3325862</td>\n",
       "<td>0.2884666</td>\n",
       "<td>0.1712337</td>\n",
       "<td>0.0744332</td>\n",
       "<td>0.8047478</td>\n",
       "<td>0.2172315</td>\n",
       "<td>0.3952847</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.7482470</td>\n",
       "<td>0.1225076</td>\n",
       "<td>0.7638889</td>\n",
       "<td>0.5785714</td>\n",
       "<td>0.9</td>\n",
       "<td>0.6862745</td>\n",
       "<td>0.8125</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.2517530</td>\n",
       "<td>0.1225076</td>\n",
       "<td>0.2361111</td>\n",
       "<td>0.4214286</td>\n",
       "<td>0.1</td>\n",
       "<td>0.3137255</td>\n",
       "<td>0.1875</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1756744</td>\n",
       "<td>0.0467332</td>\n",
       "<td>0.1859015</td>\n",
       "<td>0.1031958</td>\n",
       "<td>0.1734069</td>\n",
       "<td>0.1825203</td>\n",
       "<td>0.2333476</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.2502466</td>\n",
       "<td>0.3694670</td>\n",
       "<td>0.0283070</td>\n",
       "<td>0.0442913</td>\n",
       "<td>0.903952</td>\n",
       "<td>0.1097477</td>\n",
       "<td>0.1649349</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.2717338</td>\n",
       "<td>0.3104085</td>\n",
       "<td>0.0555556</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.8095238</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.25</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>-1.9196415</td>\n",
       "<td>2.4237905</td>\n",
       "<td>-6.069421</td>\n",
       "<td>-1.0182151</td>\n",
       "<td>0.3017822</td>\n",
       "<td>-1.449709</td>\n",
       "<td>-1.3626449</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.2357023</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.4158220</td>\n",
       "<td>0.0588054</td>\n",
       "<td>0.4311629</td>\n",
       "<td>0.3212410</td>\n",
       "<td>0.4164215</td>\n",
       "<td>0.4272240</td>\n",
       "<td>0.4830607</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.6631606</td>\n",
       "<td>0.1004628</td>\n",
       "<td>0.5277778</td>\n",
       "<td>0.6571429</td>\n",
       "<td>0.8</td>\n",
       "<td>0.7058824</td>\n",
       "<td>0.625</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-10.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-10 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-10 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-10 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table th,\n",
       "#h2o-table-10 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2023-05-20 14:50:14</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-20 14:50:14</td>\n",
       "<td> 4 min 39.256 sec</td>\n",
       "<td>102222 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>1</td>\n",
       "<td>1840.0</td>\n",
       "<td>0.3921435</td>\n",
       "<td>1.0124278</td>\n",
       "<td>-0.2281808</td>\n",
       "<td>0.8076197</td>\n",
       "<td>0.4378846</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.2445652</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-20 14:50:17</td>\n",
       "<td> 4 min 41.818 sec</td>\n",
       "<td>100468 obs/sec</td>\n",
       "<td>1400.0</td>\n",
       "<td>140</td>\n",
       "<td>257600.0</td>\n",
       "<td>0.0396858</td>\n",
       "<td>0.0106430</td>\n",
       "<td>0.9874211</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-11.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-11 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-11 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-11 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table th,\n",
       "#h2o-table-11 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>horror</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0487981</td></tr>\n",
       "<tr><td>rating</td>\n",
       "<td>0.8502323</td>\n",
       "<td>0.8502323</td>\n",
       "<td>0.0414897</td></tr>\n",
       "<tr><td>numVotes</td>\n",
       "<td>0.7655110</td>\n",
       "<td>0.7655110</td>\n",
       "<td>0.0373555</td></tr>\n",
       "<tr><td>western</td>\n",
       "<td>0.7426908</td>\n",
       "<td>0.7426908</td>\n",
       "<td>0.0362419</td></tr>\n",
       "<tr><td>war</td>\n",
       "<td>0.7314382</td>\n",
       "<td>0.7314382</td>\n",
       "<td>0.0356928</td></tr>\n",
       "<tr><td>year</td>\n",
       "<td>0.7181134</td>\n",
       "<td>0.7181134</td>\n",
       "<td>0.0350426</td></tr>\n",
       "<tr><td>mystery</td>\n",
       "<td>0.7123615</td>\n",
       "<td>0.7123615</td>\n",
       "<td>0.0347619</td></tr>\n",
       "<tr><td>drama</td>\n",
       "<td>0.6477461</td>\n",
       "<td>0.6477461</td>\n",
       "<td>0.0316088</td></tr>\n",
       "<tr><td>thriller</td>\n",
       "<td>0.6443076</td>\n",
       "<td>0.6443076</td>\n",
       "<td>0.0314410</td></tr>\n",
       "<tr><td>fantasy</td>\n",
       "<td>0.6419211</td>\n",
       "<td>0.6419211</td>\n",
       "<td>0.0313245</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>family</td>\n",
       "<td>0.4509559</td>\n",
       "<td>0.4509559</td>\n",
       "<td>0.0220058</td></tr>\n",
       "<tr><td>nom_gg_comedy</td>\n",
       "<td>0.4497407</td>\n",
       "<td>0.4497407</td>\n",
       "<td>0.0219465</td></tr>\n",
       "<tr><td>nom_bafta</td>\n",
       "<td>0.4440299</td>\n",
       "<td>0.4440299</td>\n",
       "<td>0.0216678</td></tr>\n",
       "<tr><td>sport</td>\n",
       "<td>0.4401552</td>\n",
       "<td>0.4401552</td>\n",
       "<td>0.0214787</td></tr>\n",
       "<tr><td>nom_gg_drama</td>\n",
       "<td>0.4321747</td>\n",
       "<td>0.4321747</td>\n",
       "<td>0.0210893</td></tr>\n",
       "<tr><td>nominations</td>\n",
       "<td>0.4268954</td>\n",
       "<td>0.4268954</td>\n",
       "<td>0.0208317</td></tr>\n",
       "<tr><td>winner_bafta</td>\n",
       "<td>0.4094583</td>\n",
       "<td>0.4094583</td>\n",
       "<td>0.0199808</td></tr>\n",
       "<tr><td>adventure</td>\n",
       "<td>0.4005443</td>\n",
       "<td>0.4005443</td>\n",
       "<td>0.0195458</td></tr>\n",
       "<tr><td>nom_dga</td>\n",
       "<td>0.3788831</td>\n",
       "<td>0.3788831</td>\n",
       "<td>0.0184888</td></tr>\n",
       "<tr><td>nom_sag</td>\n",
       "<td>0.3029537</td>\n",
       "<td>0.3029537</td>\n",
       "<td>0.0147836</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[36 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_1_AutoML_1_20230520_144514_model_15\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 782 weights/biases, 16,4 KB, 257 600 training samples, mini-batch size 1\n",
       "    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight           weight_rms           mean_bias             bias_rms\n",
       "--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  --------------------  -------------------  --------------------  -------------------\n",
       "    1        36       Input             5.0\n",
       "    2        20       RectifierDropout  10.0       0.0   0.0   0.0022078270879218407  0.003123491071164608  0.0         0.09029229445762516   0.26058220863342285  0.2456089317952399    0.21000957489013672\n",
       "    3        2        Softmax                      0.0   0.0   0.0018783423904096708  0.003721131943166256  0.0         -0.05552845075726509  1.3402414321899414   -0.03331026685106242  0.5842199325561523\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.0015749634753609823\n",
       "RMSE: 0.03968580949610304\n",
       "LogLoss: 0.010643031295491859\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7357392318050676\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      157  0    0        (0.0/157.0)\n",
       "1      0    27   0        (0.0/27.0)\n",
       "Total  157  27   0        (0.0/184.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.735739     1         25\n",
       "max f2                       0.735739     1         25\n",
       "max f0point5                 0.735739     1         25\n",
       "max accuracy                 0.735739     1         25\n",
       "max precision                1            1         0\n",
       "max recall                   0.735739     1         25\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.735739     1         25\n",
       "max min_per_class_accuracy   0.735739     1         25\n",
       "max mean_per_class_accuracy  0.735739     1         25\n",
       "max tns                      1            157       0\n",
       "max fns                      1            25        0\n",
       "max fps                      3.34352e-20  157       182\n",
       "max tps                      0.735739     27        25\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.925926  0\n",
       "max fpr                      3.34352e-20  1         182\n",
       "max tpr                      0.735739     1         25\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,67 %, avg score: 14,62 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0108696                   0.999999           6.81481  6.81481            1                1            1                           1                   0.0740741       0.0740741                  581.481  581.481            0.0740741\n",
       "2        0.0217391                   0.999988           6.81481  6.81481            1                0.999996     1                           0.999998            0.0740741       0.148148                   581.481  581.481            0.148148\n",
       "3        0.0326087                   0.999891           6.81481  6.81481            1                0.999974     1                           0.99999             0.0740741       0.222222                   581.481  581.481            0.222222\n",
       "4        0.0434783                   0.999514           6.81481  6.81481            1                0.999767     1                           0.999934            0.0740741       0.296296                   581.481  581.481            0.296296\n",
       "5        0.0543478                   0.998889           6.81481  6.81481            1                0.999049     1                           0.999757            0.0740741       0.37037                    581.481  581.481            0.37037\n",
       "6        0.103261                    0.984588           6.81481  6.81481            1                0.993357     1                           0.996726            0.333333        0.703704                   581.481  581.481            0.703704\n",
       "7        0.152174                    0.245007           6.05761  6.57143            0.888889         0.822531     0.964286                    0.940735            0.296296        1                          505.761  557.143            0.993631\n",
       "8        0.201087                    0.0128189          0        4.97297            0                0.0486563    0.72973                     0.723743            0               1                          -100     397.297            0.936306\n",
       "9        0.298913                    0.00180143         0        3.34545            0                0.00574037   0.490909                    0.48876             0               1                          -100     234.545            0.821656\n",
       "10       0.402174                    0.000163703        0        2.48649            0                0.000618871  0.364865                    0.363427            0               1                          -100     148.649            0.700637\n",
       "11       0.5                         3.97655e-05        0        2                  0                8.81676e-05  0.293478                    0.292339            0               1                          -100     100                0.585987\n",
       "12       0.597826                    1.30169e-05        0        1.67273            0                2.54273e-05  0.245455                    0.244506            0               1                          -100     67.2727            0.471338\n",
       "13       0.701087                    3.41516e-06        0        1.42636            0                8.03047e-06  0.209302                    0.208494            0               1                          -100     42.6357            0.350318\n",
       "14       0.798913                    1.06987e-07        0        1.2517             0                1.08507e-06  0.183673                    0.182964            0               1                          -100     25.1701            0.235669\n",
       "15       0.896739                    3.82532e-10        0        1.11515            0                2.94739e-08  0.163636                    0.163005            0               1                          -100     11.5152            0.121019\n",
       "16       1                           3.34352e-20        0        1                  0                8.00133e-11  0.146739                    0.146173            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.17536099202568806\n",
       "RMSE: 0.4187612589837891\n",
       "LogLoss: 1.0968279650321282\n",
       "Mean Per-Class Error: 0.25902335456475584\n",
       "AUC: 0.7911063930172211\n",
       "AUCPR: 0.43306267605736654\n",
       "Gini: 0.5822127860344422\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.12780196671204258\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      128  29   0.1847   (29.0/157.0)\n",
       "1      9    18   0.3333   (9.0/27.0)\n",
       "Total  137  47   0.2065   (38.0/184.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.127802     0.486486  41\n",
       "max f2                       0.00913718   0.625     70\n",
       "max f0point5                 1            0.545455  1\n",
       "max accuracy                 1            0.880435  1\n",
       "max precision                1            0.857143  1\n",
       "max recall                   1.19742e-08  1         166\n",
       "max specificity              1            0.993631  0\n",
       "max absolute_mcc             1            0.399258  1\n",
       "max min_per_class_accuracy   0.0221843    0.719745  58\n",
       "max mean_per_class_accuracy  0.00913718   0.757136  70\n",
       "max tns                      1            156       0\n",
       "max fns                      1            22        0\n",
       "max fps                      3.00613e-13  157       178\n",
       "max tps                      1.19742e-08  27        166\n",
       "max tnr                      1            0.993631  0\n",
       "max fnr                      1            0.814815  0\n",
       "max fpr                      3.00613e-13  1         178\n",
       "max tpr                      1.19742e-08  1         166\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,67 %, avg score: 20,09 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0271739                   1                  5.45185   5.45185            0.8              1            0.8                         1                   0.148148        0.148148                   445.185   445.185            0.141779\n",
       "2        0.0326087                   1                  6.81481   5.67901            1                1            0.833333                    1                   0.037037        0.185185                   581.481   467.901            0.178816\n",
       "3        0.0434783                   0.999993           3.40741   5.11111            0.5              1            0.75                        1                   0.037037        0.222222                   240.741   411.111            0.209483\n",
       "4        0.0543478                   0.999861           0         4.08889            0                0.99997      0.6                         0.999994            0               0.222222                   -100      308.889            0.196745\n",
       "5        0.103261                    0.934885           0.757202  2.51072            0.111111         0.967737     0.368421                    0.984714            0.037037        0.259259                   -24.2798  151.072            0.182826\n",
       "6        0.152174                    0.841325           1.5144    2.19048            0.222222         0.896632     0.321429                    0.956402            0.0740741       0.333333                   51.4403   119.048            0.212314\n",
       "7        0.201087                    0.443298           3.02881   2.39439            0.444444         0.689389     0.351351                    0.891453            0.148148        0.481481                   202.881   139.439            0.328615\n",
       "8        0.298913                    0.0442015          2.2716    2.35421            0.333333         0.19147      0.345455                    0.662368            0.222222        0.703704                   127.16    135.421            0.474404\n",
       "9        0.402174                    0.00991594         1.07602   2.02603            0.157895         0.0234602    0.297297                    0.498324            0.111111        0.814815                   7.60234   102.603            0.483605\n",
       "10       0.5                         0.00122731         0.378601  1.7037             0.0555556        0.00391895   0.25                        0.401592            0.037037        0.851852                   -62.1399  70.3704            0.412361\n",
       "11       0.597826                    0.000155206        0.757202  1.54882            0.111111         0.000559013  0.227273                    0.335969            0.0740741       0.925926                   -24.2798  54.8822            0.384525\n",
       "12       0.701087                    2.0897e-05         0         1.3207             0                6.73053e-05  0.193798                    0.286495            0               0.925926                   -100      32.0701            0.263506\n",
       "13       0.798913                    2.416e-06          0.378601  1.20534            0.0555556        1.00389e-05  0.176871                    0.251415            0.037037        0.962963                   -62.1399  20.5341            0.192262\n",
       "14       0.896739                    5.3e-08            0         1.07385            0                6.57778e-07  0.157576                    0.223988            0               0.962963                   -100      7.38496            0.0776126\n",
       "15       1                           0                  0.358674  1                  0.0526316        8.94737e-09  0.146739                    0.200859            0.037037        1                          -64.1326  0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean      sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.69009   0.127979   0.54054       0.648649      0.891892      0.702703      0.666667\n",
       "auc                      0.648829  0.194745   0.527778      0.414286      0.926471      0.656863      0.71875\n",
       "err                      0.30991   0.127979   0.459459      0.351351      0.108108      0.297297      0.333333\n",
       "err_count                11.4      4.72229    17            13            4             11            12\n",
       "f0point5                 0.298573  0.316524   0.0684932     0.0925926     0.841584      0.196078      0.294118\n",
       "f1                       0.36      0.32114    0.105263      0.133333      0.894737      0.266667      0.4\n",
       "f2                       0.492418  0.305095   0.227273      0.238095      0.955056      0.416667      0.625\n",
       "lift_top_group           0.435294  0.973347   0             0             2.17647       0             0\n",
       "logloss                  1.09566   0.483891   1.4018        0.82297       0.592477      1.78053       0.880519\n",
       "max_per_class_error      0.376111  0.119825   0.472222      0.5           0.2           0.333333      0.375\n",
       "mcc                      0.332586  0.288467   0.171234      0.0744332     0.804748      0.217232      0.395285\n",
       "mean_per_class_accuracy  0.748247  0.122508   0.763889      0.578571      0.9           0.686275      0.8125\n",
       "mean_per_class_error     0.251753  0.122508   0.236111      0.421429      0.1           0.313725      0.1875\n",
       "mse                      0.175674  0.0467332  0.185901      0.103196      0.173407      0.18252       0.233348\n",
       "pr_auc                   0.250247  0.369467   0.028307      0.0442913     0.903952      0.109748      0.164935\n",
       "precision                0.271734  0.310409   0.0555556     0.0769231     0.809524      0.166667      0.25\n",
       "r2                       -1.91964  2.42379    -6.06942      -1.01822      0.301782      -1.44971      -1.36264\n",
       "recall                   0.833333  0.235702   1             0.5           1             0.666667      1\n",
       "rmse                     0.415822  0.0588054  0.431163      0.321241      0.416422      0.427224      0.483061\n",
       "specificity              0.663161  0.100463   0.527778      0.657143      0.8           0.705882      0.625\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2023-05-20 14:50:14  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan\n",
       "    2023-05-20 14:50:14  4 min 39.256 sec  102222 obs/sec    10        1             1840       0.392144         1.01243             -0.228181      0.80762         0.437885           6.81481          0.244565\n",
       "    2023-05-20 14:50:17  4 min 41.818 sec  100468 obs/sec    1400      140           257600     0.0396858        0.010643            0.987421       1               1                  6.81481          0\n",
       "\n",
       "Variable Importances: \n",
       "variable       relative_importance    scaled_importance    percentage\n",
       "-------------  ---------------------  -------------------  --------------------\n",
       "horror         1.0                    1.0                  0.048798104589326444\n",
       "rating         0.8502323031425476     0.8502323031425476   0.041489724853973946\n",
       "numVotes       0.7655109763145447     0.7655109763145447   0.03735548468647455\n",
       "western        0.7426908016204834     0.7426908016204834   0.03624190341500705\n",
       "war            0.731438159942627      0.731438159942627    0.03569279582950479\n",
       "year           0.718113362789154      0.718113362789154    0.03504257098437807\n",
       "mystery        0.7123615145683289     0.7123615145683289   0.0347618916933163\n",
       "drama          0.6477460861206055     0.6477460861206055   0.03160878125784016\n",
       "thriller       0.644307553768158      0.644307553768158    0.031440987396471644\n",
       "fantasy        0.6419211030006409     0.6419211030006409   0.031324533122321065\n",
       "---            ---                    ---                  ---\n",
       "family         0.450955867767334      0.450955867767334    0.02200579160048083\n",
       "nom_gg_comedy  0.4497406780719757     0.4497406780719757   0.021946492646630865\n",
       "nom_bafta      0.44402989745140076    0.44402989745140076  0.02166781737662135\n",
       "sport          0.4401552081108093     0.4401552081108093   0.02147873988092802\n",
       "nom_gg_drama   0.4321746528148651     0.4321746528148651   0.02108930390891563\n",
       "nominations    0.4268953502178192     0.4268953502178192   0.020831683948626282\n",
       "winner_bafta   0.40945833921432495    0.40945833921432495  0.019980790861952535\n",
       "adventure      0.40054431557655334    0.40054431557655334  0.019545803404164827\n",
       "nom_dga        0.3788830637931824     0.3788830637931824   0.018488775374104156\n",
       "nom_sag        0.30295369029045105    0.30295369029045105  0.014783565864515841\n",
       "[36 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model = aml.leader\n",
    "top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "H2OResponseError",
     "evalue": "Server error water.exceptions.H2OIllegalArgumentException:\n  Error: Illegal argument: dir of function: importModel: water.api.FSIOException: FS IO Failure: \n accessed path : file:/c:/Users/Aleksandra%20Czaplak/Desktop/oscars_ml/oscar_predictions/additional_data/./additional_data/model/DeepLearning_grid_2_AutoML_6_20230519_91906_model_4 msg: File not found\n  Request: POST /99/Models.bin/\n    data: {'dir': './additional_data/model/DeepLearning_grid_2_AutoML_6_20230519_91906_model_4'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mH2OResponseError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Aleksandra Czaplak\\Desktop\\oscars_ml\\oscar_predictions\\additional_data\\ml.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Aleksandra%20Czaplak/Desktop/oscars_ml/oscar_predictions/additional_data/ml.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m h2o\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39m./additional_data/model/DeepLearning_grid_2_AutoML_6_20230519_91906_model_4\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\h2o\\h2o.py:1581\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m   1558\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[39mLoad a saved H2O model from disk. (Note that ensemble binary models can now be loaded using this method.)\u001b[39;00m\n\u001b[0;32m   1560\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1578\u001b[0m \u001b[39m>>> h2o.load_model(model)\u001b[39;00m\n\u001b[0;32m   1579\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1580\u001b[0m assert_is_type(path, \u001b[39mstr\u001b[39m)\n\u001b[1;32m-> 1581\u001b[0m res \u001b[39m=\u001b[39m api(\u001b[39m\"\u001b[39;49m\u001b[39mPOST /99/Models.bin/\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m, data\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mdir\u001b[39;49m\u001b[39m\"\u001b[39;49m: path})\n\u001b[0;32m   1582\u001b[0m \u001b[39mreturn\u001b[39;00m get_model(res[\u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmodel_id\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\h2o\\h2o.py:124\u001b[0m, in \u001b[0;36mapi\u001b[1;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m# type checks are performed in H2OConnection class\u001b[39;00m\n\u001b[0;32m    123\u001b[0m _check_connection()\n\u001b[1;32m--> 124\u001b[0m \u001b[39mreturn\u001b[39;00m h2oconn\u001b[39m.\u001b[39;49mrequest(endpoint, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, filename\u001b[39m=\u001b[39;49mfilename, save_to\u001b[39m=\u001b[39;49msave_to)\n",
      "File \u001b[1;32mc:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\h2o\\backend\\connection.py:499\u001b[0m, in \u001b[0;36mH2OConnection.request\u001b[1;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[0;32m    497\u001b[0m         save_to \u001b[39m=\u001b[39m save_to(resp)\n\u001b[0;32m    498\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_end_transaction(start_time, resp)\n\u001b[1;32m--> 499\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_response(resp, save_to)\n\u001b[0;32m    501\u001b[0m \u001b[39mexcept\u001b[39;00m (requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mConnectionError, requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mHTTPError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    502\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_server \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_server\u001b[39m.\u001b[39mis_running():\n",
      "File \u001b[1;32mc:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\h2o\\backend\\connection.py:853\u001b[0m, in \u001b[0;36mH2OConnection._process_response\u001b[1;34m(response, save_to)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39mif\u001b[39;00m status_code \u001b[39min\u001b[39;00m {\u001b[39m400\u001b[39m, \u001b[39m404\u001b[39m, \u001b[39m412\u001b[39m} \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(data, H2OErrorV3):\n\u001b[0;32m    852\u001b[0m     data\u001b[39m.\u001b[39mshow_stacktrace \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 853\u001b[0m     \u001b[39mraise\u001b[39;00m H2OResponseError(data)\n\u001b[0;32m    855\u001b[0m \u001b[39m# Server errors (notably 500 = \"Server Error\")\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39m# Note that it is possible to receive valid H2OErrorV3 object in this case, however it merely means the server\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[39m# did not provide the correct status code.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39mraise\u001b[39;00m H2OServerError(\u001b[39m\"\u001b[39m\u001b[39mHTTP \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (status_code, response\u001b[39m.\u001b[39mreason, data))\n",
      "\u001b[1;31mH2OResponseError\u001b[0m: Server error water.exceptions.H2OIllegalArgumentException:\n  Error: Illegal argument: dir of function: importModel: water.api.FSIOException: FS IO Failure: \n accessed path : file:/c:/Users/Aleksandra%20Czaplak/Desktop/oscars_ml/oscar_predictions/additional_data/./additional_data/model/DeepLearning_grid_2_AutoML_6_20230519_91906_model_4 msg: File not found\n  Request: POST /99/Models.bin/\n    data: {'dir': './additional_data/model/DeepLearning_grid_2_AutoML_6_20230519_91906_model_4'}\n"
     ]
    }
   ],
   "source": [
    "model = h2o.load_model('./additional_data/model/DeepLearning_grid_2_AutoML_6_20230519_91906_model_4')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Predict on 2019's films\n",
    "test = full_table.loc[(full_table['year'] == 2021)]\n",
    "\n",
    "# Import a binary outcome train/test set into H2O\n",
    "test = h2o.H2OFrame(test)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">        p0</th><th style=\"text-align: right;\">         p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999976  </td><td style=\"text-align: right;\">2.37118e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.00165605</td><td style=\"text-align: right;\">0.998344   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.995174  </td><td style=\"text-align: right;\">0.00482619 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1         </td><td style=\"text-align: right;\">1.74511e-07</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.995249  </td><td style=\"text-align: right;\">0.00475117 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999972  </td><td style=\"text-align: right;\">2.78123e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999979  </td><td style=\"text-align: right;\">2.0885e-05 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1         </td><td style=\"text-align: right;\">9.07248e-09</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999955  </td><td style=\"text-align: right;\">4.5392e-05 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999999  </td><td style=\"text-align: right;\">1.10776e-06</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 3 columns]</pre>"
      ],
      "text/plain": [
       "  predict          p0           p1\n",
       "---------  ----------  -----------\n",
       "        0  0.999976    2.37118e-05\n",
       "        1  0.00165605  0.998344\n",
       "        0  0.995174    0.00482619\n",
       "        0  1           1.74511e-07\n",
       "        0  0.995249    0.00475117\n",
       "        0  0.999972    2.78123e-05\n",
       "        0  0.999979    2.0885e-05\n",
       "        0  1           9.07248e-09\n",
       "        0  0.999955    4.5392e-05\n",
       "        0  0.999999    1.10776e-06\n",
       "[10 rows x 3 columns]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = top_model.predict(test)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred'] = preds['predict']\n",
    "test['probA'] = preds['p1']\n",
    "test_pd = test.as_data_frame(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>probA</th>\n",
       "      <th>%_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CODA</td>\n",
       "      <td>9.983440e-01</td>\n",
       "      <td>9.903809e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Belfast</td>\n",
       "      <td>4.826187e-03</td>\n",
       "      <td>4.787692e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drive My Car</td>\n",
       "      <td>4.751175e-03</td>\n",
       "      <td>4.713278e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nightmare Alley</td>\n",
       "      <td>4.539204e-05</td>\n",
       "      <td>4.502998e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dune</td>\n",
       "      <td>2.781235e-05</td>\n",
       "      <td>2.759051e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West Side Story</td>\n",
       "      <td>2.371181e-05</td>\n",
       "      <td>2.352268e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>King Richard</td>\n",
       "      <td>2.088495e-05</td>\n",
       "      <td>2.071837e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Power of the Dog</td>\n",
       "      <td>1.107759e-06</td>\n",
       "      <td>1.098923e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Don't Look Up</td>\n",
       "      <td>1.745112e-07</td>\n",
       "      <td>1.731192e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Licorice Pizza</td>\n",
       "      <td>9.072485e-09</td>\n",
       "      <td>9.000120e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    film         probA  %_confidence\n",
       "1                  CODA   9.983440e-01  9.903809e+01\n",
       "2               Belfast   4.826187e-03  4.787692e-01\n",
       "4          Drive My Car   4.751175e-03  4.713278e-01\n",
       "8       Nightmare Alley   4.539204e-05  4.502998e-03\n",
       "5                  Dune   2.781235e-05  2.759051e-03\n",
       "0       West Side Story   2.371181e-05  2.352268e-03\n",
       "6          King Richard   2.088495e-05  2.071837e-03\n",
       "9  The Power of the Dog   1.107759e-06  1.098923e-04\n",
       "3          Don't Look Up  1.745112e-07  1.731192e-05\n",
       "7         Licorice Pizza  9.072485e-09  9.000120e-07"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rankings = test_pd[['film','probA']].sort_values('probA', ascending = False)\n",
    "final_rankings['%_confidence'] = final_rankings['probA']/final_rankings['probA'].sum() * 100\n",
    "final_rankings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And the Oscar goes to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_winner = np.array(final_rankings.reset_index())[0][1].split('(')[0].strip()\n",
    "print(f'And the Oscar goes to...\\n🎉🏆{bp_winner}🏆🎉')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
