{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-Oscar Prediction with AutoML\n",
    "After out dataframe has been assemlbed (see scraping and table_assembling) notebooks we have the data we need to make predictions on the Best Picture winner. [AutoML](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html) represents a quick, but powerful route though the Machine Learning process. H2O's AutoML runs many models through the dataset and using cross-validation, picks the best one. For my purposes I use it to confirm/compare to the Preferential Balloting Random Forest model I created.\n",
    "If you are gunning to win your office's Oscar pool, scroll down to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'film', 'wiki', 'winner', 'rating', 'numVotes',\n",
       "       'worldwide_box_office', 'action', 'adventure', 'animation', 'biography',\n",
       "       'comedy', 'crime', 'documentary', 'drama', 'family', 'fantasy',\n",
       "       'film-noir', 'history', 'horror', 'music', 'musical', 'mystery',\n",
       "       'romance', 'sci-fi', 'sport', 'thriller', 'war', 'western',\n",
       "       'nominations', 'Oscar_win', 'nom_gg_drama', 'winner_gg_drama',\n",
       "       'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga', 'winner_pga',\n",
       "       'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga', 'nom_sag',\n",
       "       'winner_sag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_table = pd.read_csv('../data/processed_results/extended_df.csv')\n",
    "full_table=full_table.drop('Unnamed: 0', axis=1)\n",
    "full_table.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Using h2o Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'film', 'wiki', 'winner', 'rating', 'numVotes',\n",
       "       'worldwide_box_office', 'action', 'adventure', 'animation', 'biography',\n",
       "       'comedy', 'crime', 'documentary', 'drama', 'family', 'fantasy',\n",
       "       'film-noir', 'history', 'horror', 'music', 'musical', 'mystery',\n",
       "       'romance', 'sci-fi', 'sport', 'thriller', 'war', 'western',\n",
       "       'nominations', 'Oscar_win', 'nom_gg_drama', 'winner_gg_drama',\n",
       "       'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga', 'winner_pga',\n",
       "       'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga', 'nom_sag',\n",
       "       'winner_sag', 'Acting', 'Production Design', 'Directing', 'VFX',\n",
       "       'Writing', 'Cinematography', 'Sound', 'Film Editing', 'Music'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_table = pd.read_csv('../data/processed_results/everything.csv')\n",
    "full_table=full_table.drop('Unnamed: 0', axis=1)\n",
    "full_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode)\n",
      "  Starting server from C:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmpwulvrab2\n",
      "  JVM stdout: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmpwulvrab2\\h2o_Aleksandra_Czaplak_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmpwulvrab2\\h2o_Aleksandra_Czaplak_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>08 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Berlin</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>27 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Aleksandra_Czaplak_4b3lbg</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.761 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.2 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------------------\n",
       "H2O_cluster_uptime:         08 secs\n",
       "H2O_cluster_timezone:       Europe/Berlin\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    27 days\n",
       "H2O_cluster_name:           H2O_from_python_Aleksandra_Czaplak_4b3lbg\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.761 Gb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.2 final\n",
       "--------------------------  -----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Year of Existance. This data will be used below\n",
    "- golden_globes 1943\n",
    "- pga 1989\n",
    "- bafta 1960\n",
    "- dga 1948\n",
    "- sag 1995\n",
    "- cannes 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I pick a min_year where the awards shows will be relevant\n",
    "min_year = 1995"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O's Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set contains: 176 movies\n"
     ]
    }
   ],
   "source": [
    "# Auto ML uses Cross Validation, so we do not specifiy a validation set\n",
    "train = full_table.loc[((full_table['year'] < 2022) & (full_table['year'] >= min_year))]\n",
    "\n",
    "print('training set contains:', train.shape[0], 'movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'film', 'wiki', 'winner', 'rating', 'numVotes',\n",
       "       'worldwide_box_office', 'action', 'adventure', 'animation', 'biography',\n",
       "       'comedy', 'crime', 'documentary', 'drama', 'family', 'fantasy',\n",
       "       'film-noir', 'history', 'horror', 'music', 'musical', 'mystery',\n",
       "       'romance', 'sci-fi', 'sport', 'thriller', 'war', 'western',\n",
       "       'nominations', 'Oscar_win', 'nom_gg_drama', 'winner_gg_drama',\n",
       "       'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga', 'winner_pga',\n",
       "       'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga', 'nom_sag',\n",
       "       'winner_sag', 'Acting', 'Production Design', 'Directing', 'VFX',\n",
       "       'Writing', 'Cinematography', 'Sound', 'Film Editing', 'Music'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train = train.drop(['index', '[]'], axis=1)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model na df everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "08:57:22.228: AutoML: XGBoost is not available; skipping it.\n",
      "08:57:22.458: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "█\n",
      "08:57:24.737: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "08:57:24.738: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 176.0.\n",
      "08:57:24.764: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "██\n",
      "08:57:26.950: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "██\n",
      "08:57:28.249: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "08:57:29.742: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "█\n",
      "08:57:31.80: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "██\n",
      "08:57:32.51: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "███\n",
      "08:57:33.200: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "███████████████████████████████████████████████████\n",
      "09:34:17.671: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "█| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                            </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th><th style=\"text-align: right;\">  training_time_ms</th><th style=\"text-align: right;\">  predict_time_per_row_ms</th><th>algo        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_5 </td><td style=\"text-align: right;\">0.830513</td><td style=\"text-align: right;\"> 0.695563</td><td style=\"text-align: right;\">0.448287</td><td style=\"text-align: right;\">              0.248974</td><td style=\"text-align: right;\">0.372326</td><td style=\"text-align: right;\">0.138627</td><td style=\"text-align: right;\">              2709</td><td style=\"text-align: right;\">                 0.710977</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_2 </td><td style=\"text-align: right;\">0.823077</td><td style=\"text-align: right;\"> 0.417719</td><td style=\"text-align: right;\">0.39347 </td><td style=\"text-align: right;\">              0.233077</td><td style=\"text-align: right;\">0.344425</td><td style=\"text-align: right;\">0.118629</td><td style=\"text-align: right;\">              2689</td><td style=\"text-align: right;\">                 0.760255</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_22</td><td style=\"text-align: right;\">0.817179</td><td style=\"text-align: right;\"> 0.464433</td><td style=\"text-align: right;\">0.513033</td><td style=\"text-align: right;\">              0.251538</td><td style=\"text-align: right;\">0.321971</td><td style=\"text-align: right;\">0.103665</td><td style=\"text-align: right;\">              2708</td><td style=\"text-align: right;\">                 0.164375</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_5 </td><td style=\"text-align: right;\">0.813077</td><td style=\"text-align: right;\"> 0.654276</td><td style=\"text-align: right;\">0.381339</td><td style=\"text-align: right;\">              0.299231</td><td style=\"text-align: right;\">0.38311 </td><td style=\"text-align: right;\">0.146773</td><td style=\"text-align: right;\">              2062</td><td style=\"text-align: right;\">                 0.109675</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_14</td><td style=\"text-align: right;\">0.809487</td><td style=\"text-align: right;\"> 0.53134 </td><td style=\"text-align: right;\">0.396423</td><td style=\"text-align: right;\">              0.23641 </td><td style=\"text-align: right;\">0.361284</td><td style=\"text-align: right;\">0.130526</td><td style=\"text-align: right;\">              3939</td><td style=\"text-align: right;\">                 0.177956</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_10</td><td style=\"text-align: right;\">0.808846</td><td style=\"text-align: right;\"> 0.738022</td><td style=\"text-align: right;\">0.378064</td><td style=\"text-align: right;\">              0.258205</td><td style=\"text-align: right;\">0.373639</td><td style=\"text-align: right;\">0.139606</td><td style=\"text-align: right;\">              3034</td><td style=\"text-align: right;\">                 0.908088</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_4 </td><td style=\"text-align: right;\">0.802821</td><td style=\"text-align: right;\"> 0.671927</td><td style=\"text-align: right;\">0.381739</td><td style=\"text-align: right;\">              0.212821</td><td style=\"text-align: right;\">0.402897</td><td style=\"text-align: right;\">0.162326</td><td style=\"text-align: right;\">              4143</td><td style=\"text-align: right;\">                 0.270085</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_3 </td><td style=\"text-align: right;\">0.797692</td><td style=\"text-align: right;\"> 0.597201</td><td style=\"text-align: right;\">0.321101</td><td style=\"text-align: right;\">              0.254615</td><td style=\"text-align: right;\">0.400425</td><td style=\"text-align: right;\">0.16034 </td><td style=\"text-align: right;\">              2784</td><td style=\"text-align: right;\">                 0.086429</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_16</td><td style=\"text-align: right;\">0.795128</td><td style=\"text-align: right;\"> 1.49879 </td><td style=\"text-align: right;\">0.359095</td><td style=\"text-align: right;\">              0.273077</td><td style=\"text-align: right;\">0.414024</td><td style=\"text-align: right;\">0.171416</td><td style=\"text-align: right;\">              2630</td><td style=\"text-align: right;\">                 0.117531</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_2 </td><td style=\"text-align: right;\">0.793077</td><td style=\"text-align: right;\"> 0.73027 </td><td style=\"text-align: right;\">0.377618</td><td style=\"text-align: right;\">              0.285641</td><td style=\"text-align: right;\">0.404787</td><td style=\"text-align: right;\">0.163852</td><td style=\"text-align: right;\">              2700</td><td style=\"text-align: right;\">                 0.14276 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_11</td><td style=\"text-align: right;\">0.792564</td><td style=\"text-align: right;\"> 0.386072</td><td style=\"text-align: right;\">0.338971</td><td style=\"text-align: right;\">              0.209487</td><td style=\"text-align: right;\">0.34739 </td><td style=\"text-align: right;\">0.12068 </td><td style=\"text-align: right;\">              2390</td><td style=\"text-align: right;\">                 0.274097</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_12</td><td style=\"text-align: right;\">0.784615</td><td style=\"text-align: right;\"> 0.90519 </td><td style=\"text-align: right;\">0.378051</td><td style=\"text-align: right;\">              0.240513</td><td style=\"text-align: right;\">0.378227</td><td style=\"text-align: right;\">0.143056</td><td style=\"text-align: right;\">              4581</td><td style=\"text-align: right;\">                 0.467057</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_14</td><td style=\"text-align: right;\">0.782051</td><td style=\"text-align: right;\"> 0.412528</td><td style=\"text-align: right;\">0.379142</td><td style=\"text-align: right;\">              0.284103</td><td style=\"text-align: right;\">0.344026</td><td style=\"text-align: right;\">0.118354</td><td style=\"text-align: right;\">              3951</td><td style=\"text-align: right;\">                 0.145976</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_8 </td><td style=\"text-align: right;\">0.781795</td><td style=\"text-align: right;\"> 0.590756</td><td style=\"text-align: right;\">0.372474</td><td style=\"text-align: right;\">              0.274103</td><td style=\"text-align: right;\">0.374488</td><td style=\"text-align: right;\">0.140241</td><td style=\"text-align: right;\">              5329</td><td style=\"text-align: right;\">                 0.138053</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.781026</td><td style=\"text-align: right;\"> 0.360178</td><td style=\"text-align: right;\">0.387828</td><td style=\"text-align: right;\">              0.216154</td><td style=\"text-align: right;\">0.333761</td><td style=\"text-align: right;\">0.111396</td><td style=\"text-align: right;\">                96</td><td style=\"text-align: right;\">                 0.102436</td><td>GLM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_1 </td><td style=\"text-align: right;\">0.779744</td><td style=\"text-align: right;\"> 0.591486</td><td style=\"text-align: right;\">0.406765</td><td style=\"text-align: right;\">              0.261282</td><td style=\"text-align: right;\">0.377667</td><td style=\"text-align: right;\">0.142632</td><td style=\"text-align: right;\">              5603</td><td style=\"text-align: right;\">                 0.190538</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_16</td><td style=\"text-align: right;\">0.779487</td><td style=\"text-align: right;\"> 1.76003 </td><td style=\"text-align: right;\">0.365117</td><td style=\"text-align: right;\">              0.288205</td><td style=\"text-align: right;\">0.430472</td><td style=\"text-align: right;\">0.185306</td><td style=\"text-align: right;\">              2990</td><td style=\"text-align: right;\">                 0.168645</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_1 </td><td style=\"text-align: right;\">0.778205</td><td style=\"text-align: right;\"> 0.637349</td><td style=\"text-align: right;\">0.399865</td><td style=\"text-align: right;\">              0.237179</td><td style=\"text-align: right;\">0.356818</td><td style=\"text-align: right;\">0.127319</td><td style=\"text-align: right;\">              4287</td><td style=\"text-align: right;\">                 0.121014</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_16</td><td style=\"text-align: right;\">0.773077</td><td style=\"text-align: right;\"> 1.10118 </td><td style=\"text-align: right;\">0.355061</td><td style=\"text-align: right;\">              0.248718</td><td style=\"text-align: right;\">0.430749</td><td style=\"text-align: right;\">0.185545</td><td style=\"text-align: right;\">              2940</td><td style=\"text-align: right;\">                 0.184386</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_21</td><td style=\"text-align: right;\">0.769487</td><td style=\"text-align: right;\"> 1.15463 </td><td style=\"text-align: right;\">0.308691</td><td style=\"text-align: right;\">              0.298205</td><td style=\"text-align: right;\">0.421771</td><td style=\"text-align: right;\">0.177891</td><td style=\"text-align: right;\">              2795</td><td style=\"text-align: right;\">                 0.101911</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DRF_1_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.769103</td><td style=\"text-align: right;\"> 0.377327</td><td style=\"text-align: right;\">0.380961</td><td style=\"text-align: right;\">              0.268205</td><td style=\"text-align: right;\">0.329112</td><td style=\"text-align: right;\">0.108315</td><td style=\"text-align: right;\">               184</td><td style=\"text-align: right;\">                 0.082132</td><td>DRF         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_11         </td><td style=\"text-align: right;\">0.763846</td><td style=\"text-align: right;\"> 0.371534</td><td style=\"text-align: right;\">0.279444</td><td style=\"text-align: right;\">              0.28641 </td><td style=\"text-align: right;\">0.339534</td><td style=\"text-align: right;\">0.115283</td><td style=\"text-align: right;\">                60</td><td style=\"text-align: right;\">                 0.10914 </td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_19</td><td style=\"text-align: right;\">0.761795</td><td style=\"text-align: right;\"> 0.773505</td><td style=\"text-align: right;\">0.365195</td><td style=\"text-align: right;\">              0.341026</td><td style=\"text-align: right;\">0.38679 </td><td style=\"text-align: right;\">0.149606</td><td style=\"text-align: right;\">              2386</td><td style=\"text-align: right;\">                 0.178094</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_21         </td><td style=\"text-align: right;\">0.759231</td><td style=\"text-align: right;\"> 0.433061</td><td style=\"text-align: right;\">0.275309</td><td style=\"text-align: right;\">              0.280513</td><td style=\"text-align: right;\">0.362156</td><td style=\"text-align: right;\">0.131157</td><td style=\"text-align: right;\">               120</td><td style=\"text-align: right;\">                 0.401146</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_7 </td><td style=\"text-align: right;\">0.758462</td><td style=\"text-align: right;\"> 0.676088</td><td style=\"text-align: right;\">0.367014</td><td style=\"text-align: right;\">              0.285641</td><td style=\"text-align: right;\">0.414402</td><td style=\"text-align: right;\">0.171729</td><td style=\"text-align: right;\">              5532</td><td style=\"text-align: right;\">                 0.378401</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_2 </td><td style=\"text-align: right;\">0.756923</td><td style=\"text-align: right;\"> 0.555452</td><td style=\"text-align: right;\">0.350468</td><td style=\"text-align: right;\">              0.27641 </td><td style=\"text-align: right;\">0.387615</td><td style=\"text-align: right;\">0.150245</td><td style=\"text-align: right;\">              2591</td><td style=\"text-align: right;\">                 0.139453</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_13         </td><td style=\"text-align: right;\">0.756923</td><td style=\"text-align: right;\"> 0.414042</td><td style=\"text-align: right;\">0.301439</td><td style=\"text-align: right;\">              0.29641 </td><td style=\"text-align: right;\">0.352838</td><td style=\"text-align: right;\">0.124495</td><td style=\"text-align: right;\">               129</td><td style=\"text-align: right;\">                 0.054001</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_2          </td><td style=\"text-align: right;\">0.756795</td><td style=\"text-align: right;\"> 0.400463</td><td style=\"text-align: right;\">0.285598</td><td style=\"text-align: right;\">              0.299744</td><td style=\"text-align: right;\">0.354225</td><td style=\"text-align: right;\">0.125475</td><td style=\"text-align: right;\">                88</td><td style=\"text-align: right;\">                 0.09191 </td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_5 </td><td style=\"text-align: right;\">0.75641 </td><td style=\"text-align: right;\"> 0.745685</td><td style=\"text-align: right;\">0.32153 </td><td style=\"text-align: right;\">              0.335128</td><td style=\"text-align: right;\">0.391403</td><td style=\"text-align: right;\">0.153197</td><td style=\"text-align: right;\">              2803</td><td style=\"text-align: right;\">                 0.350275</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_4 </td><td style=\"text-align: right;\">0.754359</td><td style=\"text-align: right;\"> 0.661384</td><td style=\"text-align: right;\">0.378926</td><td style=\"text-align: right;\">              0.292308</td><td style=\"text-align: right;\">0.394163</td><td style=\"text-align: right;\">0.155365</td><td style=\"text-align: right;\">              5376</td><td style=\"text-align: right;\">                 0.188155</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_17         </td><td style=\"text-align: right;\">0.750897</td><td style=\"text-align: right;\"> 0.408353</td><td style=\"text-align: right;\">0.271268</td><td style=\"text-align: right;\">              0.304103</td><td style=\"text-align: right;\">0.359621</td><td style=\"text-align: right;\">0.129327</td><td style=\"text-align: right;\">                85</td><td style=\"text-align: right;\">                 0.121253</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_12         </td><td style=\"text-align: right;\">0.750513</td><td style=\"text-align: right;\"> 0.408181</td><td style=\"text-align: right;\">0.289041</td><td style=\"text-align: right;\">              0.28641 </td><td style=\"text-align: right;\">0.355011</td><td style=\"text-align: right;\">0.126033</td><td style=\"text-align: right;\">               132</td><td style=\"text-align: right;\">                 0.267484</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_20</td><td style=\"text-align: right;\">0.747692</td><td style=\"text-align: right;\"> 0.456588</td><td style=\"text-align: right;\">0.318082</td><td style=\"text-align: right;\">              0.258718</td><td style=\"text-align: right;\">0.355447</td><td style=\"text-align: right;\">0.126343</td><td style=\"text-align: right;\">              2668</td><td style=\"text-align: right;\">                 0.654688</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_12</td><td style=\"text-align: right;\">0.743077</td><td style=\"text-align: right;\"> 0.832753</td><td style=\"text-align: right;\">0.350161</td><td style=\"text-align: right;\">              0.321538</td><td style=\"text-align: right;\">0.430192</td><td style=\"text-align: right;\">0.185065</td><td style=\"text-align: right;\">              3142</td><td style=\"text-align: right;\">                 0.166638</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_3 </td><td style=\"text-align: right;\">0.743077</td><td style=\"text-align: right;\"> 2.24259 </td><td style=\"text-align: right;\">0.294094</td><td style=\"text-align: right;\">              0.298718</td><td style=\"text-align: right;\">0.465047</td><td style=\"text-align: right;\">0.216268</td><td style=\"text-align: right;\">              2595</td><td style=\"text-align: right;\">                 0.276043</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_3_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.741538</td><td style=\"text-align: right;\"> 0.380115</td><td style=\"text-align: right;\">0.289527</td><td style=\"text-align: right;\">              0.324103</td><td style=\"text-align: right;\">0.342256</td><td style=\"text-align: right;\">0.117139</td><td style=\"text-align: right;\">               152</td><td style=\"text-align: right;\">                 0.055528</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_9          </td><td style=\"text-align: right;\">0.740513</td><td style=\"text-align: right;\"> 0.380416</td><td style=\"text-align: right;\">0.274504</td><td style=\"text-align: right;\">              0.28641 </td><td style=\"text-align: right;\">0.343803</td><td style=\"text-align: right;\">0.118201</td><td style=\"text-align: right;\">                72</td><td style=\"text-align: right;\">                 0.064468</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_8 </td><td style=\"text-align: right;\">0.739744</td><td style=\"text-align: right;\"> 0.748565</td><td style=\"text-align: right;\">0.377619</td><td style=\"text-align: right;\">              0.268974</td><td style=\"text-align: right;\">0.370169</td><td style=\"text-align: right;\">0.137025</td><td style=\"text-align: right;\">              3998</td><td style=\"text-align: right;\">                 0.11151 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_1 </td><td style=\"text-align: right;\">0.739487</td><td style=\"text-align: right;\"> 0.56148 </td><td style=\"text-align: right;\">0.315495</td><td style=\"text-align: right;\">              0.298974</td><td style=\"text-align: right;\">0.380489</td><td style=\"text-align: right;\">0.144772</td><td style=\"text-align: right;\">              2802</td><td style=\"text-align: right;\">                 0.080513</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_19</td><td style=\"text-align: right;\">0.738974</td><td style=\"text-align: right;\"> 0.62602 </td><td style=\"text-align: right;\">0.366896</td><td style=\"text-align: right;\">              0.268974</td><td style=\"text-align: right;\">0.357083</td><td style=\"text-align: right;\">0.127509</td><td style=\"text-align: right;\">              4089</td><td style=\"text-align: right;\">                 0.15411 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_10         </td><td style=\"text-align: right;\">0.738462</td><td style=\"text-align: right;\"> 0.377071</td><td style=\"text-align: right;\">0.294111</td><td style=\"text-align: right;\">              0.290513</td><td style=\"text-align: right;\">0.341778</td><td style=\"text-align: right;\">0.116812</td><td style=\"text-align: right;\">                94</td><td style=\"text-align: right;\">                 0.129367</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_5_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.737179</td><td style=\"text-align: right;\"> 0.434135</td><td style=\"text-align: right;\">0.276889</td><td style=\"text-align: right;\">              0.332564</td><td style=\"text-align: right;\">0.359962</td><td style=\"text-align: right;\">0.129573</td><td style=\"text-align: right;\">               189</td><td style=\"text-align: right;\">                 0.163997</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_1          </td><td style=\"text-align: right;\">0.736154</td><td style=\"text-align: right;\"> 0.381772</td><td style=\"text-align: right;\">0.257161</td><td style=\"text-align: right;\">              0.324103</td><td style=\"text-align: right;\">0.346236</td><td style=\"text-align: right;\">0.119879</td><td style=\"text-align: right;\">                93</td><td style=\"text-align: right;\">                 0.124114</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_19</td><td style=\"text-align: right;\">0.734359</td><td style=\"text-align: right;\"> 0.724492</td><td style=\"text-align: right;\">0.286856</td><td style=\"text-align: right;\">              0.342564</td><td style=\"text-align: right;\">0.38865 </td><td style=\"text-align: right;\">0.151049</td><td style=\"text-align: right;\">              4069</td><td style=\"text-align: right;\">                 0.31668 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_11</td><td style=\"text-align: right;\">0.734103</td><td style=\"text-align: right;\"> 0.585997</td><td style=\"text-align: right;\">0.350118</td><td style=\"text-align: right;\">              0.274872</td><td style=\"text-align: right;\">0.367134</td><td style=\"text-align: right;\">0.134787</td><td style=\"text-align: right;\">              2663</td><td style=\"text-align: right;\">                 0.121672</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_15         </td><td style=\"text-align: right;\">0.73359 </td><td style=\"text-align: right;\"> 0.40042 </td><td style=\"text-align: right;\">0.286015</td><td style=\"text-align: right;\">              0.279487</td><td style=\"text-align: right;\">0.350108</td><td style=\"text-align: right;\">0.122575</td><td style=\"text-align: right;\">                86</td><td style=\"text-align: right;\">                 0.171516</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_4          </td><td style=\"text-align: right;\">0.733205</td><td style=\"text-align: right;\"> 0.37826 </td><td style=\"text-align: right;\">0.248004</td><td style=\"text-align: right;\">              0.292308</td><td style=\"text-align: right;\">0.343261</td><td style=\"text-align: right;\">0.117828</td><td style=\"text-align: right;\">                89</td><td style=\"text-align: right;\">                 0.321691</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_7 </td><td style=\"text-align: right;\">0.731026</td><td style=\"text-align: right;\"> 0.599752</td><td style=\"text-align: right;\">0.344847</td><td style=\"text-align: right;\">              0.306667</td><td style=\"text-align: right;\">0.373629</td><td style=\"text-align: right;\">0.139599</td><td style=\"text-align: right;\">              4315</td><td style=\"text-align: right;\">                 0.123526</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_6 </td><td style=\"text-align: right;\">0.730513</td><td style=\"text-align: right;\"> 0.71592 </td><td style=\"text-align: right;\">0.294893</td><td style=\"text-align: right;\">              0.275128</td><td style=\"text-align: right;\">0.40819 </td><td style=\"text-align: right;\">0.166619</td><td style=\"text-align: right;\">              2868</td><td style=\"text-align: right;\">                 0.107911</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_20</td><td style=\"text-align: right;\">0.729487</td><td style=\"text-align: right;\"> 0.775452</td><td style=\"text-align: right;\">0.345496</td><td style=\"text-align: right;\">              0.311538</td><td style=\"text-align: right;\">0.385905</td><td style=\"text-align: right;\">0.148923</td><td style=\"text-align: right;\">              2881</td><td style=\"text-align: right;\">                 0.102733</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_7          </td><td style=\"text-align: right;\">0.727692</td><td style=\"text-align: right;\"> 0.408609</td><td style=\"text-align: right;\">0.252227</td><td style=\"text-align: right;\">              0.289231</td><td style=\"text-align: right;\">0.358455</td><td style=\"text-align: right;\">0.12849 </td><td style=\"text-align: right;\">                66</td><td style=\"text-align: right;\">                 0.066875</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_11</td><td style=\"text-align: right;\">0.727179</td><td style=\"text-align: right;\"> 0.759333</td><td style=\"text-align: right;\">0.299522</td><td style=\"text-align: right;\">              0.284872</td><td style=\"text-align: right;\">0.383881</td><td style=\"text-align: right;\">0.147364</td><td style=\"text-align: right;\">              2645</td><td style=\"text-align: right;\">                 0.132849</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_8          </td><td style=\"text-align: right;\">0.725641</td><td style=\"text-align: right;\"> 0.433043</td><td style=\"text-align: right;\">0.28079 </td><td style=\"text-align: right;\">              0.295641</td><td style=\"text-align: right;\">0.358929</td><td style=\"text-align: right;\">0.12883 </td><td style=\"text-align: right;\">               131</td><td style=\"text-align: right;\">                 0.089563</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_10</td><td style=\"text-align: right;\">0.721282</td><td style=\"text-align: right;\"> 0.665981</td><td style=\"text-align: right;\">0.341346</td><td style=\"text-align: right;\">              0.324872</td><td style=\"text-align: right;\">0.434704</td><td style=\"text-align: right;\">0.188967</td><td style=\"text-align: right;\">              5331</td><td style=\"text-align: right;\">                 0.139759</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_14</td><td style=\"text-align: right;\">0.72    </td><td style=\"text-align: right;\"> 0.675661</td><td style=\"text-align: right;\">0.337286</td><td style=\"text-align: right;\">              0.33    </td><td style=\"text-align: right;\">0.359504</td><td style=\"text-align: right;\">0.129243</td><td style=\"text-align: right;\">              1856</td><td style=\"text-align: right;\">                 0.082228</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_22         </td><td style=\"text-align: right;\">0.719487</td><td style=\"text-align: right;\"> 0.385287</td><td style=\"text-align: right;\">0.276424</td><td style=\"text-align: right;\">              0.275385</td><td style=\"text-align: right;\">0.342366</td><td style=\"text-align: right;\">0.117214</td><td style=\"text-align: right;\">                69</td><td style=\"text-align: right;\">                 0.067556</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_7 </td><td style=\"text-align: right;\">0.718205</td><td style=\"text-align: right;\"> 0.749389</td><td style=\"text-align: right;\">0.35717 </td><td style=\"text-align: right;\">              0.257949</td><td style=\"text-align: right;\">0.400645</td><td style=\"text-align: right;\">0.160516</td><td style=\"text-align: right;\">              2744</td><td style=\"text-align: right;\">                 0.11812 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_4_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.715641</td><td style=\"text-align: right;\"> 0.394532</td><td style=\"text-align: right;\">0.298985</td><td style=\"text-align: right;\">              0.281282</td><td style=\"text-align: right;\">0.347308</td><td style=\"text-align: right;\">0.120623</td><td style=\"text-align: right;\">               164</td><td style=\"text-align: right;\">                 0.077411</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_20         </td><td style=\"text-align: right;\">0.71359 </td><td style=\"text-align: right;\"> 0.384883</td><td style=\"text-align: right;\">0.245127</td><td style=\"text-align: right;\">              0.308205</td><td style=\"text-align: right;\">0.344086</td><td style=\"text-align: right;\">0.118395</td><td style=\"text-align: right;\">                61</td><td style=\"text-align: right;\">                 0.100552</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_3          </td><td style=\"text-align: right;\">0.711795</td><td style=\"text-align: right;\"> 0.385044</td><td style=\"text-align: right;\">0.302615</td><td style=\"text-align: right;\">              0.333333</td><td style=\"text-align: right;\">0.341844</td><td style=\"text-align: right;\">0.116857</td><td style=\"text-align: right;\">               112</td><td style=\"text-align: right;\">                 0.072263</td><td>GBM         </td></tr>\n",
       "<tr><td>XRT_1_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.711538</td><td style=\"text-align: right;\"> 0.398451</td><td style=\"text-align: right;\">0.268246</td><td style=\"text-align: right;\">              0.313333</td><td style=\"text-align: right;\">0.347068</td><td style=\"text-align: right;\">0.120456</td><td style=\"text-align: right;\">               107</td><td style=\"text-align: right;\">                 0.092367</td><td>DRF         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_12</td><td style=\"text-align: right;\">0.709487</td><td style=\"text-align: right;\"> 0.916957</td><td style=\"text-align: right;\">0.286277</td><td style=\"text-align: right;\">              0.323333</td><td style=\"text-align: right;\">0.411415</td><td style=\"text-align: right;\">0.169262</td><td style=\"text-align: right;\">              3527</td><td style=\"text-align: right;\">                 0.202031</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_5          </td><td style=\"text-align: right;\">0.709231</td><td style=\"text-align: right;\"> 0.397116</td><td style=\"text-align: right;\">0.255828</td><td style=\"text-align: right;\">              0.313077</td><td style=\"text-align: right;\">0.349821</td><td style=\"text-align: right;\">0.122375</td><td style=\"text-align: right;\">               112</td><td style=\"text-align: right;\">                 0.073839</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_1_20230524_85722              </td><td style=\"text-align: right;\">0.707949</td><td style=\"text-align: right;\"> 0.566049</td><td style=\"text-align: right;\">0.253395</td><td style=\"text-align: right;\">              0.335897</td><td style=\"text-align: right;\">0.397394</td><td style=\"text-align: right;\">0.157922</td><td style=\"text-align: right;\">               101</td><td style=\"text-align: right;\">                 0.095452</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_6 </td><td style=\"text-align: right;\">0.706154</td><td style=\"text-align: right;\"> 0.605361</td><td style=\"text-align: right;\">0.32798 </td><td style=\"text-align: right;\">              0.320769</td><td style=\"text-align: right;\">0.365197</td><td style=\"text-align: right;\">0.133369</td><td style=\"text-align: right;\">              4077</td><td style=\"text-align: right;\">                 0.119695</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_10</td><td style=\"text-align: right;\">0.698974</td><td style=\"text-align: right;\"> 0.659814</td><td style=\"text-align: right;\">0.390984</td><td style=\"text-align: right;\">              0.322564</td><td style=\"text-align: right;\">0.391506</td><td style=\"text-align: right;\">0.153277</td><td style=\"text-align: right;\">              4903</td><td style=\"text-align: right;\">                 0.180571</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_18         </td><td style=\"text-align: right;\">0.695897</td><td style=\"text-align: right;\"> 0.437023</td><td style=\"text-align: right;\">0.276155</td><td style=\"text-align: right;\">              0.327436</td><td style=\"text-align: right;\">0.354882</td><td style=\"text-align: right;\">0.125941</td><td style=\"text-align: right;\">               131</td><td style=\"text-align: right;\">                 0.115914</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_18</td><td style=\"text-align: right;\">0.690769</td><td style=\"text-align: right;\"> 0.613497</td><td style=\"text-align: right;\">0.374577</td><td style=\"text-align: right;\">              0.340769</td><td style=\"text-align: right;\">0.375103</td><td style=\"text-align: right;\">0.140702</td><td style=\"text-align: right;\">              3110</td><td style=\"text-align: right;\">                 0.088781</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_22</td><td style=\"text-align: right;\">0.689744</td><td style=\"text-align: right;\"> 0.71721 </td><td style=\"text-align: right;\">0.351706</td><td style=\"text-align: right;\">              0.277179</td><td style=\"text-align: right;\">0.358253</td><td style=\"text-align: right;\">0.128345</td><td style=\"text-align: right;\">              2609</td><td style=\"text-align: right;\">                 0.150519</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_2_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.684103</td><td style=\"text-align: right;\"> 0.416181</td><td style=\"text-align: right;\">0.225593</td><td style=\"text-align: right;\">              0.358205</td><td style=\"text-align: right;\">0.358297</td><td style=\"text-align: right;\">0.128377</td><td style=\"text-align: right;\">               126</td><td style=\"text-align: right;\">                 0.042361</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_13</td><td style=\"text-align: right;\">0.683333</td><td style=\"text-align: right;\"> 0.640924</td><td style=\"text-align: right;\">0.283034</td><td style=\"text-align: right;\">              0.341538</td><td style=\"text-align: right;\">0.371735</td><td style=\"text-align: right;\">0.138187</td><td style=\"text-align: right;\">              3901</td><td style=\"text-align: right;\">                 0.172116</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_8 </td><td style=\"text-align: right;\">0.678462</td><td style=\"text-align: right;\"> 0.635846</td><td style=\"text-align: right;\">0.275963</td><td style=\"text-align: right;\">              0.366923</td><td style=\"text-align: right;\">0.395044</td><td style=\"text-align: right;\">0.15606 </td><td style=\"text-align: right;\">              5460</td><td style=\"text-align: right;\">                 0.369481</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_15</td><td style=\"text-align: right;\">0.675385</td><td style=\"text-align: right;\"> 1.6378  </td><td style=\"text-align: right;\">0.284622</td><td style=\"text-align: right;\">              0.34641 </td><td style=\"text-align: right;\">0.520244</td><td style=\"text-align: right;\">0.270654</td><td style=\"text-align: right;\">              2722</td><td style=\"text-align: right;\">                 0.092243</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_9 </td><td style=\"text-align: right;\">0.673077</td><td style=\"text-align: right;\"> 1.01995 </td><td style=\"text-align: right;\">0.218572</td><td style=\"text-align: right;\">              0.319744</td><td style=\"text-align: right;\">0.441642</td><td style=\"text-align: right;\">0.195047</td><td style=\"text-align: right;\">              2933</td><td style=\"text-align: right;\">                 0.081322</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_21</td><td style=\"text-align: right;\">0.669231</td><td style=\"text-align: right;\"> 0.830025</td><td style=\"text-align: right;\">0.295992</td><td style=\"text-align: right;\">              0.356667</td><td style=\"text-align: right;\">0.443183</td><td style=\"text-align: right;\">0.196411</td><td style=\"text-align: right;\">              2636</td><td style=\"text-align: right;\">                 0.060905</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_23</td><td style=\"text-align: right;\">0.668718</td><td style=\"text-align: right;\"> 1.41541 </td><td style=\"text-align: right;\">0.255323</td><td style=\"text-align: right;\">              0.350513</td><td style=\"text-align: right;\">0.468592</td><td style=\"text-align: right;\">0.219579</td><td style=\"text-align: right;\">              2594</td><td style=\"text-align: right;\">                 0.059538</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_21</td><td style=\"text-align: right;\">0.666154</td><td style=\"text-align: right;\"> 0.666535</td><td style=\"text-align: right;\">0.284685</td><td style=\"text-align: right;\">              0.340769</td><td style=\"text-align: right;\">0.404423</td><td style=\"text-align: right;\">0.163558</td><td style=\"text-align: right;\">              2731</td><td style=\"text-align: right;\">                 0.083045</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_20</td><td style=\"text-align: right;\">0.657692</td><td style=\"text-align: right;\"> 0.567925</td><td style=\"text-align: right;\">0.314398</td><td style=\"text-align: right;\">              0.326667</td><td style=\"text-align: right;\">0.356959</td><td style=\"text-align: right;\">0.127419</td><td style=\"text-align: right;\">              2699</td><td style=\"text-align: right;\">                 0.079024</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_13</td><td style=\"text-align: right;\">0.654103</td><td style=\"text-align: right;\"> 1.05637 </td><td style=\"text-align: right;\">0.255971</td><td style=\"text-align: right;\">              0.361538</td><td style=\"text-align: right;\">0.382364</td><td style=\"text-align: right;\">0.146202</td><td style=\"text-align: right;\">              3733</td><td style=\"text-align: right;\">                 0.093792</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_22</td><td style=\"text-align: right;\">0.653077</td><td style=\"text-align: right;\"> 1.30272 </td><td style=\"text-align: right;\">0.200791</td><td style=\"text-align: right;\">              0.33359 </td><td style=\"text-align: right;\">0.464225</td><td style=\"text-align: right;\">0.215505</td><td style=\"text-align: right;\">              2735</td><td style=\"text-align: right;\">                 0.199886</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_17</td><td style=\"text-align: right;\">0.64    </td><td style=\"text-align: right;\"> 0.637143</td><td style=\"text-align: right;\">0.398898</td><td style=\"text-align: right;\">              0.378718</td><td style=\"text-align: right;\">0.346699</td><td style=\"text-align: right;\">0.1202  </td><td style=\"text-align: right;\">              2628</td><td style=\"text-align: right;\">                 0.751002</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_13</td><td style=\"text-align: right;\">0.622308</td><td style=\"text-align: right;\"> 0.840956</td><td style=\"text-align: right;\">0.237018</td><td style=\"text-align: right;\">              0.360513</td><td style=\"text-align: right;\">0.438958</td><td style=\"text-align: right;\">0.192685</td><td style=\"text-align: right;\">              2415</td><td style=\"text-align: right;\">                 0.589494</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_3 </td><td style=\"text-align: right;\">0.620769</td><td style=\"text-align: right;\"> 0.81861 </td><td style=\"text-align: right;\">0.21137 </td><td style=\"text-align: right;\">              0.364103</td><td style=\"text-align: right;\">0.410995</td><td style=\"text-align: right;\">0.168917</td><td style=\"text-align: right;\">              2863</td><td style=\"text-align: right;\">                36.2781  </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_4 </td><td style=\"text-align: right;\">0.614872</td><td style=\"text-align: right;\"> 1.16054 </td><td style=\"text-align: right;\">0.24582 </td><td style=\"text-align: right;\">              0.347949</td><td style=\"text-align: right;\">0.410871</td><td style=\"text-align: right;\">0.168815</td><td style=\"text-align: right;\">              3194</td><td style=\"text-align: right;\">                 0.275344</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_9 </td><td style=\"text-align: right;\">0.591795</td><td style=\"text-align: right;\"> 0.983963</td><td style=\"text-align: right;\">0.285678</td><td style=\"text-align: right;\">              0.35    </td><td style=\"text-align: right;\">0.400895</td><td style=\"text-align: right;\">0.160717</td><td style=\"text-align: right;\">              2777</td><td style=\"text-align: right;\">                 0.11525 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_6 </td><td style=\"text-align: right;\">0.580513</td><td style=\"text-align: right;\"> 0.760781</td><td style=\"text-align: right;\">0.188506</td><td style=\"text-align: right;\">              0.382564</td><td style=\"text-align: right;\">0.379782</td><td style=\"text-align: right;\">0.144234</td><td style=\"text-align: right;\">              4951</td><td style=\"text-align: right;\">                 0.30105 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_15</td><td style=\"text-align: right;\">0.572821</td><td style=\"text-align: right;\"> 0.746677</td><td style=\"text-align: right;\">0.214842</td><td style=\"text-align: right;\">              0.373333</td><td style=\"text-align: right;\">0.371236</td><td style=\"text-align: right;\">0.137816</td><td style=\"text-align: right;\">              2545</td><td style=\"text-align: right;\">                 0.230366</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_15</td><td style=\"text-align: right;\">0.57    </td><td style=\"text-align: right;\"> 0.972834</td><td style=\"text-align: right;\">0.223291</td><td style=\"text-align: right;\">              0.408718</td><td style=\"text-align: right;\">0.401614</td><td style=\"text-align: right;\">0.161294</td><td style=\"text-align: right;\">              2705</td><td style=\"text-align: right;\">                 0.093188</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_18</td><td style=\"text-align: right;\">0.569487</td><td style=\"text-align: right;\"> 0.561799</td><td style=\"text-align: right;\">0.204888</td><td style=\"text-align: right;\">              0.396923</td><td style=\"text-align: right;\">0.372262</td><td style=\"text-align: right;\">0.138579</td><td style=\"text-align: right;\">              2550</td><td style=\"text-align: right;\">                 0.088106</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_18</td><td style=\"text-align: right;\">0.568718</td><td style=\"text-align: right;\"> 0.897296</td><td style=\"text-align: right;\">0.238073</td><td style=\"text-align: right;\">              0.422051</td><td style=\"text-align: right;\">0.386014</td><td style=\"text-align: right;\">0.149007</td><td style=\"text-align: right;\">              2630</td><td style=\"text-align: right;\">                 0.202487</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_17</td><td style=\"text-align: right;\">0.504615</td><td style=\"text-align: right;\"> 0.902361</td><td style=\"text-align: right;\">0.160535</td><td style=\"text-align: right;\">              0.422051</td><td style=\"text-align: right;\">0.420276</td><td style=\"text-align: right;\">0.176632</td><td style=\"text-align: right;\">              2376</td><td style=\"text-align: right;\">                 0.103973</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_17</td><td style=\"text-align: right;\">0.499231</td><td style=\"text-align: right;\"> 0.877267</td><td style=\"text-align: right;\">0.191124</td><td style=\"text-align: right;\">              0.458718</td><td style=\"text-align: right;\">0.381507</td><td style=\"text-align: right;\">0.145548</td><td style=\"text-align: right;\">              2457</td><td style=\"text-align: right;\">                 2.07925 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_9 </td><td style=\"text-align: right;\">0.483077</td><td style=\"text-align: right;\"> 0.605123</td><td style=\"text-align: right;\">0.134492</td><td style=\"text-align: right;\">              0.463333</td><td style=\"text-align: right;\">0.390951</td><td style=\"text-align: right;\">0.152842</td><td style=\"text-align: right;\">              2139</td><td style=\"text-align: right;\">                 0.09187 </td><td>DeepLearning</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[93 rows x 10 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                   auc    logloss     aucpr    mean_per_class_error      rmse       mse    training_time_ms    predict_time_per_row_ms  algo\n",
       "----------------------------------------------------  --------  ---------  --------  ----------------------  --------  --------  ------------------  -------------------------  ------------\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_5   0.830513   0.695563  0.448287                0.248974  0.372326  0.138627                2709                   0.710977  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_2   0.823077   0.417719  0.39347                 0.233077  0.344425  0.118629                2689                   0.760255  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_22  0.817179   0.464433  0.513033                0.251538  0.321971  0.103665                2708                   0.164375  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_5   0.813077   0.654276  0.381339                0.299231  0.38311   0.146773                2062                   0.109675  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_14  0.809487   0.53134   0.396423                0.23641   0.361284  0.130526                3939                   0.177956  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_10  0.808846   0.738022  0.378064                0.258205  0.373639  0.139606                3034                   0.908088  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_4   0.802821   0.671927  0.381739                0.212821  0.402897  0.162326                4143                   0.270085  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_3   0.797692   0.597201  0.321101                0.254615  0.400425  0.16034                 2784                   0.086429  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_16  0.795128   1.49879   0.359095                0.273077  0.414024  0.171416                2630                   0.117531  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_2   0.793077   0.73027   0.377618                0.285641  0.404787  0.163852                2700                   0.14276   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_11  0.792564   0.386072  0.338971                0.209487  0.34739   0.12068                 2390                   0.274097  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_12  0.784615   0.90519   0.378051                0.240513  0.378227  0.143056                4581                   0.467057  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_14  0.782051   0.412528  0.379142                0.284103  0.344026  0.118354                3951                   0.145976  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_8   0.781795   0.590756  0.372474                0.274103  0.374488  0.140241                5329                   0.138053  DeepLearning\n",
       "GLM_1_AutoML_1_20230524_85722                         0.781026   0.360178  0.387828                0.216154  0.333761  0.111396                  96                   0.102436  GLM\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_1   0.779744   0.591486  0.406765                0.261282  0.377667  0.142632                5603                   0.190538  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_16  0.779487   1.76003   0.365117                0.288205  0.430472  0.185306                2990                   0.168645  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_1   0.778205   0.637349  0.399865                0.237179  0.356818  0.127319                4287                   0.121014  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_16  0.773077   1.10118   0.355061                0.248718  0.430749  0.185545                2940                   0.184386  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_21  0.769487   1.15463   0.308691                0.298205  0.421771  0.177891                2795                   0.101911  DeepLearning\n",
       "DRF_1_AutoML_1_20230524_85722                         0.769103   0.377327  0.380961                0.268205  0.329112  0.108315                 184                   0.082132  DRF\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_11           0.763846   0.371534  0.279444                0.28641   0.339534  0.115283                  60                   0.10914   GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_19  0.761795   0.773505  0.365195                0.341026  0.38679   0.149606                2386                   0.178094  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_21           0.759231   0.433061  0.275309                0.280513  0.362156  0.131157                 120                   0.401146  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_7   0.758462   0.676088  0.367014                0.285641  0.414402  0.171729                5532                   0.378401  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_2   0.756923   0.555452  0.350468                0.27641   0.387615  0.150245                2591                   0.139453  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_13           0.756923   0.414042  0.301439                0.29641   0.352838  0.124495                 129                   0.054001  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_2            0.756795   0.400463  0.285598                0.299744  0.354225  0.125475                  88                   0.09191   GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_5   0.75641    0.745685  0.32153                 0.335128  0.391403  0.153197                2803                   0.350275  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_4   0.754359   0.661384  0.378926                0.292308  0.394163  0.155365                5376                   0.188155  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_17           0.750897   0.408353  0.271268                0.304103  0.359621  0.129327                  85                   0.121253  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_12           0.750513   0.408181  0.289041                0.28641   0.355011  0.126033                 132                   0.267484  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_20  0.747692   0.456588  0.318082                0.258718  0.355447  0.126343                2668                   0.654688  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_12  0.743077   0.832753  0.350161                0.321538  0.430192  0.185065                3142                   0.166638  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_3   0.743077   2.24259   0.294094                0.298718  0.465047  0.216268                2595                   0.276043  DeepLearning\n",
       "GBM_3_AutoML_1_20230524_85722                         0.741538   0.380115  0.289527                0.324103  0.342256  0.117139                 152                   0.055528  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_9            0.740513   0.380416  0.274504                0.28641   0.343803  0.118201                  72                   0.064468  GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_8   0.739744   0.748565  0.377619                0.268974  0.370169  0.137025                3998                   0.11151   DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_1   0.739487   0.56148   0.315495                0.298974  0.380489  0.144772                2802                   0.080513  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_19  0.738974   0.62602   0.366896                0.268974  0.357083  0.127509                4089                   0.15411   DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_10           0.738462   0.377071  0.294111                0.290513  0.341778  0.116812                  94                   0.129367  GBM\n",
       "GBM_5_AutoML_1_20230524_85722                         0.737179   0.434135  0.276889                0.332564  0.359962  0.129573                 189                   0.163997  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_1            0.736154   0.381772  0.257161                0.324103  0.346236  0.119879                  93                   0.124114  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_19  0.734359   0.724492  0.286856                0.342564  0.38865   0.151049                4069                   0.31668   DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_11  0.734103   0.585997  0.350118                0.274872  0.367134  0.134787                2663                   0.121672  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_15           0.73359    0.40042   0.286015                0.279487  0.350108  0.122575                  86                   0.171516  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_4            0.733205   0.37826   0.248004                0.292308  0.343261  0.117828                  89                   0.321691  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_7   0.731026   0.599752  0.344847                0.306667  0.373629  0.139599                4315                   0.123526  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_6   0.730513   0.71592   0.294893                0.275128  0.40819   0.166619                2868                   0.107911  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_20  0.729487   0.775452  0.345496                0.311538  0.385905  0.148923                2881                   0.102733  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_7            0.727692   0.408609  0.252227                0.289231  0.358455  0.12849                   66                   0.066875  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_11  0.727179   0.759333  0.299522                0.284872  0.383881  0.147364                2645                   0.132849  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_8            0.725641   0.433043  0.28079                 0.295641  0.358929  0.12883                  131                   0.089563  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_10  0.721282   0.665981  0.341346                0.324872  0.434704  0.188967                5331                   0.139759  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_14  0.72       0.675661  0.337286                0.33      0.359504  0.129243                1856                   0.082228  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_22           0.719487   0.385287  0.276424                0.275385  0.342366  0.117214                  69                   0.067556  GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_7   0.718205   0.749389  0.35717                 0.257949  0.400645  0.160516                2744                   0.11812   DeepLearning\n",
       "GBM_4_AutoML_1_20230524_85722                         0.715641   0.394532  0.298985                0.281282  0.347308  0.120623                 164                   0.077411  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_20           0.71359    0.384883  0.245127                0.308205  0.344086  0.118395                  61                   0.100552  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_3            0.711795   0.385044  0.302615                0.333333  0.341844  0.116857                 112                   0.072263  GBM\n",
       "XRT_1_AutoML_1_20230524_85722                         0.711538   0.398451  0.268246                0.313333  0.347068  0.120456                 107                   0.092367  DRF\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_12  0.709487   0.916957  0.286277                0.323333  0.411415  0.169262                3527                   0.202031  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_5            0.709231   0.397116  0.255828                0.313077  0.349821  0.122375                 112                   0.073839  GBM\n",
       "DeepLearning_1_AutoML_1_20230524_85722                0.707949   0.566049  0.253395                0.335897  0.397394  0.157922                 101                   0.095452  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_6   0.706154   0.605361  0.32798                 0.320769  0.365197  0.133369                4077                   0.119695  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_10  0.698974   0.659814  0.390984                0.322564  0.391506  0.153277                4903                   0.180571  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_18           0.695897   0.437023  0.276155                0.327436  0.354882  0.125941                 131                   0.115914  GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_18  0.690769   0.613497  0.374577                0.340769  0.375103  0.140702                3110                   0.088781  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_22  0.689744   0.71721   0.351706                0.277179  0.358253  0.128345                2609                   0.150519  DeepLearning\n",
       "GBM_2_AutoML_1_20230524_85722                         0.684103   0.416181  0.225593                0.358205  0.358297  0.128377                 126                   0.042361  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_13  0.683333   0.640924  0.283034                0.341538  0.371735  0.138187                3901                   0.172116  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_8   0.678462   0.635846  0.275963                0.366923  0.395044  0.15606                 5460                   0.369481  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_15  0.675385   1.6378    0.284622                0.34641   0.520244  0.270654                2722                   0.092243  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_9   0.673077   1.01995   0.218572                0.319744  0.441642  0.195047                2933                   0.081322  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_21  0.669231   0.830025  0.295992                0.356667  0.443183  0.196411                2636                   0.060905  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_23  0.668718   1.41541   0.255323                0.350513  0.468592  0.219579                2594                   0.059538  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_21  0.666154   0.666535  0.284685                0.340769  0.404423  0.163558                2731                   0.083045  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_20  0.657692   0.567925  0.314398                0.326667  0.356959  0.127419                2699                   0.079024  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_13  0.654103   1.05637   0.255971                0.361538  0.382364  0.146202                3733                   0.093792  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_22  0.653077   1.30272   0.200791                0.33359   0.464225  0.215505                2735                   0.199886  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_17  0.64       0.637143  0.398898                0.378718  0.346699  0.1202                  2628                   0.751002  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_13  0.622308   0.840956  0.237018                0.360513  0.438958  0.192685                2415                   0.589494  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_3   0.620769   0.81861   0.21137                 0.364103  0.410995  0.168917                2863                  36.2781    DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_4   0.614872   1.16054   0.24582                 0.347949  0.410871  0.168815                3194                   0.275344  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_9   0.591795   0.983963  0.285678                0.35      0.400895  0.160717                2777                   0.11525   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_6   0.580513   0.760781  0.188506                0.382564  0.379782  0.144234                4951                   0.30105   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_15  0.572821   0.746677  0.214842                0.373333  0.371236  0.137816                2545                   0.230366  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_15  0.57       0.972834  0.223291                0.408718  0.401614  0.161294                2705                   0.093188  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_18  0.569487   0.561799  0.204888                0.396923  0.372262  0.138579                2550                   0.088106  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_18  0.568718   0.897296  0.238073                0.422051  0.386014  0.149007                2630                   0.202487  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_17  0.504615   0.902361  0.160535                0.422051  0.420276  0.176632                2376                   0.103973  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_17  0.499231   0.877267  0.191124                0.458718  0.381507  0.145548                2457                   2.07925   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_9   0.483077   0.605123  0.134492                0.463333  0.390951  0.152842                2139                   0.09187   DeepLearning\n",
       "[93 rows x 10 columns]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.automl import H2OAutoML, get_leaderboard\n",
    "\n",
    "# Import a sample binary outcome train/test set into H2O\n",
    "train1 = h2o.H2OFrame(train)\n",
    "\n",
    "# Identify predictors and response\n",
    "predictors = ['year', 'rating', 'numVotes',\n",
    "       'worldwide_box_office', 'action', 'adventure',\n",
    "       'animation', 'biography', 'comedy', 'crime', 'documentary', 'drama',\n",
    "       'family', 'fantasy', 'film-noir', 'history', 'horror', 'music',\n",
    "       'musical', 'mystery', 'romance', 'sci-fi', 'sport', 'thriller', 'war',\n",
    "       'western', 'nominations', 'nom_gg_drama',\n",
    "       'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga',\n",
    "       'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga',\n",
    "       'nom_sag', 'winner_sag','Acting',\n",
    "       'Production Design', 'Directing', 'VFX', 'Writing', 'Cinematography',\n",
    "       'Sound', 'Film Editing', 'Music']\n",
    "\n",
    "x = predictors\n",
    "y = 'Oscar_win'\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train1[y] = train1[y].asfactor()\n",
    "\n",
    "# Run AutoML for 100 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=100, seed=1\n",
    "                , keep_cross_validation_predictions= True\n",
    "               , exclude_algos = ['StackedEnsemble'])\n",
    "\n",
    "aml.train(x=x, y=y, training_frame=train1)\n",
    "\n",
    "# AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "\n",
    "# Optionally edd extra model information to the leaderboard\n",
    "lb = get_leaderboard(aml, extra_columns='ALL')\n",
    "\n",
    "# Print all rows (instead of default 10 rows)\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_1_20230524_85722_model_5\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 15 002 weights/biases, 187,0 KB, 61 600 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>46</td>\n",
       "<td>Input</td>\n",
       "<td>10.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>100</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>40.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0240016</td>\n",
       "<td>0.0330112</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0086950</td>\n",
       "<td>0.1495203</td>\n",
       "<td>0.3626150</td>\n",
       "<td>0.0869916</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>100</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>40.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0412028</td>\n",
       "<td>0.1104845</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0231518</td>\n",
       "<td>0.1138108</td>\n",
       "<td>0.8343524</td>\n",
       "<td>0.0980829</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0117487</td>\n",
       "<td>0.0094979</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0413580</td>\n",
       "<td>0.5311203</td>\n",
       "<td>0.0047554</td>\n",
       "<td>0.0053207</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 1.811046872184211e-05\n",
       "RMSE: 0.0042556396372157865\n",
       "LogLoss: 0.0007151719579600746\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9929139937321374</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/150.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>26.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/26.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>150.0</td>\n",
       "<td>26.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/176.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999996</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999996</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999996</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999996</td>\n",
       "<td>25.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>150.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.9929140</td>\n",
       "<td>26.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999996</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999996</td>\n",
       "<td>0.9615385</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,77 %, avg score: 14,82 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0113636</td>\n",
       "<td>0.9999977</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999988</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999988</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.0769231</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.0769231</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.9999946</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999966</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999977</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.1538462</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.1538462</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0340909</td>\n",
       "<td>0.9999896</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999919</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999958</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.2307692</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.2307692</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.9999804</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999842</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999929</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.3076923</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.3076923</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0511364</td>\n",
       "<td>0.9999783</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999789</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999913</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.3461538</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.3461538</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1022727</td>\n",
       "<td>0.9996659</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998545</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999229</td>\n",
       "<td>0.3461538</td>\n",
       "<td>0.6923077</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.6923077</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1534091</td>\n",
       "<td>0.0417790</td>\n",
       "<td>6.0170940</td>\n",
       "<td>6.5185185</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.8921820</td>\n",
       "<td>0.9629630</td>\n",
       "<td>0.9640093</td>\n",
       "<td>0.3076923</td>\n",
       "<td>1.0</td>\n",
       "<td>501.7094017</td>\n",
       "<td>551.8518519</td>\n",
       "<td>0.9933333</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.0011363</td>\n",
       "<td>0.0</td>\n",
       "<td>4.8888889</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0061911</td>\n",
       "<td>0.7222222</td>\n",
       "<td>0.7245547</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>388.8888889</td>\n",
       "<td>0.9333333</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3011364</td>\n",
       "<td>0.0000876</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3207547</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002847</td>\n",
       "<td>0.4905660</td>\n",
       "<td>0.4922417</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>232.0754717</td>\n",
       "<td>0.8200000</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4034091</td>\n",
       "<td>0.0000140</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4788732</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000406</td>\n",
       "<td>0.3661972</td>\n",
       "<td>0.3674583</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>147.8873239</td>\n",
       "<td>0.7</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0000037</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000076</td>\n",
       "<td>0.2954545</td>\n",
       "<td>0.2964735</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td>\n",
       "<td>0.5866667</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6022727</td>\n",
       "<td>0.0000009</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6603774</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000018</td>\n",
       "<td>0.2452830</td>\n",
       "<td>0.2461293</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.0377358</td>\n",
       "<td>0.4666667</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6988636</td>\n",
       "<td>0.0000002</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4308943</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.2113821</td>\n",
       "<td>0.2121115</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.0894309</td>\n",
       "<td>0.3533333</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8011364</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2482270</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.1843972</td>\n",
       "<td>0.1850334</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.8226950</td>\n",
       "<td>0.2333333</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8977273</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1139241</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1645570</td>\n",
       "<td>0.1651248</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.3924051</td>\n",
       "<td>0.12</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1477273</td>\n",
       "<td>0.1482370</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.138626542100689\n",
       "RMSE: 0.37232585473035446\n",
       "LogLoss: 0.6955626030444713\n",
       "Mean Per-Class Error: 0.248974358974359\n",
       "AUC: 0.8305128205128205\n",
       "AUCPR: 0.4482871529081092\n",
       "Gini: 0.661025641025641</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.07940738509974507</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>133.0</td>\n",
       "<td>17.0</td>\n",
       "<td>0.1133</td>\n",
       "<td> (17.0/150.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>10.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.3846</td>\n",
       "<td> (10.0/26.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>143.0</td>\n",
       "<td>33.0</td>\n",
       "<td>0.1534</td>\n",
       "<td> (27.0/176.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.0794074</td>\n",
       "<td>0.5423729</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0029275</td>\n",
       "<td>0.6686047</td>\n",
       "<td>67.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.0794074</td>\n",
       "<td>0.5063291</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9937201</td>\n",
       "<td>0.8636364</td>\n",
       "<td>7.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999841</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000017</td>\n",
       "<td>1.0</td>\n",
       "<td>147.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999841</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.0794074</td>\n",
       "<td>0.4564103</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0079099</td>\n",
       "<td>0.7466667</td>\n",
       "<td>57.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0029275</td>\n",
       "<td>0.7923077</td>\n",
       "<td>67.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999841</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999841</td>\n",
       "<td>25.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>150.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0000017</td>\n",
       "<td>26.0</td>\n",
       "<td>147.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999841</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999841</td>\n",
       "<td>0.9615385</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0000017</td>\n",
       "<td>1.0</td>\n",
       "<td>147.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,77 %, avg score: 11,76 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0113636</td>\n",
       "<td>0.9992442</td>\n",
       "<td>3.3846154</td>\n",
       "<td>3.3846154</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9999827</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9999827</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.0384615</td>\n",
       "<td>238.4615385</td>\n",
       "<td>238.4615385</td>\n",
       "<td>0.0317949</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.9963245</td>\n",
       "<td>3.3846154</td>\n",
       "<td>3.3846154</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9983397</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9991612</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.0769231</td>\n",
       "<td>238.4615385</td>\n",
       "<td>238.4615385</td>\n",
       "<td>0.0635897</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0340909</td>\n",
       "<td>0.9943115</td>\n",
       "<td>3.3846154</td>\n",
       "<td>3.3846154</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9947086</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9976770</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.1153846</td>\n",
       "<td>238.4615385</td>\n",
       "<td>238.4615385</td>\n",
       "<td>0.0953846</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.9937201</td>\n",
       "<td>6.7692308</td>\n",
       "<td>4.2307692</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9938094</td>\n",
       "<td>0.625</td>\n",
       "<td>0.9967101</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.1923077</td>\n",
       "<td>576.9230769</td>\n",
       "<td>323.0769231</td>\n",
       "<td>0.1723077</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0511364</td>\n",
       "<td>0.9763412</td>\n",
       "<td>0.0</td>\n",
       "<td>3.7606838</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9775552</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.9945818</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1923077</td>\n",
       "<td>-100.0</td>\n",
       "<td>276.0683761</td>\n",
       "<td>0.1656410</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1022727</td>\n",
       "<td>0.5301438</td>\n",
       "<td>2.2564103</td>\n",
       "<td>3.0085470</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.8899175</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.9422496</td>\n",
       "<td>0.1153846</td>\n",
       "<td>0.3076923</td>\n",
       "<td>125.6410256</td>\n",
       "<td>200.8547009</td>\n",
       "<td>0.2410256</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1534091</td>\n",
       "<td>0.1361475</td>\n",
       "<td>3.7606838</td>\n",
       "<td>3.2592593</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.2673719</td>\n",
       "<td>0.4814815</td>\n",
       "<td>0.7172904</td>\n",
       "<td>0.1923077</td>\n",
       "<td>0.5</td>\n",
       "<td>276.0683761</td>\n",
       "<td>225.9259259</td>\n",
       "<td>0.4066667</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.0516889</td>\n",
       "<td>2.2564103</td>\n",
       "<td>3.0085470</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.0889868</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.5602145</td>\n",
       "<td>0.1153846</td>\n",
       "<td>0.6153846</td>\n",
       "<td>125.6410256</td>\n",
       "<td>200.8547009</td>\n",
       "<td>0.4820513</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3011364</td>\n",
       "<td>0.0101030</td>\n",
       "<td>0.3981900</td>\n",
       "<td>2.1712627</td>\n",
       "<td>0.0588235</td>\n",
       "<td>0.0244045</td>\n",
       "<td>0.3207547</td>\n",
       "<td>0.3883509</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.6538462</td>\n",
       "<td>-60.1809955</td>\n",
       "<td>117.1262700</td>\n",
       "<td>0.4138462</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4034091</td>\n",
       "<td>0.0025541</td>\n",
       "<td>2.2564103</td>\n",
       "<td>2.1928494</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.0053476</td>\n",
       "<td>0.3239437</td>\n",
       "<td>0.2912515</td>\n",
       "<td>0.2307692</td>\n",
       "<td>0.8846154</td>\n",
       "<td>125.6410256</td>\n",
       "<td>119.2849404</td>\n",
       "<td>0.5646154</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0004614</td>\n",
       "<td>0.0</td>\n",
       "<td>1.7692308</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010518</td>\n",
       "<td>0.2613636</td>\n",
       "<td>0.2351902</td>\n",
       "<td>0.0</td>\n",
       "<td>0.8846154</td>\n",
       "<td>-100.0</td>\n",
       "<td>76.9230769</td>\n",
       "<td>0.4512821</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6022727</td>\n",
       "<td>0.0001360</td>\n",
       "<td>0.7521368</td>\n",
       "<td>1.5965167</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.0002748</td>\n",
       "<td>0.2358491</td>\n",
       "<td>0.1952989</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.9615385</td>\n",
       "<td>-24.7863248</td>\n",
       "<td>59.6516691</td>\n",
       "<td>0.4215385</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6988636</td>\n",
       "<td>0.0000380</td>\n",
       "<td>0.0</td>\n",
       "<td>1.3758599</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000686</td>\n",
       "<td>0.2032520</td>\n",
       "<td>0.1683158</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9615385</td>\n",
       "<td>-100.0</td>\n",
       "<td>37.5859912</td>\n",
       "<td>0.3082051</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8011364</td>\n",
       "<td>3.63e-06</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2002182</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000158</td>\n",
       "<td>0.1773050</td>\n",
       "<td>0.1468307</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9615385</td>\n",
       "<td>-100.0</td>\n",
       "<td>20.0218221</td>\n",
       "<td>0.1882051</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8977273</td>\n",
       "<td>6.15e-07</td>\n",
       "<td>0.3981900</td>\n",
       "<td>1.1139241</td>\n",
       "<td>0.0588235</td>\n",
       "<td>0.0000018</td>\n",
       "<td>0.1645570</td>\n",
       "<td>0.1310327</td>\n",
       "<td>0.0384615</td>\n",
       "<td>1.0</td>\n",
       "<td>-60.1809955</td>\n",
       "<td>11.3924051</td>\n",
       "<td>0.12</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000002</td>\n",
       "<td>0.1477273</td>\n",
       "<td>0.1176316</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.8179365</td>\n",
       "<td>0.1352280</td>\n",
       "<td>0.8611111</td>\n",
       "<td>0.6285715</td>\n",
       "<td>0.8285714</td>\n",
       "<td>0.7714286</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.8202349</td>\n",
       "<td>0.1284522</td>\n",
       "<td>0.8967742</td>\n",
       "<td>0.6724138</td>\n",
       "<td>0.7592593</td>\n",
       "<td>0.7727272</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.1820635</td>\n",
       "<td>0.1352280</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.3714286</td>\n",
       "<td>0.1714286</td>\n",
       "<td>0.2285714</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>6.4</td>\n",
       "<td>4.7222877</td>\n",
       "<td>5.0</td>\n",
       "<td>13.0</td>\n",
       "<td>6.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.5512977</td>\n",
       "<td>0.2959919</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.3378378</td>\n",
       "<td>0.625</td>\n",
       "<td>0.2380952</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.6012422</td>\n",
       "<td>0.2567396</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.4347826</td>\n",
       "<td>0.5714286</td>\n",
       "<td>0.3333333</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.7049922</td>\n",
       "<td>0.2042226</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.6097561</td>\n",
       "<td>0.5263158</td>\n",
       "<td>0.5555556</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>3.715</td>\n",
       "<td>3.5698214</td>\n",
       "<td>7.2</td>\n",
       "<td>0.0</td>\n",
       "<td>4.375</td>\n",
       "<td>0.0</td>\n",
       "<td>7.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.6949008</td>\n",
       "<td>0.3962450</td>\n",
       "<td>0.8113807</td>\n",
       "<td>0.9612369</td>\n",
       "<td>1.13753</td>\n",
       "<td>0.3410734</td>\n",
       "<td>0.2232830</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.2635015</td>\n",
       "<td>0.1992759</td>\n",
       "<td>0.1612903</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2424243</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.5655490</td>\n",
       "<td>0.2724567</td>\n",
       "<td>0.6475762</td>\n",
       "<td>0.3163644</td>\n",
       "<td>0.4745548</td>\n",
       "<td>0.3892495</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.8441752</td>\n",
       "<td>0.1288534</td>\n",
       "<td>0.9193549</td>\n",
       "<td>0.7097701</td>\n",
       "<td>0.712963</td>\n",
       "<td>0.8787879</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.1558248</td>\n",
       "<td>0.1288534</td>\n",
       "<td>0.0806452</td>\n",
       "<td>0.2902299</td>\n",
       "<td>0.2870370</td>\n",
       "<td>0.1212121</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1384705</td>\n",
       "<td>0.0635008</td>\n",
       "<td>0.1659251</td>\n",
       "<td>0.2009354</td>\n",
       "<td>0.1840445</td>\n",
       "<td>0.0602929</td>\n",
       "<td>0.0811549</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.5103099</td>\n",
       "<td>0.3483282</td>\n",
       "<td>0.562232</td>\n",
       "<td>0.2474944</td>\n",
       "<td>0.6306249</td>\n",
       "<td>0.1111981</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.5321569</td>\n",
       "<td>0.3181961</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2941177</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.2</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>-0.1255176</td>\n",
       "<td>0.3053708</td>\n",
       "<td>-0.3873475</td>\n",
       "<td>-0.414631</td>\n",
       "<td>-0.0437708</td>\n",
       "<td>-0.1190736</td>\n",
       "<td>0.3372348</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.8666667</td>\n",
       "<td>0.2173067</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3630049</td>\n",
       "<td>0.0915014</td>\n",
       "<td>0.4073390</td>\n",
       "<td>0.4482581</td>\n",
       "<td>0.4290041</td>\n",
       "<td>0.2455462</td>\n",
       "<td>0.2848770</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.8216836</td>\n",
       "<td>0.1600876</td>\n",
       "<td>0.8387096</td>\n",
       "<td>0.5862069</td>\n",
       "<td>0.9259259</td>\n",
       "<td>0.7575757</td>\n",
       "<td>1.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-10.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-10 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-10 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-10 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table th,\n",
       "#h2o-table-10 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2023-05-24 09:04:19</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-24 09:04:19</td>\n",
       "<td> 1 min 17.936 sec</td>\n",
       "<td>18333 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>1</td>\n",
       "<td>1760.0</td>\n",
       "<td>0.2598035</td>\n",
       "<td>0.2337768</td>\n",
       "<td>0.4638937</td>\n",
       "<td>0.9448718</td>\n",
       "<td>0.7749020</td>\n",
       "<td>6.7692308</td>\n",
       "<td>0.0795455</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-24 09:04:21</td>\n",
       "<td> 1 min 20.517 sec</td>\n",
       "<td>23149 obs/sec</td>\n",
       "<td>350.0</td>\n",
       "<td>35</td>\n",
       "<td>61600.0</td>\n",
       "<td>0.0042556</td>\n",
       "<td>0.0007152</td>\n",
       "<td>0.9998562</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.7692308</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-11.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-11 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-11 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-11 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table th,\n",
       "#h2o-table-11 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>Cinematography</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0287648</td></tr>\n",
       "<tr><td>Sound</td>\n",
       "<td>0.9666976</td>\n",
       "<td>0.9666976</td>\n",
       "<td>0.0278068</td></tr>\n",
       "<tr><td>Film Editing</td>\n",
       "<td>0.9421129</td>\n",
       "<td>0.9421129</td>\n",
       "<td>0.0270997</td></tr>\n",
       "<tr><td>fantasy</td>\n",
       "<td>0.8859197</td>\n",
       "<td>0.8859197</td>\n",
       "<td>0.0254833</td></tr>\n",
       "<tr><td>winner_dga</td>\n",
       "<td>0.8770376</td>\n",
       "<td>0.8770376</td>\n",
       "<td>0.0252278</td></tr>\n",
       "<tr><td>year</td>\n",
       "<td>0.8713606</td>\n",
       "<td>0.8713606</td>\n",
       "<td>0.0250645</td></tr>\n",
       "<tr><td>Writing</td>\n",
       "<td>0.8564401</td>\n",
       "<td>0.8564401</td>\n",
       "<td>0.0246353</td></tr>\n",
       "<tr><td>nom_gg_drama</td>\n",
       "<td>0.8487479</td>\n",
       "<td>0.8487479</td>\n",
       "<td>0.0244140</td></tr>\n",
       "<tr><td>animation</td>\n",
       "<td>0.8429738</td>\n",
       "<td>0.8429738</td>\n",
       "<td>0.0242479</td></tr>\n",
       "<tr><td>biography</td>\n",
       "<td>0.8374502</td>\n",
       "<td>0.8374502</td>\n",
       "<td>0.0240891</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>nom_pga</td>\n",
       "<td>0.6655245</td>\n",
       "<td>0.6655245</td>\n",
       "<td>0.0191437</td></tr>\n",
       "<tr><td>nom_sag</td>\n",
       "<td>0.6598480</td>\n",
       "<td>0.6598480</td>\n",
       "<td>0.0189804</td></tr>\n",
       "<tr><td>sci-fi</td>\n",
       "<td>0.6524937</td>\n",
       "<td>0.6524937</td>\n",
       "<td>0.0187688</td></tr>\n",
       "<tr><td>nom_bafta</td>\n",
       "<td>0.6417699</td>\n",
       "<td>0.6417699</td>\n",
       "<td>0.0184604</td></tr>\n",
       "<tr><td>crime</td>\n",
       "<td>0.6242755</td>\n",
       "<td>0.6242755</td>\n",
       "<td>0.0179571</td></tr>\n",
       "<tr><td>winner_pga</td>\n",
       "<td>0.6173485</td>\n",
       "<td>0.6173485</td>\n",
       "<td>0.0177579</td></tr>\n",
       "<tr><td>adventure</td>\n",
       "<td>0.5881366</td>\n",
       "<td>0.5881366</td>\n",
       "<td>0.0169176</td></tr>\n",
       "<tr><td>musical</td>\n",
       "<td>0.5724465</td>\n",
       "<td>0.5724465</td>\n",
       "<td>0.0164663</td></tr>\n",
       "<tr><td>nom_dga</td>\n",
       "<td>0.5532149</td>\n",
       "<td>0.5532149</td>\n",
       "<td>0.0159131</td></tr>\n",
       "<tr><td>winner_bafta</td>\n",
       "<td>0.5306445</td>\n",
       "<td>0.5306445</td>\n",
       "<td>0.0152639</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[46 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_1_20230524_85722_model_5\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 15 002 weights/biases, 187,0 KB, 61 600 training samples, mini-batch size 1\n",
       "    layer    units    type              dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight           weight_rms           mean_bias             bias_rms\n",
       "--  -------  -------  ----------------  ---------  ----  ----  --------------------  --------------------  ----------  --------------------  -------------------  --------------------  --------------------\n",
       "    1        46       Input             10.0\n",
       "    2        100      RectifierDropout  40.0       0.0   0.0   0.024001602752263273  0.033011242747306824  0.0         0.008695049894723406  0.14952033758163452  0.36261498813666504   0.0869915783405304\n",
       "    3        100      RectifierDropout  40.0       0.0   0.0   0.0412027502400917    0.11048451066017151   0.0         -0.02315176722473684  0.11381083726882935  0.8343523728225254    0.09808292984962463\n",
       "    4        2        Softmax                      0.0   0.0   0.011748650879599153  0.009497851133346558  0.0         -0.04135797238530358  0.5311203002929688   0.004755425862202034  0.005320673808455467\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 1.811046872184211e-05\n",
       "RMSE: 0.0042556396372157865\n",
       "LogLoss: 0.0007151719579600746\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9929139937321374\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      150  0    0        (0.0/150.0)\n",
       "1      0    26   0        (0.0/26.0)\n",
       "Total  150  26   0        (0.0/176.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.992914     1         25\n",
       "max f2                       0.992914     1         25\n",
       "max f0point5                 0.992914     1         25\n",
       "max accuracy                 0.992914     1         25\n",
       "max precision                1            1         0\n",
       "max recall                   0.992914     1         25\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.992914     1         25\n",
       "max min_per_class_accuracy   0.992914     1         25\n",
       "max mean_per_class_accuracy  0.992914     1         25\n",
       "max tns                      1            150       0\n",
       "max fns                      1            25        0\n",
       "max fps                      4.66436e-18  150       175\n",
       "max tps                      0.992914     26        25\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.961538  0\n",
       "max fpr                      4.66436e-18  1         175\n",
       "max tpr                      0.992914     1         25\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,77 %, avg score: 14,82 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0113636                   0.999998           6.76923  6.76923            1                0.999999     1                           0.999999            0.0769231       0.0769231                  576.923  576.923            0.0769231\n",
       "2        0.0227273                   0.999995           6.76923  6.76923            1                0.999997     1                           0.999998            0.0769231       0.153846                   576.923  576.923            0.153846\n",
       "3        0.0340909                   0.99999            6.76923  6.76923            1                0.999992     1                           0.999996            0.0769231       0.230769                   576.923  576.923            0.230769\n",
       "4        0.0454545                   0.99998            6.76923  6.76923            1                0.999984     1                           0.999993            0.0769231       0.307692                   576.923  576.923            0.307692\n",
       "5        0.0511364                   0.999978           6.76923  6.76923            1                0.999979     1                           0.999991            0.0384615       0.346154                   576.923  576.923            0.346154\n",
       "6        0.102273                    0.999666           6.76923  6.76923            1                0.999854     1                           0.999923            0.346154        0.692308                   576.923  576.923            0.692308\n",
       "7        0.153409                    0.041779           6.01709  6.51852            0.888889         0.892182     0.962963                    0.964009            0.307692        1                          501.709  551.852            0.993333\n",
       "8        0.204545                    0.00113631         0        4.88889            0                0.00619106   0.722222                    0.724555            0               1                          -100     388.889            0.933333\n",
       "9        0.301136                    8.75713e-05        0        3.32075            0                0.000284727  0.490566                    0.492242            0               1                          -100     232.075            0.82\n",
       "10       0.403409                    1.4011e-05         0        2.47887            0                4.05564e-05  0.366197                    0.367458            0               1                          -100     147.887            0.7\n",
       "11       0.5                         3.73337e-06        0        2                  0                7.64592e-06  0.295455                    0.296474            0               1                          -100     100                0.586667\n",
       "12       0.602273                    9.25663e-07        0        1.66038            0                1.77168e-06  0.245283                    0.246129            0               1                          -100     66.0377            0.466667\n",
       "13       0.698864                    1.8219e-07         0        1.43089            0                4.7178e-07   0.211382                    0.212111            0               1                          -100     43.0894            0.353333\n",
       "14       0.801136                    3.32252e-09        0        1.24823            0                6.22435e-08  0.184397                    0.185033            0               1                          -100     24.8227            0.233333\n",
       "15       0.897727                    4.50653e-11        0        1.11392            0                9.49407e-10  0.164557                    0.165125            0               1                          -100     11.3924            0.12\n",
       "16       1                           4.66436e-18        0        1                  0                5.87157e-12  0.147727                    0.148237            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.138626542100689\n",
       "RMSE: 0.37232585473035446\n",
       "LogLoss: 0.6955626030444713\n",
       "Mean Per-Class Error: 0.248974358974359\n",
       "AUC: 0.8305128205128205\n",
       "AUCPR: 0.4482871529081092\n",
       "Gini: 0.661025641025641\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.07940738509974507\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      133  17   0.1133   (17.0/150.0)\n",
       "1      10   16   0.3846   (10.0/26.0)\n",
       "Total  143  33   0.1534   (27.0/176.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.0794074    0.542373  32\n",
       "max f2                       0.00292745   0.668605  67\n",
       "max f0point5                 0.0794074    0.506329  32\n",
       "max accuracy                 0.99372      0.863636  7\n",
       "max precision                0.999984     1         0\n",
       "max recall                   1.67547e-06  1         147\n",
       "max specificity              0.999984     1         0\n",
       "max absolute_mcc             0.0794074    0.45641   32\n",
       "max min_per_class_accuracy   0.00790987   0.746667  57\n",
       "max mean_per_class_accuracy  0.00292745   0.792308  67\n",
       "max tns                      0.999984     150       0\n",
       "max fns                      0.999984     25        0\n",
       "max fps                      1.11845e-09  150       175\n",
       "max tps                      1.67547e-06  26        147\n",
       "max tnr                      0.999984     1         0\n",
       "max fnr                      0.999984     0.961538  0\n",
       "max fpr                      1.11845e-09  1         175\n",
       "max tpr                      1.67547e-06  1         147\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,77 %, avg score: 11,76 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0113636                   0.999244           3.38462   3.38462            0.5              0.999983     0.5                         0.999983            0.0384615       0.0384615                  238.462   238.462            0.0317949\n",
       "2        0.0227273                   0.996324           3.38462   3.38462            0.5              0.99834      0.5                         0.999161            0.0384615       0.0769231                  238.462   238.462            0.0635897\n",
       "3        0.0340909                   0.994311           3.38462   3.38462            0.5              0.994709     0.5                         0.997677            0.0384615       0.115385                   238.462   238.462            0.0953846\n",
       "4        0.0454545                   0.99372            6.76923   4.23077            1                0.993809     0.625                       0.99671             0.0769231       0.192308                   576.923   323.077            0.172308\n",
       "5        0.0511364                   0.976341           0         3.76068            0                0.977555     0.555556                    0.994582            0               0.192308                   -100      276.068            0.165641\n",
       "6        0.102273                    0.530144           2.25641   3.00855            0.333333         0.889917     0.444444                    0.94225             0.115385        0.307692                   125.641   200.855            0.241026\n",
       "7        0.153409                    0.136148           3.76068   3.25926            0.555556         0.267372     0.481481                    0.71729             0.192308        0.5                        276.068   225.926            0.406667\n",
       "8        0.204545                    0.0516889          2.25641   3.00855            0.333333         0.0889868    0.444444                    0.560214            0.115385        0.615385                   125.641   200.855            0.482051\n",
       "9        0.301136                    0.010103           0.39819   2.17126            0.0588235        0.0244045    0.320755                    0.388351            0.0384615       0.653846                   -60.181   117.126            0.413846\n",
       "10       0.403409                    0.00255415         2.25641   2.19285            0.333333         0.00534765   0.323944                    0.291251            0.230769        0.884615                   125.641   119.285            0.564615\n",
       "11       0.5                         0.00046136         0         1.76923            0                0.00105179   0.261364                    0.23519             0               0.884615                   -100      76.9231            0.451282\n",
       "12       0.602273                    0.00013598         0.752137  1.59652            0.111111         0.000274824  0.235849                    0.195299            0.0769231       0.961538                   -24.7863  59.6517            0.421538\n",
       "13       0.698864                    3.802e-05          0         1.37586            0                6.85518e-05  0.203252                    0.168316            0               0.961538                   -100      37.586             0.308205\n",
       "14       0.801136                    3.63e-06           0         1.20022            0                1.58306e-05  0.177305                    0.146831            0               0.961538                   -100      20.0218            0.188205\n",
       "15       0.897727                    6.15e-07           0.39819   1.11392            0.0588235        1.76706e-06  0.164557                    0.131033            0.0384615       1                          -60.181   11.3924            0.12\n",
       "16       1                           0                  0         1                  0                1.96111e-07  0.147727                    0.117632            0               1                          -100      0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean       sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.817936   0.135228   0.861111      0.628571      0.828571      0.771429      1\n",
       "auc                      0.820235   0.128452   0.896774      0.672414      0.759259      0.772727      1\n",
       "err                      0.182063   0.135228   0.138889      0.371429      0.171429      0.228571      0\n",
       "err_count                6.4        4.72229    5             13            6             8             0\n",
       "f0point5                 0.551298   0.295992   0.555556      0.337838      0.625         0.238095      1\n",
       "f1                       0.601242   0.25674    0.666667      0.434783      0.571429      0.333333      1\n",
       "f2                       0.704992   0.204223   0.833333      0.609756      0.526316      0.555556      1\n",
       "lift_top_group           3.715      3.56982    7.2           0             4.375         0             7\n",
       "logloss                  0.694901   0.396245   0.811381      0.961237      1.13753       0.341073      0.223283\n",
       "max_per_class_error      0.263502   0.199276   0.16129       0.413793      0.5           0.242424      0\n",
       "mcc                      0.565549   0.272457   0.647576      0.316364      0.474555      0.389249      1\n",
       "mean_per_class_accuracy  0.844175   0.128853   0.919355      0.70977       0.712963      0.878788      1\n",
       "mean_per_class_error     0.155825   0.128853   0.0806452     0.29023       0.287037      0.121212      0\n",
       "mse                      0.138471   0.0635008  0.165925      0.200935      0.184044      0.0602929     0.0811549\n",
       "pr_auc                   0.51031    0.348328   0.562232      0.247494      0.630625      0.111198      1\n",
       "precision                0.532157   0.318196   0.5           0.294118      0.666667      0.2           1\n",
       "r2                       -0.125518  0.305371   -0.387348     -0.414631     -0.0437708    -0.119074     0.337235\n",
       "recall                   0.866667   0.217307   1             0.833333      0.5           1             1\n",
       "rmse                     0.363005   0.0915014  0.407339      0.448258      0.429004      0.245546      0.284877\n",
       "specificity              0.821684   0.160088   0.83871       0.586207      0.925926      0.757576      1\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2023-05-24 09:04:19  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan\n",
       "    2023-05-24 09:04:19  1 min 17.936 sec  18333 obs/sec     10        1             1760       0.259804         0.233777            0.463894       0.944872        0.774902           6.76923          0.0795455\n",
       "    2023-05-24 09:04:21  1 min 20.517 sec  23149 obs/sec     350       35            61600      0.00425564       0.000715172         0.999856       1               1                  6.76923          0\n",
       "\n",
       "Variable Importances: \n",
       "variable        relative_importance    scaled_importance    percentage\n",
       "--------------  ---------------------  -------------------  --------------------\n",
       "Cinematography  1.0                    1.0                  0.028764766737907455\n",
       "Sound           0.9666975736618042     0.9666975736618042   0.027806830212482907\n",
       "Film Editing    0.9421128630638123     0.9421128630638123   0.02709965674681271\n",
       "fantasy         0.8859196901321411     0.8859196901321411   0.02548327323517029\n",
       "winner_dga      0.8770375847816467     0.8770375847816467   0.0252277815466218\n",
       "year            0.8713605999946594     0.8713605999946594   0.025064484403449463\n",
       "Writing         0.8564401268959045     0.8564401268959045   0.024635300475144555\n",
       "nom_gg_drama    0.8487479090690613     0.8487479090690613   0.024414035623658233\n",
       "animation       0.8429737687110901     0.8429737687110901   0.024247943823149255\n",
       "biography       0.8374502062797546     0.8374502062797546   0.024089059838249622\n",
       "---             ---                    ---                  ---\n",
       "nom_pga         0.6655244827270508     0.6655244827270508   0.019143656504010134\n",
       "nom_sag         0.6598480343818665     0.6598480343818665   0.018980374791461127\n",
       "sci-fi          0.6524936556816101     0.6524936556816101   0.018768827803646016\n",
       "nom_bafta       0.6417699456214905     0.6417699456214905   0.018460362785201724\n",
       "crime           0.6242755055427551     0.6242755055427551   0.017957139297126605\n",
       "winner_pga      0.6173484921455383     0.6173484921455383   0.017757885372565303\n",
       "adventure       0.588136613368988      0.588136613368988    0.016917612493581802\n",
       "musical         0.5724464654922485     0.5724464654922485   0.01646628904982412\n",
       "nom_dga         0.5532149076461792     0.5532149076461792   0.01591309777437536\n",
       "winner_bafta    0.5306445360183716     0.5306445360183716   0.015263866299313589\n",
       "[46 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model = aml.leader\n",
    "top_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model jest na wszystkich danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the leaderboard\n",
    "leaderboard = aml.leaderboard\n",
    "\n",
    "# Get the model ID of the third model (assuming zero-based indexing)\n",
    "third_model_id = leaderboard[2, 'model_id']\n",
    "\n",
    "# Retrieve the model from the third position using the model ID\n",
    "third_model = h2o.get_model(third_model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_1_20230524_85722_model_22\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-12.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-12 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-12 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-12 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table th,\n",
       "#h2o-table-12 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-12 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-12\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 5 002 weights/biases, 68,6 KB, 103 840 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>46</td>\n",
       "<td>Input</td>\n",
       "<td>15.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>50</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>30.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0388930</td>\n",
       "<td>0.1034923</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0099326</td>\n",
       "<td>0.1927573</td>\n",
       "<td>0.4152283</td>\n",
       "<td>0.1329616</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>50</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>30.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0356380</td>\n",
       "<td>0.1158385</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0130971</td>\n",
       "<td>0.1586027</td>\n",
       "<td>0.8645436</td>\n",
       "<td>0.1220017</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0188418</td>\n",
       "<td>0.0968402</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0268669</td>\n",
       "<td>0.7908759</td>\n",
       "<td>-0.0138362</td>\n",
       "<td>0.3820567</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.0002918639572209168\n",
       "RMSE: 0.01708402637614789\n",
       "LogLoss: 0.00258135695067732\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-13.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-13 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-13 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-13 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table th,\n",
       "#h2o-table-13 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-13 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-13\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9935320906464516</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/150.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>26.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/26.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>150.0</td>\n",
       "<td>26.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/176.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-14.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-14 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-14 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-14 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-14 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-14 .h2o-table th,\n",
       "#h2o-table-14 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-14 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-14\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999997</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999997</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999997</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999997</td>\n",
       "<td>25.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>150.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.9935321</td>\n",
       "<td>26.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999997</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999997</td>\n",
       "<td>0.9615385</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-15.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-15 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-15 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-15 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-15 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-15 .h2o-table th,\n",
       "#h2o-table-15 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-15 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-15\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,77 %, avg score: 14,99 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0113636</td>\n",
       "<td>0.9999996</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999997</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999997</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.0769231</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.0769231</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.9999986</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999992</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999995</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.1538462</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.1538462</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0340909</td>\n",
       "<td>0.9999955</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999970</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999986</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.2307692</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.2307692</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.9999896</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999924</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999971</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.3076923</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.3076923</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0511364</td>\n",
       "<td>0.9999699</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999804</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999952</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.3461538</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.3461538</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1022727</td>\n",
       "<td>0.9997540</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998751</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999351</td>\n",
       "<td>0.3461538</td>\n",
       "<td>0.6923077</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.6923077</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1534091</td>\n",
       "<td>0.1728078</td>\n",
       "<td>6.0170940</td>\n",
       "<td>6.5185185</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.9085394</td>\n",
       "<td>0.9629630</td>\n",
       "<td>0.9694699</td>\n",
       "<td>0.3076923</td>\n",
       "<td>1.0</td>\n",
       "<td>501.7094017</td>\n",
       "<td>551.8518519</td>\n",
       "<td>0.9933333</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.0038251</td>\n",
       "<td>0.0</td>\n",
       "<td>4.8888889</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0219737</td>\n",
       "<td>0.7222222</td>\n",
       "<td>0.7325959</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>388.8888889</td>\n",
       "<td>0.9333333</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3011364</td>\n",
       "<td>0.0000652</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3207547</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0008912</td>\n",
       "<td>0.4905660</td>\n",
       "<td>0.4978981</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>232.0754717</td>\n",
       "<td>0.8200000</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4034091</td>\n",
       "<td>0.0000078</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4788732</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000297</td>\n",
       "<td>0.3661972</td>\n",
       "<td>0.3716780</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>147.8873239</td>\n",
       "<td>0.7</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0000016</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000043</td>\n",
       "<td>0.2954545</td>\n",
       "<td>0.2998774</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td>\n",
       "<td>0.5866667</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6022727</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6603774</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.2452830</td>\n",
       "<td>0.2489549</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.0377358</td>\n",
       "<td>0.4666667</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6988636</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4308943</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.2113821</td>\n",
       "<td>0.2145465</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.0894309</td>\n",
       "<td>0.3533333</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8011364</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2482270</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1843972</td>\n",
       "<td>0.1871576</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.8226950</td>\n",
       "<td>0.2333333</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8977273</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1139241</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1645570</td>\n",
       "<td>0.1670204</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.3924051</td>\n",
       "<td>0.12</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1477273</td>\n",
       "<td>0.1499387</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.10366535538522567\n",
       "RMSE: 0.32197104743319027\n",
       "LogLoss: 0.46443296707093845\n",
       "Mean Per-Class Error: 0.25153846153846154\n",
       "AUC: 0.8171794871794872\n",
       "AUCPR: 0.5130330741669865\n",
       "Gini: 0.6343589743589744</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-16.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-16 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-16 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-16 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-16 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-16 .h2o-table th,\n",
       "#h2o-table-16 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-16 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-16\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.15663830936437467</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>138.0</td>\n",
       "<td>12.0</td>\n",
       "<td>0.08</td>\n",
       "<td> (12.0/150.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>11.0</td>\n",
       "<td>15.0</td>\n",
       "<td>0.4231</td>\n",
       "<td> (11.0/26.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>149.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.1307</td>\n",
       "<td> (23.0/176.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-17.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-17 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-17 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-17 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-17 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-17 .h2o-table th,\n",
       "#h2o-table-17 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-17 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-17\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.1566383</td>\n",
       "<td>0.5660377</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0663705</td>\n",
       "<td>0.6071429</td>\n",
       "<td>35.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4022784</td>\n",
       "<td>0.6382979</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4022784</td>\n",
       "<td>0.8920455</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9977479</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0006610</td>\n",
       "<td>1.0</td>\n",
       "<td>122.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9977479</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4022784</td>\n",
       "<td>0.5143528</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0102010</td>\n",
       "<td>0.7066667</td>\n",
       "<td>62.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0663705</td>\n",
       "<td>0.7635897</td>\n",
       "<td>35.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9977479</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9977479</td>\n",
       "<td>25.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000003</td>\n",
       "<td>150.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0006610</td>\n",
       "<td>26.0</td>\n",
       "<td>122.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9977479</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9977479</td>\n",
       "<td>0.9615385</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000003</td>\n",
       "<td>1.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0006610</td>\n",
       "<td>1.0</td>\n",
       "<td>122.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-18.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-18 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-18 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-18 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-18 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-18 .h2o-table th,\n",
       "#h2o-table-18 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-18 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-18\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,77 %, avg score:  9,17 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0113636</td>\n",
       "<td>0.9867128</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974541</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974541</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.0769231</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.0769231</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.9647778</td>\n",
       "<td>3.3846154</td>\n",
       "<td>5.0769231</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9769173</td>\n",
       "<td>0.75</td>\n",
       "<td>0.9871857</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.1153846</td>\n",
       "<td>238.4615385</td>\n",
       "<td>407.6923077</td>\n",
       "<td>0.1087179</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0340909</td>\n",
       "<td>0.8916931</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3846154</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9325579</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9689764</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1153846</td>\n",
       "<td>-100.0</td>\n",
       "<td>238.4615385</td>\n",
       "<td>0.0953846</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.7247166</td>\n",
       "<td>6.7692308</td>\n",
       "<td>4.2307692</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7864977</td>\n",
       "<td>0.625</td>\n",
       "<td>0.9233568</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.1923077</td>\n",
       "<td>576.9230769</td>\n",
       "<td>323.0769231</td>\n",
       "<td>0.1723077</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0511364</td>\n",
       "<td>0.6575481</td>\n",
       "<td>0.0</td>\n",
       "<td>3.7606838</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6739311</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.8956428</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1923077</td>\n",
       "<td>-100.0</td>\n",
       "<td>276.0683761</td>\n",
       "<td>0.1656410</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1022727</td>\n",
       "<td>0.2656580</td>\n",
       "<td>5.2649573</td>\n",
       "<td>4.5128205</td>\n",
       "<td>0.7777778</td>\n",
       "<td>0.4822783</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.6889606</td>\n",
       "<td>0.2692308</td>\n",
       "<td>0.4615385</td>\n",
       "<td>426.4957265</td>\n",
       "<td>351.2820513</td>\n",
       "<td>0.4215385</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1534091</td>\n",
       "<td>0.1538703</td>\n",
       "<td>2.2564103</td>\n",
       "<td>3.7606838</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.1971789</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.5250333</td>\n",
       "<td>0.1153846</td>\n",
       "<td>0.5769231</td>\n",
       "<td>125.6410256</td>\n",
       "<td>276.0683761</td>\n",
       "<td>0.4969231</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.0663705</td>\n",
       "<td>1.5042735</td>\n",
       "<td>3.1965812</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.1118445</td>\n",
       "<td>0.4722222</td>\n",
       "<td>0.4217361</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.6538462</td>\n",
       "<td>50.4273504</td>\n",
       "<td>219.6581197</td>\n",
       "<td>0.5271795</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3011364</td>\n",
       "<td>0.0172974</td>\n",
       "<td>0.3981900</td>\n",
       "<td>2.2989840</td>\n",
       "<td>0.0588235</td>\n",
       "<td>0.0333273</td>\n",
       "<td>0.3396226</td>\n",
       "<td>0.2971522</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.6923077</td>\n",
       "<td>-60.1809955</td>\n",
       "<td>129.8984035</td>\n",
       "<td>0.4589744</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4034091</td>\n",
       "<td>0.0088347</td>\n",
       "<td>0.7521368</td>\n",
       "<td>1.9068256</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.0115442</td>\n",
       "<td>0.2816901</td>\n",
       "<td>0.2247445</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.7692308</td>\n",
       "<td>-24.7863248</td>\n",
       "<td>90.6825569</td>\n",
       "<td>0.4292308</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0037716</td>\n",
       "<td>0.7963801</td>\n",
       "<td>1.6923077</td>\n",
       "<td>0.1176471</td>\n",
       "<td>0.0067207</td>\n",
       "<td>0.25</td>\n",
       "<td>0.1826263</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.8461538</td>\n",
       "<td>-20.3619910</td>\n",
       "<td>69.2307692</td>\n",
       "<td>0.4061538</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6022727</td>\n",
       "<td>0.0013098</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4049347</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0021203</td>\n",
       "<td>0.2075472</td>\n",
       "<td>0.1519743</td>\n",
       "<td>0.0</td>\n",
       "<td>0.8461538</td>\n",
       "<td>-100.0</td>\n",
       "<td>40.4934688</td>\n",
       "<td>0.2861538</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6988636</td>\n",
       "<td>0.0006594</td>\n",
       "<td>1.5927602</td>\n",
       "<td>1.4308943</td>\n",
       "<td>0.2352941</td>\n",
       "<td>0.0009641</td>\n",
       "<td>0.2113821</td>\n",
       "<td>0.1311030</td>\n",
       "<td>0.1538462</td>\n",
       "<td>1.0</td>\n",
       "<td>59.2760181</td>\n",
       "<td>43.0894309</td>\n",
       "<td>0.3533333</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8011364</td>\n",
       "<td>0.0001918</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2482270</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003688</td>\n",
       "<td>0.1843972</td>\n",
       "<td>0.1144135</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.8226950</td>\n",
       "<td>0.2333333</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8977273</td>\n",
       "<td>0.0000629</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1139241</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001277</td>\n",
       "<td>0.1645570</td>\n",
       "<td>0.1021169</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.3924051</td>\n",
       "<td>0.12</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>2.8e-07</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000237</td>\n",
       "<td>0.1477273</td>\n",
       "<td>0.0916756</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-19.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-19 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-19 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-19 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-19 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-19 .h2o-table th,\n",
       "#h2o-table-19 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-19 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-19\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.8806349</td>\n",
       "<td>0.0652379</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.8285714</td>\n",
       "<td>0.8</td>\n",
       "<td>0.9428572</td>\n",
       "<td>0.9428572</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.8479612</td>\n",
       "<td>0.0982881</td>\n",
       "<td>0.9354839</td>\n",
       "<td>0.7988506</td>\n",
       "<td>0.7175926</td>\n",
       "<td>0.9545454</td>\n",
       "<td>0.8333333</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.1193651</td>\n",
       "<td>0.0652379</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.1714286</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0571429</td>\n",
       "<td>0.0571429</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>4.2</td>\n",
       "<td>2.280351</td>\n",
       "<td>4.0</td>\n",
       "<td>6.0</td>\n",
       "<td>7.0</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.6094366</td>\n",
       "<td>0.1107135</td>\n",
       "<td>0.6097561</td>\n",
       "<td>0.5263158</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.8</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.6571429</td>\n",
       "<td>0.1077496</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.5714286</td>\n",
       "<td>0.5333334</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.8</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.7266446</td>\n",
       "<td>0.1509600</td>\n",
       "<td>0.8620689</td>\n",
       "<td>0.625</td>\n",
       "<td>0.5128205</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.8</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>4.0066667</td>\n",
       "<td>3.6946206</td>\n",
       "<td>7.2</td>\n",
       "<td>5.8333335</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>7.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.4649309</td>\n",
       "<td>0.2637554</td>\n",
       "<td>0.3772995</td>\n",
       "<td>0.5116247</td>\n",
       "<td>0.9001822</td>\n",
       "<td>0.24305</td>\n",
       "<td>0.2924979</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.2445943</td>\n",
       "<td>0.1748582</td>\n",
       "<td>0.1290322</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0606061</td>\n",
       "<td>0.2</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.6060845</td>\n",
       "<td>0.1553404</td>\n",
       "<td>0.6956083</td>\n",
       "<td>0.4745548</td>\n",
       "<td>0.4082483</td>\n",
       "<td>0.6853444</td>\n",
       "<td>0.7666667</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.8494653</td>\n",
       "<td>0.1164849</td>\n",
       "<td>0.9354839</td>\n",
       "<td>0.7643678</td>\n",
       "<td>0.6944444</td>\n",
       "<td>0.969697</td>\n",
       "<td>0.8833333</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.1505347</td>\n",
       "<td>0.1164849</td>\n",
       "<td>0.0645161</td>\n",
       "<td>0.2356322</td>\n",
       "<td>0.3055556</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.1166667</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1036406</td>\n",
       "<td>0.0538626</td>\n",
       "<td>0.1079964</td>\n",
       "<td>0.1138983</td>\n",
       "<td>0.1859831</td>\n",
       "<td>0.0552518</td>\n",
       "<td>0.0550734</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.5750192</td>\n",
       "<td>0.1783179</td>\n",
       "<td>0.7038902</td>\n",
       "<td>0.5905984</td>\n",
       "<td>0.4279301</td>\n",
       "<td>0.3657443</td>\n",
       "<td>0.7869329</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.5853968</td>\n",
       "<td>0.1242230</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5714286</td>\n",
       "<td>0.5</td>\n",
       "<td>0.8</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.1530204</td>\n",
       "<td>0.2439249</td>\n",
       "<td>0.0970112</td>\n",
       "<td>0.1981297</td>\n",
       "<td>-0.0547655</td>\n",
       "<td>-0.0255071</td>\n",
       "<td>0.5502338</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.7933334</td>\n",
       "<td>0.2165384</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3134216</td>\n",
       "<td>0.0822153</td>\n",
       "<td>0.3286280</td>\n",
       "<td>0.3374882</td>\n",
       "<td>0.4312576</td>\n",
       "<td>0.2350570</td>\n",
       "<td>0.2346773</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9055973</td>\n",
       "<td>0.0454004</td>\n",
       "<td>0.8709678</td>\n",
       "<td>0.8620689</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.9393939</td>\n",
       "<td>0.9666666</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-20.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-20 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-20 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-20 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-20 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-20 .h2o-table th,\n",
       "#h2o-table-20 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-20 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-20\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2023-05-24 09:09:09</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-24 09:09:09</td>\n",
       "<td> 6 min  8.005 sec</td>\n",
       "<td>33207 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>1</td>\n",
       "<td>1760.0</td>\n",
       "<td>0.2542635</td>\n",
       "<td>0.2367326</td>\n",
       "<td>0.4865137</td>\n",
       "<td>0.9387179</td>\n",
       "<td>0.7675712</td>\n",
       "<td>6.7692308</td>\n",
       "<td>0.0738636</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-24 09:09:12</td>\n",
       "<td> 6 min 10.633 sec</td>\n",
       "<td>38949 obs/sec</td>\n",
       "<td>590.0</td>\n",
       "<td>59</td>\n",
       "<td>103840.0</td>\n",
       "<td>0.0170840</td>\n",
       "<td>0.0025814</td>\n",
       "<td>0.9976819</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.7692308</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-21.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-21 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-21 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-21 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table th,\n",
       "#h2o-table-21 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-21 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-21\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>Cinematography</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0361720</td></tr>\n",
       "<tr><td>winner_sag</td>\n",
       "<td>0.7646658</td>\n",
       "<td>0.7646658</td>\n",
       "<td>0.0276595</td></tr>\n",
       "<tr><td>rating</td>\n",
       "<td>0.7306981</td>\n",
       "<td>0.7306981</td>\n",
       "<td>0.0264308</td></tr>\n",
       "<tr><td>history</td>\n",
       "<td>0.7269079</td>\n",
       "<td>0.7269079</td>\n",
       "<td>0.0262937</td></tr>\n",
       "<tr><td>biography</td>\n",
       "<td>0.7232850</td>\n",
       "<td>0.7232850</td>\n",
       "<td>0.0261627</td></tr>\n",
       "<tr><td>Film Editing</td>\n",
       "<td>0.7223579</td>\n",
       "<td>0.7223579</td>\n",
       "<td>0.0261292</td></tr>\n",
       "<tr><td>winner_dga</td>\n",
       "<td>0.7008595</td>\n",
       "<td>0.7008595</td>\n",
       "<td>0.0253515</td></tr>\n",
       "<tr><td>numVotes</td>\n",
       "<td>0.6862598</td>\n",
       "<td>0.6862598</td>\n",
       "<td>0.0248234</td></tr>\n",
       "<tr><td>year</td>\n",
       "<td>0.6608877</td>\n",
       "<td>0.6608877</td>\n",
       "<td>0.0239057</td></tr>\n",
       "<tr><td>Sound</td>\n",
       "<td>0.6562886</td>\n",
       "<td>0.6562886</td>\n",
       "<td>0.0237393</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>nominations</td>\n",
       "<td>0.5305830</td>\n",
       "<td>0.5305830</td>\n",
       "<td>0.0191923</td></tr>\n",
       "<tr><td>Directing</td>\n",
       "<td>0.5289589</td>\n",
       "<td>0.5289589</td>\n",
       "<td>0.0191335</td></tr>\n",
       "<tr><td>adventure</td>\n",
       "<td>0.5270043</td>\n",
       "<td>0.5270043</td>\n",
       "<td>0.0190628</td></tr>\n",
       "<tr><td>winner_bafta</td>\n",
       "<td>0.5157127</td>\n",
       "<td>0.5157127</td>\n",
       "<td>0.0186544</td></tr>\n",
       "<tr><td>winner_gg_comedy</td>\n",
       "<td>0.5098381</td>\n",
       "<td>0.5098381</td>\n",
       "<td>0.0184419</td></tr>\n",
       "<tr><td>sport</td>\n",
       "<td>0.4981127</td>\n",
       "<td>0.4981127</td>\n",
       "<td>0.0180178</td></tr>\n",
       "<tr><td>nom_gg_comedy</td>\n",
       "<td>0.4789034</td>\n",
       "<td>0.4789034</td>\n",
       "<td>0.0173229</td></tr>\n",
       "<tr><td>musical</td>\n",
       "<td>0.4689341</td>\n",
       "<td>0.4689341</td>\n",
       "<td>0.0169623</td></tr>\n",
       "<tr><td>drama</td>\n",
       "<td>0.4469302</td>\n",
       "<td>0.4469302</td>\n",
       "<td>0.0161664</td></tr>\n",
       "<tr><td>nom_dga</td>\n",
       "<td>0.4176803</td>\n",
       "<td>0.4176803</td>\n",
       "<td>0.0151083</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[46 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_1_20230524_85722_model_22\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 5 002 weights/biases, 68,6 KB, 103 840 training samples, mini-batch size 1\n",
       "    layer    units    type              dropout    l1    l2    mean_rate             rate_rms             momentum    mean_weight            weight_rms           mean_bias              bias_rms\n",
       "--  -------  -------  ----------------  ---------  ----  ----  --------------------  -------------------  ----------  ---------------------  -------------------  ---------------------  -------------------\n",
       "    1        46       Input             15.0\n",
       "    2        50       RectifierDropout  30.0       0.0   0.0   0.038892969792017854  0.10349225997924805  0.0         0.009932569338811648   0.19275730848312378  0.41522828157936453    0.13296157121658325\n",
       "    3        50       RectifierDropout  30.0       0.0   0.0   0.035638015663798435  0.11583846807479858  0.0         -0.013097085671580862  0.15860271453857422  0.8645436029005091     0.12200167775154114\n",
       "    4        2        Softmax                      0.0   0.0   0.018841800816589968  0.09684017300605774  0.0         0.02686685076914728    0.7908759117126465   -0.013836189397350096  0.38205671310424805\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.0002918639572209168\n",
       "RMSE: 0.01708402637614789\n",
       "LogLoss: 0.00258135695067732\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9935320906464516\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      150  0    0        (0.0/150.0)\n",
       "1      0    26   0        (0.0/26.0)\n",
       "Total  150  26   0        (0.0/176.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.993532     1         25\n",
       "max f2                       0.993532     1         25\n",
       "max f0point5                 0.993532     1         25\n",
       "max accuracy                 0.993532     1         25\n",
       "max precision                1            1         0\n",
       "max recall                   0.993532     1         25\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.993532     1         25\n",
       "max min_per_class_accuracy   0.993532     1         25\n",
       "max mean_per_class_accuracy  0.993532     1         25\n",
       "max tns                      1            150       0\n",
       "max fns                      1            25        0\n",
       "max fps                      4.70512e-32  150       175\n",
       "max tps                      0.993532     26        25\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.961538  0\n",
       "max fpr                      4.70512e-32  1         175\n",
       "max tpr                      0.993532     1         25\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,77 %, avg score: 14,99 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0113636                   1                  6.76923  6.76923            1                1            1                           1                   0.0769231       0.0769231                  576.923  576.923            0.0769231\n",
       "2        0.0227273                   0.999999           6.76923  6.76923            1                0.999999     1                           0.999999            0.0769231       0.153846                   576.923  576.923            0.153846\n",
       "3        0.0340909                   0.999995           6.76923  6.76923            1                0.999997     1                           0.999999            0.0769231       0.230769                   576.923  576.923            0.230769\n",
       "4        0.0454545                   0.99999            6.76923  6.76923            1                0.999992     1                           0.999997            0.0769231       0.307692                   576.923  576.923            0.307692\n",
       "5        0.0511364                   0.99997            6.76923  6.76923            1                0.99998      1                           0.999995            0.0384615       0.346154                   576.923  576.923            0.346154\n",
       "6        0.102273                    0.999754           6.76923  6.76923            1                0.999875     1                           0.999935            0.346154        0.692308                   576.923  576.923            0.692308\n",
       "7        0.153409                    0.172808           6.01709  6.51852            0.888889         0.908539     0.962963                    0.96947             0.307692        1                          501.709  551.852            0.993333\n",
       "8        0.204545                    0.00382511         0        4.88889            0                0.0219737    0.722222                    0.732596            0               1                          -100     388.889            0.933333\n",
       "9        0.301136                    6.51623e-05        0        3.32075            0                0.000891208  0.490566                    0.497898            0               1                          -100     232.075            0.82\n",
       "10       0.403409                    7.77671e-06        0        2.47887            0                2.97249e-05  0.366197                    0.371678            0               1                          -100     147.887            0.7\n",
       "11       0.5                         1.62967e-06        0        2                  0                4.2984e-06   0.295455                    0.299877            0               1                          -100     100                0.586667\n",
       "12       0.602273                    1.25093e-07        0        1.66038            0                4.50949e-07  0.245283                    0.248955            0               1                          -100     66.0377            0.466667\n",
       "13       0.698864                    2.0678e-09         0        1.43089            0                3.02965e-08  0.211382                    0.214546            0               1                          -100     43.0894            0.353333\n",
       "14       0.801136                    2.10235e-11        0        1.24823            0                3.98363e-10  0.184397                    0.187158            0               1                          -100     24.8227            0.233333\n",
       "15       0.897727                    4.69443e-18        0        1.11392            0                2.51734e-12  0.164557                    0.16702             0               1                          -100     11.3924            0.12\n",
       "16       1                           4.70512e-32        0        1                  0                2.75527e-19  0.147727                    0.149939            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.10366535538522567\n",
       "RMSE: 0.32197104743319027\n",
       "LogLoss: 0.46443296707093845\n",
       "Mean Per-Class Error: 0.25153846153846154\n",
       "AUC: 0.8171794871794872\n",
       "AUCPR: 0.5130330741669865\n",
       "Gini: 0.6343589743589744\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.15663830936437467\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      138  12   0.08     (12.0/150.0)\n",
       "1      11   15   0.4231   (11.0/26.0)\n",
       "Total  149  27   0.1307   (23.0/176.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.156638     0.566038  26\n",
       "max f2                       0.0663705    0.607143  35\n",
       "max f0point5                 0.402278     0.638298  16\n",
       "max accuracy                 0.402278     0.892045  16\n",
       "max precision                0.997748     1         0\n",
       "max recall                   0.000661022  1         122\n",
       "max specificity              0.997748     1         0\n",
       "max absolute_mcc             0.402278     0.514353  16\n",
       "max min_per_class_accuracy   0.010201     0.706667  62\n",
       "max mean_per_class_accuracy  0.0663705    0.76359   35\n",
       "max tns                      0.997748     150       0\n",
       "max fns                      0.997748     25        0\n",
       "max fps                      2.76754e-07  150       175\n",
       "max tps                      0.000661022  26        122\n",
       "max tnr                      0.997748     1         0\n",
       "max fnr                      0.997748     0.961538  0\n",
       "max fpr                      2.76754e-07  1         175\n",
       "max tpr                      0.000661022  1         122\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,77 %, avg score:  9,17 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0113636                   0.986713           6.76923   6.76923            1                0.997454     1                           0.997454            0.0769231       0.0769231                  576.923   576.923            0.0769231\n",
       "2        0.0227273                   0.964778           3.38462   5.07692            0.5              0.976917     0.75                        0.987186            0.0384615       0.115385                   238.462   407.692            0.108718\n",
       "3        0.0340909                   0.891693           0         3.38462            0                0.932558     0.5                         0.968976            0               0.115385                   -100      238.462            0.0953846\n",
       "4        0.0454545                   0.724717           6.76923   4.23077            1                0.786498     0.625                       0.923357            0.0769231       0.192308                   576.923   323.077            0.172308\n",
       "5        0.0511364                   0.657548           0         3.76068            0                0.673931     0.555556                    0.895643            0               0.192308                   -100      276.068            0.165641\n",
       "6        0.102273                    0.265658           5.26496   4.51282            0.777778         0.482278     0.666667                    0.688961            0.269231        0.461538                   426.496   351.282            0.421538\n",
       "7        0.153409                    0.15387            2.25641   3.76068            0.333333         0.197179     0.555556                    0.525033            0.115385        0.576923                   125.641   276.068            0.496923\n",
       "8        0.204545                    0.0663705          1.50427   3.19658            0.222222         0.111844     0.472222                    0.421736            0.0769231       0.653846                   50.4274   219.658            0.527179\n",
       "9        0.301136                    0.0172974          0.39819   2.29898            0.0588235        0.0333273    0.339623                    0.297152            0.0384615       0.692308                   -60.181   129.898            0.458974\n",
       "10       0.403409                    0.00883467         0.752137  1.90683            0.111111         0.0115442    0.28169                     0.224744            0.0769231       0.769231                   -24.7863  90.6826            0.429231\n",
       "11       0.5                         0.00377158         0.79638   1.69231            0.117647         0.00672068   0.25                        0.182626            0.0769231       0.846154                   -20.362   69.2308            0.406154\n",
       "12       0.602273                    0.0013098          0         1.40493            0                0.00212033   0.207547                    0.151974            0               0.846154                   -100      40.4935            0.286154\n",
       "13       0.698864                    0.00065939         1.59276   1.43089            0.235294         0.000964103  0.211382                    0.131103            0.153846        1                          59.276    43.0894            0.353333\n",
       "14       0.801136                    0.00019184         0         1.24823            0                0.000368839  0.184397                    0.114414            0               1                          -100      24.8227            0.233333\n",
       "15       0.897727                    6.2905e-05         0         1.11392            0                0.000127739  0.164557                    0.102117            0               1                          -100      11.3924            0.12\n",
       "16       1                           2.8e-07            0         1                  0                2.36883e-05  0.147727                    0.0916756           0               1                          -100      0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean      sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.880635  0.0652379  0.888889      0.828571      0.8           0.942857      0.942857\n",
       "auc                      0.847961  0.0982881  0.935484      0.798851      0.717593      0.954545      0.833333\n",
       "err                      0.119365  0.0652379  0.111111      0.171429      0.2           0.0571429     0.0571429\n",
       "err_count                4.2       2.28035    4             6             7             2             2\n",
       "f0point5                 0.609437  0.110714   0.609756      0.526316      0.555556      0.555556      0.8\n",
       "f1                       0.657143  0.10775    0.714286      0.571429      0.533333      0.666667      0.8\n",
       "f2                       0.726645  0.15096    0.862069      0.625         0.512821      0.833333      0.8\n",
       "lift_top_group           4.00667   3.69462    7.2           5.83333       0             0             7\n",
       "logloss                  0.464931  0.263755   0.3773        0.511625      0.900182      0.24305       0.292498\n",
       "max_per_class_error      0.244594  0.174858   0.129032      0.333333      0.5           0.0606061     0.2\n",
       "mcc                      0.606084  0.15534    0.695608      0.474555      0.408248      0.685344      0.766667\n",
       "mean_per_class_accuracy  0.849465  0.116485   0.935484      0.764368      0.694444      0.969697      0.883333\n",
       "mean_per_class_error     0.150535  0.116485   0.0645161     0.235632      0.305556      0.030303      0.116667\n",
       "mse                      0.103641  0.0538626  0.107996      0.113898      0.185983      0.0552518     0.0550734\n",
       "pr_auc                   0.575019  0.178318   0.70389       0.590598      0.42793       0.365744      0.786933\n",
       "precision                0.585397  0.124223   0.555556      0.5           0.571429      0.5           0.8\n",
       "r2                       0.15302   0.243925   0.0970112     0.19813       -0.0547655    -0.0255071    0.550234\n",
       "recall                   0.793333  0.216538   1             0.666667      0.5           1             0.8\n",
       "rmse                     0.313422  0.0822153  0.328628      0.337488      0.431258      0.235057      0.234677\n",
       "specificity              0.905597  0.0454004  0.870968      0.862069      0.888889      0.939394      0.966667\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2023-05-24 09:09:09  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan\n",
       "    2023-05-24 09:09:09  6 min  8.005 sec  33207 obs/sec     10        1             1760       0.254264         0.236733            0.486514       0.938718        0.767571           6.76923          0.0738636\n",
       "    2023-05-24 09:09:12  6 min 10.633 sec  38949 obs/sec     590       59            103840     0.017084         0.00258136          0.997682       1               1                  6.76923          0\n",
       "\n",
       "Variable Importances: \n",
       "variable          relative_importance    scaled_importance    percentage\n",
       "----------------  ---------------------  -------------------  --------------------\n",
       "Cinematography    1.0                    1.0                  0.0361720438363004\n",
       "winner_sag        0.7646657824516296     0.7646657824516296   0.027659524202959293\n",
       "rating            0.7306981086730957     0.7306981086730957   0.02643084401802501\n",
       "history           0.7269079089164734     0.7269079089164734   0.026293744746280132\n",
       "biography         0.7232850193977356     0.7232850193977356   0.026162697427794278\n",
       "Film Editing      0.7223579287528992     0.7223579287528992   0.026129162664349028\n",
       "winner_dga        0.7008594870567322     0.7008594870567322   0.02535152008890313\n",
       "numVotes          0.6862598061561584     0.6862598061561584   0.02482341979137158\n",
       "year              0.6608876585960388     0.6608876585960388   0.023905657357605848\n",
       "Sound             0.6562885642051697     0.6562885642051697   0.023739298713692045\n",
       "---               ---                    ---                  ---\n",
       "nominations       0.5305830240249634     0.5305830240249634   0.019192272403827804\n",
       "Directing         0.5289588570594788     0.5289588570594788   0.019133522965154824\n",
       "adventure         0.5270043015480042     0.5270043015480042   0.01906282269751328\n",
       "winner_bafta      0.5157126784324646     0.5157126784324646   0.018654381611195002\n",
       "winner_gg_comedy  0.5098381042480469     0.5098381042480469   0.018441886256276643\n",
       "sport             0.4981127083301544     0.4981127083301544   0.01801775472113666\n",
       "nom_gg_comedy     0.4789034426212311     0.4789034426212311   0.017322916319850345\n",
       "musical           0.4689340889453888     0.4689340889453888   0.016962304421668194\n",
       "drama             0.4469301998615265     0.4469301998615265   0.016166378781157634\n",
       "nom_dga           0.4176802933216095     0.4176802933216095   0.015108349879588067\n",
       "[46 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "        C10     rating0    numVotes0    worldwide_box_office0      action0    adventure0    animation0    biography0      comedy0       crime0    documentary0      drama0      family0    fantasy0    film-noir0    history0      horror0      music0     musical0     mystery0      romance0      sci-fi0       sport0    thriller0          war0     western0    nominations0    Oscar_win0    nom_gg_drama0    winner_gg_drama0    nom_gg_comedy0    winner_gg_comedy0    nom_pga0    winner_pga0    nom_bafta0    winner_bafta0    nom_dga0    winner_dga0    nom_sag0    winner_sag0\n",
      " 1            0.314227    0.386407                 0.209462    -0.0251696     -0.0152674   -0.00567338    0.139222    -0.0820067   -0.0922513      -0.0903216    0.0475568  -0.0425951   -0.0170899   -0.110394     0.0253929  -0.0681248   -0.0102693  -0.0967491   -0.0351218   -0.196358      0.108229    -0.0254172   -0.0359547   -0.0360996    -0.015139        0.0733317    -0.00537012       0.342112            0.102824          0.166098              0.0512977   0.423179       0.132652      0.236108         0.0754091   0.214161       0.0610043   0.30596        0.15723\n",
      " 0.314227     1           0.593096                 0.179044    -0.113108      -0.0230901    0.0401639     0.0460973   -0.162579     0.0194296      -0.0304294   -0.0738244  -0.0244946   -0.0694397   -0.0280892   -0.0445398  -0.0330228    0.0683098   0.00661021  -0.00504493  -0.175171      0.0316074   -0.110307    -0.0780591    0.000717577  -0.0284381       0.192307      0.187489         0.30599             0.157413         -0.0472676            -0.0264947   0.198098       0.127823      0.216438         0.100631    0.243389       0.242703    0.124196       0.0693361\n",
      " 0.386407     0.593096    1                        0.361612    -0.00278305     0.0291351    0.0450236    -0.0287351   -0.0885467    0.0449875      -0.0497313   -0.102784   -0.0199374    0.0182413   -0.0470585   -0.0927261  -0.0218886   -0.0258629  -0.0703792   -0.00320173  -0.164166      0.113466    -0.0445424   -0.00318189  -0.0425826    -0.0433077       0.223754      0.220679         0.263899            0.178136         -0.0101834            -0.0360619   0.390494       0.237977      0.275207         0.129905    0.291197       0.239488    0.260235       0.158354\n",
      " 0.209462     0.179044    0.361612                 1            0.0508011      0.0955564    0.0612752     0.0136341   -0.00460532   0.00473332     -0.03308     -0.0438607   0.0777249    0.0290886   -0.0382438   -0.02487    -0.0115604    0.0209602   0.0196055   -0.0107505   -0.0872886     0.0439794   -0.00620426   0.0516066    0.00600797   -0.0120651       0.15667       0.0221471        0.100986            0.00951081        0.0769518             0.0818453   0.178783       0.142933      0.16018          0.114084    0.166799       0.105566    0.145468       0.116811\n",
      "-0.0251696   -0.113108   -0.00278305               0.0508011    1              0.365221    -0.0151861    -0.0629061    0.0660847    0.151702       -0.0186182    0.0695292   0.010701     0.0588801   -0.0215206    0.064809   -0.0240857   -0.0514339  -0.0449728   -0.0155341   -0.0387451     0.209908    -0.0305611    0.190769     0.158425      0.139141       -0.0195085    -0.00624795       0.0411957           0.0646109        -0.101655             -0.0726385  -0.103234      -0.0435839    -0.0992684       -0.0514339  -0.136629      -0.0657964  -0.0735805     -0.040683\n",
      "-0.0152674   -0.0230901   0.0291351                0.0955564    0.365221       1            0.234432     -0.0558372    0.0882695   -0.0280995      -0.0214771    0.0925761   0.277754     0.266076    -0.0248252    0.127267   -0.0277841   -0.0593317   0.0797923    0.0427215   -0.0430774     0.229628    -0.0352538   -0.0126443    0.0251977     0.216469       -0.0225041    -0.0122231        0.0587055           0.0781292        -0.0506905            -0.0264052  -0.119086      -0.0502763    -0.114511        -0.0593317  -0.157609      -0.0758997  -0.0848791     -0.04693\n",
      "-0.00567338   0.0401639   0.0450236                0.0612752   -0.0151861      0.234432     1            -0.0244193    0.081835    -0.0198984      -0.00503493   0.0631732   0.360242     0.168324    -0.00581982  -0.0188659  -0.00651348  -0.0139092  -0.012162    -0.0151861   -0.0298124    -0.00972149  -0.00826462  -0.0216273   -0.0169577    -0.0101644      -0.00527569   -0.0283422        0.00618806          0.067648         -0.0274905            -0.0196436  -0.0279175     -0.0117864    -0.0268451       -0.0139092  -0.0369486     -0.0177933  -0.0198984     -0.0110019\n",
      " 0.139222     0.0460973  -0.0287351                0.0136341   -0.0629061     -0.0558372   -0.0244193     1            0.00811336   0.0335958       0.127478     0.351047    0.00349862  -0.0700828   -0.0346052    0.318859   -0.0387297    0.213798    0.0283364   -0.090298    -0.000492957  -0.0578049    0.0962037   -0.0271715    0.172543     -0.0604385      -0.0313697     0.030851         0.147937            0.062648         -0.0277523            -0.0510002  -0.166         -0.0700828    -0.159623        -0.0827056  -0.219699      -0.105801   -0.118317      -0.0654183\n",
      "-0.0820067   -0.162579   -0.0885467               -0.00460532   0.0660847      0.0882695    0.081835      0.00811336   1            0.0802842      -0.0271021    0.101212    0.169461     0.0857104   -0.0313271   -0.0770651  -0.0350609    0.0531427   0.115602    -0.0817442    0.203786     -0.0523291    0.0601003   -0.0945211   -0.0644559    -0.011837       -0.0283981    -0.0270283       -0.193287           -0.118157          0.25484               0.131011   -0.150275      -0.063444     -0.144503        -0.074871   -0.183557      -0.0957783  -0.107109      -0.0592213\n",
      "-0.0922513    0.0194296   0.0449875                0.00473332   0.151702      -0.0280995   -0.0198984     0.0335958    0.0802842    1              -0.0243955    0.161655   -0.0552361   -0.0165181    0.212308    -0.0647554  -0.0315594   -0.0673938   0.0593309    0.280435    -0.0122787     0.00159334  -0.0400442    0.395716    -0.0821644    -0.00257699     -0.025562     -0.0201996       -0.0498179          -0.0817229         0.00631754            0.033676   -0.135267      -0.0571079    -0.130071        -0.0673938  -0.162337      -0.086213   -0.0964126     -0.053307\n",
      "[40 rows x 40 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Załadowanie danych do ramki danych H2O\n",
    "data = h2o.import_file(\"../data/processed_results/extended_df.csv\")\n",
    "\n",
    "data = data.drop(['film', 'wiki', 'year', 'winner'], axis=1)\n",
    "# # Sprawdzenie typów kolumn\n",
    "# column_types = data.types\n",
    "\n",
    "# # Wyświetlenie kolumn typu string\n",
    "# string_columns = [column for column, col_type in column_types.items() if col_type == 'string']\n",
    "# print(string_columns)\n",
    "\n",
    "# Obliczenie macierzy korelacji\n",
    "correlations = data.cor(na_rm=True)\n",
    "\n",
    "# Wyświetlenie macierzy korelacji\n",
    "print(correlations)\n",
    "\n",
    "# Wydrukowanie korelacji powyżej progu 0.8\n",
    "threshold = 0.8\n",
    "for row in range(correlations.shape[0]):\n",
    "    for col in range(row + 1, correlations.shape[1]):\n",
    "        correlation = correlations[row, col]\n",
    "        if abs(correlation) > threshold:\n",
    "            print(f\"Korelacja między zmienną {data.col_names[row]} a {data.col_names[col]}: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  C1</th><th style=\"text-align: right;\">  rating</th><th style=\"text-align: right;\">  numVotes</th><th style=\"text-align: right;\">  worldwide_box_office</th><th style=\"text-align: right;\">  action</th><th style=\"text-align: right;\">  adventure</th><th style=\"text-align: right;\">  animation</th><th style=\"text-align: right;\">  biography</th><th style=\"text-align: right;\">  comedy</th><th style=\"text-align: right;\">  crime</th><th style=\"text-align: right;\">  documentary</th><th style=\"text-align: right;\">  drama</th><th style=\"text-align: right;\">  family</th><th style=\"text-align: right;\">  fantasy</th><th style=\"text-align: right;\">  film-noir</th><th style=\"text-align: right;\">  history</th><th style=\"text-align: right;\">  horror</th><th style=\"text-align: right;\">  music</th><th style=\"text-align: right;\">  musical</th><th style=\"text-align: right;\">  mystery</th><th style=\"text-align: right;\">  romance</th><th style=\"text-align: right;\">  sci-fi</th><th style=\"text-align: right;\">  sport</th><th style=\"text-align: right;\">  thriller</th><th style=\"text-align: right;\">  war</th><th style=\"text-align: right;\">  western</th><th style=\"text-align: right;\">  nominations</th><th style=\"text-align: right;\">  Oscar_win</th><th style=\"text-align: right;\">  nom_gg_drama</th><th style=\"text-align: right;\">  winner_gg_drama</th><th style=\"text-align: right;\">  nom_gg_comedy</th><th style=\"text-align: right;\">  winner_gg_comedy</th><th style=\"text-align: right;\">  nom_pga</th><th style=\"text-align: right;\">  winner_pga</th><th style=\"text-align: right;\">  nom_bafta</th><th style=\"text-align: right;\">  winner_bafta</th><th style=\"text-align: right;\">  nom_dga</th><th style=\"text-align: right;\">  winner_dga</th><th style=\"text-align: right;\">  nom_sag</th><th style=\"text-align: right;\">  winner_sag</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">     7.3</td><td style=\"text-align: right;\">     13576</td><td style=\"text-align: right;\">         746          </td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            7</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">     5.2</td><td style=\"text-align: right;\">     26223</td><td style=\"text-align: right;\">       79808          </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            7</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   2</td><td style=\"text-align: right;\">     6.7</td><td style=\"text-align: right;\">      3149</td><td style=\"text-align: right;\">           2.17332e+07</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            7</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">     5.6</td><td style=\"text-align: right;\">      7605</td><td style=\"text-align: right;\">      223723          </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   4</td><td style=\"text-align: right;\">     7.4</td><td style=\"text-align: right;\">       391</td><td style=\"text-align: right;\">       42915          </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            7</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   5</td><td style=\"text-align: right;\">     5.5</td><td style=\"text-align: right;\">      1199</td><td style=\"text-align: right;\">        6344          </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   6</td><td style=\"text-align: right;\">     7.2</td><td style=\"text-align: right;\">    282275</td><td style=\"text-align: right;\">           2.15294e+08</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            7</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   9</td><td style=\"text-align: right;\">     6.8</td><td style=\"text-align: right;\">      4322</td><td style=\"text-align: right;\">           1.73959e+08</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            7</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  10</td><td style=\"text-align: right;\">     6.1</td><td style=\"text-align: right;\">      1318</td><td style=\"text-align: right;\">           1.30259e+07</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            7</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  11</td><td style=\"text-align: right;\">     6.7</td><td style=\"text-align: right;\">      3366</td><td style=\"text-align: right;\">        6253          </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[489 rows x 40 columns]</pre>"
      ],
      "text/plain": [
       "  C1    rating    numVotes    worldwide_box_office    action    adventure    animation    biography    comedy    crime    documentary    drama    family    fantasy    film-noir    history    horror    music    musical    mystery    romance    sci-fi    sport    thriller    war    western    nominations    Oscar_win    nom_gg_drama    winner_gg_drama    nom_gg_comedy    winner_gg_comedy    nom_pga    winner_pga    nom_bafta    winner_bafta    nom_dga    winner_dga    nom_sag    winner_sag\n",
       "----  --------  ----------  ----------------------  --------  -----------  -----------  -----------  --------  -------  -------------  -------  --------  ---------  -----------  ---------  --------  -------  ---------  ---------  ---------  --------  -------  ----------  -----  ---------  -------------  -----------  --------------  -----------------  ---------------  ------------------  ---------  ------------  -----------  --------------  ---------  ------------  ---------  ------------\n",
       "   0       7.3       13576           746                   1            0            0            0         0        0              0        1         0          0            0          0         0        0          0          0          1         0        0           0      1          0              7            1               0                  0                0                   0          0             0            0               0          0             0          0             0\n",
       "   1       5.2       26223         79808                   0            0            0            0         0        0              0        1         0          0            0          0         0        0          0          0          0         0        0           0      0          0              7            0               0                  0                0                   0          0             0            0               0          0             0          0             0\n",
       "   2       6.7        3149             2.17332e+07         0            0            0            0         0        0              0        1         0          1            0          0         0        0          0          1          0         1        0           1      0          0              7            0               0                  0                0                   0          0             0            0               0          0             0          0             0\n",
       "   3       5.6        7605        223723                   0            0            0            0         0        0              0        0         0          0            0          0         0        0          0          0          0         0        0           0      0          0              3            1               0                  0                0                   0          0             0            0               0          0             0          0             0\n",
       "   4       7.4         391         42915                   0            0            0            0         0        1              0        0         0          0            0          0         0        0          0          0          0         0        0           1      0          0              7            0               0                  0                0                   0          0             0            0               0          0             0          0             0\n",
       "   5       5.5        1199          6344                   0            0            0            0         0        0              0        0         0          0            0          0         0        0          0          0          0         0        0           0      0          0              5            0               0                  0                0                   0          0             0            0               0          0             0          0             0\n",
       "   6       7.2      282275             2.15294e+08         1            0            0            0         0        0              0        1         0          0            0          1         0        0          0          0          0         0        0           0      1          0              7            0               0                  0                0                   0          0             0            0               0          0             0          0             0\n",
       "   9       6.8        4322             1.73959e+08         1            0            0            0         1        1              0        0         0          0            0          0         0        0          0          0          0         0        0           0      0          0              7            0               0                  0                0                   0          0             0            0               0          0             0          0             0\n",
       "  10       6.1        1318             1.30259e+07         0            0            0            0         0        1              0        1         0          0            0          0         0        0          0          0          0         0        0           1      0          0              7            0               0                  0                0                   0          0             0            0               0          0             0          0             0\n",
       "  11       6.7        3366          6253                   0            0            0            0         0        0              0        0         0          0            0          0         0        0          0          0          0         0        0           0      0          0              4            0               0                  0                0                   0          0             0            0               0          0             0          0             0\n",
       "[489 rows x 40 columns]\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the correlation matrix stored in a variable called 'correlation_matrix'\n",
    "\n",
    "# Convert the correlation matrix to a numeric format\n",
    "correlation_matrix = correlations.as_data_frame().values.astype(float)\n",
    "column_names=correlations.columns\n",
    "\n",
    "# Create a masked array from the correlation matrix to hide the upper triangle\n",
    "masked_corr = np.ma.masked_where(np.triu(np.ones_like(correlation_matrix, dtype=bool)), correlation_matrix)\n",
    "\n",
    "# Set up the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Create the heatmap\n",
    "heatmap = ax.imshow(masked_corr, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = fig.colorbar(heatmap)\n",
    "\n",
    "# Set the axis labels\n",
    "ax.set_xticks(np.arange(correlation_matrix.shape[1]))\n",
    "ax.set_yticks(np.arange(correlation_matrix.shape[0]))\n",
    "ax.set_xticklabels(column_names, rotation=90)\n",
    "ax.set_yticklabels(column_names)\n",
    "\n",
    "# Set the title\n",
    "ax.set_title(\"Correlation Heatmap\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = h2o.load_model('./additional_data/model/DeepLearning_grid_2_AutoML_6_20230519_91906_model_4')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Predict on 2019's films\n",
    "test = full_table.loc[(full_table['year'] == 2021)]\n",
    "\n",
    "# Import a binary outcome train/test set into H2O\n",
    "test = h2o.H2OFrame(test)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">        p0</th><th style=\"text-align: right;\">         p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999976  </td><td style=\"text-align: right;\">2.37118e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.00165605</td><td style=\"text-align: right;\">0.998344   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.995174  </td><td style=\"text-align: right;\">0.00482619 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1         </td><td style=\"text-align: right;\">1.74511e-07</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.995249  </td><td style=\"text-align: right;\">0.00475117 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999972  </td><td style=\"text-align: right;\">2.78123e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999979  </td><td style=\"text-align: right;\">2.0885e-05 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1         </td><td style=\"text-align: right;\">9.07248e-09</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999955  </td><td style=\"text-align: right;\">4.5392e-05 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999999  </td><td style=\"text-align: right;\">1.10776e-06</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 3 columns]</pre>"
      ],
      "text/plain": [
       "  predict          p0           p1\n",
       "---------  ----------  -----------\n",
       "        0  0.999976    2.37118e-05\n",
       "        1  0.00165605  0.998344\n",
       "        0  0.995174    0.00482619\n",
       "        0  1           1.74511e-07\n",
       "        0  0.995249    0.00475117\n",
       "        0  0.999972    2.78123e-05\n",
       "        0  0.999979    2.0885e-05\n",
       "        0  1           9.07248e-09\n",
       "        0  0.999955    4.5392e-05\n",
       "        0  0.999999    1.10776e-06\n",
       "[10 rows x 3 columns]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = top_model.predict(test)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred'] = preds['predict']\n",
    "test['probA'] = preds['p1']\n",
    "test_pd = test.as_data_frame(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>probA</th>\n",
       "      <th>%_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CODA</td>\n",
       "      <td>9.983440e-01</td>\n",
       "      <td>9.903809e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Belfast</td>\n",
       "      <td>4.826187e-03</td>\n",
       "      <td>4.787692e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drive My Car</td>\n",
       "      <td>4.751175e-03</td>\n",
       "      <td>4.713278e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nightmare Alley</td>\n",
       "      <td>4.539204e-05</td>\n",
       "      <td>4.502998e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dune</td>\n",
       "      <td>2.781235e-05</td>\n",
       "      <td>2.759051e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West Side Story</td>\n",
       "      <td>2.371181e-05</td>\n",
       "      <td>2.352268e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>King Richard</td>\n",
       "      <td>2.088495e-05</td>\n",
       "      <td>2.071837e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Power of the Dog</td>\n",
       "      <td>1.107759e-06</td>\n",
       "      <td>1.098923e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Don't Look Up</td>\n",
       "      <td>1.745112e-07</td>\n",
       "      <td>1.731192e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Licorice Pizza</td>\n",
       "      <td>9.072485e-09</td>\n",
       "      <td>9.000120e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    film         probA  %_confidence\n",
       "1                  CODA   9.983440e-01  9.903809e+01\n",
       "2               Belfast   4.826187e-03  4.787692e-01\n",
       "4          Drive My Car   4.751175e-03  4.713278e-01\n",
       "8       Nightmare Alley   4.539204e-05  4.502998e-03\n",
       "5                  Dune   2.781235e-05  2.759051e-03\n",
       "0       West Side Story   2.371181e-05  2.352268e-03\n",
       "6          King Richard   2.088495e-05  2.071837e-03\n",
       "9  The Power of the Dog   1.107759e-06  1.098923e-04\n",
       "3          Don't Look Up  1.745112e-07  1.731192e-05\n",
       "7         Licorice Pizza  9.072485e-09  9.000120e-07"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rankings = test_pd[['film','probA']].sort_values('probA', ascending = False)\n",
    "final_rankings['%_confidence'] = final_rankings['probA']/final_rankings['probA'].sum() * 100\n",
    "final_rankings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And the Oscar goes to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_winner = np.array(final_rankings.reset_index())[0][1].split('(')[0].strip()\n",
    "print(f'And the Oscar goes to...\\n🎉🏆{bp_winner}🏆🎉')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
