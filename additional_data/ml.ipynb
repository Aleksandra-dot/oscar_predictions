{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-Oscar Prediction with AutoML\n",
    "After out dataframe has been assemlbed (see scraping and table_assembling) notebooks we have the data we need to make predictions on the Best Picture winner. [AutoML](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html) represents a quick, but powerful route though the Machine Learning process. H2O's AutoML runs many models through the dataset and using cross-validation, picks the best one. For my purposes I use it to confirm/compare to the Preferential Balloting Random Forest model I created.\n",
    "If you are gunning to win your office's Oscar pool, scroll down to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h2o"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Using h2o Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>film</th>\n",
       "      <th>wiki</th>\n",
       "      <th>winner</th>\n",
       "      <th>rating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>worldwide_box_office</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_pga</th>\n",
       "      <th>winner_pga</th>\n",
       "      <th>nom_bafta</th>\n",
       "      <th>winner_bafta</th>\n",
       "      <th>nom_dga</th>\n",
       "      <th>winner_dga</th>\n",
       "      <th>nom_sag</th>\n",
       "      <th>winner_sag</th>\n",
       "      <th>nom_cannes</th>\n",
       "      <th>winner_cannes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1927</td>\n",
       "      <td>Wings</td>\n",
       "      <td>/wiki/Wings_(1927_film)</td>\n",
       "      <td>True</td>\n",
       "      <td>7.3</td>\n",
       "      <td>13576.0</td>\n",
       "      <td>$746</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1927</td>\n",
       "      <td>7th Heaven</td>\n",
       "      <td>/wiki/7th_Heaven_(1927_film)</td>\n",
       "      <td>False</td>\n",
       "      <td>5.2</td>\n",
       "      <td>26223.0</td>\n",
       "      <td>$79,808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1927</td>\n",
       "      <td>The Racket</td>\n",
       "      <td>/wiki/The_Racket_(1928_film)</td>\n",
       "      <td>False</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3149.0</td>\n",
       "      <td>$21,733,230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1928</td>\n",
       "      <td>The Broadway Melody</td>\n",
       "      <td>/wiki/The_Broadway_Melody</td>\n",
       "      <td>True</td>\n",
       "      <td>5.6</td>\n",
       "      <td>7605.0</td>\n",
       "      <td>$223,723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1928</td>\n",
       "      <td>Alibi</td>\n",
       "      <td>/wiki/Alibi_(1929_film)</td>\n",
       "      <td>False</td>\n",
       "      <td>7.4</td>\n",
       "      <td>391.0</td>\n",
       "      <td>$42,915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2022</td>\n",
       "      <td>The Fabelmans</td>\n",
       "      <td>/wiki/The_Fabelmans</td>\n",
       "      <td>False</td>\n",
       "      <td>7.6</td>\n",
       "      <td>85709.0</td>\n",
       "      <td>$45,164,110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2022</td>\n",
       "      <td>TÃ¡r</td>\n",
       "      <td>/wiki/T%C3%A1r</td>\n",
       "      <td>False</td>\n",
       "      <td>7.5</td>\n",
       "      <td>69684.0</td>\n",
       "      <td>$27,541,681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>2022</td>\n",
       "      <td>Top Gun: Maverick</td>\n",
       "      <td>/wiki/Top_Gun:_Maverick</td>\n",
       "      <td>False</td>\n",
       "      <td>8.3</td>\n",
       "      <td>577408.0</td>\n",
       "      <td>$1,493,491,858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>2022</td>\n",
       "      <td>Triangle of Sadness</td>\n",
       "      <td>/wiki/Triangle_of_Sadness</td>\n",
       "      <td>False</td>\n",
       "      <td>7.3</td>\n",
       "      <td>128812.0</td>\n",
       "      <td>$25,615,870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>2022</td>\n",
       "      <td>Women Talking</td>\n",
       "      <td>/wiki/Women_Talking_(film)</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>29341.0</td>\n",
       "      <td>$8,954,708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551 rows Ã 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year                 film                          wiki  winner  rating  \\\n",
       "0    1927               Wings        /wiki/Wings_(1927_film)    True     7.3   \n",
       "1    1927          7th Heaven   /wiki/7th_Heaven_(1927_film)   False     5.2   \n",
       "2    1927          The Racket   /wiki/The_Racket_(1928_film)   False     6.7   \n",
       "3    1928  The Broadway Melody     /wiki/The_Broadway_Melody    True     5.6   \n",
       "4    1928               Alibi        /wiki/Alibi_(1929_film)   False     7.4   \n",
       "..    ...                  ...                           ...     ...     ...   \n",
       "546  2022        The Fabelmans           /wiki/The_Fabelmans   False     7.6   \n",
       "547  2022                  TÃ¡r                /wiki/T%C3%A1r   False     7.5   \n",
       "548  2022    Top Gun: Maverick       /wiki/Top_Gun:_Maverick   False     8.3   \n",
       "549  2022  Triangle of Sadness     /wiki/Triangle_of_Sadness   False     7.3   \n",
       "550  2022       Women Talking     /wiki/Women_Talking_(film)   False     6.9   \n",
       "\n",
       "     numVotes worldwide_box_office  Action  Adventure  Animation  ...  \\\n",
       "0     13576.0                 $746       0          0          0  ...   \n",
       "1     26223.0              $79,808       0          0          0  ...   \n",
       "2      3149.0          $21,733,230       0          0          0  ...   \n",
       "3      7605.0             $223,723       0          0          0  ...   \n",
       "4       391.0              $42,915       0          0          0  ...   \n",
       "..        ...                  ...     ...        ...        ...  ...   \n",
       "546   85709.0          $45,164,110       0          0          0  ...   \n",
       "547   69684.0          $27,541,681       0          0          0  ...   \n",
       "548  577408.0       $1,493,491,858       0          0          0  ...   \n",
       "549  128812.0          $25,615,870       0          0          0  ...   \n",
       "550   29341.0           $8,954,708       0          0          0  ...   \n",
       "\n",
       "     nom_pga  winner_pga  nom_bafta  winner_bafta  nom_dga  winner_dga  \\\n",
       "0          0           0          0             0        0           0   \n",
       "1          0           0          0             0        0           0   \n",
       "2          0           0          0             0        0           0   \n",
       "3          0           0          0             0        0           0   \n",
       "4          0           0          0             0        0           0   \n",
       "..       ...         ...        ...           ...      ...         ...   \n",
       "546        1           0          0             0        1           0   \n",
       "547        1           0          1             0        1           0   \n",
       "548        1           0          0             0        1           0   \n",
       "549        0           0          0             0        0           0   \n",
       "550        0           0          0             0        0           0   \n",
       "\n",
       "     nom_sag  winner_sag  nom_cannes  winner_cannes  \n",
       "0          0           0           0              0  \n",
       "1          0           0           0              0  \n",
       "2          0           0           0              0  \n",
       "3          0           0           0              0  \n",
       "4          0           0           0              0  \n",
       "..       ...         ...         ...            ...  \n",
       "546        1           0           0              0  \n",
       "547        0           0           0              0  \n",
       "548        0           0           0              0  \n",
       "549        0           0           1              1  \n",
       "550        0           0           0              0  \n",
       "\n",
       "[551 rows x 72 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_table = pd.read_csv('../data/processed_results/extended_df.csv')\n",
    "full_table=full_table.drop('Unnamed: 0', axis=1)\n",
    "full_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) Client VM (build 25.371-b11, mixed mode)\n",
      "  Starting server from C:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmpc6ug8_k7\n",
      "  JVM stdout: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmpc6ug8_k7\\h2o_Aleksandra_Czaplak_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmpc6ug8_k7\\h2o_Aleksandra_Czaplak_started_from_python.err\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\h2o\\backend\\server.py:386: UserWarning:   You have a 32-bit version of Java. H2O works best with 64-bit Java.\n",
      "  Please download the latest 64-bit Java SE JDK from Oracle.\n",
      "\n",
      "  warn(\"  You have a 32-bit version of Java. H2O works best with 64-bit Java.\\n\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>06 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Berlin</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>18 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Aleksandra_Czaplak_xe0jmq</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>247.5 Mb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.2 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------------------\n",
       "H2O_cluster_uptime:         06 secs\n",
       "H2O_cluster_timezone:       Europe/Berlin\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    18 days\n",
       "H2O_cluster_name:           H2O_from_python_Aleksandra_Czaplak_xe0jmq\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    247.5 Mb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.2 final\n",
       "--------------------------  -----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Year of Existance. This data will be used below\n",
    "- golden_globes 1943\n",
    "- pga 1989\n",
    "- bafta 1960\n",
    "- dga 1948\n",
    "- sag 1995\n",
    "- cannes 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I pick a min_year where the awards shows will be relevant\n",
    "min_year = 1995"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O's Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set contains: 184 movies\n"
     ]
    }
   ],
   "source": [
    "# Auto ML uses Cross Validation, so we do not specifiy a validation set\n",
    "train = full_table.loc[((full_table['year'] < 2022) & (full_table['year'] >= min_year))]\n",
    "\n",
    "print('training set contains:', train.shape[0], 'movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'film', 'wiki', 'winner', 'rating', 'numVotes',\n",
       "       'worldwide_box_office', 'Action', 'Adventure', 'Animation', 'Biography',\n",
       "       'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy',\n",
       "       'Film-Noir', 'Game-Show', 'History', 'Horror', 'Music', 'Musical',\n",
       "       'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
       "       'Talk-Show', 'Thriller', 'War', 'Western', 'action', 'adventure',\n",
       "       'animation', 'biography', 'comedy', 'crime', 'documentary', 'drama',\n",
       "       'family', 'fantasy', 'film-noir', 'history', 'horror', 'music',\n",
       "       'musical', 'mystery', 'romance', 'sci-fi', 'sport', 'thriller', 'war',\n",
       "       'western', 'nominations', 'Oscar_win', 'nom_gg_drama',\n",
       "       'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga',\n",
       "       'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga',\n",
       "       'nom_sag', 'winner_sag', 'nom_cannes', 'winner_cannes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train = train.drop(['index', '[]'], axis=1)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| (done) 100%\n",
      "AutoML progress: |\n",
      "20:40:09.288: AutoML: XGBoost is not available; skipping it.\n",
      "20:40:09.405: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n",
      "\n",
      "20:40:10.708: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "20:40:10.708: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 184.0.\n",
      "20:40:10.719: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n",
      "âââ\n",
      "20:40:12.325: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n",
      "ââââââ\n",
      "20:40:24.968: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n",
      "ââ\n",
      "20:40:37.865: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n",
      "âââ\n",
      "20:40:56.82: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "20:40:56.806: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n",
      "âââ\n",
      "20:41:16.896: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n",
      "âââââââââââââââââââââââââââââââââââââââââââââ\n",
      "21:05:37.213: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n",
      "â| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                             </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">    logloss</th><th style=\"text-align: right;\">    aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">       rmse</th><th style=\"text-align: right;\">        mse</th><th style=\"text-align: right;\">  training_time_ms</th><th style=\"text-align: right;\">  predict_time_per_row_ms</th><th>algo        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_2_AutoML_1_20230516_204009                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00737889 </td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">0.0331065  </td><td style=\"text-align: right;\">0.00109604 </td><td style=\"text-align: right;\">              2688</td><td style=\"text-align: right;\">                 0.447721</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_23         </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.0276576  </td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">0.0929754  </td><td style=\"text-align: right;\">0.00864442 </td><td style=\"text-align: right;\">              3893</td><td style=\"text-align: right;\">                 0.482572</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_7          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00241718 </td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">0.01406    </td><td style=\"text-align: right;\">0.000197684</td><td style=\"text-align: right;\">              3639</td><td style=\"text-align: right;\">                 0.475077</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_32         </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">1.3837e-05 </td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">0.000108532</td><td style=\"text-align: right;\">1.17792e-08</td><td style=\"text-align: right;\">              3349</td><td style=\"text-align: right;\">                 0.468091</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_21         </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.0351646  </td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">0.0933088  </td><td style=\"text-align: right;\">0.00870654 </td><td style=\"text-align: right;\">              1558</td><td style=\"text-align: right;\">                 0.297523</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_5_AutoML_1_20230516_204009                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">1.67674e-12</td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">7.31043e-12</td><td style=\"text-align: right;\">5.34425e-23</td><td style=\"text-align: right;\">              5743</td><td style=\"text-align: right;\">                 0.445983</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_3          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.068937   </td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">0.156675   </td><td style=\"text-align: right;\">0.0245472  </td><td style=\"text-align: right;\">              3245</td><td style=\"text-align: right;\">                 0.392354</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_10         </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.0703679  </td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">0.156364   </td><td style=\"text-align: right;\">0.0244497  </td><td style=\"text-align: right;\">              1955</td><td style=\"text-align: right;\">                 0.34111 </td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_17         </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">2.31509e-10</td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">2.69854e-09</td><td style=\"text-align: right;\">7.28213e-18</td><td style=\"text-align: right;\">              2582</td><td style=\"text-align: right;\">                 0.479831</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_35         </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">1.89568e-05</td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">0.000164082</td><td style=\"text-align: right;\">2.6923e-08 </td><td style=\"text-align: right;\">              2933</td><td style=\"text-align: right;\">                 0.485245</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_2          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">7.36126e-17</td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">3.722e-16  </td><td style=\"text-align: right;\">1.38533e-31</td><td style=\"text-align: right;\">              2910</td><td style=\"text-align: right;\">                 0.359657</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_33         </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.0224434  </td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">0.0630308  </td><td style=\"text-align: right;\">0.00397288 </td><td style=\"text-align: right;\">               850</td><td style=\"text-align: right;\">                 0.23594 </td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_1          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.0624392  </td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">0.149366   </td><td style=\"text-align: right;\">0.0223103  </td><td style=\"text-align: right;\">              3333</td><td style=\"text-align: right;\">                 0.497433</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_3_AutoML_1_20230516_204009                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">4.83643e-05</td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">0.000393079</td><td style=\"text-align: right;\">1.54511e-07</td><td style=\"text-align: right;\">              2732</td><td style=\"text-align: right;\">                 0.392175</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_13         </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">1.56827e-06</td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">7.75635e-06</td><td style=\"text-align: right;\">6.0161e-11 </td><td style=\"text-align: right;\">              5037</td><td style=\"text-align: right;\">                 0.546291</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_4_AutoML_1_20230516_204009                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">7.18643e-07</td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">9.3646e-06 </td><td style=\"text-align: right;\">8.76958e-11</td><td style=\"text-align: right;\">              6213</td><td style=\"text-align: right;\">                 0.360597</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_12         </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">8.32667e-17</td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">6.50772e-16</td><td style=\"text-align: right;\">4.23504e-31</td><td style=\"text-align: right;\">              2709</td><td style=\"text-align: right;\">                 0.328248</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_8          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.000355136</td><td style=\"text-align: right;\">1        </td><td style=\"text-align: right;\">            0         </td><td style=\"text-align: right;\">0.00203733 </td><td style=\"text-align: right;\">4.15073e-06</td><td style=\"text-align: right;\">              4741</td><td style=\"text-align: right;\">                 0.523237</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_9          </td><td style=\"text-align: right;\">0.999528</td><td style=\"text-align: right;\">0.116205   </td><td style=\"text-align: right;\">0.997255 </td><td style=\"text-align: right;\">            0.00318471</td><td style=\"text-align: right;\">0.207505   </td><td style=\"text-align: right;\">0.0430584  </td><td style=\"text-align: right;\">              2289</td><td style=\"text-align: right;\">                 0.328979</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_15         </td><td style=\"text-align: right;\">0.995754</td><td style=\"text-align: right;\">0.131321   </td><td style=\"text-align: right;\">0.961866 </td><td style=\"text-align: right;\">            0.00318471</td><td style=\"text-align: right;\">0.215064   </td><td style=\"text-align: right;\">0.0462524  </td><td style=\"text-align: right;\">               452</td><td style=\"text-align: right;\">                 0.104259</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_18         </td><td style=\"text-align: right;\">0.995518</td><td style=\"text-align: right;\">0.260425   </td><td style=\"text-align: right;\">0.957964 </td><td style=\"text-align: right;\">            0.00318471</td><td style=\"text-align: right;\">0.309194   </td><td style=\"text-align: right;\">0.0956009  </td><td style=\"text-align: right;\">               417</td><td style=\"text-align: right;\">                 0.093103</td><td>GBM         </td></tr>\n",
       "<tr><td>DRF_1_AutoML_1_20230516_204009                       </td><td style=\"text-align: right;\">0.995046</td><td style=\"text-align: right;\">0.152241   </td><td style=\"text-align: right;\">0.963345 </td><td style=\"text-align: right;\">            0.00636943</td><td style=\"text-align: right;\">0.206222   </td><td style=\"text-align: right;\">0.0425277  </td><td style=\"text-align: right;\">               251</td><td style=\"text-align: right;\">                 0.069863</td><td>DRF         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_22         </td><td style=\"text-align: right;\">0.987969</td><td style=\"text-align: right;\">0.189745   </td><td style=\"text-align: right;\">0.941336 </td><td style=\"text-align: right;\">            0.0529606 </td><td style=\"text-align: right;\">0.246071   </td><td style=\"text-align: right;\">0.060551   </td><td style=\"text-align: right;\">               299</td><td style=\"text-align: right;\">                 0.072435</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_16</td><td style=\"text-align: right;\">0.977235</td><td style=\"text-align: right;\">0.543796   </td><td style=\"text-align: right;\">0.836602 </td><td style=\"text-align: right;\">            0.05933   </td><td style=\"text-align: right;\">0.262228   </td><td style=\"text-align: right;\">0.0687634  </td><td style=\"text-align: right;\">              3634</td><td style=\"text-align: right;\">                 0.163266</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_7 </td><td style=\"text-align: right;\">0.975702</td><td style=\"text-align: right;\">0.317707   </td><td style=\"text-align: right;\">0.883501 </td><td style=\"text-align: right;\">            0.0408115 </td><td style=\"text-align: right;\">0.257052   </td><td style=\"text-align: right;\">0.0660755  </td><td style=\"text-align: right;\">              2730</td><td style=\"text-align: right;\">                 0.078795</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20230516_204009                       </td><td style=\"text-align: right;\">0.974758</td><td style=\"text-align: right;\">0.186266   </td><td style=\"text-align: right;\">0.874505 </td><td style=\"text-align: right;\">            0.0899976 </td><td style=\"text-align: right;\">0.234246   </td><td style=\"text-align: right;\">0.054871   </td><td style=\"text-align: right;\">                85</td><td style=\"text-align: right;\">                 0.065055</td><td>GLM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_9 </td><td style=\"text-align: right;\">0.972399</td><td style=\"text-align: right;\">0.381428   </td><td style=\"text-align: right;\">0.911255 </td><td style=\"text-align: right;\">            0.0561453 </td><td style=\"text-align: right;\">0.236077   </td><td style=\"text-align: right;\">0.0557323  </td><td style=\"text-align: right;\">              2677</td><td style=\"text-align: right;\">                 0.059581</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_34         </td><td style=\"text-align: right;\">0.969686</td><td style=\"text-align: right;\">0.242737   </td><td style=\"text-align: right;\">0.857357 </td><td style=\"text-align: right;\">            0.114886  </td><td style=\"text-align: right;\">0.269958   </td><td style=\"text-align: right;\">0.0728772  </td><td style=\"text-align: right;\">              4265</td><td style=\"text-align: right;\">                 0.406005</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_18</td><td style=\"text-align: right;\">0.969332</td><td style=\"text-align: right;\">0.486464   </td><td style=\"text-align: right;\">0.852064 </td><td style=\"text-align: right;\">            0.0344421 </td><td style=\"text-align: right;\">0.258328   </td><td style=\"text-align: right;\">0.0667334  </td><td style=\"text-align: right;\">              2472</td><td style=\"text-align: right;\">                 0.06613 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_3 </td><td style=\"text-align: right;\">0.967327</td><td style=\"text-align: right;\">0.751456   </td><td style=\"text-align: right;\">0.792463 </td><td style=\"text-align: right;\">            0.111701  </td><td style=\"text-align: right;\">0.269893   </td><td style=\"text-align: right;\">0.0728424  </td><td style=\"text-align: right;\">              8129</td><td style=\"text-align: right;\">                 0.076823</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_10</td><td style=\"text-align: right;\">0.966502</td><td style=\"text-align: right;\">0.282501   </td><td style=\"text-align: right;\">0.844965 </td><td style=\"text-align: right;\">            0.0874027 </td><td style=\"text-align: right;\">0.256959   </td><td style=\"text-align: right;\">0.0660281  </td><td style=\"text-align: right;\">              4629</td><td style=\"text-align: right;\">                 0.069958</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_1 </td><td style=\"text-align: right;\">0.966266</td><td style=\"text-align: right;\">0.394726   </td><td style=\"text-align: right;\">0.817673 </td><td style=\"text-align: right;\">            0.0995518 </td><td style=\"text-align: right;\">0.288427   </td><td style=\"text-align: right;\">0.0831903  </td><td style=\"text-align: right;\">              3831</td><td style=\"text-align: right;\">                 0.082663</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_6 </td><td style=\"text-align: right;\">0.966266</td><td style=\"text-align: right;\">0.379472   </td><td style=\"text-align: right;\">0.783478 </td><td style=\"text-align: right;\">            0.0752536 </td><td style=\"text-align: right;\">0.25609    </td><td style=\"text-align: right;\">0.065582   </td><td style=\"text-align: right;\">              2767</td><td style=\"text-align: right;\">                 0.129255</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_4 </td><td style=\"text-align: right;\">0.963435</td><td style=\"text-align: right;\">0.251584   </td><td style=\"text-align: right;\">0.845932 </td><td style=\"text-align: right;\">            0.0931824 </td><td style=\"text-align: right;\">0.224507   </td><td style=\"text-align: right;\">0.0504032  </td><td style=\"text-align: right;\">              4076</td><td style=\"text-align: right;\">                 0.135328</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_26         </td><td style=\"text-align: right;\">0.961312</td><td style=\"text-align: right;\">0.267212   </td><td style=\"text-align: right;\">0.816665 </td><td style=\"text-align: right;\">            0.0605096 </td><td style=\"text-align: right;\">0.278515   </td><td style=\"text-align: right;\">0.0775707  </td><td style=\"text-align: right;\">              3217</td><td style=\"text-align: right;\">                 0.366022</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_5          </td><td style=\"text-align: right;\">0.960722</td><td style=\"text-align: right;\">0.275847   </td><td style=\"text-align: right;\">0.811426 </td><td style=\"text-align: right;\">            0.0758434 </td><td style=\"text-align: right;\">0.279237   </td><td style=\"text-align: right;\">0.0779734  </td><td style=\"text-align: right;\">              1002</td><td style=\"text-align: right;\">                 0.114454</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_5 </td><td style=\"text-align: right;\">0.959188</td><td style=\"text-align: right;\">0.554104   </td><td style=\"text-align: right;\">0.703668 </td><td style=\"text-align: right;\">            0.0720689 </td><td style=\"text-align: right;\">0.307621   </td><td style=\"text-align: right;\">0.094631   </td><td style=\"text-align: right;\">              5769</td><td style=\"text-align: right;\">                 0.111081</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_18</td><td style=\"text-align: right;\">0.959188</td><td style=\"text-align: right;\">0.409966   </td><td style=\"text-align: right;\">0.721469 </td><td style=\"text-align: right;\">            0.0879925 </td><td style=\"text-align: right;\">0.294345   </td><td style=\"text-align: right;\">0.0866389  </td><td style=\"text-align: right;\">              2475</td><td style=\"text-align: right;\">                 0.070641</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_2 </td><td style=\"text-align: right;\">0.958245</td><td style=\"text-align: right;\">0.345041   </td><td style=\"text-align: right;\">0.845385 </td><td style=\"text-align: right;\">            0.135999  </td><td style=\"text-align: right;\">0.251972   </td><td style=\"text-align: right;\">0.0634899  </td><td style=\"text-align: right;\">                85</td><td style=\"text-align: right;\">                 0.05949 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_11</td><td style=\"text-align: right;\">0.955178</td><td style=\"text-align: right;\">0.736577   </td><td style=\"text-align: right;\">0.771916 </td><td style=\"text-align: right;\">            0.112291  </td><td style=\"text-align: right;\">0.288728   </td><td style=\"text-align: right;\">0.0833639  </td><td style=\"text-align: right;\">              2703</td><td style=\"text-align: right;\">                 0.076405</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_13</td><td style=\"text-align: right;\">0.954234</td><td style=\"text-align: right;\">0.362449   </td><td style=\"text-align: right;\">0.746768 </td><td style=\"text-align: right;\">            0.127624  </td><td style=\"text-align: right;\">0.275987   </td><td style=\"text-align: right;\">0.0761689  </td><td style=\"text-align: right;\">              2594</td><td style=\"text-align: right;\">                 0.070642</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_2 </td><td style=\"text-align: right;\">0.952111</td><td style=\"text-align: right;\">0.577566   </td><td style=\"text-align: right;\">0.7573   </td><td style=\"text-align: right;\">            0.225407  </td><td style=\"text-align: right;\">0.271402   </td><td style=\"text-align: right;\">0.0736592  </td><td style=\"text-align: right;\">              2494</td><td style=\"text-align: right;\">                 0.072238</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_2 </td><td style=\"text-align: right;\">0.951875</td><td style=\"text-align: right;\">0.340967   </td><td style=\"text-align: right;\">0.759821 </td><td style=\"text-align: right;\">            0.0879925 </td><td style=\"text-align: right;\">0.280014   </td><td style=\"text-align: right;\">0.0784076  </td><td style=\"text-align: right;\">               192</td><td style=\"text-align: right;\">                 0.065379</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_12</td><td style=\"text-align: right;\">0.951404</td><td style=\"text-align: right;\">0.563041   </td><td style=\"text-align: right;\">0.714493 </td><td style=\"text-align: right;\">            0.102736  </td><td style=\"text-align: right;\">0.286353   </td><td style=\"text-align: right;\">0.081998   </td><td style=\"text-align: right;\">              3430</td><td style=\"text-align: right;\">                 0.073062</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_5 </td><td style=\"text-align: right;\">0.946214</td><td style=\"text-align: right;\">0.448992   </td><td style=\"text-align: right;\">0.742922 </td><td style=\"text-align: right;\">            0.133404  </td><td style=\"text-align: right;\">0.26711    </td><td style=\"text-align: right;\">0.0713478  </td><td style=\"text-align: right;\">              1634</td><td style=\"text-align: right;\">                 0.079871</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_28         </td><td style=\"text-align: right;\">0.942439</td><td style=\"text-align: right;\">0.276871   </td><td style=\"text-align: right;\">0.785789 </td><td style=\"text-align: right;\">            0.210073  </td><td style=\"text-align: right;\">0.288499   </td><td style=\"text-align: right;\">0.0832317  </td><td style=\"text-align: right;\">              2029</td><td style=\"text-align: right;\">                 0.220136</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_15</td><td style=\"text-align: right;\">0.937249</td><td style=\"text-align: right;\">0.782382   </td><td style=\"text-align: right;\">0.602438 </td><td style=\"text-align: right;\">            0.133994  </td><td style=\"text-align: right;\">0.305461   </td><td style=\"text-align: right;\">0.0933066  </td><td style=\"text-align: right;\">              2599</td><td style=\"text-align: right;\">                 0.106687</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_3 </td><td style=\"text-align: right;\">0.935362</td><td style=\"text-align: right;\">0.425621   </td><td style=\"text-align: right;\">0.761447 </td><td style=\"text-align: right;\">            0.213258  </td><td style=\"text-align: right;\">0.279549   </td><td style=\"text-align: right;\">0.0781477  </td><td style=\"text-align: right;\">              2654</td><td style=\"text-align: right;\">                 0.069215</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_14</td><td style=\"text-align: right;\">0.932059</td><td style=\"text-align: right;\">0.623595   </td><td style=\"text-align: right;\">0.692524 </td><td style=\"text-align: right;\">            0.197924  </td><td style=\"text-align: right;\">0.294764   </td><td style=\"text-align: right;\">0.086886   </td><td style=\"text-align: right;\">              2758</td><td style=\"text-align: right;\">                 0.077913</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_4 </td><td style=\"text-align: right;\">0.930644</td><td style=\"text-align: right;\">0.755485   </td><td style=\"text-align: right;\">0.802352 </td><td style=\"text-align: right;\">            0.142368  </td><td style=\"text-align: right;\">0.297571   </td><td style=\"text-align: right;\">0.0885487  </td><td style=\"text-align: right;\">              2371</td><td style=\"text-align: right;\">                 0.080662</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_19</td><td style=\"text-align: right;\">0.92569 </td><td style=\"text-align: right;\">0.607629   </td><td style=\"text-align: right;\">0.700622 </td><td style=\"text-align: right;\">            0.216443  </td><td style=\"text-align: right;\">0.302936   </td><td style=\"text-align: right;\">0.0917701  </td><td style=\"text-align: right;\">              2847</td><td style=\"text-align: right;\">                 0.0761  </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_5 </td><td style=\"text-align: right;\">0.923095</td><td style=\"text-align: right;\">0.641769   </td><td style=\"text-align: right;\">0.648794 </td><td style=\"text-align: right;\">            0.137179  </td><td style=\"text-align: right;\">0.302341   </td><td style=\"text-align: right;\">0.0914102  </td><td style=\"text-align: right;\">              1683</td><td style=\"text-align: right;\">                 0.09258 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_8 </td><td style=\"text-align: right;\">0.917905</td><td style=\"text-align: right;\">0.589929   </td><td style=\"text-align: right;\">0.786008 </td><td style=\"text-align: right;\">            0.139184  </td><td style=\"text-align: right;\">0.276393   </td><td style=\"text-align: right;\">0.0763931  </td><td style=\"text-align: right;\">              3245</td><td style=\"text-align: right;\">                 0.077197</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_24         </td><td style=\"text-align: right;\">0.915782</td><td style=\"text-align: right;\">0.310753   </td><td style=\"text-align: right;\">0.720358 </td><td style=\"text-align: right;\">            0.222812  </td><td style=\"text-align: right;\">0.294695   </td><td style=\"text-align: right;\">0.0868451  </td><td style=\"text-align: right;\">              1846</td><td style=\"text-align: right;\">                 0.257355</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_4 </td><td style=\"text-align: right;\">0.914603</td><td style=\"text-align: right;\">0.529243   </td><td style=\"text-align: right;\">0.714787 </td><td style=\"text-align: right;\">            0.185775  </td><td style=\"text-align: right;\">0.274062   </td><td style=\"text-align: right;\">0.0751099  </td><td style=\"text-align: right;\">              3329</td><td style=\"text-align: right;\">                 0.095058</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_14</td><td style=\"text-align: right;\">0.908705</td><td style=\"text-align: right;\">0.607685   </td><td style=\"text-align: right;\">0.649423 </td><td style=\"text-align: right;\">            0.197924  </td><td style=\"text-align: right;\">0.293267   </td><td style=\"text-align: right;\">0.0860053  </td><td style=\"text-align: right;\">              3274</td><td style=\"text-align: right;\">                 0.087156</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_16</td><td style=\"text-align: right;\">0.908115</td><td style=\"text-align: right;\">0.954789   </td><td style=\"text-align: right;\">0.642806 </td><td style=\"text-align: right;\">            0.158292  </td><td style=\"text-align: right;\">0.310542   </td><td style=\"text-align: right;\">0.0964362  </td><td style=\"text-align: right;\">               427</td><td style=\"text-align: right;\">                 0.097935</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_1 </td><td style=\"text-align: right;\">0.902571</td><td style=\"text-align: right;\">0.498041   </td><td style=\"text-align: right;\">0.657058 </td><td style=\"text-align: right;\">            0.231776  </td><td style=\"text-align: right;\">0.297138   </td><td style=\"text-align: right;\">0.0882912  </td><td style=\"text-align: right;\">              5244</td><td style=\"text-align: right;\">                 0.095408</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_16</td><td style=\"text-align: right;\">0.898561</td><td style=\"text-align: right;\">0.976635   </td><td style=\"text-align: right;\">0.656411 </td><td style=\"text-align: right;\">            0.185775  </td><td style=\"text-align: right;\">0.309246   </td><td style=\"text-align: right;\">0.0956331  </td><td style=\"text-align: right;\">              1578</td><td style=\"text-align: right;\">                 0.078277</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_13</td><td style=\"text-align: right;\">0.898325</td><td style=\"text-align: right;\">0.598415   </td><td style=\"text-align: right;\">0.727435 </td><td style=\"text-align: right;\">            0.207478  </td><td style=\"text-align: right;\">0.307293   </td><td style=\"text-align: right;\">0.0944291  </td><td style=\"text-align: right;\">              3957</td><td style=\"text-align: right;\">                 0.07766 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_17</td><td style=\"text-align: right;\">0.892663</td><td style=\"text-align: right;\">0.871935   </td><td style=\"text-align: right;\">0.719877 </td><td style=\"text-align: right;\">            0.240741  </td><td style=\"text-align: right;\">0.282681   </td><td style=\"text-align: right;\">0.0799084  </td><td style=\"text-align: right;\">              2540</td><td style=\"text-align: right;\">                 0.061178</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_7 </td><td style=\"text-align: right;\">0.89172 </td><td style=\"text-align: right;\">0.36835    </td><td style=\"text-align: right;\">0.577984 </td><td style=\"text-align: right;\">            0.232366  </td><td style=\"text-align: right;\">0.296189   </td><td style=\"text-align: right;\">0.0877277  </td><td style=\"text-align: right;\">              3182</td><td style=\"text-align: right;\">                 0.103724</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_9 </td><td style=\"text-align: right;\">0.89172 </td><td style=\"text-align: right;\">0.590558   </td><td style=\"text-align: right;\">0.483498 </td><td style=\"text-align: right;\">            0.141543  </td><td style=\"text-align: right;\">0.350421   </td><td style=\"text-align: right;\">0.122795   </td><td style=\"text-align: right;\">              2653</td><td style=\"text-align: right;\">                 0.055485</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_1 </td><td style=\"text-align: right;\">0.891012</td><td style=\"text-align: right;\">0.360365   </td><td style=\"text-align: right;\">0.628879 </td><td style=\"text-align: right;\">            0.175395  </td><td style=\"text-align: right;\">0.313196   </td><td style=\"text-align: right;\">0.0980915  </td><td style=\"text-align: right;\">              3934</td><td style=\"text-align: right;\">                 0.147113</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_19</td><td style=\"text-align: right;\">0.887709</td><td style=\"text-align: right;\">0.460523   </td><td style=\"text-align: right;\">0.558756 </td><td style=\"text-align: right;\">            0.140363  </td><td style=\"text-align: right;\">0.323416   </td><td style=\"text-align: right;\">0.104598   </td><td style=\"text-align: right;\">              4241</td><td style=\"text-align: right;\">                 0.106301</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_17</td><td style=\"text-align: right;\">0.88653 </td><td style=\"text-align: right;\">0.552784   </td><td style=\"text-align: right;\">0.596239 </td><td style=\"text-align: right;\">            0.238736  </td><td style=\"text-align: right;\">0.340984   </td><td style=\"text-align: right;\">0.11627    </td><td style=\"text-align: right;\">              2806</td><td style=\"text-align: right;\">                 0.077322</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_12</td><td style=\"text-align: right;\">0.884407</td><td style=\"text-align: right;\">0.517664   </td><td style=\"text-align: right;\">0.652741 </td><td style=\"text-align: right;\">            0.162067  </td><td style=\"text-align: right;\">0.30965    </td><td style=\"text-align: right;\">0.0958834  </td><td style=\"text-align: right;\">              3973</td><td style=\"text-align: right;\">                 0.113267</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_6 </td><td style=\"text-align: right;\">0.884171</td><td style=\"text-align: right;\">0.613146   </td><td style=\"text-align: right;\">0.623411 </td><td style=\"text-align: right;\">            0.284147  </td><td style=\"text-align: right;\">0.300042   </td><td style=\"text-align: right;\">0.0900249  </td><td style=\"text-align: right;\">              5445</td><td style=\"text-align: right;\">                 0.112772</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_15</td><td style=\"text-align: right;\">0.878745</td><td style=\"text-align: right;\">0.754808   </td><td style=\"text-align: right;\">0.632714 </td><td style=\"text-align: right;\">            0.278368  </td><td style=\"text-align: right;\">0.315479   </td><td style=\"text-align: right;\">0.0995269  </td><td style=\"text-align: right;\">              2720</td><td style=\"text-align: right;\">                 0.073986</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_12</td><td style=\"text-align: right;\">0.871668</td><td style=\"text-align: right;\">0.585886   </td><td style=\"text-align: right;\">0.576613 </td><td style=\"text-align: right;\">            0.241331  </td><td style=\"text-align: right;\">0.305632   </td><td style=\"text-align: right;\">0.0934112  </td><td style=\"text-align: right;\">              2970</td><td style=\"text-align: right;\">                 0.093247</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_10</td><td style=\"text-align: right;\">0.868837</td><td style=\"text-align: right;\">0.542946   </td><td style=\"text-align: right;\">0.603706 </td><td style=\"text-align: right;\">            0.202288  </td><td style=\"text-align: right;\">0.318163   </td><td style=\"text-align: right;\">0.101228   </td><td style=\"text-align: right;\">              3338</td><td style=\"text-align: right;\">                 0.102005</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_7 </td><td style=\"text-align: right;\">0.866714</td><td style=\"text-align: right;\">0.525258   </td><td style=\"text-align: right;\">0.602803 </td><td style=\"text-align: right;\">            0.229181  </td><td style=\"text-align: right;\">0.299544   </td><td style=\"text-align: right;\">0.0897268  </td><td style=\"text-align: right;\">              6218</td><td style=\"text-align: right;\">                 0.114946</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_8 </td><td style=\"text-align: right;\">0.86577 </td><td style=\"text-align: right;\">0.620046   </td><td style=\"text-align: right;\">0.532676 </td><td style=\"text-align: right;\">            0.201699  </td><td style=\"text-align: right;\">0.322309   </td><td style=\"text-align: right;\">0.103883   </td><td style=\"text-align: right;\">              6327</td><td style=\"text-align: right;\">                 0.131995</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_17</td><td style=\"text-align: right;\">0.861524</td><td style=\"text-align: right;\">0.634448   </td><td style=\"text-align: right;\">0.457779 </td><td style=\"text-align: right;\">            0.187544  </td><td style=\"text-align: right;\">0.362161   </td><td style=\"text-align: right;\">0.13116    </td><td style=\"text-align: right;\">              2544</td><td style=\"text-align: right;\">                 0.076615</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_8 </td><td style=\"text-align: right;\">0.856806</td><td style=\"text-align: right;\">0.599374   </td><td style=\"text-align: right;\">0.601814 </td><td style=\"text-align: right;\">            0.217032  </td><td style=\"text-align: right;\">0.305326   </td><td style=\"text-align: right;\">0.0932237  </td><td style=\"text-align: right;\">              4742</td><td style=\"text-align: right;\">                 0.084994</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_3 </td><td style=\"text-align: right;\">0.854683</td><td style=\"text-align: right;\">0.518469   </td><td style=\"text-align: right;\">0.560786 </td><td style=\"text-align: right;\">            0.232956  </td><td style=\"text-align: right;\">0.334382   </td><td style=\"text-align: right;\">0.111812   </td><td style=\"text-align: right;\">              4321</td><td style=\"text-align: right;\">                 0.070196</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_19</td><td style=\"text-align: right;\">0.85256 </td><td style=\"text-align: right;\">0.547712   </td><td style=\"text-align: right;\">0.475265 </td><td style=\"text-align: right;\">            0.217622  </td><td style=\"text-align: right;\">0.333469   </td><td style=\"text-align: right;\">0.111201   </td><td style=\"text-align: right;\">              3075</td><td style=\"text-align: right;\">                 0.090846</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_13</td><td style=\"text-align: right;\">0.850436</td><td style=\"text-align: right;\">0.54229    </td><td style=\"text-align: right;\">0.651599 </td><td style=\"text-align: right;\">            0.208068  </td><td style=\"text-align: right;\">0.307883   </td><td style=\"text-align: right;\">0.0947919  </td><td style=\"text-align: right;\">              2760</td><td style=\"text-align: right;\">                 0.080178</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230516_204009_model_11</td><td style=\"text-align: right;\">0.82661 </td><td style=\"text-align: right;\">0.531859   </td><td style=\"text-align: right;\">0.610224 </td><td style=\"text-align: right;\">            0.205473  </td><td style=\"text-align: right;\">0.306574   </td><td style=\"text-align: right;\">0.0939876  </td><td style=\"text-align: right;\">              2575</td><td style=\"text-align: right;\">                 0.080202</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_14</td><td style=\"text-align: right;\">0.825902</td><td style=\"text-align: right;\">0.597162   </td><td style=\"text-align: right;\">0.512333 </td><td style=\"text-align: right;\">            0.275183  </td><td style=\"text-align: right;\">0.31556    </td><td style=\"text-align: right;\">0.0995783  </td><td style=\"text-align: right;\">              3589</td><td style=\"text-align: right;\">                 0.101133</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_6 </td><td style=\"text-align: right;\">0.808917</td><td style=\"text-align: right;\">0.646922   </td><td style=\"text-align: right;\">0.562941 </td><td style=\"text-align: right;\">            0.30644   </td><td style=\"text-align: right;\">0.323777   </td><td style=\"text-align: right;\">0.104832   </td><td style=\"text-align: right;\">              2619</td><td style=\"text-align: right;\">                 0.0855  </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230516_204009_model_15</td><td style=\"text-align: right;\">0.805379</td><td style=\"text-align: right;\">1.07268    </td><td style=\"text-align: right;\">0.466417 </td><td style=\"text-align: right;\">            0.291106  </td><td style=\"text-align: right;\">0.338213   </td><td style=\"text-align: right;\">0.114388   </td><td style=\"text-align: right;\">              2645</td><td style=\"text-align: right;\">                 0.097244</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_18</td><td style=\"text-align: right;\">0.804671</td><td style=\"text-align: right;\">0.636199   </td><td style=\"text-align: right;\">0.51936  </td><td style=\"text-align: right;\">            0.336518  </td><td style=\"text-align: right;\">0.322238   </td><td style=\"text-align: right;\">0.103837   </td><td style=\"text-align: right;\">              2658</td><td style=\"text-align: right;\">                 0.04801 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_1_20230516_204009              </td><td style=\"text-align: right;\">0.772352</td><td style=\"text-align: right;\">0.458223   </td><td style=\"text-align: right;\">0.382743 </td><td style=\"text-align: right;\">            0.31281   </td><td style=\"text-align: right;\">0.352924   </td><td style=\"text-align: right;\">0.124555   </td><td style=\"text-align: right;\">                96</td><td style=\"text-align: right;\">                 0.051454</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_11</td><td style=\"text-align: right;\">0.772116</td><td style=\"text-align: right;\">0.554062   </td><td style=\"text-align: right;\">0.449246 </td><td style=\"text-align: right;\">            0.262208  </td><td style=\"text-align: right;\">0.352817   </td><td style=\"text-align: right;\">0.12448    </td><td style=\"text-align: right;\">              2609</td><td style=\"text-align: right;\">                 0.057688</td><td>DeepLearning</td></tr>\n",
       "<tr><td>XRT_1_AutoML_1_20230516_204009                       </td><td style=\"text-align: right;\">0.753244</td><td style=\"text-align: right;\">0.393839   </td><td style=\"text-align: right;\">0.267562 </td><td style=\"text-align: right;\">            0.199457  </td><td style=\"text-align: right;\">0.345321   </td><td style=\"text-align: right;\">0.119247   </td><td style=\"text-align: right;\">               106</td><td style=\"text-align: right;\">                 0.059894</td><td>DRF         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_10</td><td style=\"text-align: right;\">0.748054</td><td style=\"text-align: right;\">0.464747   </td><td style=\"text-align: right;\">0.365351 </td><td style=\"text-align: right;\">            0.288511  </td><td style=\"text-align: right;\">0.340955   </td><td style=\"text-align: right;\">0.116251   </td><td style=\"text-align: right;\">              6188</td><td style=\"text-align: right;\">                 0.107735</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230516_204009_model_9 </td><td style=\"text-align: right;\">0.636235</td><td style=\"text-align: right;\">0.85968    </td><td style=\"text-align: right;\">0.271714 </td><td style=\"text-align: right;\">            0.299363  </td><td style=\"text-align: right;\">0.363652   </td><td style=\"text-align: right;\">0.132243   </td><td style=\"text-align: right;\">              2634</td><td style=\"text-align: right;\">                 0.061821</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_29         </td><td style=\"text-align: right;\">0.334867</td><td style=\"text-align: right;\">0.504393   </td><td style=\"text-align: right;\">0.105934 </td><td style=\"text-align: right;\">            0.5       </td><td style=\"text-align: right;\">0.378386   </td><td style=\"text-align: right;\">0.143176   </td><td style=\"text-align: right;\">               103</td><td style=\"text-align: right;\">                 0.041563</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_20         </td><td style=\"text-align: right;\">0.331564</td><td style=\"text-align: right;\">0.505372   </td><td style=\"text-align: right;\">0.104527 </td><td style=\"text-align: right;\">            0.493631  </td><td style=\"text-align: right;\">0.379002   </td><td style=\"text-align: right;\">0.143642   </td><td style=\"text-align: right;\">                83</td><td style=\"text-align: right;\">                 0.190738</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_25         </td><td style=\"text-align: right;\">0.313753</td><td style=\"text-align: right;\">0.510751   </td><td style=\"text-align: right;\">0.102389 </td><td style=\"text-align: right;\">            0.5       </td><td style=\"text-align: right;\">0.382755   </td><td style=\"text-align: right;\">0.146501   </td><td style=\"text-align: right;\">                95</td><td style=\"text-align: right;\">                 0.054952</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_11         </td><td style=\"text-align: right;\">0.301014</td><td style=\"text-align: right;\">0.483181   </td><td style=\"text-align: right;\">0.101812 </td><td style=\"text-align: right;\">            0.496815  </td><td style=\"text-align: right;\">0.373875   </td><td style=\"text-align: right;\">0.139783   </td><td style=\"text-align: right;\">                99</td><td style=\"text-align: right;\">                 0.049964</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_4          </td><td style=\"text-align: right;\">0.288865</td><td style=\"text-align: right;\">0.501679   </td><td style=\"text-align: right;\">0.0986975</td><td style=\"text-align: right;\">            0.5       </td><td style=\"text-align: right;\">0.378215   </td><td style=\"text-align: right;\">0.143047   </td><td style=\"text-align: right;\">                95</td><td style=\"text-align: right;\">                 0.038312</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230516_204009_model_31         </td><td style=\"text-align: right;\">0.28226 </td><td style=\"text-align: right;\">0.52298    </td><td style=\"text-align: right;\">0.0989787</td><td style=\"text-align: right;\">            0.496815  </td><td style=\"text-align: right;\">0.382106   </td><td style=\"text-align: right;\">0.146005   </td><td style=\"text-align: right;\">                98</td><td style=\"text-align: right;\">                 0.05773 </td><td>GBM         </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[94 rows x 10 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                    auc      logloss      aucpr    mean_per_class_error         rmse          mse    training_time_ms    predict_time_per_row_ms  algo\n",
       "-----------------------------------------------------  --------  -----------  ---------  ----------------------  -----------  -----------  ------------------  -------------------------  ------------\n",
       "GBM_2_AutoML_1_20230516_204009                         1         0.00737889   1                      0           0.0331065    0.00109604                 2688                   0.447721  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_23           1         0.0276576    1                      0           0.0929754    0.00864442                 3893                   0.482572  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_7            1         0.00241718   1                      0           0.01406      0.000197684                3639                   0.475077  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_32           1         1.3837e-05   1                      0           0.000108532  1.17792e-08                3349                   0.468091  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_21           1         0.0351646    1                      0           0.0933088    0.00870654                 1558                   0.297523  GBM\n",
       "GBM_5_AutoML_1_20230516_204009                         1         1.67674e-12  1                      0           7.31043e-12  5.34425e-23                5743                   0.445983  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_3            1         0.068937     1                      0           0.156675     0.0245472                  3245                   0.392354  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_10           1         0.0703679    1                      0           0.156364     0.0244497                  1955                   0.34111   GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_17           1         2.31509e-10  1                      0           2.69854e-09  7.28213e-18                2582                   0.479831  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_35           1         1.89568e-05  1                      0           0.000164082  2.6923e-08                 2933                   0.485245  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_2            1         7.36126e-17  1                      0           3.722e-16    1.38533e-31                2910                   0.359657  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_33           1         0.0224434    1                      0           0.0630308    0.00397288                  850                   0.23594   GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_1            1         0.0624392    1                      0           0.149366     0.0223103                  3333                   0.497433  GBM\n",
       "GBM_3_AutoML_1_20230516_204009                         1         4.83643e-05  1                      0           0.000393079  1.54511e-07                2732                   0.392175  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_13           1         1.56827e-06  1                      0           7.75635e-06  6.0161e-11                 5037                   0.546291  GBM\n",
       "GBM_4_AutoML_1_20230516_204009                         1         7.18643e-07  1                      0           9.3646e-06   8.76958e-11                6213                   0.360597  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_12           1         8.32667e-17  1                      0           6.50772e-16  4.23504e-31                2709                   0.328248  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_8            1         0.000355136  1                      0           0.00203733   4.15073e-06                4741                   0.523237  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_9            0.999528  0.116205     0.997255               0.00318471  0.207505     0.0430584                  2289                   0.328979  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_15           0.995754  0.131321     0.961866               0.00318471  0.215064     0.0462524                   452                   0.104259  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_18           0.995518  0.260425     0.957964               0.00318471  0.309194     0.0956009                   417                   0.093103  GBM\n",
       "DRF_1_AutoML_1_20230516_204009                         0.995046  0.152241     0.963345               0.00636943  0.206222     0.0425277                   251                   0.069863  DRF\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_22           0.987969  0.189745     0.941336               0.0529606   0.246071     0.060551                    299                   0.072435  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_16  0.977235  0.543796     0.836602               0.05933     0.262228     0.0687634                  3634                   0.163266  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_7   0.975702  0.317707     0.883501               0.0408115   0.257052     0.0660755                  2730                   0.078795  DeepLearning\n",
       "GLM_1_AutoML_1_20230516_204009                         0.974758  0.186266     0.874505               0.0899976   0.234246     0.054871                     85                   0.065055  GLM\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_9   0.972399  0.381428     0.911255               0.0561453   0.236077     0.0557323                  2677                   0.059581  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_34           0.969686  0.242737     0.857357               0.114886    0.269958     0.0728772                  4265                   0.406005  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_18  0.969332  0.486464     0.852064               0.0344421   0.258328     0.0667334                  2472                   0.06613   DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_3   0.967327  0.751456     0.792463               0.111701    0.269893     0.0728424                  8129                   0.076823  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_10  0.966502  0.282501     0.844965               0.0874027   0.256959     0.0660281                  4629                   0.069958  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_1   0.966266  0.394726     0.817673               0.0995518   0.288427     0.0831903                  3831                   0.082663  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_6   0.966266  0.379472     0.783478               0.0752536   0.25609      0.065582                   2767                   0.129255  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_4   0.963435  0.251584     0.845932               0.0931824   0.224507     0.0504032                  4076                   0.135328  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_26           0.961312  0.267212     0.816665               0.0605096   0.278515     0.0775707                  3217                   0.366022  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_5            0.960722  0.275847     0.811426               0.0758434   0.279237     0.0779734                  1002                   0.114454  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_5   0.959188  0.554104     0.703668               0.0720689   0.307621     0.094631                   5769                   0.111081  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_18  0.959188  0.409966     0.721469               0.0879925   0.294345     0.0866389                  2475                   0.070641  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_2   0.958245  0.345041     0.845385               0.135999    0.251972     0.0634899                    85                   0.05949   DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_11  0.955178  0.736577     0.771916               0.112291    0.288728     0.0833639                  2703                   0.076405  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_13  0.954234  0.362449     0.746768               0.127624    0.275987     0.0761689                  2594                   0.070642  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_2   0.952111  0.577566     0.7573                 0.225407    0.271402     0.0736592                  2494                   0.072238  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_2   0.951875  0.340967     0.759821               0.0879925   0.280014     0.0784076                   192                   0.065379  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_12  0.951404  0.563041     0.714493               0.102736    0.286353     0.081998                   3430                   0.073062  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_5   0.946214  0.448992     0.742922               0.133404    0.26711      0.0713478                  1634                   0.079871  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_28           0.942439  0.276871     0.785789               0.210073    0.288499     0.0832317                  2029                   0.220136  GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_15  0.937249  0.782382     0.602438               0.133994    0.305461     0.0933066                  2599                   0.106687  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_3   0.935362  0.425621     0.761447               0.213258    0.279549     0.0781477                  2654                   0.069215  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_14  0.932059  0.623595     0.692524               0.197924    0.294764     0.086886                   2758                   0.077913  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_4   0.930644  0.755485     0.802352               0.142368    0.297571     0.0885487                  2371                   0.080662  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_19  0.92569   0.607629     0.700622               0.216443    0.302936     0.0917701                  2847                   0.0761    DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_5   0.923095  0.641769     0.648794               0.137179    0.302341     0.0914102                  1683                   0.09258   DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_8   0.917905  0.589929     0.786008               0.139184    0.276393     0.0763931                  3245                   0.077197  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_24           0.915782  0.310753     0.720358               0.222812    0.294695     0.0868451                  1846                   0.257355  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_4   0.914603  0.529243     0.714787               0.185775    0.274062     0.0751099                  3329                   0.095058  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_14  0.908705  0.607685     0.649423               0.197924    0.293267     0.0860053                  3274                   0.087156  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_16  0.908115  0.954789     0.642806               0.158292    0.310542     0.0964362                   427                   0.097935  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_1   0.902571  0.498041     0.657058               0.231776    0.297138     0.0882912                  5244                   0.095408  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_16  0.898561  0.976635     0.656411               0.185775    0.309246     0.0956331                  1578                   0.078277  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_13  0.898325  0.598415     0.727435               0.207478    0.307293     0.0944291                  3957                   0.07766   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_17  0.892663  0.871935     0.719877               0.240741    0.282681     0.0799084                  2540                   0.061178  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_7   0.89172   0.36835      0.577984               0.232366    0.296189     0.0877277                  3182                   0.103724  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_9   0.89172   0.590558     0.483498               0.141543    0.350421     0.122795                   2653                   0.055485  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_1   0.891012  0.360365     0.628879               0.175395    0.313196     0.0980915                  3934                   0.147113  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_19  0.887709  0.460523     0.558756               0.140363    0.323416     0.104598                   4241                   0.106301  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_17  0.88653   0.552784     0.596239               0.238736    0.340984     0.11627                    2806                   0.077322  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_12  0.884407  0.517664     0.652741               0.162067    0.30965      0.0958834                  3973                   0.113267  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_6   0.884171  0.613146     0.623411               0.284147    0.300042     0.0900249                  5445                   0.112772  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_15  0.878745  0.754808     0.632714               0.278368    0.315479     0.0995269                  2720                   0.073986  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_12  0.871668  0.585886     0.576613               0.241331    0.305632     0.0934112                  2970                   0.093247  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_10  0.868837  0.542946     0.603706               0.202288    0.318163     0.101228                   3338                   0.102005  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_7   0.866714  0.525258     0.602803               0.229181    0.299544     0.0897268                  6218                   0.114946  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_8   0.86577   0.620046     0.532676               0.201699    0.322309     0.103883                   6327                   0.131995  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_17  0.861524  0.634448     0.457779               0.187544    0.362161     0.13116                    2544                   0.076615  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_8   0.856806  0.599374     0.601814               0.217032    0.305326     0.0932237                  4742                   0.084994  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_3   0.854683  0.518469     0.560786               0.232956    0.334382     0.111812                   4321                   0.070196  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_19  0.85256   0.547712     0.475265               0.217622    0.333469     0.111201                   3075                   0.090846  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_13  0.850436  0.54229      0.651599               0.208068    0.307883     0.0947919                  2760                   0.080178  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230516_204009_model_11  0.82661   0.531859     0.610224               0.205473    0.306574     0.0939876                  2575                   0.080202  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_14  0.825902  0.597162     0.512333               0.275183    0.31556      0.0995783                  3589                   0.101133  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_6   0.808917  0.646922     0.562941               0.30644     0.323777     0.104832                   2619                   0.0855    DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230516_204009_model_15  0.805379  1.07268      0.466417               0.291106    0.338213     0.114388                   2645                   0.097244  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_18  0.804671  0.636199     0.51936                0.336518    0.322238     0.103837                   2658                   0.04801   DeepLearning\n",
       "DeepLearning_1_AutoML_1_20230516_204009                0.772352  0.458223     0.382743               0.31281     0.352924     0.124555                     96                   0.051454  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_11  0.772116  0.554062     0.449246               0.262208    0.352817     0.12448                    2609                   0.057688  DeepLearning\n",
       "XRT_1_AutoML_1_20230516_204009                         0.753244  0.393839     0.267562               0.199457    0.345321     0.119247                    106                   0.059894  DRF\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_10  0.748054  0.464747     0.365351               0.288511    0.340955     0.116251                   6188                   0.107735  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230516_204009_model_9   0.636235  0.85968      0.271714               0.299363    0.363652     0.132243                   2634                   0.061821  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_29           0.334867  0.504393     0.105934               0.5         0.378386     0.143176                    103                   0.041563  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_20           0.331564  0.505372     0.104527               0.493631    0.379002     0.143642                     83                   0.190738  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_25           0.313753  0.510751     0.102389               0.5         0.382755     0.146501                     95                   0.054952  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_11           0.301014  0.483181     0.101812               0.496815    0.373875     0.139783                     99                   0.049964  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_4            0.288865  0.501679     0.0986975              0.5         0.378215     0.143047                     95                   0.038312  GBM\n",
       "GBM_grid_1_AutoML_1_20230516_204009_model_31           0.28226   0.52298      0.0989787              0.496815    0.382106     0.146005                     98                   0.05773   GBM\n",
       "[94 rows x 10 columns]\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.automl import H2OAutoML, get_leaderboard\n",
    "\n",
    "# Import a sample binary outcome train/test set into H2O\n",
    "train1 = h2o.H2OFrame(train)\n",
    "\n",
    "# Identify predictors and response\n",
    "predictors = ['year', 'film', 'wiki', 'winner', 'rating', 'numVotes',\n",
    "       'worldwide_box_office', 'Action', 'Adventure', 'Animation', 'Biography',\n",
    "       'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy',\n",
    "       'Film-Noir', 'Game-Show', 'History', 'Horror', 'Music', 'Musical',\n",
    "       'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
    "       'Talk-Show', 'Thriller', 'War', 'Western', 'action', 'adventure',\n",
    "       'animation', 'biography', 'comedy', 'crime', 'documentary', 'drama',\n",
    "       'family', 'fantasy', 'film-noir', 'history', 'horror', 'music',\n",
    "       'musical', 'mystery', 'romance', 'sci-fi', 'sport', 'thriller', 'war',\n",
    "       'western', 'nominations', 'nom_gg_drama',\n",
    "       'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga',\n",
    "       'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga',\n",
    "       'nom_sag', 'winner_sag', 'nom_cannes', 'winner_cannes']\n",
    "\n",
    "x = predictors\n",
    "y = 'Oscar_win'\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train1[y] = train1[y].asfactor()\n",
    "\n",
    "# Run AutoML for 100 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=100, seed=1\n",
    "                , keep_cross_validation_predictions= True\n",
    "               , exclude_algos = ['StackedEnsemble'])\n",
    "\n",
    "aml.train(x=x, y=y, training_frame=train1)\n",
    "\n",
    "# AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "\n",
    "# Optionally edd extra model information to the leaderboard\n",
    "lb = get_leaderboard(aml, extra_columns='ALL')\n",
    "\n",
    "# Print all rows (instead of default 10 rows)\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
       "Model Key: GBM_2_AutoML_1_20230516_204009\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Model Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>number_of_trees</th>\n",
       "<th>number_of_internal_trees</th>\n",
       "<th>model_size_in_bytes</th>\n",
       "<th>min_depth</th>\n",
       "<th>max_depth</th>\n",
       "<th>mean_depth</th>\n",
       "<th>min_leaves</th>\n",
       "<th>max_leaves</th>\n",
       "<th>mean_leaves</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>422.0</td>\n",
       "<td>422.0</td>\n",
       "<td>79527.0</td>\n",
       "<td>5.0</td>\n",
       "<td>7.0</td>\n",
       "<td>6.9241705</td>\n",
       "<td>8.0</td>\n",
       "<td>13.0</td>\n",
       "<td>10.21564</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 6.946142673511543e-30\n",
       "RMSE: 2.635553580087406e-15\n",
       "LogLoss: 9.467064813243894e-16\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9999999999999996</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>157.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/157.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>26.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.963</td>\n",
       "<td> (26.0/27.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>183.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1413</td>\n",
       "<td> (26.0/184.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>157.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>26.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>157.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>1.0000000</td>\n",
       "<td>27.0</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9629630</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>18.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,67 %, avg score: 14,67 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0108696</td>\n",
       "<td>1.0000000</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.0740741</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.0740741</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0217391</td>\n",
       "<td>1.0000000</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.1481481</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.1481481</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0380435</td>\n",
       "<td>1.0000000</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.2592593</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.2592593</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0543478</td>\n",
       "<td>1.0000000</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.3703704</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.3703704</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.1086957</td>\n",
       "<td>1.0000000</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.3703704</td>\n",
       "<td>0.7407407</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.7407407</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1521739</td>\n",
       "<td>0.0000000</td>\n",
       "<td>5.9629630</td>\n",
       "<td>6.5714286</td>\n",
       "<td>0.875</td>\n",
       "<td>0.8750000</td>\n",
       "<td>0.9642857</td>\n",
       "<td>0.9642857</td>\n",
       "<td>0.2592593</td>\n",
       "<td>1.0</td>\n",
       "<td>496.2962963</td>\n",
       "<td>557.1428571</td>\n",
       "<td>0.9936306</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.2010870</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>4.9729730</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.7297297</td>\n",
       "<td>0.7297297</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>397.2972973</td>\n",
       "<td>0.9363057</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2989130</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3454545</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4909091</td>\n",
       "<td>0.4909091</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>234.5454545</td>\n",
       "<td>0.8216561</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.4021739</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4864865</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3648649</td>\n",
       "<td>0.3648649</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>148.6486486</td>\n",
       "<td>0.7006369</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.2934783</td>\n",
       "<td>0.2934783</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td>\n",
       "<td>0.5859873</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5978261</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6727273</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.2454545</td>\n",
       "<td>0.2454545</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2727273</td>\n",
       "<td>0.4713376</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.7010870</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4263566</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.2093023</td>\n",
       "<td>0.2093023</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6356589</td>\n",
       "<td>0.3503185</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7989130</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2517007</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1836735</td>\n",
       "<td>0.1836735</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1700680</td>\n",
       "<td>0.2356688</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8967391</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1151515</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1636364</td>\n",
       "<td>0.1636364</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.5151515</td>\n",
       "<td>0.1210191</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1467391</td>\n",
       "<td>0.1467391</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.0010960410138123567\n",
       "RMSE: 0.0331065101424532\n",
       "LogLoss: 0.00737888777203201\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6636793827784128</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>157.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/157.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/27.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>157.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/184.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.6636794</td>\n",
       "<td>1.0</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.6636794</td>\n",
       "<td>1.0</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6636794</td>\n",
       "<td>1.0</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6636794</td>\n",
       "<td>1.0</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.6636794</td>\n",
       "<td>1.0</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.6636794</td>\n",
       "<td>1.0</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.6636794</td>\n",
       "<td>1.0</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.6636794</td>\n",
       "<td>1.0</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>157.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>17.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>1e-19</td>\n",
       "<td>157.0</td>\n",
       "<td>120.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.6636794</td>\n",
       "<td>27.0</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.6296296</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>1e-19</td>\n",
       "<td>1.0</td>\n",
       "<td>120.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.6636794</td>\n",
       "<td>1.0</td>\n",
       "<td>17.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,67 %, avg score: 14,01 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0543478</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3703704</td>\n",
       "<td>0.3703704</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.3703704</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0543478</td>\n",
       "<td>0.9994291</td>\n",
       "<td>0.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3703704</td>\n",
       "<td>-100.0</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.3703704</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.1032609</td>\n",
       "<td>0.9423832</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9817427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9913518</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.7037037</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.7037037</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.1521739</td>\n",
       "<td>0.0014572</td>\n",
       "<td>6.0576132</td>\n",
       "<td>6.5714286</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.7708625</td>\n",
       "<td>0.9642857</td>\n",
       "<td>0.9204802</td>\n",
       "<td>0.2962963</td>\n",
       "<td>1.0</td>\n",
       "<td>505.7613169</td>\n",
       "<td>557.1428571</td>\n",
       "<td>0.9936306</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.2010870</td>\n",
       "<td>0.0001591</td>\n",
       "<td>0.0</td>\n",
       "<td>4.9729730</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0006109</td>\n",
       "<td>0.7297297</td>\n",
       "<td>0.6967282</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>397.2972973</td>\n",
       "<td>0.9363057</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000048</td>\n",
       "<td>0.1467391</td>\n",
       "<td>0.1401068</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>15.801961</td>\n",
       "<td>13.234314</td>\n",
       "<td>37.0</td>\n",
       "<td>18.5</td>\n",
       "<td>2.1764705</td>\n",
       "<td>12.333333</td>\n",
       "<td>9.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0073390</td>\n",
       "<td>0.0164105</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0366950</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0010901</td>\n",
       "<td>0.0024376</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0054506</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9956107</td>\n",
       "<td>0.0098148</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9780534</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.0147656</td>\n",
       "<td>0.0330169</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0738281</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-10.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-10 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-10 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-10 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table th,\n",
       "#h2o-table-10 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>number_of_trees</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2023-05-16 20:40:22</td>\n",
       "<td> 9.888 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3538457</td>\n",
       "<td>0.4170108</td>\n",
       "<td>0.5</td>\n",
       "<td>0.1467391</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8532609</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:22</td>\n",
       "<td> 9.925 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.2343846</td>\n",
       "<td>0.2126662</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:22</td>\n",
       "<td> 9.955 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.1641804</td>\n",
       "<td>0.1356602</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:22</td>\n",
       "<td> 9.984 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.1059449</td>\n",
       "<td>0.0826779</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:22</td>\n",
       "<td>10.008 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.0642344</td>\n",
       "<td>0.0482426</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:22</td>\n",
       "<td>10.037 sec</td>\n",
       "<td>25.0</td>\n",
       "<td>0.0430636</td>\n",
       "<td>0.0314647</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:22</td>\n",
       "<td>10.064 sec</td>\n",
       "<td>30.0</td>\n",
       "<td>0.0282847</td>\n",
       "<td>0.0201613</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:22</td>\n",
       "<td>10.094 sec</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0185387</td>\n",
       "<td>0.0129742</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:22</td>\n",
       "<td>10.124 sec</td>\n",
       "<td>40.0</td>\n",
       "<td>0.0116179</td>\n",
       "<td>0.0080478</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:22</td>\n",
       "<td>10.151 sec</td>\n",
       "<td>45.0</td>\n",
       "<td>0.0093532</td>\n",
       "<td>0.0061864</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:24</td>\n",
       "<td>12.263 sec</td>\n",
       "<td>380.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:24</td>\n",
       "<td>12.299 sec</td>\n",
       "<td>385.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:24</td>\n",
       "<td>12.327 sec</td>\n",
       "<td>390.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:24</td>\n",
       "<td>12.363 sec</td>\n",
       "<td>395.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:24</td>\n",
       "<td>12.392 sec</td>\n",
       "<td>400.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:24</td>\n",
       "<td>12.423 sec</td>\n",
       "<td>405.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:24</td>\n",
       "<td>12.462 sec</td>\n",
       "<td>410.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:24</td>\n",
       "<td>12.492 sec</td>\n",
       "<td>415.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:24</td>\n",
       "<td>12.524 sec</td>\n",
       "<td>420.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-16 20:40:24</td>\n",
       "<td>12.547 sec</td>\n",
       "<td>422.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[86 rows x 10 columns]</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-11.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-11 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-11 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-11 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table th,\n",
       "#h2o-table-11 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>winner</td>\n",
       "<td>95.1976547</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8712171</td></tr>\n",
       "<tr><td>winner_dga</td>\n",
       "<td>4.0545001</td>\n",
       "<td>0.0425903</td>\n",
       "<td>0.0371054</td></tr>\n",
       "<tr><td>numVotes</td>\n",
       "<td>2.2383323</td>\n",
       "<td>0.0235125</td>\n",
       "<td>0.0204845</td></tr>\n",
       "<tr><td>winner_pga</td>\n",
       "<td>2.1725264</td>\n",
       "<td>0.0228212</td>\n",
       "<td>0.0198822</td></tr>\n",
       "<tr><td>winner_gg_drama</td>\n",
       "<td>1.6657178</td>\n",
       "<td>0.0174975</td>\n",
       "<td>0.0152441</td></tr>\n",
       "<tr><td>comedy</td>\n",
       "<td>1.3634382</td>\n",
       "<td>0.0143222</td>\n",
       "<td>0.0124777</td></tr>\n",
       "<tr><td>year</td>\n",
       "<td>1.1377046</td>\n",
       "<td>0.0119510</td>\n",
       "<td>0.0104119</td></tr>\n",
       "<tr><td>rating</td>\n",
       "<td>0.7210633</td>\n",
       "<td>0.0075744</td>\n",
       "<td>0.0065989</td></tr>\n",
       "<tr><td>nom_gg_drama</td>\n",
       "<td>0.3704987</td>\n",
       "<td>0.0038919</td>\n",
       "<td>0.0033907</td></tr>\n",
       "<tr><td>winner_gg_comedy</td>\n",
       "<td>0.1586510</td>\n",
       "<td>0.0016665</td>\n",
       "<td>0.0014519</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>family</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>fantasy</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>horror</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>music</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>musical</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mystery</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>sci-fi</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>sport</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>war</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>western</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[61 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
       "Model Key: GBM_2_AutoML_1_20230516_204009\n",
       "\n",
       "\n",
       "Model Summary: \n",
       "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    422                422                         79527                  5            7            6.92417       8             13            10.2156\n",
       "\n",
       "ModelMetricsBinomial: gbm\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 6.946142673511543e-30\n",
       "RMSE: 2.635553580087406e-15\n",
       "LogLoss: 9.467064813243894e-16\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9999999999999996\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      157  0    0        (0.0/157.0)\n",
       "1      26   1    0.963    (26.0/27.0)\n",
       "Total  183  1    0.1413   (26.0/184.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       1            1         18\n",
       "max f2                       1            1         18\n",
       "max f0point5                 1            1         18\n",
       "max accuracy                 1            1         18\n",
       "max precision                1            1         0\n",
       "max recall                   1            1         18\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             1            1         18\n",
       "max min_per_class_accuracy   1            1         18\n",
       "max mean_per_class_accuracy  1            1         18\n",
       "max tns                      1            157       0\n",
       "max fns                      1            26        0\n",
       "max fps                      1.975e-18    157       175\n",
       "max tps                      1            27        18\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.962963  0\n",
       "max fpr                      1.975e-18    1         175\n",
       "max tpr                      1            1         18\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,67 %, avg score: 14,67 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0108696                   1                  6.81481  6.81481            1                1            1                           1                   0.0740741       0.0740741                  581.481  581.481            0.0740741\n",
       "2        0.0217391                   1                  6.81481  6.81481            1                1            1                           1                   0.0740741       0.148148                   581.481  581.481            0.148148\n",
       "3        0.0380435                   1                  6.81481  6.81481            1                1            1                           1                   0.111111        0.259259                   581.481  581.481            0.259259\n",
       "4        0.0543478                   1                  6.81481  6.81481            1                1            1                           1                   0.111111        0.37037                    581.481  581.481            0.37037\n",
       "5        0.108696                    1                  6.81481  6.81481            1                1            1                           1                   0.37037         0.740741                   581.481  581.481            0.740741\n",
       "6        0.152174                    1.70367e-14        5.96296  6.57143            0.875            0.875        0.964286                    0.964286            0.259259        1                          496.296  557.143            0.993631\n",
       "7        0.201087                    1.1621e-15         0        4.97297            0                3.47673e-15  0.72973                     0.72973             0               1                          -100     397.297            0.936306\n",
       "8        0.298913                    4.73146e-16        0        3.34545            0                8.28951e-16  0.490909                    0.490909            0               1                          -100     234.545            0.821656\n",
       "9        0.402174                    2.62163e-16        0        2.48649            0                3.61725e-16  0.364865                    0.364865            0               1                          -100     148.649            0.700637\n",
       "10       0.5                         1.83886e-16        0        2                  0                2.2549e-16   0.293478                    0.293478            0               1                          -100     100                0.585987\n",
       "11       0.597826                    1.02196e-16        0        1.67273            0                1.36478e-16  0.245455                    0.245455            0               1                          -100     67.2727            0.471338\n",
       "12       0.701087                    4.83521e-17        0        1.42636            0                7.68172e-17  0.209302                    0.209302            0               1                          -100     42.6357            0.350318\n",
       "13       0.798913                    2.49959e-17        0        1.2517             0                3.35953e-17  0.183673                    0.183673            0               1                          -100     25.1701            0.235669\n",
       "14       0.896739                    1.27051e-17        0        1.11515            0                1.85165e-17  0.163636                    0.163636            0               1                          -100     11.5152            0.121019\n",
       "15       1                           1.975e-18          0        1                  0                6.94532e-18  0.146739                    0.146739            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: gbm\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.0010960410138123567\n",
       "RMSE: 0.0331065101424532\n",
       "LogLoss: 0.00737888777203201\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6636793827784128\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      157  0    0        (0.0/157.0)\n",
       "1      0    27   0        (0.0/27.0)\n",
       "Total  157  27   0        (0.0/184.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       0.663679     1        17\n",
       "max f2                       0.663679     1        17\n",
       "max f0point5                 0.663679     1        17\n",
       "max accuracy                 0.663679     1        17\n",
       "max precision                1            1        0\n",
       "max recall                   0.663679     1        17\n",
       "max specificity              1            1        0\n",
       "max absolute_mcc             0.663679     1        17\n",
       "max min_per_class_accuracy   0.663679     1        17\n",
       "max mean_per_class_accuracy  0.663679     1        17\n",
       "max tns                      1            157      0\n",
       "max fns                      1            17       0\n",
       "max fps                      1e-19        157      120\n",
       "max tps                      0.663679     27       17\n",
       "max tnr                      1            1        0\n",
       "max fnr                      1            0.62963  0\n",
       "max fpr                      1e-19        1        120\n",
       "max tpr                      0.663679     1        17\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,67 %, avg score: 14,01 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0543478                   1                  6.81481  6.81481            1                1            1                           1                   0.37037         0.37037                    581.481  581.481            0.37037\n",
       "2        0.0543478                   0.999429           0        6.81481            0                0            1                           1                   0               0.37037                    -100     581.481            0.37037\n",
       "3        0.103261                    0.942383           6.81481  6.81481            1                0.981743     1                           0.991352            0.333333        0.703704                   581.481  581.481            0.703704\n",
       "4        0.152174                    0.00145718         6.05761  6.57143            0.888889         0.770862     0.964286                    0.92048             0.296296        1                          505.761  557.143            0.993631\n",
       "5        0.201087                    0.000159124        0        4.97297            0                0.000610944  0.72973                     0.696728            0               1                          -100     397.297            0.936306\n",
       "6        1                           0                  0        1                  0                4.76619e-06  0.146739                    0.140107            0               1                          -100     0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean        sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ----------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 1           0           1             1             1             1             1\n",
       "auc                      1           0           1             1             1             1             1\n",
       "err                      0           0           0             0             0             0             0\n",
       "err_count                0           0           0             0             0             0             0\n",
       "f0point5                 1           0           1             1             1             1             1\n",
       "f1                       1           0           1             1             1             1             1\n",
       "f2                       1           0           1             1             1             1             1\n",
       "lift_top_group           15.802      13.2343     37            18.5          2.17647       12.3333       9\n",
       "logloss                  0.007339    0.0164105   4.71095e-16   3.18064e-16   0.036695      4.14083e-16   7.98744e-16\n",
       "max_per_class_error      0           0           0             0             0             0             0\n",
       "mcc                      1           0           1             1             1             1             1\n",
       "mean_per_class_accuracy  1           0           1             1             1             1             1\n",
       "mean_per_class_error     0           0           0             0             0             0             0\n",
       "mse                      0.00109012  0.00243757  6.61504e-30   1.93617e-30   0.00545058    2.28263e-30   1.82304e-29\n",
       "pr_auc                   1           0           1             1             1             1             1\n",
       "precision                1           0           1             1             1             1             1\n",
       "r2                       0.995611    0.00981482  1             1             0.978053      1             1\n",
       "recall                   1           0           1             1             1             1             1\n",
       "rmse                     0.0147656   0.0330169   2.57197e-15   1.39146e-15   0.0738281     1.51084e-15   4.26971e-15\n",
       "specificity              1           0           1             1             1             1             1\n",
       "\n",
       "Scoring History: \n",
       "     timestamp            duration    number_of_trees    training_rmse           training_logloss        training_auc    training_pr_auc     training_lift      training_classification_error\n",
       "---  -------------------  ----------  -----------------  ----------------------  ----------------------  --------------  ------------------  -----------------  -------------------------------\n",
       "     2023-05-16 20:40:22  9.888 sec   0.0                0.3538456697969136      0.417010829229631       0.5             0.1467391304347826  1.0                0.8532608695652174\n",
       "     2023-05-16 20:40:22  9.925 sec   5.0                0.23438461268092217     0.2126661801981953      1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:22  9.955 sec   10.0               0.1641803657785482      0.13566016480080692     1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:22  9.984 sec   15.0               0.10594492044639815     0.08267790485759714     1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:22  10.008 sec  20.0               0.06423442521847443     0.048242646621630435    1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:22  10.037 sec  25.0               0.043063640160567816    0.03146469367370463     1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:22  10.064 sec  30.0               0.028284696951980486    0.020161281155655773    1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:22  10.094 sec  35.0               0.01853865594508775     0.012974244717815294    1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:22  10.124 sec  40.0               0.011617935689758274    0.008047758773822026    1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:22  10.151 sec  45.0               0.00935323589103588     0.006186371450985466    1.0             1.0                 6.814814814814814  0.0\n",
       "---  ---                  ---         ---                ---                     ---                     ---             ---                 ---                ---\n",
       "     2023-05-16 20:40:24  12.263 sec  380.0              6.537306229485346e-14   2.6816109719249865e-14  1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:24  12.299 sec  385.0              4.1279355308631484e-14  1.6733595185832075e-14  1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:24  12.327 sec  390.0              2.920876805263066e-14   1.139185364398029e-14   1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:24  12.363 sec  395.0              2.1114261836354248e-14  8.375546633055544e-15   1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:24  12.392 sec  400.0              1.4399293586961503e-14  5.710407991876448e-15   1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:24  12.423 sec  405.0              8.735454076867601e-15   3.468843569875051e-15   1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:24  12.462 sec  410.0              5.5377582760413025e-15  2.169158572569274e-15   1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:24  12.492 sec  415.0              4.073953222038066e-15   1.5187126918377898e-15  1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:24  12.524 sec  420.0              2.8513689495788266e-15  1.0716065715947197e-15  1.0             1.0                 6.814814814814814  0.0\n",
       "     2023-05-16 20:40:24  12.547 sec  422.0              2.635553580087406e-15   9.467064813243894e-16   1.0             1.0                 6.814814814814814  0.0\n",
       "[86 rows x 10 columns]\n",
       "\n",
       "\n",
       "Variable Importances: \n",
       "variable          relative_importance    scaled_importance      percentage\n",
       "----------------  ---------------------  ---------------------  ---------------------\n",
       "winner            95.1976547241211       1.0                    0.8712170723992421\n",
       "winner_dga        4.054500102996826      0.04259033601979588    0.03710542785966656\n",
       "numVotes          2.2383322715759277     0.023512472844656972   0.02048446775658873\n",
       "winner_pga        2.1725263595581055     0.02282121724378608    0.019882234075718406\n",
       "winner_gg_drama   1.6657178401947021     0.017497467190992093   0.01524409214053792\n",
       "comedy            1.3634382486343384     0.014322183173372565   0.012477730494671333\n",
       "year              1.137704610824585      0.011950973100352171   0.010411891796810912\n",
       "rating            0.7210632562637329     0.007574380465079153   0.006598929574024269\n",
       "nom_gg_drama      0.3704987168312073     0.0038918891216899974  0.0033906802467012173\n",
       "winner_gg_comedy  0.15865103900432587    0.0016665435662684136  0.0014519212068301597\n",
       "---               ---                    ---                    ---\n",
       "family            0.0                    0.0                    0.0\n",
       "fantasy           0.0                    0.0                    0.0\n",
       "horror            0.0                    0.0                    0.0\n",
       "music             0.0                    0.0                    0.0\n",
       "musical           0.0                    0.0                    0.0\n",
       "mystery           0.0                    0.0                    0.0\n",
       "sci-fi            0.0                    0.0                    0.0\n",
       "sport             0.0                    0.0                    0.0\n",
       "war               0.0                    0.0                    0.0\n",
       "western           0.0                    0.0                    0.0\n",
       "[61 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model = aml.leader\n",
    "top_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |âââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 100%\n"
     ]
    }
   ],
   "source": [
    "# Predict on 2019's films\n",
    "test = full_table.loc[(full_table['year'] == 2019)]\n",
    "\n",
    "# Import a binary outcome train/test set into H2O\n",
    "test = h2o.H2OFrame(test)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost prediction progress: |ââââââââââââââââââââââââââââââââââââââââââââ| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">      p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.872341</td><td style=\"text-align: right;\">0.127659</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.871212</td><td style=\"text-align: right;\">0.128788</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.871916</td><td style=\"text-align: right;\">0.128084</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.871639</td><td style=\"text-align: right;\">0.128361</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.872341</td><td style=\"text-align: right;\">0.127659</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.872341</td><td style=\"text-align: right;\">0.127659</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.508026</td><td style=\"text-align: right;\">0.491974</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.871212</td><td style=\"text-align: right;\">0.128788</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.805078</td><td style=\"text-align: right;\">0.194922</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = top_model.predict(test)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred'] = preds['predict']\n",
    "test['probA'] = preds['p1']\n",
    "test_pd = test.as_data_frame(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>probA</th>\n",
       "      <th>%_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1917 (2019 film)</td>\n",
       "      <td>0.491974</td>\n",
       "      <td>31.061029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Parasite (2019 film)</td>\n",
       "      <td>0.194922</td>\n",
       "      <td>12.306475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Irishman</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>8.131125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Once Upon a Time in Hollywood</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>8.131125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joker (2019 film)</td>\n",
       "      <td>0.128361</td>\n",
       "      <td>8.104137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jojo Rabbit</td>\n",
       "      <td>0.128084</td>\n",
       "      <td>8.086673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ford v Ferrari</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>8.059812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Women (2019 film)</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>8.059812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Marriage Story</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>8.059812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            film     probA  %_confidence\n",
       "6               1917 (2019 film)  0.491974     31.061029\n",
       "8           Parasite (2019 film)  0.194922     12.306475\n",
       "1                   The Irishman  0.128788      8.131125\n",
       "7  Once Upon a Time in Hollywood  0.128788      8.131125\n",
       "3              Joker (2019 film)  0.128361      8.104137\n",
       "2                    Jojo Rabbit  0.128084      8.086673\n",
       "0                 Ford v Ferrari  0.127659      8.059812\n",
       "4       Little Women (2019 film)  0.127659      8.059812\n",
       "5                 Marriage Story  0.127659      8.059812"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rankings = test_pd[['film','probA']].sort_values('probA', ascending = False)\n",
    "final_rankings['%_confidence'] = final_rankings['probA']/final_rankings['probA'].sum() * 100\n",
    "final_rankings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And the Oscar goes to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And the Oscar goes to...\n",
      "ðð1917ðð\n"
     ]
    }
   ],
   "source": [
    "bp_winner = np.array(final_rankings.reset_index())[0][1].split('(')[0].strip()\n",
    "print(f'And the Oscar goes to...\\nðð{bp_winner}ðð')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
