{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-Oscar Prediction with AutoML\n",
    "After out dataframe has been assemlbed (see scraping and table_assembling) notebooks we have the data we need to make predictions on the Best Picture winner. [AutoML](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html) represents a quick, but powerful route though the Machine Learning process. H2O's AutoML runs many models through the dataset and using cross-validation, picks the best one. For my purposes I use it to confirm/compare to the Preferential Balloting Random Forest model I created.\n",
    "If you are gunning to win your office's Oscar pool, scroll down to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'film', 'wiki', 'winner', 'rating', 'numVotes',\n",
       "       'worldwide_box_office', 'action', 'adventure', 'animation', 'biography',\n",
       "       'comedy', 'crime', 'documentary', 'drama', 'family', 'fantasy',\n",
       "       'film-noir', 'history', 'horror', 'music', 'musical', 'mystery',\n",
       "       'romance', 'sci-fi', 'sport', 'thriller', 'war', 'western',\n",
       "       'nominations', 'Oscar_win', 'nom_gg_drama', 'winner_gg_drama',\n",
       "       'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga', 'winner_pga',\n",
       "       'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga', 'nom_sag',\n",
       "       'winner_sag', 'nom_cannes', 'winner_cannes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_table = pd.read_csv('../data/processed_results/extended_df.csv')\n",
    "full_table=full_table.drop('Unnamed: 0', axis=1)\n",
    "full_table.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Using h2o Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'film', 'wiki', 'winner', 'rating', 'numVotes',\n",
       "       'worldwide_box_office', 'action', 'adventure', 'animation', 'biography',\n",
       "       'comedy', 'crime', 'documentary', 'drama', 'family', 'fantasy',\n",
       "       'film-noir', 'history', 'horror', 'music', 'musical', 'mystery',\n",
       "       'romance', 'sci-fi', 'sport', 'thriller', 'war', 'western',\n",
       "       'nominations', 'Oscar_win', 'nom_gg_drama', 'winner_gg_drama',\n",
       "       'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga', 'winner_pga',\n",
       "       'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga', 'nom_sag',\n",
       "       'winner_sag', 'nom_cannes', 'winner_cannes', 'Acting',\n",
       "       'Production Design', 'Directing', 'VFX', 'Writing', 'Cinematography',\n",
       "       'Sound', 'Film Editing', 'Music'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_table = pd.read_csv('../data/processed_results/everything.csv')\n",
    "full_table=full_table.drop('Unnamed: 0', axis=1)\n",
    "full_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode)\n",
      "  Starting server from C:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmpwulvrab2\n",
      "  JVM stdout: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmpwulvrab2\\h2o_Aleksandra_Czaplak_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmpwulvrab2\\h2o_Aleksandra_Czaplak_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>08 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Berlin</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>27 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Aleksandra_Czaplak_4b3lbg</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.761 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.2 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------------------\n",
       "H2O_cluster_uptime:         08 secs\n",
       "H2O_cluster_timezone:       Europe/Berlin\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    27 days\n",
       "H2O_cluster_name:           H2O_from_python_Aleksandra_Czaplak_4b3lbg\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.761 Gb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.2 final\n",
       "--------------------------  -----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Year of Existance. This data will be used below\n",
    "- golden_globes 1943\n",
    "- pga 1989\n",
    "- bafta 1960\n",
    "- dga 1948\n",
    "- sag 1995\n",
    "- cannes 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I pick a min_year where the awards shows will be relevant\n",
    "min_year = 1995"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O's Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set contains: 176 movies\n"
     ]
    }
   ],
   "source": [
    "# Auto ML uses Cross Validation, so we do not specifiy a validation set\n",
    "train = full_table.loc[((full_table['year'] < 2022) & (full_table['year'] >= min_year))]\n",
    "\n",
    "print('training set contains:', train.shape[0], 'movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'film', 'wiki', 'winner', 'rating', 'numVotes',\n",
       "       'worldwide_box_office', 'action', 'adventure', 'animation', 'biography',\n",
       "       'comedy', 'crime', 'documentary', 'drama', 'family', 'fantasy',\n",
       "       'film-noir', 'history', 'horror', 'music', 'musical', 'mystery',\n",
       "       'romance', 'sci-fi', 'sport', 'thriller', 'war', 'western',\n",
       "       'nominations', 'Oscar_win', 'nom_gg_drama', 'winner_gg_drama',\n",
       "       'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga', 'winner_pga',\n",
       "       'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga', 'nom_sag',\n",
       "       'winner_sag', 'nom_cannes', 'winner_cannes', 'Acting',\n",
       "       'Production Design', 'Directing', 'VFX', 'Writing', 'Cinematography',\n",
       "       'Sound', 'Film Editing', 'Music'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train = train.drop(['index', '[]'], axis=1)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model na df everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "08:57:22.228: AutoML: XGBoost is not available; skipping it.\n",
      "08:57:22.458: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "█\n",
      "08:57:24.737: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "08:57:24.738: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 176.0.\n",
      "08:57:24.764: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "██\n",
      "08:57:26.950: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "██\n",
      "08:57:28.249: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "08:57:29.742: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "█\n",
      "08:57:31.80: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "██\n",
      "08:57:32.51: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "███\n",
      "08:57:33.200: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "███████████████████████████████████████████████████\n",
      "09:34:17.671: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "█| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                            </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th><th style=\"text-align: right;\">  training_time_ms</th><th style=\"text-align: right;\">  predict_time_per_row_ms</th><th>algo        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_5 </td><td style=\"text-align: right;\">0.830513</td><td style=\"text-align: right;\"> 0.695563</td><td style=\"text-align: right;\">0.448287</td><td style=\"text-align: right;\">              0.248974</td><td style=\"text-align: right;\">0.372326</td><td style=\"text-align: right;\">0.138627</td><td style=\"text-align: right;\">              2709</td><td style=\"text-align: right;\">                 0.710977</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_2 </td><td style=\"text-align: right;\">0.823077</td><td style=\"text-align: right;\"> 0.417719</td><td style=\"text-align: right;\">0.39347 </td><td style=\"text-align: right;\">              0.233077</td><td style=\"text-align: right;\">0.344425</td><td style=\"text-align: right;\">0.118629</td><td style=\"text-align: right;\">              2689</td><td style=\"text-align: right;\">                 0.760255</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_22</td><td style=\"text-align: right;\">0.817179</td><td style=\"text-align: right;\"> 0.464433</td><td style=\"text-align: right;\">0.513033</td><td style=\"text-align: right;\">              0.251538</td><td style=\"text-align: right;\">0.321971</td><td style=\"text-align: right;\">0.103665</td><td style=\"text-align: right;\">              2708</td><td style=\"text-align: right;\">                 0.164375</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_5 </td><td style=\"text-align: right;\">0.813077</td><td style=\"text-align: right;\"> 0.654276</td><td style=\"text-align: right;\">0.381339</td><td style=\"text-align: right;\">              0.299231</td><td style=\"text-align: right;\">0.38311 </td><td style=\"text-align: right;\">0.146773</td><td style=\"text-align: right;\">              2062</td><td style=\"text-align: right;\">                 0.109675</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_14</td><td style=\"text-align: right;\">0.809487</td><td style=\"text-align: right;\"> 0.53134 </td><td style=\"text-align: right;\">0.396423</td><td style=\"text-align: right;\">              0.23641 </td><td style=\"text-align: right;\">0.361284</td><td style=\"text-align: right;\">0.130526</td><td style=\"text-align: right;\">              3939</td><td style=\"text-align: right;\">                 0.177956</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_10</td><td style=\"text-align: right;\">0.808846</td><td style=\"text-align: right;\"> 0.738022</td><td style=\"text-align: right;\">0.378064</td><td style=\"text-align: right;\">              0.258205</td><td style=\"text-align: right;\">0.373639</td><td style=\"text-align: right;\">0.139606</td><td style=\"text-align: right;\">              3034</td><td style=\"text-align: right;\">                 0.908088</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_4 </td><td style=\"text-align: right;\">0.802821</td><td style=\"text-align: right;\"> 0.671927</td><td style=\"text-align: right;\">0.381739</td><td style=\"text-align: right;\">              0.212821</td><td style=\"text-align: right;\">0.402897</td><td style=\"text-align: right;\">0.162326</td><td style=\"text-align: right;\">              4143</td><td style=\"text-align: right;\">                 0.270085</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_3 </td><td style=\"text-align: right;\">0.797692</td><td style=\"text-align: right;\"> 0.597201</td><td style=\"text-align: right;\">0.321101</td><td style=\"text-align: right;\">              0.254615</td><td style=\"text-align: right;\">0.400425</td><td style=\"text-align: right;\">0.16034 </td><td style=\"text-align: right;\">              2784</td><td style=\"text-align: right;\">                 0.086429</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_16</td><td style=\"text-align: right;\">0.795128</td><td style=\"text-align: right;\"> 1.49879 </td><td style=\"text-align: right;\">0.359095</td><td style=\"text-align: right;\">              0.273077</td><td style=\"text-align: right;\">0.414024</td><td style=\"text-align: right;\">0.171416</td><td style=\"text-align: right;\">              2630</td><td style=\"text-align: right;\">                 0.117531</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_2 </td><td style=\"text-align: right;\">0.793077</td><td style=\"text-align: right;\"> 0.73027 </td><td style=\"text-align: right;\">0.377618</td><td style=\"text-align: right;\">              0.285641</td><td style=\"text-align: right;\">0.404787</td><td style=\"text-align: right;\">0.163852</td><td style=\"text-align: right;\">              2700</td><td style=\"text-align: right;\">                 0.14276 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_11</td><td style=\"text-align: right;\">0.792564</td><td style=\"text-align: right;\"> 0.386072</td><td style=\"text-align: right;\">0.338971</td><td style=\"text-align: right;\">              0.209487</td><td style=\"text-align: right;\">0.34739 </td><td style=\"text-align: right;\">0.12068 </td><td style=\"text-align: right;\">              2390</td><td style=\"text-align: right;\">                 0.274097</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_12</td><td style=\"text-align: right;\">0.784615</td><td style=\"text-align: right;\"> 0.90519 </td><td style=\"text-align: right;\">0.378051</td><td style=\"text-align: right;\">              0.240513</td><td style=\"text-align: right;\">0.378227</td><td style=\"text-align: right;\">0.143056</td><td style=\"text-align: right;\">              4581</td><td style=\"text-align: right;\">                 0.467057</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_14</td><td style=\"text-align: right;\">0.782051</td><td style=\"text-align: right;\"> 0.412528</td><td style=\"text-align: right;\">0.379142</td><td style=\"text-align: right;\">              0.284103</td><td style=\"text-align: right;\">0.344026</td><td style=\"text-align: right;\">0.118354</td><td style=\"text-align: right;\">              3951</td><td style=\"text-align: right;\">                 0.145976</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_8 </td><td style=\"text-align: right;\">0.781795</td><td style=\"text-align: right;\"> 0.590756</td><td style=\"text-align: right;\">0.372474</td><td style=\"text-align: right;\">              0.274103</td><td style=\"text-align: right;\">0.374488</td><td style=\"text-align: right;\">0.140241</td><td style=\"text-align: right;\">              5329</td><td style=\"text-align: right;\">                 0.138053</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.781026</td><td style=\"text-align: right;\"> 0.360178</td><td style=\"text-align: right;\">0.387828</td><td style=\"text-align: right;\">              0.216154</td><td style=\"text-align: right;\">0.333761</td><td style=\"text-align: right;\">0.111396</td><td style=\"text-align: right;\">                96</td><td style=\"text-align: right;\">                 0.102436</td><td>GLM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_1 </td><td style=\"text-align: right;\">0.779744</td><td style=\"text-align: right;\"> 0.591486</td><td style=\"text-align: right;\">0.406765</td><td style=\"text-align: right;\">              0.261282</td><td style=\"text-align: right;\">0.377667</td><td style=\"text-align: right;\">0.142632</td><td style=\"text-align: right;\">              5603</td><td style=\"text-align: right;\">                 0.190538</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_16</td><td style=\"text-align: right;\">0.779487</td><td style=\"text-align: right;\"> 1.76003 </td><td style=\"text-align: right;\">0.365117</td><td style=\"text-align: right;\">              0.288205</td><td style=\"text-align: right;\">0.430472</td><td style=\"text-align: right;\">0.185306</td><td style=\"text-align: right;\">              2990</td><td style=\"text-align: right;\">                 0.168645</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_1 </td><td style=\"text-align: right;\">0.778205</td><td style=\"text-align: right;\"> 0.637349</td><td style=\"text-align: right;\">0.399865</td><td style=\"text-align: right;\">              0.237179</td><td style=\"text-align: right;\">0.356818</td><td style=\"text-align: right;\">0.127319</td><td style=\"text-align: right;\">              4287</td><td style=\"text-align: right;\">                 0.121014</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_16</td><td style=\"text-align: right;\">0.773077</td><td style=\"text-align: right;\"> 1.10118 </td><td style=\"text-align: right;\">0.355061</td><td style=\"text-align: right;\">              0.248718</td><td style=\"text-align: right;\">0.430749</td><td style=\"text-align: right;\">0.185545</td><td style=\"text-align: right;\">              2940</td><td style=\"text-align: right;\">                 0.184386</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_21</td><td style=\"text-align: right;\">0.769487</td><td style=\"text-align: right;\"> 1.15463 </td><td style=\"text-align: right;\">0.308691</td><td style=\"text-align: right;\">              0.298205</td><td style=\"text-align: right;\">0.421771</td><td style=\"text-align: right;\">0.177891</td><td style=\"text-align: right;\">              2795</td><td style=\"text-align: right;\">                 0.101911</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DRF_1_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.769103</td><td style=\"text-align: right;\"> 0.377327</td><td style=\"text-align: right;\">0.380961</td><td style=\"text-align: right;\">              0.268205</td><td style=\"text-align: right;\">0.329112</td><td style=\"text-align: right;\">0.108315</td><td style=\"text-align: right;\">               184</td><td style=\"text-align: right;\">                 0.082132</td><td>DRF         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_11         </td><td style=\"text-align: right;\">0.763846</td><td style=\"text-align: right;\"> 0.371534</td><td style=\"text-align: right;\">0.279444</td><td style=\"text-align: right;\">              0.28641 </td><td style=\"text-align: right;\">0.339534</td><td style=\"text-align: right;\">0.115283</td><td style=\"text-align: right;\">                60</td><td style=\"text-align: right;\">                 0.10914 </td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_19</td><td style=\"text-align: right;\">0.761795</td><td style=\"text-align: right;\"> 0.773505</td><td style=\"text-align: right;\">0.365195</td><td style=\"text-align: right;\">              0.341026</td><td style=\"text-align: right;\">0.38679 </td><td style=\"text-align: right;\">0.149606</td><td style=\"text-align: right;\">              2386</td><td style=\"text-align: right;\">                 0.178094</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_21         </td><td style=\"text-align: right;\">0.759231</td><td style=\"text-align: right;\"> 0.433061</td><td style=\"text-align: right;\">0.275309</td><td style=\"text-align: right;\">              0.280513</td><td style=\"text-align: right;\">0.362156</td><td style=\"text-align: right;\">0.131157</td><td style=\"text-align: right;\">               120</td><td style=\"text-align: right;\">                 0.401146</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_7 </td><td style=\"text-align: right;\">0.758462</td><td style=\"text-align: right;\"> 0.676088</td><td style=\"text-align: right;\">0.367014</td><td style=\"text-align: right;\">              0.285641</td><td style=\"text-align: right;\">0.414402</td><td style=\"text-align: right;\">0.171729</td><td style=\"text-align: right;\">              5532</td><td style=\"text-align: right;\">                 0.378401</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_2 </td><td style=\"text-align: right;\">0.756923</td><td style=\"text-align: right;\"> 0.555452</td><td style=\"text-align: right;\">0.350468</td><td style=\"text-align: right;\">              0.27641 </td><td style=\"text-align: right;\">0.387615</td><td style=\"text-align: right;\">0.150245</td><td style=\"text-align: right;\">              2591</td><td style=\"text-align: right;\">                 0.139453</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_13         </td><td style=\"text-align: right;\">0.756923</td><td style=\"text-align: right;\"> 0.414042</td><td style=\"text-align: right;\">0.301439</td><td style=\"text-align: right;\">              0.29641 </td><td style=\"text-align: right;\">0.352838</td><td style=\"text-align: right;\">0.124495</td><td style=\"text-align: right;\">               129</td><td style=\"text-align: right;\">                 0.054001</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_2          </td><td style=\"text-align: right;\">0.756795</td><td style=\"text-align: right;\"> 0.400463</td><td style=\"text-align: right;\">0.285598</td><td style=\"text-align: right;\">              0.299744</td><td style=\"text-align: right;\">0.354225</td><td style=\"text-align: right;\">0.125475</td><td style=\"text-align: right;\">                88</td><td style=\"text-align: right;\">                 0.09191 </td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_5 </td><td style=\"text-align: right;\">0.75641 </td><td style=\"text-align: right;\"> 0.745685</td><td style=\"text-align: right;\">0.32153 </td><td style=\"text-align: right;\">              0.335128</td><td style=\"text-align: right;\">0.391403</td><td style=\"text-align: right;\">0.153197</td><td style=\"text-align: right;\">              2803</td><td style=\"text-align: right;\">                 0.350275</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_4 </td><td style=\"text-align: right;\">0.754359</td><td style=\"text-align: right;\"> 0.661384</td><td style=\"text-align: right;\">0.378926</td><td style=\"text-align: right;\">              0.292308</td><td style=\"text-align: right;\">0.394163</td><td style=\"text-align: right;\">0.155365</td><td style=\"text-align: right;\">              5376</td><td style=\"text-align: right;\">                 0.188155</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_17         </td><td style=\"text-align: right;\">0.750897</td><td style=\"text-align: right;\"> 0.408353</td><td style=\"text-align: right;\">0.271268</td><td style=\"text-align: right;\">              0.304103</td><td style=\"text-align: right;\">0.359621</td><td style=\"text-align: right;\">0.129327</td><td style=\"text-align: right;\">                85</td><td style=\"text-align: right;\">                 0.121253</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_12         </td><td style=\"text-align: right;\">0.750513</td><td style=\"text-align: right;\"> 0.408181</td><td style=\"text-align: right;\">0.289041</td><td style=\"text-align: right;\">              0.28641 </td><td style=\"text-align: right;\">0.355011</td><td style=\"text-align: right;\">0.126033</td><td style=\"text-align: right;\">               132</td><td style=\"text-align: right;\">                 0.267484</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_20</td><td style=\"text-align: right;\">0.747692</td><td style=\"text-align: right;\"> 0.456588</td><td style=\"text-align: right;\">0.318082</td><td style=\"text-align: right;\">              0.258718</td><td style=\"text-align: right;\">0.355447</td><td style=\"text-align: right;\">0.126343</td><td style=\"text-align: right;\">              2668</td><td style=\"text-align: right;\">                 0.654688</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_12</td><td style=\"text-align: right;\">0.743077</td><td style=\"text-align: right;\"> 0.832753</td><td style=\"text-align: right;\">0.350161</td><td style=\"text-align: right;\">              0.321538</td><td style=\"text-align: right;\">0.430192</td><td style=\"text-align: right;\">0.185065</td><td style=\"text-align: right;\">              3142</td><td style=\"text-align: right;\">                 0.166638</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_3 </td><td style=\"text-align: right;\">0.743077</td><td style=\"text-align: right;\"> 2.24259 </td><td style=\"text-align: right;\">0.294094</td><td style=\"text-align: right;\">              0.298718</td><td style=\"text-align: right;\">0.465047</td><td style=\"text-align: right;\">0.216268</td><td style=\"text-align: right;\">              2595</td><td style=\"text-align: right;\">                 0.276043</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_3_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.741538</td><td style=\"text-align: right;\"> 0.380115</td><td style=\"text-align: right;\">0.289527</td><td style=\"text-align: right;\">              0.324103</td><td style=\"text-align: right;\">0.342256</td><td style=\"text-align: right;\">0.117139</td><td style=\"text-align: right;\">               152</td><td style=\"text-align: right;\">                 0.055528</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_9          </td><td style=\"text-align: right;\">0.740513</td><td style=\"text-align: right;\"> 0.380416</td><td style=\"text-align: right;\">0.274504</td><td style=\"text-align: right;\">              0.28641 </td><td style=\"text-align: right;\">0.343803</td><td style=\"text-align: right;\">0.118201</td><td style=\"text-align: right;\">                72</td><td style=\"text-align: right;\">                 0.064468</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_8 </td><td style=\"text-align: right;\">0.739744</td><td style=\"text-align: right;\"> 0.748565</td><td style=\"text-align: right;\">0.377619</td><td style=\"text-align: right;\">              0.268974</td><td style=\"text-align: right;\">0.370169</td><td style=\"text-align: right;\">0.137025</td><td style=\"text-align: right;\">              3998</td><td style=\"text-align: right;\">                 0.11151 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_1 </td><td style=\"text-align: right;\">0.739487</td><td style=\"text-align: right;\"> 0.56148 </td><td style=\"text-align: right;\">0.315495</td><td style=\"text-align: right;\">              0.298974</td><td style=\"text-align: right;\">0.380489</td><td style=\"text-align: right;\">0.144772</td><td style=\"text-align: right;\">              2802</td><td style=\"text-align: right;\">                 0.080513</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_19</td><td style=\"text-align: right;\">0.738974</td><td style=\"text-align: right;\"> 0.62602 </td><td style=\"text-align: right;\">0.366896</td><td style=\"text-align: right;\">              0.268974</td><td style=\"text-align: right;\">0.357083</td><td style=\"text-align: right;\">0.127509</td><td style=\"text-align: right;\">              4089</td><td style=\"text-align: right;\">                 0.15411 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_10         </td><td style=\"text-align: right;\">0.738462</td><td style=\"text-align: right;\"> 0.377071</td><td style=\"text-align: right;\">0.294111</td><td style=\"text-align: right;\">              0.290513</td><td style=\"text-align: right;\">0.341778</td><td style=\"text-align: right;\">0.116812</td><td style=\"text-align: right;\">                94</td><td style=\"text-align: right;\">                 0.129367</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_5_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.737179</td><td style=\"text-align: right;\"> 0.434135</td><td style=\"text-align: right;\">0.276889</td><td style=\"text-align: right;\">              0.332564</td><td style=\"text-align: right;\">0.359962</td><td style=\"text-align: right;\">0.129573</td><td style=\"text-align: right;\">               189</td><td style=\"text-align: right;\">                 0.163997</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_1          </td><td style=\"text-align: right;\">0.736154</td><td style=\"text-align: right;\"> 0.381772</td><td style=\"text-align: right;\">0.257161</td><td style=\"text-align: right;\">              0.324103</td><td style=\"text-align: right;\">0.346236</td><td style=\"text-align: right;\">0.119879</td><td style=\"text-align: right;\">                93</td><td style=\"text-align: right;\">                 0.124114</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_19</td><td style=\"text-align: right;\">0.734359</td><td style=\"text-align: right;\"> 0.724492</td><td style=\"text-align: right;\">0.286856</td><td style=\"text-align: right;\">              0.342564</td><td style=\"text-align: right;\">0.38865 </td><td style=\"text-align: right;\">0.151049</td><td style=\"text-align: right;\">              4069</td><td style=\"text-align: right;\">                 0.31668 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_11</td><td style=\"text-align: right;\">0.734103</td><td style=\"text-align: right;\"> 0.585997</td><td style=\"text-align: right;\">0.350118</td><td style=\"text-align: right;\">              0.274872</td><td style=\"text-align: right;\">0.367134</td><td style=\"text-align: right;\">0.134787</td><td style=\"text-align: right;\">              2663</td><td style=\"text-align: right;\">                 0.121672</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_15         </td><td style=\"text-align: right;\">0.73359 </td><td style=\"text-align: right;\"> 0.40042 </td><td style=\"text-align: right;\">0.286015</td><td style=\"text-align: right;\">              0.279487</td><td style=\"text-align: right;\">0.350108</td><td style=\"text-align: right;\">0.122575</td><td style=\"text-align: right;\">                86</td><td style=\"text-align: right;\">                 0.171516</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_4          </td><td style=\"text-align: right;\">0.733205</td><td style=\"text-align: right;\"> 0.37826 </td><td style=\"text-align: right;\">0.248004</td><td style=\"text-align: right;\">              0.292308</td><td style=\"text-align: right;\">0.343261</td><td style=\"text-align: right;\">0.117828</td><td style=\"text-align: right;\">                89</td><td style=\"text-align: right;\">                 0.321691</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_7 </td><td style=\"text-align: right;\">0.731026</td><td style=\"text-align: right;\"> 0.599752</td><td style=\"text-align: right;\">0.344847</td><td style=\"text-align: right;\">              0.306667</td><td style=\"text-align: right;\">0.373629</td><td style=\"text-align: right;\">0.139599</td><td style=\"text-align: right;\">              4315</td><td style=\"text-align: right;\">                 0.123526</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_6 </td><td style=\"text-align: right;\">0.730513</td><td style=\"text-align: right;\"> 0.71592 </td><td style=\"text-align: right;\">0.294893</td><td style=\"text-align: right;\">              0.275128</td><td style=\"text-align: right;\">0.40819 </td><td style=\"text-align: right;\">0.166619</td><td style=\"text-align: right;\">              2868</td><td style=\"text-align: right;\">                 0.107911</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_20</td><td style=\"text-align: right;\">0.729487</td><td style=\"text-align: right;\"> 0.775452</td><td style=\"text-align: right;\">0.345496</td><td style=\"text-align: right;\">              0.311538</td><td style=\"text-align: right;\">0.385905</td><td style=\"text-align: right;\">0.148923</td><td style=\"text-align: right;\">              2881</td><td style=\"text-align: right;\">                 0.102733</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_7          </td><td style=\"text-align: right;\">0.727692</td><td style=\"text-align: right;\"> 0.408609</td><td style=\"text-align: right;\">0.252227</td><td style=\"text-align: right;\">              0.289231</td><td style=\"text-align: right;\">0.358455</td><td style=\"text-align: right;\">0.12849 </td><td style=\"text-align: right;\">                66</td><td style=\"text-align: right;\">                 0.066875</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_11</td><td style=\"text-align: right;\">0.727179</td><td style=\"text-align: right;\"> 0.759333</td><td style=\"text-align: right;\">0.299522</td><td style=\"text-align: right;\">              0.284872</td><td style=\"text-align: right;\">0.383881</td><td style=\"text-align: right;\">0.147364</td><td style=\"text-align: right;\">              2645</td><td style=\"text-align: right;\">                 0.132849</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_8          </td><td style=\"text-align: right;\">0.725641</td><td style=\"text-align: right;\"> 0.433043</td><td style=\"text-align: right;\">0.28079 </td><td style=\"text-align: right;\">              0.295641</td><td style=\"text-align: right;\">0.358929</td><td style=\"text-align: right;\">0.12883 </td><td style=\"text-align: right;\">               131</td><td style=\"text-align: right;\">                 0.089563</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_10</td><td style=\"text-align: right;\">0.721282</td><td style=\"text-align: right;\"> 0.665981</td><td style=\"text-align: right;\">0.341346</td><td style=\"text-align: right;\">              0.324872</td><td style=\"text-align: right;\">0.434704</td><td style=\"text-align: right;\">0.188967</td><td style=\"text-align: right;\">              5331</td><td style=\"text-align: right;\">                 0.139759</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_14</td><td style=\"text-align: right;\">0.72    </td><td style=\"text-align: right;\"> 0.675661</td><td style=\"text-align: right;\">0.337286</td><td style=\"text-align: right;\">              0.33    </td><td style=\"text-align: right;\">0.359504</td><td style=\"text-align: right;\">0.129243</td><td style=\"text-align: right;\">              1856</td><td style=\"text-align: right;\">                 0.082228</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_22         </td><td style=\"text-align: right;\">0.719487</td><td style=\"text-align: right;\"> 0.385287</td><td style=\"text-align: right;\">0.276424</td><td style=\"text-align: right;\">              0.275385</td><td style=\"text-align: right;\">0.342366</td><td style=\"text-align: right;\">0.117214</td><td style=\"text-align: right;\">                69</td><td style=\"text-align: right;\">                 0.067556</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_7 </td><td style=\"text-align: right;\">0.718205</td><td style=\"text-align: right;\"> 0.749389</td><td style=\"text-align: right;\">0.35717 </td><td style=\"text-align: right;\">              0.257949</td><td style=\"text-align: right;\">0.400645</td><td style=\"text-align: right;\">0.160516</td><td style=\"text-align: right;\">              2744</td><td style=\"text-align: right;\">                 0.11812 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_4_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.715641</td><td style=\"text-align: right;\"> 0.394532</td><td style=\"text-align: right;\">0.298985</td><td style=\"text-align: right;\">              0.281282</td><td style=\"text-align: right;\">0.347308</td><td style=\"text-align: right;\">0.120623</td><td style=\"text-align: right;\">               164</td><td style=\"text-align: right;\">                 0.077411</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_20         </td><td style=\"text-align: right;\">0.71359 </td><td style=\"text-align: right;\"> 0.384883</td><td style=\"text-align: right;\">0.245127</td><td style=\"text-align: right;\">              0.308205</td><td style=\"text-align: right;\">0.344086</td><td style=\"text-align: right;\">0.118395</td><td style=\"text-align: right;\">                61</td><td style=\"text-align: right;\">                 0.100552</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_3          </td><td style=\"text-align: right;\">0.711795</td><td style=\"text-align: right;\"> 0.385044</td><td style=\"text-align: right;\">0.302615</td><td style=\"text-align: right;\">              0.333333</td><td style=\"text-align: right;\">0.341844</td><td style=\"text-align: right;\">0.116857</td><td style=\"text-align: right;\">               112</td><td style=\"text-align: right;\">                 0.072263</td><td>GBM         </td></tr>\n",
       "<tr><td>XRT_1_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.711538</td><td style=\"text-align: right;\"> 0.398451</td><td style=\"text-align: right;\">0.268246</td><td style=\"text-align: right;\">              0.313333</td><td style=\"text-align: right;\">0.347068</td><td style=\"text-align: right;\">0.120456</td><td style=\"text-align: right;\">               107</td><td style=\"text-align: right;\">                 0.092367</td><td>DRF         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_12</td><td style=\"text-align: right;\">0.709487</td><td style=\"text-align: right;\"> 0.916957</td><td style=\"text-align: right;\">0.286277</td><td style=\"text-align: right;\">              0.323333</td><td style=\"text-align: right;\">0.411415</td><td style=\"text-align: right;\">0.169262</td><td style=\"text-align: right;\">              3527</td><td style=\"text-align: right;\">                 0.202031</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_5          </td><td style=\"text-align: right;\">0.709231</td><td style=\"text-align: right;\"> 0.397116</td><td style=\"text-align: right;\">0.255828</td><td style=\"text-align: right;\">              0.313077</td><td style=\"text-align: right;\">0.349821</td><td style=\"text-align: right;\">0.122375</td><td style=\"text-align: right;\">               112</td><td style=\"text-align: right;\">                 0.073839</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_1_20230524_85722              </td><td style=\"text-align: right;\">0.707949</td><td style=\"text-align: right;\"> 0.566049</td><td style=\"text-align: right;\">0.253395</td><td style=\"text-align: right;\">              0.335897</td><td style=\"text-align: right;\">0.397394</td><td style=\"text-align: right;\">0.157922</td><td style=\"text-align: right;\">               101</td><td style=\"text-align: right;\">                 0.095452</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_6 </td><td style=\"text-align: right;\">0.706154</td><td style=\"text-align: right;\"> 0.605361</td><td style=\"text-align: right;\">0.32798 </td><td style=\"text-align: right;\">              0.320769</td><td style=\"text-align: right;\">0.365197</td><td style=\"text-align: right;\">0.133369</td><td style=\"text-align: right;\">              4077</td><td style=\"text-align: right;\">                 0.119695</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_10</td><td style=\"text-align: right;\">0.698974</td><td style=\"text-align: right;\"> 0.659814</td><td style=\"text-align: right;\">0.390984</td><td style=\"text-align: right;\">              0.322564</td><td style=\"text-align: right;\">0.391506</td><td style=\"text-align: right;\">0.153277</td><td style=\"text-align: right;\">              4903</td><td style=\"text-align: right;\">                 0.180571</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_18         </td><td style=\"text-align: right;\">0.695897</td><td style=\"text-align: right;\"> 0.437023</td><td style=\"text-align: right;\">0.276155</td><td style=\"text-align: right;\">              0.327436</td><td style=\"text-align: right;\">0.354882</td><td style=\"text-align: right;\">0.125941</td><td style=\"text-align: right;\">               131</td><td style=\"text-align: right;\">                 0.115914</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_18</td><td style=\"text-align: right;\">0.690769</td><td style=\"text-align: right;\"> 0.613497</td><td style=\"text-align: right;\">0.374577</td><td style=\"text-align: right;\">              0.340769</td><td style=\"text-align: right;\">0.375103</td><td style=\"text-align: right;\">0.140702</td><td style=\"text-align: right;\">              3110</td><td style=\"text-align: right;\">                 0.088781</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_22</td><td style=\"text-align: right;\">0.689744</td><td style=\"text-align: right;\"> 0.71721 </td><td style=\"text-align: right;\">0.351706</td><td style=\"text-align: right;\">              0.277179</td><td style=\"text-align: right;\">0.358253</td><td style=\"text-align: right;\">0.128345</td><td style=\"text-align: right;\">              2609</td><td style=\"text-align: right;\">                 0.150519</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_2_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.684103</td><td style=\"text-align: right;\"> 0.416181</td><td style=\"text-align: right;\">0.225593</td><td style=\"text-align: right;\">              0.358205</td><td style=\"text-align: right;\">0.358297</td><td style=\"text-align: right;\">0.128377</td><td style=\"text-align: right;\">               126</td><td style=\"text-align: right;\">                 0.042361</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_13</td><td style=\"text-align: right;\">0.683333</td><td style=\"text-align: right;\"> 0.640924</td><td style=\"text-align: right;\">0.283034</td><td style=\"text-align: right;\">              0.341538</td><td style=\"text-align: right;\">0.371735</td><td style=\"text-align: right;\">0.138187</td><td style=\"text-align: right;\">              3901</td><td style=\"text-align: right;\">                 0.172116</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_8 </td><td style=\"text-align: right;\">0.678462</td><td style=\"text-align: right;\"> 0.635846</td><td style=\"text-align: right;\">0.275963</td><td style=\"text-align: right;\">              0.366923</td><td style=\"text-align: right;\">0.395044</td><td style=\"text-align: right;\">0.15606 </td><td style=\"text-align: right;\">              5460</td><td style=\"text-align: right;\">                 0.369481</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_15</td><td style=\"text-align: right;\">0.675385</td><td style=\"text-align: right;\"> 1.6378  </td><td style=\"text-align: right;\">0.284622</td><td style=\"text-align: right;\">              0.34641 </td><td style=\"text-align: right;\">0.520244</td><td style=\"text-align: right;\">0.270654</td><td style=\"text-align: right;\">              2722</td><td style=\"text-align: right;\">                 0.092243</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_9 </td><td style=\"text-align: right;\">0.673077</td><td style=\"text-align: right;\"> 1.01995 </td><td style=\"text-align: right;\">0.218572</td><td style=\"text-align: right;\">              0.319744</td><td style=\"text-align: right;\">0.441642</td><td style=\"text-align: right;\">0.195047</td><td style=\"text-align: right;\">              2933</td><td style=\"text-align: right;\">                 0.081322</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_21</td><td style=\"text-align: right;\">0.669231</td><td style=\"text-align: right;\"> 0.830025</td><td style=\"text-align: right;\">0.295992</td><td style=\"text-align: right;\">              0.356667</td><td style=\"text-align: right;\">0.443183</td><td style=\"text-align: right;\">0.196411</td><td style=\"text-align: right;\">              2636</td><td style=\"text-align: right;\">                 0.060905</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_23</td><td style=\"text-align: right;\">0.668718</td><td style=\"text-align: right;\"> 1.41541 </td><td style=\"text-align: right;\">0.255323</td><td style=\"text-align: right;\">              0.350513</td><td style=\"text-align: right;\">0.468592</td><td style=\"text-align: right;\">0.219579</td><td style=\"text-align: right;\">              2594</td><td style=\"text-align: right;\">                 0.059538</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_21</td><td style=\"text-align: right;\">0.666154</td><td style=\"text-align: right;\"> 0.666535</td><td style=\"text-align: right;\">0.284685</td><td style=\"text-align: right;\">              0.340769</td><td style=\"text-align: right;\">0.404423</td><td style=\"text-align: right;\">0.163558</td><td style=\"text-align: right;\">              2731</td><td style=\"text-align: right;\">                 0.083045</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_20</td><td style=\"text-align: right;\">0.657692</td><td style=\"text-align: right;\"> 0.567925</td><td style=\"text-align: right;\">0.314398</td><td style=\"text-align: right;\">              0.326667</td><td style=\"text-align: right;\">0.356959</td><td style=\"text-align: right;\">0.127419</td><td style=\"text-align: right;\">              2699</td><td style=\"text-align: right;\">                 0.079024</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_13</td><td style=\"text-align: right;\">0.654103</td><td style=\"text-align: right;\"> 1.05637 </td><td style=\"text-align: right;\">0.255971</td><td style=\"text-align: right;\">              0.361538</td><td style=\"text-align: right;\">0.382364</td><td style=\"text-align: right;\">0.146202</td><td style=\"text-align: right;\">              3733</td><td style=\"text-align: right;\">                 0.093792</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_22</td><td style=\"text-align: right;\">0.653077</td><td style=\"text-align: right;\"> 1.30272 </td><td style=\"text-align: right;\">0.200791</td><td style=\"text-align: right;\">              0.33359 </td><td style=\"text-align: right;\">0.464225</td><td style=\"text-align: right;\">0.215505</td><td style=\"text-align: right;\">              2735</td><td style=\"text-align: right;\">                 0.199886</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_17</td><td style=\"text-align: right;\">0.64    </td><td style=\"text-align: right;\"> 0.637143</td><td style=\"text-align: right;\">0.398898</td><td style=\"text-align: right;\">              0.378718</td><td style=\"text-align: right;\">0.346699</td><td style=\"text-align: right;\">0.1202  </td><td style=\"text-align: right;\">              2628</td><td style=\"text-align: right;\">                 0.751002</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_13</td><td style=\"text-align: right;\">0.622308</td><td style=\"text-align: right;\"> 0.840956</td><td style=\"text-align: right;\">0.237018</td><td style=\"text-align: right;\">              0.360513</td><td style=\"text-align: right;\">0.438958</td><td style=\"text-align: right;\">0.192685</td><td style=\"text-align: right;\">              2415</td><td style=\"text-align: right;\">                 0.589494</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_3 </td><td style=\"text-align: right;\">0.620769</td><td style=\"text-align: right;\"> 0.81861 </td><td style=\"text-align: right;\">0.21137 </td><td style=\"text-align: right;\">              0.364103</td><td style=\"text-align: right;\">0.410995</td><td style=\"text-align: right;\">0.168917</td><td style=\"text-align: right;\">              2863</td><td style=\"text-align: right;\">                36.2781  </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_4 </td><td style=\"text-align: right;\">0.614872</td><td style=\"text-align: right;\"> 1.16054 </td><td style=\"text-align: right;\">0.24582 </td><td style=\"text-align: right;\">              0.347949</td><td style=\"text-align: right;\">0.410871</td><td style=\"text-align: right;\">0.168815</td><td style=\"text-align: right;\">              3194</td><td style=\"text-align: right;\">                 0.275344</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_9 </td><td style=\"text-align: right;\">0.591795</td><td style=\"text-align: right;\"> 0.983963</td><td style=\"text-align: right;\">0.285678</td><td style=\"text-align: right;\">              0.35    </td><td style=\"text-align: right;\">0.400895</td><td style=\"text-align: right;\">0.160717</td><td style=\"text-align: right;\">              2777</td><td style=\"text-align: right;\">                 0.11525 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_6 </td><td style=\"text-align: right;\">0.580513</td><td style=\"text-align: right;\"> 0.760781</td><td style=\"text-align: right;\">0.188506</td><td style=\"text-align: right;\">              0.382564</td><td style=\"text-align: right;\">0.379782</td><td style=\"text-align: right;\">0.144234</td><td style=\"text-align: right;\">              4951</td><td style=\"text-align: right;\">                 0.30105 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_15</td><td style=\"text-align: right;\">0.572821</td><td style=\"text-align: right;\"> 0.746677</td><td style=\"text-align: right;\">0.214842</td><td style=\"text-align: right;\">              0.373333</td><td style=\"text-align: right;\">0.371236</td><td style=\"text-align: right;\">0.137816</td><td style=\"text-align: right;\">              2545</td><td style=\"text-align: right;\">                 0.230366</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_15</td><td style=\"text-align: right;\">0.57    </td><td style=\"text-align: right;\"> 0.972834</td><td style=\"text-align: right;\">0.223291</td><td style=\"text-align: right;\">              0.408718</td><td style=\"text-align: right;\">0.401614</td><td style=\"text-align: right;\">0.161294</td><td style=\"text-align: right;\">              2705</td><td style=\"text-align: right;\">                 0.093188</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_18</td><td style=\"text-align: right;\">0.569487</td><td style=\"text-align: right;\"> 0.561799</td><td style=\"text-align: right;\">0.204888</td><td style=\"text-align: right;\">              0.396923</td><td style=\"text-align: right;\">0.372262</td><td style=\"text-align: right;\">0.138579</td><td style=\"text-align: right;\">              2550</td><td style=\"text-align: right;\">                 0.088106</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_18</td><td style=\"text-align: right;\">0.568718</td><td style=\"text-align: right;\"> 0.897296</td><td style=\"text-align: right;\">0.238073</td><td style=\"text-align: right;\">              0.422051</td><td style=\"text-align: right;\">0.386014</td><td style=\"text-align: right;\">0.149007</td><td style=\"text-align: right;\">              2630</td><td style=\"text-align: right;\">                 0.202487</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_17</td><td style=\"text-align: right;\">0.504615</td><td style=\"text-align: right;\"> 0.902361</td><td style=\"text-align: right;\">0.160535</td><td style=\"text-align: right;\">              0.422051</td><td style=\"text-align: right;\">0.420276</td><td style=\"text-align: right;\">0.176632</td><td style=\"text-align: right;\">              2376</td><td style=\"text-align: right;\">                 0.103973</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_17</td><td style=\"text-align: right;\">0.499231</td><td style=\"text-align: right;\"> 0.877267</td><td style=\"text-align: right;\">0.191124</td><td style=\"text-align: right;\">              0.458718</td><td style=\"text-align: right;\">0.381507</td><td style=\"text-align: right;\">0.145548</td><td style=\"text-align: right;\">              2457</td><td style=\"text-align: right;\">                 2.07925 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_9 </td><td style=\"text-align: right;\">0.483077</td><td style=\"text-align: right;\"> 0.605123</td><td style=\"text-align: right;\">0.134492</td><td style=\"text-align: right;\">              0.463333</td><td style=\"text-align: right;\">0.390951</td><td style=\"text-align: right;\">0.152842</td><td style=\"text-align: right;\">              2139</td><td style=\"text-align: right;\">                 0.09187 </td><td>DeepLearning</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[93 rows x 10 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                   auc    logloss     aucpr    mean_per_class_error      rmse       mse    training_time_ms    predict_time_per_row_ms  algo\n",
       "----------------------------------------------------  --------  ---------  --------  ----------------------  --------  --------  ------------------  -------------------------  ------------\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_5   0.830513   0.695563  0.448287                0.248974  0.372326  0.138627                2709                   0.710977  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_2   0.823077   0.417719  0.39347                 0.233077  0.344425  0.118629                2689                   0.760255  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_22  0.817179   0.464433  0.513033                0.251538  0.321971  0.103665                2708                   0.164375  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_5   0.813077   0.654276  0.381339                0.299231  0.38311   0.146773                2062                   0.109675  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_14  0.809487   0.53134   0.396423                0.23641   0.361284  0.130526                3939                   0.177956  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_10  0.808846   0.738022  0.378064                0.258205  0.373639  0.139606                3034                   0.908088  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_4   0.802821   0.671927  0.381739                0.212821  0.402897  0.162326                4143                   0.270085  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_3   0.797692   0.597201  0.321101                0.254615  0.400425  0.16034                 2784                   0.086429  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_16  0.795128   1.49879   0.359095                0.273077  0.414024  0.171416                2630                   0.117531  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_2   0.793077   0.73027   0.377618                0.285641  0.404787  0.163852                2700                   0.14276   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_11  0.792564   0.386072  0.338971                0.209487  0.34739   0.12068                 2390                   0.274097  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_12  0.784615   0.90519   0.378051                0.240513  0.378227  0.143056                4581                   0.467057  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_14  0.782051   0.412528  0.379142                0.284103  0.344026  0.118354                3951                   0.145976  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_8   0.781795   0.590756  0.372474                0.274103  0.374488  0.140241                5329                   0.138053  DeepLearning\n",
       "GLM_1_AutoML_1_20230524_85722                         0.781026   0.360178  0.387828                0.216154  0.333761  0.111396                  96                   0.102436  GLM\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_1   0.779744   0.591486  0.406765                0.261282  0.377667  0.142632                5603                   0.190538  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_16  0.779487   1.76003   0.365117                0.288205  0.430472  0.185306                2990                   0.168645  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_1   0.778205   0.637349  0.399865                0.237179  0.356818  0.127319                4287                   0.121014  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_16  0.773077   1.10118   0.355061                0.248718  0.430749  0.185545                2940                   0.184386  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_21  0.769487   1.15463   0.308691                0.298205  0.421771  0.177891                2795                   0.101911  DeepLearning\n",
       "DRF_1_AutoML_1_20230524_85722                         0.769103   0.377327  0.380961                0.268205  0.329112  0.108315                 184                   0.082132  DRF\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_11           0.763846   0.371534  0.279444                0.28641   0.339534  0.115283                  60                   0.10914   GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_19  0.761795   0.773505  0.365195                0.341026  0.38679   0.149606                2386                   0.178094  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_21           0.759231   0.433061  0.275309                0.280513  0.362156  0.131157                 120                   0.401146  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_7   0.758462   0.676088  0.367014                0.285641  0.414402  0.171729                5532                   0.378401  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_2   0.756923   0.555452  0.350468                0.27641   0.387615  0.150245                2591                   0.139453  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_13           0.756923   0.414042  0.301439                0.29641   0.352838  0.124495                 129                   0.054001  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_2            0.756795   0.400463  0.285598                0.299744  0.354225  0.125475                  88                   0.09191   GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_5   0.75641    0.745685  0.32153                 0.335128  0.391403  0.153197                2803                   0.350275  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_4   0.754359   0.661384  0.378926                0.292308  0.394163  0.155365                5376                   0.188155  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_17           0.750897   0.408353  0.271268                0.304103  0.359621  0.129327                  85                   0.121253  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_12           0.750513   0.408181  0.289041                0.28641   0.355011  0.126033                 132                   0.267484  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_20  0.747692   0.456588  0.318082                0.258718  0.355447  0.126343                2668                   0.654688  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_12  0.743077   0.832753  0.350161                0.321538  0.430192  0.185065                3142                   0.166638  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_3   0.743077   2.24259   0.294094                0.298718  0.465047  0.216268                2595                   0.276043  DeepLearning\n",
       "GBM_3_AutoML_1_20230524_85722                         0.741538   0.380115  0.289527                0.324103  0.342256  0.117139                 152                   0.055528  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_9            0.740513   0.380416  0.274504                0.28641   0.343803  0.118201                  72                   0.064468  GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_8   0.739744   0.748565  0.377619                0.268974  0.370169  0.137025                3998                   0.11151   DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_1   0.739487   0.56148   0.315495                0.298974  0.380489  0.144772                2802                   0.080513  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_19  0.738974   0.62602   0.366896                0.268974  0.357083  0.127509                4089                   0.15411   DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_10           0.738462   0.377071  0.294111                0.290513  0.341778  0.116812                  94                   0.129367  GBM\n",
       "GBM_5_AutoML_1_20230524_85722                         0.737179   0.434135  0.276889                0.332564  0.359962  0.129573                 189                   0.163997  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_1            0.736154   0.381772  0.257161                0.324103  0.346236  0.119879                  93                   0.124114  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_19  0.734359   0.724492  0.286856                0.342564  0.38865   0.151049                4069                   0.31668   DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_11  0.734103   0.585997  0.350118                0.274872  0.367134  0.134787                2663                   0.121672  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_15           0.73359    0.40042   0.286015                0.279487  0.350108  0.122575                  86                   0.171516  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_4            0.733205   0.37826   0.248004                0.292308  0.343261  0.117828                  89                   0.321691  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_7   0.731026   0.599752  0.344847                0.306667  0.373629  0.139599                4315                   0.123526  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_6   0.730513   0.71592   0.294893                0.275128  0.40819   0.166619                2868                   0.107911  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_20  0.729487   0.775452  0.345496                0.311538  0.385905  0.148923                2881                   0.102733  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_7            0.727692   0.408609  0.252227                0.289231  0.358455  0.12849                   66                   0.066875  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_11  0.727179   0.759333  0.299522                0.284872  0.383881  0.147364                2645                   0.132849  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_8            0.725641   0.433043  0.28079                 0.295641  0.358929  0.12883                  131                   0.089563  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_10  0.721282   0.665981  0.341346                0.324872  0.434704  0.188967                5331                   0.139759  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_14  0.72       0.675661  0.337286                0.33      0.359504  0.129243                1856                   0.082228  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_22           0.719487   0.385287  0.276424                0.275385  0.342366  0.117214                  69                   0.067556  GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_7   0.718205   0.749389  0.35717                 0.257949  0.400645  0.160516                2744                   0.11812   DeepLearning\n",
       "GBM_4_AutoML_1_20230524_85722                         0.715641   0.394532  0.298985                0.281282  0.347308  0.120623                 164                   0.077411  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_20           0.71359    0.384883  0.245127                0.308205  0.344086  0.118395                  61                   0.100552  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_3            0.711795   0.385044  0.302615                0.333333  0.341844  0.116857                 112                   0.072263  GBM\n",
       "XRT_1_AutoML_1_20230524_85722                         0.711538   0.398451  0.268246                0.313333  0.347068  0.120456                 107                   0.092367  DRF\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_12  0.709487   0.916957  0.286277                0.323333  0.411415  0.169262                3527                   0.202031  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_5            0.709231   0.397116  0.255828                0.313077  0.349821  0.122375                 112                   0.073839  GBM\n",
       "DeepLearning_1_AutoML_1_20230524_85722                0.707949   0.566049  0.253395                0.335897  0.397394  0.157922                 101                   0.095452  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_6   0.706154   0.605361  0.32798                 0.320769  0.365197  0.133369                4077                   0.119695  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_10  0.698974   0.659814  0.390984                0.322564  0.391506  0.153277                4903                   0.180571  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_18           0.695897   0.437023  0.276155                0.327436  0.354882  0.125941                 131                   0.115914  GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_18  0.690769   0.613497  0.374577                0.340769  0.375103  0.140702                3110                   0.088781  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_22  0.689744   0.71721   0.351706                0.277179  0.358253  0.128345                2609                   0.150519  DeepLearning\n",
       "GBM_2_AutoML_1_20230524_85722                         0.684103   0.416181  0.225593                0.358205  0.358297  0.128377                 126                   0.042361  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_13  0.683333   0.640924  0.283034                0.341538  0.371735  0.138187                3901                   0.172116  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_8   0.678462   0.635846  0.275963                0.366923  0.395044  0.15606                 5460                   0.369481  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_15  0.675385   1.6378    0.284622                0.34641   0.520244  0.270654                2722                   0.092243  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_9   0.673077   1.01995   0.218572                0.319744  0.441642  0.195047                2933                   0.081322  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_21  0.669231   0.830025  0.295992                0.356667  0.443183  0.196411                2636                   0.060905  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_23  0.668718   1.41541   0.255323                0.350513  0.468592  0.219579                2594                   0.059538  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_21  0.666154   0.666535  0.284685                0.340769  0.404423  0.163558                2731                   0.083045  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_20  0.657692   0.567925  0.314398                0.326667  0.356959  0.127419                2699                   0.079024  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_13  0.654103   1.05637   0.255971                0.361538  0.382364  0.146202                3733                   0.093792  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_22  0.653077   1.30272   0.200791                0.33359   0.464225  0.215505                2735                   0.199886  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_17  0.64       0.637143  0.398898                0.378718  0.346699  0.1202                  2628                   0.751002  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_13  0.622308   0.840956  0.237018                0.360513  0.438958  0.192685                2415                   0.589494  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_3   0.620769   0.81861   0.21137                 0.364103  0.410995  0.168917                2863                  36.2781    DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_4   0.614872   1.16054   0.24582                 0.347949  0.410871  0.168815                3194                   0.275344  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_9   0.591795   0.983963  0.285678                0.35      0.400895  0.160717                2777                   0.11525   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_6   0.580513   0.760781  0.188506                0.382564  0.379782  0.144234                4951                   0.30105   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_15  0.572821   0.746677  0.214842                0.373333  0.371236  0.137816                2545                   0.230366  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_15  0.57       0.972834  0.223291                0.408718  0.401614  0.161294                2705                   0.093188  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_18  0.569487   0.561799  0.204888                0.396923  0.372262  0.138579                2550                   0.088106  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_18  0.568718   0.897296  0.238073                0.422051  0.386014  0.149007                2630                   0.202487  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_17  0.504615   0.902361  0.160535                0.422051  0.420276  0.176632                2376                   0.103973  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_17  0.499231   0.877267  0.191124                0.458718  0.381507  0.145548                2457                   2.07925   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_9   0.483077   0.605123  0.134492                0.463333  0.390951  0.152842                2139                   0.09187   DeepLearning\n",
       "[93 rows x 10 columns]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.automl import H2OAutoML, get_leaderboard\n",
    "\n",
    "# Import a sample binary outcome train/test set into H2O\n",
    "train1 = h2o.H2OFrame(train)\n",
    "\n",
    "# Identify predictors and response\n",
    "predictors = ['year', 'rating', 'numVotes',\n",
    "       'worldwide_box_office', 'action', 'adventure',\n",
    "       'animation', 'biography', 'comedy', 'crime', 'documentary', 'drama',\n",
    "       'family', 'fantasy', 'film-noir', 'history', 'horror', 'music',\n",
    "       'musical', 'mystery', 'romance', 'sci-fi', 'sport', 'thriller', 'war',\n",
    "       'western', 'nominations', 'nom_gg_drama',\n",
    "       'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga',\n",
    "       'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga',\n",
    "       'nom_sag', 'winner_sag', 'nom_cannes', 'winner_cannes','Acting',\n",
    "       'Production Design', 'Directing', 'VFX', 'Writing', 'Cinematography',\n",
    "       'Sound', 'Film Editing', 'Music']\n",
    "\n",
    "x = predictors\n",
    "y = 'Oscar_win'\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train1[y] = train1[y].asfactor()\n",
    "\n",
    "# Run AutoML for 100 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=100, seed=1\n",
    "                , keep_cross_validation_predictions= True\n",
    "               , exclude_algos = ['StackedEnsemble'])\n",
    "\n",
    "aml.train(x=x, y=y, training_frame=train1)\n",
    "\n",
    "# AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "\n",
    "# Optionally edd extra model information to the leaderboard\n",
    "lb = get_leaderboard(aml, extra_columns='ALL')\n",
    "\n",
    "# Print all rows (instead of default 10 rows)\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_1_20230524_85722_model_5\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 15 002 weights/biases, 187,0 KB, 61 600 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>46</td>\n",
       "<td>Input</td>\n",
       "<td>10.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>100</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>40.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0240016</td>\n",
       "<td>0.0330112</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0086950</td>\n",
       "<td>0.1495203</td>\n",
       "<td>0.3626150</td>\n",
       "<td>0.0869916</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>100</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>40.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0412028</td>\n",
       "<td>0.1104845</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0231518</td>\n",
       "<td>0.1138108</td>\n",
       "<td>0.8343524</td>\n",
       "<td>0.0980829</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0117487</td>\n",
       "<td>0.0094979</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0413580</td>\n",
       "<td>0.5311203</td>\n",
       "<td>0.0047554</td>\n",
       "<td>0.0053207</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 1.811046872184211e-05\n",
       "RMSE: 0.0042556396372157865\n",
       "LogLoss: 0.0007151719579600746\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9929139937321374</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/150.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>26.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/26.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>150.0</td>\n",
       "<td>26.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/176.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999996</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999996</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999996</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999996</td>\n",
       "<td>25.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>150.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.9929140</td>\n",
       "<td>26.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999996</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999996</td>\n",
       "<td>0.9615385</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,77 %, avg score: 14,82 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0113636</td>\n",
       "<td>0.9999977</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999988</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999988</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.0769231</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.0769231</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.9999946</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999966</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999977</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.1538462</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.1538462</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0340909</td>\n",
       "<td>0.9999896</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999919</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999958</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.2307692</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.2307692</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.9999804</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999842</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999929</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.3076923</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.3076923</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0511364</td>\n",
       "<td>0.9999783</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999789</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999913</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.3461538</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.3461538</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1022727</td>\n",
       "<td>0.9996659</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998545</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999229</td>\n",
       "<td>0.3461538</td>\n",
       "<td>0.6923077</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.6923077</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1534091</td>\n",
       "<td>0.0417790</td>\n",
       "<td>6.0170940</td>\n",
       "<td>6.5185185</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.8921820</td>\n",
       "<td>0.9629630</td>\n",
       "<td>0.9640093</td>\n",
       "<td>0.3076923</td>\n",
       "<td>1.0</td>\n",
       "<td>501.7094017</td>\n",
       "<td>551.8518519</td>\n",
       "<td>0.9933333</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.0011363</td>\n",
       "<td>0.0</td>\n",
       "<td>4.8888889</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0061911</td>\n",
       "<td>0.7222222</td>\n",
       "<td>0.7245547</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>388.8888889</td>\n",
       "<td>0.9333333</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3011364</td>\n",
       "<td>0.0000876</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3207547</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002847</td>\n",
       "<td>0.4905660</td>\n",
       "<td>0.4922417</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>232.0754717</td>\n",
       "<td>0.8200000</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4034091</td>\n",
       "<td>0.0000140</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4788732</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000406</td>\n",
       "<td>0.3661972</td>\n",
       "<td>0.3674583</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>147.8873239</td>\n",
       "<td>0.7</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0000037</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000076</td>\n",
       "<td>0.2954545</td>\n",
       "<td>0.2964735</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td>\n",
       "<td>0.5866667</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6022727</td>\n",
       "<td>0.0000009</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6603774</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000018</td>\n",
       "<td>0.2452830</td>\n",
       "<td>0.2461293</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.0377358</td>\n",
       "<td>0.4666667</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6988636</td>\n",
       "<td>0.0000002</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4308943</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.2113821</td>\n",
       "<td>0.2121115</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.0894309</td>\n",
       "<td>0.3533333</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8011364</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2482270</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.1843972</td>\n",
       "<td>0.1850334</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.8226950</td>\n",
       "<td>0.2333333</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8977273</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1139241</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1645570</td>\n",
       "<td>0.1651248</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.3924051</td>\n",
       "<td>0.12</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1477273</td>\n",
       "<td>0.1482370</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.138626542100689\n",
       "RMSE: 0.37232585473035446\n",
       "LogLoss: 0.6955626030444713\n",
       "Mean Per-Class Error: 0.248974358974359\n",
       "AUC: 0.8305128205128205\n",
       "AUCPR: 0.4482871529081092\n",
       "Gini: 0.661025641025641</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.07940738509974507</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>133.0</td>\n",
       "<td>17.0</td>\n",
       "<td>0.1133</td>\n",
       "<td> (17.0/150.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>10.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.3846</td>\n",
       "<td> (10.0/26.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>143.0</td>\n",
       "<td>33.0</td>\n",
       "<td>0.1534</td>\n",
       "<td> (27.0/176.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.0794074</td>\n",
       "<td>0.5423729</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0029275</td>\n",
       "<td>0.6686047</td>\n",
       "<td>67.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.0794074</td>\n",
       "<td>0.5063291</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9937201</td>\n",
       "<td>0.8636364</td>\n",
       "<td>7.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999841</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000017</td>\n",
       "<td>1.0</td>\n",
       "<td>147.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999841</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.0794074</td>\n",
       "<td>0.4564103</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0079099</td>\n",
       "<td>0.7466667</td>\n",
       "<td>57.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0029275</td>\n",
       "<td>0.7923077</td>\n",
       "<td>67.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999841</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999841</td>\n",
       "<td>25.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>150.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0000017</td>\n",
       "<td>26.0</td>\n",
       "<td>147.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999841</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999841</td>\n",
       "<td>0.9615385</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0000017</td>\n",
       "<td>1.0</td>\n",
       "<td>147.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,77 %, avg score: 11,76 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0113636</td>\n",
       "<td>0.9992442</td>\n",
       "<td>3.3846154</td>\n",
       "<td>3.3846154</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9999827</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9999827</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.0384615</td>\n",
       "<td>238.4615385</td>\n",
       "<td>238.4615385</td>\n",
       "<td>0.0317949</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.9963245</td>\n",
       "<td>3.3846154</td>\n",
       "<td>3.3846154</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9983397</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9991612</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.0769231</td>\n",
       "<td>238.4615385</td>\n",
       "<td>238.4615385</td>\n",
       "<td>0.0635897</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0340909</td>\n",
       "<td>0.9943115</td>\n",
       "<td>3.3846154</td>\n",
       "<td>3.3846154</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9947086</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9976770</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.1153846</td>\n",
       "<td>238.4615385</td>\n",
       "<td>238.4615385</td>\n",
       "<td>0.0953846</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.9937201</td>\n",
       "<td>6.7692308</td>\n",
       "<td>4.2307692</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9938094</td>\n",
       "<td>0.625</td>\n",
       "<td>0.9967101</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.1923077</td>\n",
       "<td>576.9230769</td>\n",
       "<td>323.0769231</td>\n",
       "<td>0.1723077</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0511364</td>\n",
       "<td>0.9763412</td>\n",
       "<td>0.0</td>\n",
       "<td>3.7606838</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9775552</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.9945818</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1923077</td>\n",
       "<td>-100.0</td>\n",
       "<td>276.0683761</td>\n",
       "<td>0.1656410</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1022727</td>\n",
       "<td>0.5301438</td>\n",
       "<td>2.2564103</td>\n",
       "<td>3.0085470</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.8899175</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.9422496</td>\n",
       "<td>0.1153846</td>\n",
       "<td>0.3076923</td>\n",
       "<td>125.6410256</td>\n",
       "<td>200.8547009</td>\n",
       "<td>0.2410256</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1534091</td>\n",
       "<td>0.1361475</td>\n",
       "<td>3.7606838</td>\n",
       "<td>3.2592593</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.2673719</td>\n",
       "<td>0.4814815</td>\n",
       "<td>0.7172904</td>\n",
       "<td>0.1923077</td>\n",
       "<td>0.5</td>\n",
       "<td>276.0683761</td>\n",
       "<td>225.9259259</td>\n",
       "<td>0.4066667</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.0516889</td>\n",
       "<td>2.2564103</td>\n",
       "<td>3.0085470</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.0889868</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.5602145</td>\n",
       "<td>0.1153846</td>\n",
       "<td>0.6153846</td>\n",
       "<td>125.6410256</td>\n",
       "<td>200.8547009</td>\n",
       "<td>0.4820513</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3011364</td>\n",
       "<td>0.0101030</td>\n",
       "<td>0.3981900</td>\n",
       "<td>2.1712627</td>\n",
       "<td>0.0588235</td>\n",
       "<td>0.0244045</td>\n",
       "<td>0.3207547</td>\n",
       "<td>0.3883509</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.6538462</td>\n",
       "<td>-60.1809955</td>\n",
       "<td>117.1262700</td>\n",
       "<td>0.4138462</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4034091</td>\n",
       "<td>0.0025541</td>\n",
       "<td>2.2564103</td>\n",
       "<td>2.1928494</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.0053476</td>\n",
       "<td>0.3239437</td>\n",
       "<td>0.2912515</td>\n",
       "<td>0.2307692</td>\n",
       "<td>0.8846154</td>\n",
       "<td>125.6410256</td>\n",
       "<td>119.2849404</td>\n",
       "<td>0.5646154</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0004614</td>\n",
       "<td>0.0</td>\n",
       "<td>1.7692308</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010518</td>\n",
       "<td>0.2613636</td>\n",
       "<td>0.2351902</td>\n",
       "<td>0.0</td>\n",
       "<td>0.8846154</td>\n",
       "<td>-100.0</td>\n",
       "<td>76.9230769</td>\n",
       "<td>0.4512821</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6022727</td>\n",
       "<td>0.0001360</td>\n",
       "<td>0.7521368</td>\n",
       "<td>1.5965167</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.0002748</td>\n",
       "<td>0.2358491</td>\n",
       "<td>0.1952989</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.9615385</td>\n",
       "<td>-24.7863248</td>\n",
       "<td>59.6516691</td>\n",
       "<td>0.4215385</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6988636</td>\n",
       "<td>0.0000380</td>\n",
       "<td>0.0</td>\n",
       "<td>1.3758599</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000686</td>\n",
       "<td>0.2032520</td>\n",
       "<td>0.1683158</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9615385</td>\n",
       "<td>-100.0</td>\n",
       "<td>37.5859912</td>\n",
       "<td>0.3082051</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8011364</td>\n",
       "<td>3.63e-06</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2002182</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000158</td>\n",
       "<td>0.1773050</td>\n",
       "<td>0.1468307</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9615385</td>\n",
       "<td>-100.0</td>\n",
       "<td>20.0218221</td>\n",
       "<td>0.1882051</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8977273</td>\n",
       "<td>6.15e-07</td>\n",
       "<td>0.3981900</td>\n",
       "<td>1.1139241</td>\n",
       "<td>0.0588235</td>\n",
       "<td>0.0000018</td>\n",
       "<td>0.1645570</td>\n",
       "<td>0.1310327</td>\n",
       "<td>0.0384615</td>\n",
       "<td>1.0</td>\n",
       "<td>-60.1809955</td>\n",
       "<td>11.3924051</td>\n",
       "<td>0.12</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000002</td>\n",
       "<td>0.1477273</td>\n",
       "<td>0.1176316</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.8179365</td>\n",
       "<td>0.1352280</td>\n",
       "<td>0.8611111</td>\n",
       "<td>0.6285715</td>\n",
       "<td>0.8285714</td>\n",
       "<td>0.7714286</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.8202349</td>\n",
       "<td>0.1284522</td>\n",
       "<td>0.8967742</td>\n",
       "<td>0.6724138</td>\n",
       "<td>0.7592593</td>\n",
       "<td>0.7727272</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.1820635</td>\n",
       "<td>0.1352280</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.3714286</td>\n",
       "<td>0.1714286</td>\n",
       "<td>0.2285714</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>6.4</td>\n",
       "<td>4.7222877</td>\n",
       "<td>5.0</td>\n",
       "<td>13.0</td>\n",
       "<td>6.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.5512977</td>\n",
       "<td>0.2959919</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.3378378</td>\n",
       "<td>0.625</td>\n",
       "<td>0.2380952</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.6012422</td>\n",
       "<td>0.2567396</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.4347826</td>\n",
       "<td>0.5714286</td>\n",
       "<td>0.3333333</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.7049922</td>\n",
       "<td>0.2042226</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.6097561</td>\n",
       "<td>0.5263158</td>\n",
       "<td>0.5555556</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>3.715</td>\n",
       "<td>3.5698214</td>\n",
       "<td>7.2</td>\n",
       "<td>0.0</td>\n",
       "<td>4.375</td>\n",
       "<td>0.0</td>\n",
       "<td>7.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.6949008</td>\n",
       "<td>0.3962450</td>\n",
       "<td>0.8113807</td>\n",
       "<td>0.9612369</td>\n",
       "<td>1.13753</td>\n",
       "<td>0.3410734</td>\n",
       "<td>0.2232830</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.2635015</td>\n",
       "<td>0.1992759</td>\n",
       "<td>0.1612903</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2424243</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.5655490</td>\n",
       "<td>0.2724567</td>\n",
       "<td>0.6475762</td>\n",
       "<td>0.3163644</td>\n",
       "<td>0.4745548</td>\n",
       "<td>0.3892495</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.8441752</td>\n",
       "<td>0.1288534</td>\n",
       "<td>0.9193549</td>\n",
       "<td>0.7097701</td>\n",
       "<td>0.712963</td>\n",
       "<td>0.8787879</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.1558248</td>\n",
       "<td>0.1288534</td>\n",
       "<td>0.0806452</td>\n",
       "<td>0.2902299</td>\n",
       "<td>0.2870370</td>\n",
       "<td>0.1212121</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1384705</td>\n",
       "<td>0.0635008</td>\n",
       "<td>0.1659251</td>\n",
       "<td>0.2009354</td>\n",
       "<td>0.1840445</td>\n",
       "<td>0.0602929</td>\n",
       "<td>0.0811549</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.5103099</td>\n",
       "<td>0.3483282</td>\n",
       "<td>0.562232</td>\n",
       "<td>0.2474944</td>\n",
       "<td>0.6306249</td>\n",
       "<td>0.1111981</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.5321569</td>\n",
       "<td>0.3181961</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2941177</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.2</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>-0.1255176</td>\n",
       "<td>0.3053708</td>\n",
       "<td>-0.3873475</td>\n",
       "<td>-0.414631</td>\n",
       "<td>-0.0437708</td>\n",
       "<td>-0.1190736</td>\n",
       "<td>0.3372348</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.8666667</td>\n",
       "<td>0.2173067</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3630049</td>\n",
       "<td>0.0915014</td>\n",
       "<td>0.4073390</td>\n",
       "<td>0.4482581</td>\n",
       "<td>0.4290041</td>\n",
       "<td>0.2455462</td>\n",
       "<td>0.2848770</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.8216836</td>\n",
       "<td>0.1600876</td>\n",
       "<td>0.8387096</td>\n",
       "<td>0.5862069</td>\n",
       "<td>0.9259259</td>\n",
       "<td>0.7575757</td>\n",
       "<td>1.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-10.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-10 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-10 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-10 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table th,\n",
       "#h2o-table-10 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2023-05-24 09:04:19</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-24 09:04:19</td>\n",
       "<td> 1 min 17.936 sec</td>\n",
       "<td>18333 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>1</td>\n",
       "<td>1760.0</td>\n",
       "<td>0.2598035</td>\n",
       "<td>0.2337768</td>\n",
       "<td>0.4638937</td>\n",
       "<td>0.9448718</td>\n",
       "<td>0.7749020</td>\n",
       "<td>6.7692308</td>\n",
       "<td>0.0795455</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-24 09:04:21</td>\n",
       "<td> 1 min 20.517 sec</td>\n",
       "<td>23149 obs/sec</td>\n",
       "<td>350.0</td>\n",
       "<td>35</td>\n",
       "<td>61600.0</td>\n",
       "<td>0.0042556</td>\n",
       "<td>0.0007152</td>\n",
       "<td>0.9998562</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.7692308</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-11.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-11 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-11 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-11 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table th,\n",
       "#h2o-table-11 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>Cinematography</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0287648</td></tr>\n",
       "<tr><td>Sound</td>\n",
       "<td>0.9666976</td>\n",
       "<td>0.9666976</td>\n",
       "<td>0.0278068</td></tr>\n",
       "<tr><td>Film Editing</td>\n",
       "<td>0.9421129</td>\n",
       "<td>0.9421129</td>\n",
       "<td>0.0270997</td></tr>\n",
       "<tr><td>fantasy</td>\n",
       "<td>0.8859197</td>\n",
       "<td>0.8859197</td>\n",
       "<td>0.0254833</td></tr>\n",
       "<tr><td>winner_dga</td>\n",
       "<td>0.8770376</td>\n",
       "<td>0.8770376</td>\n",
       "<td>0.0252278</td></tr>\n",
       "<tr><td>year</td>\n",
       "<td>0.8713606</td>\n",
       "<td>0.8713606</td>\n",
       "<td>0.0250645</td></tr>\n",
       "<tr><td>Writing</td>\n",
       "<td>0.8564401</td>\n",
       "<td>0.8564401</td>\n",
       "<td>0.0246353</td></tr>\n",
       "<tr><td>nom_gg_drama</td>\n",
       "<td>0.8487479</td>\n",
       "<td>0.8487479</td>\n",
       "<td>0.0244140</td></tr>\n",
       "<tr><td>animation</td>\n",
       "<td>0.8429738</td>\n",
       "<td>0.8429738</td>\n",
       "<td>0.0242479</td></tr>\n",
       "<tr><td>biography</td>\n",
       "<td>0.8374502</td>\n",
       "<td>0.8374502</td>\n",
       "<td>0.0240891</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>nom_pga</td>\n",
       "<td>0.6655245</td>\n",
       "<td>0.6655245</td>\n",
       "<td>0.0191437</td></tr>\n",
       "<tr><td>nom_sag</td>\n",
       "<td>0.6598480</td>\n",
       "<td>0.6598480</td>\n",
       "<td>0.0189804</td></tr>\n",
       "<tr><td>sci-fi</td>\n",
       "<td>0.6524937</td>\n",
       "<td>0.6524937</td>\n",
       "<td>0.0187688</td></tr>\n",
       "<tr><td>nom_bafta</td>\n",
       "<td>0.6417699</td>\n",
       "<td>0.6417699</td>\n",
       "<td>0.0184604</td></tr>\n",
       "<tr><td>crime</td>\n",
       "<td>0.6242755</td>\n",
       "<td>0.6242755</td>\n",
       "<td>0.0179571</td></tr>\n",
       "<tr><td>winner_pga</td>\n",
       "<td>0.6173485</td>\n",
       "<td>0.6173485</td>\n",
       "<td>0.0177579</td></tr>\n",
       "<tr><td>adventure</td>\n",
       "<td>0.5881366</td>\n",
       "<td>0.5881366</td>\n",
       "<td>0.0169176</td></tr>\n",
       "<tr><td>musical</td>\n",
       "<td>0.5724465</td>\n",
       "<td>0.5724465</td>\n",
       "<td>0.0164663</td></tr>\n",
       "<tr><td>nom_dga</td>\n",
       "<td>0.5532149</td>\n",
       "<td>0.5532149</td>\n",
       "<td>0.0159131</td></tr>\n",
       "<tr><td>winner_bafta</td>\n",
       "<td>0.5306445</td>\n",
       "<td>0.5306445</td>\n",
       "<td>0.0152639</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[46 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_1_20230524_85722_model_5\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 15 002 weights/biases, 187,0 KB, 61 600 training samples, mini-batch size 1\n",
       "    layer    units    type              dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight           weight_rms           mean_bias             bias_rms\n",
       "--  -------  -------  ----------------  ---------  ----  ----  --------------------  --------------------  ----------  --------------------  -------------------  --------------------  --------------------\n",
       "    1        46       Input             10.0\n",
       "    2        100      RectifierDropout  40.0       0.0   0.0   0.024001602752263273  0.033011242747306824  0.0         0.008695049894723406  0.14952033758163452  0.36261498813666504   0.0869915783405304\n",
       "    3        100      RectifierDropout  40.0       0.0   0.0   0.0412027502400917    0.11048451066017151   0.0         -0.02315176722473684  0.11381083726882935  0.8343523728225254    0.09808292984962463\n",
       "    4        2        Softmax                      0.0   0.0   0.011748650879599153  0.009497851133346558  0.0         -0.04135797238530358  0.5311203002929688   0.004755425862202034  0.005320673808455467\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 1.811046872184211e-05\n",
       "RMSE: 0.0042556396372157865\n",
       "LogLoss: 0.0007151719579600746\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9929139937321374\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      150  0    0        (0.0/150.0)\n",
       "1      0    26   0        (0.0/26.0)\n",
       "Total  150  26   0        (0.0/176.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.992914     1         25\n",
       "max f2                       0.992914     1         25\n",
       "max f0point5                 0.992914     1         25\n",
       "max accuracy                 0.992914     1         25\n",
       "max precision                1            1         0\n",
       "max recall                   0.992914     1         25\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.992914     1         25\n",
       "max min_per_class_accuracy   0.992914     1         25\n",
       "max mean_per_class_accuracy  0.992914     1         25\n",
       "max tns                      1            150       0\n",
       "max fns                      1            25        0\n",
       "max fps                      4.66436e-18  150       175\n",
       "max tps                      0.992914     26        25\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.961538  0\n",
       "max fpr                      4.66436e-18  1         175\n",
       "max tpr                      0.992914     1         25\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,77 %, avg score: 14,82 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0113636                   0.999998           6.76923  6.76923            1                0.999999     1                           0.999999            0.0769231       0.0769231                  576.923  576.923            0.0769231\n",
       "2        0.0227273                   0.999995           6.76923  6.76923            1                0.999997     1                           0.999998            0.0769231       0.153846                   576.923  576.923            0.153846\n",
       "3        0.0340909                   0.99999            6.76923  6.76923            1                0.999992     1                           0.999996            0.0769231       0.230769                   576.923  576.923            0.230769\n",
       "4        0.0454545                   0.99998            6.76923  6.76923            1                0.999984     1                           0.999993            0.0769231       0.307692                   576.923  576.923            0.307692\n",
       "5        0.0511364                   0.999978           6.76923  6.76923            1                0.999979     1                           0.999991            0.0384615       0.346154                   576.923  576.923            0.346154\n",
       "6        0.102273                    0.999666           6.76923  6.76923            1                0.999854     1                           0.999923            0.346154        0.692308                   576.923  576.923            0.692308\n",
       "7        0.153409                    0.041779           6.01709  6.51852            0.888889         0.892182     0.962963                    0.964009            0.307692        1                          501.709  551.852            0.993333\n",
       "8        0.204545                    0.00113631         0        4.88889            0                0.00619106   0.722222                    0.724555            0               1                          -100     388.889            0.933333\n",
       "9        0.301136                    8.75713e-05        0        3.32075            0                0.000284727  0.490566                    0.492242            0               1                          -100     232.075            0.82\n",
       "10       0.403409                    1.4011e-05         0        2.47887            0                4.05564e-05  0.366197                    0.367458            0               1                          -100     147.887            0.7\n",
       "11       0.5                         3.73337e-06        0        2                  0                7.64592e-06  0.295455                    0.296474            0               1                          -100     100                0.586667\n",
       "12       0.602273                    9.25663e-07        0        1.66038            0                1.77168e-06  0.245283                    0.246129            0               1                          -100     66.0377            0.466667\n",
       "13       0.698864                    1.8219e-07         0        1.43089            0                4.7178e-07   0.211382                    0.212111            0               1                          -100     43.0894            0.353333\n",
       "14       0.801136                    3.32252e-09        0        1.24823            0                6.22435e-08  0.184397                    0.185033            0               1                          -100     24.8227            0.233333\n",
       "15       0.897727                    4.50653e-11        0        1.11392            0                9.49407e-10  0.164557                    0.165125            0               1                          -100     11.3924            0.12\n",
       "16       1                           4.66436e-18        0        1                  0                5.87157e-12  0.147727                    0.148237            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.138626542100689\n",
       "RMSE: 0.37232585473035446\n",
       "LogLoss: 0.6955626030444713\n",
       "Mean Per-Class Error: 0.248974358974359\n",
       "AUC: 0.8305128205128205\n",
       "AUCPR: 0.4482871529081092\n",
       "Gini: 0.661025641025641\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.07940738509974507\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      133  17   0.1133   (17.0/150.0)\n",
       "1      10   16   0.3846   (10.0/26.0)\n",
       "Total  143  33   0.1534   (27.0/176.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.0794074    0.542373  32\n",
       "max f2                       0.00292745   0.668605  67\n",
       "max f0point5                 0.0794074    0.506329  32\n",
       "max accuracy                 0.99372      0.863636  7\n",
       "max precision                0.999984     1         0\n",
       "max recall                   1.67547e-06  1         147\n",
       "max specificity              0.999984     1         0\n",
       "max absolute_mcc             0.0794074    0.45641   32\n",
       "max min_per_class_accuracy   0.00790987   0.746667  57\n",
       "max mean_per_class_accuracy  0.00292745   0.792308  67\n",
       "max tns                      0.999984     150       0\n",
       "max fns                      0.999984     25        0\n",
       "max fps                      1.11845e-09  150       175\n",
       "max tps                      1.67547e-06  26        147\n",
       "max tnr                      0.999984     1         0\n",
       "max fnr                      0.999984     0.961538  0\n",
       "max fpr                      1.11845e-09  1         175\n",
       "max tpr                      1.67547e-06  1         147\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,77 %, avg score: 11,76 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0113636                   0.999244           3.38462   3.38462            0.5              0.999983     0.5                         0.999983            0.0384615       0.0384615                  238.462   238.462            0.0317949\n",
       "2        0.0227273                   0.996324           3.38462   3.38462            0.5              0.99834      0.5                         0.999161            0.0384615       0.0769231                  238.462   238.462            0.0635897\n",
       "3        0.0340909                   0.994311           3.38462   3.38462            0.5              0.994709     0.5                         0.997677            0.0384615       0.115385                   238.462   238.462            0.0953846\n",
       "4        0.0454545                   0.99372            6.76923   4.23077            1                0.993809     0.625                       0.99671             0.0769231       0.192308                   576.923   323.077            0.172308\n",
       "5        0.0511364                   0.976341           0         3.76068            0                0.977555     0.555556                    0.994582            0               0.192308                   -100      276.068            0.165641\n",
       "6        0.102273                    0.530144           2.25641   3.00855            0.333333         0.889917     0.444444                    0.94225             0.115385        0.307692                   125.641   200.855            0.241026\n",
       "7        0.153409                    0.136148           3.76068   3.25926            0.555556         0.267372     0.481481                    0.71729             0.192308        0.5                        276.068   225.926            0.406667\n",
       "8        0.204545                    0.0516889          2.25641   3.00855            0.333333         0.0889868    0.444444                    0.560214            0.115385        0.615385                   125.641   200.855            0.482051\n",
       "9        0.301136                    0.010103           0.39819   2.17126            0.0588235        0.0244045    0.320755                    0.388351            0.0384615       0.653846                   -60.181   117.126            0.413846\n",
       "10       0.403409                    0.00255415         2.25641   2.19285            0.333333         0.00534765   0.323944                    0.291251            0.230769        0.884615                   125.641   119.285            0.564615\n",
       "11       0.5                         0.00046136         0         1.76923            0                0.00105179   0.261364                    0.23519             0               0.884615                   -100      76.9231            0.451282\n",
       "12       0.602273                    0.00013598         0.752137  1.59652            0.111111         0.000274824  0.235849                    0.195299            0.0769231       0.961538                   -24.7863  59.6517            0.421538\n",
       "13       0.698864                    3.802e-05          0         1.37586            0                6.85518e-05  0.203252                    0.168316            0               0.961538                   -100      37.586             0.308205\n",
       "14       0.801136                    3.63e-06           0         1.20022            0                1.58306e-05  0.177305                    0.146831            0               0.961538                   -100      20.0218            0.188205\n",
       "15       0.897727                    6.15e-07           0.39819   1.11392            0.0588235        1.76706e-06  0.164557                    0.131033            0.0384615       1                          -60.181   11.3924            0.12\n",
       "16       1                           0                  0         1                  0                1.96111e-07  0.147727                    0.117632            0               1                          -100      0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean       sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.817936   0.135228   0.861111      0.628571      0.828571      0.771429      1\n",
       "auc                      0.820235   0.128452   0.896774      0.672414      0.759259      0.772727      1\n",
       "err                      0.182063   0.135228   0.138889      0.371429      0.171429      0.228571      0\n",
       "err_count                6.4        4.72229    5             13            6             8             0\n",
       "f0point5                 0.551298   0.295992   0.555556      0.337838      0.625         0.238095      1\n",
       "f1                       0.601242   0.25674    0.666667      0.434783      0.571429      0.333333      1\n",
       "f2                       0.704992   0.204223   0.833333      0.609756      0.526316      0.555556      1\n",
       "lift_top_group           3.715      3.56982    7.2           0             4.375         0             7\n",
       "logloss                  0.694901   0.396245   0.811381      0.961237      1.13753       0.341073      0.223283\n",
       "max_per_class_error      0.263502   0.199276   0.16129       0.413793      0.5           0.242424      0\n",
       "mcc                      0.565549   0.272457   0.647576      0.316364      0.474555      0.389249      1\n",
       "mean_per_class_accuracy  0.844175   0.128853   0.919355      0.70977       0.712963      0.878788      1\n",
       "mean_per_class_error     0.155825   0.128853   0.0806452     0.29023       0.287037      0.121212      0\n",
       "mse                      0.138471   0.0635008  0.165925      0.200935      0.184044      0.0602929     0.0811549\n",
       "pr_auc                   0.51031    0.348328   0.562232      0.247494      0.630625      0.111198      1\n",
       "precision                0.532157   0.318196   0.5           0.294118      0.666667      0.2           1\n",
       "r2                       -0.125518  0.305371   -0.387348     -0.414631     -0.0437708    -0.119074     0.337235\n",
       "recall                   0.866667   0.217307   1             0.833333      0.5           1             1\n",
       "rmse                     0.363005   0.0915014  0.407339      0.448258      0.429004      0.245546      0.284877\n",
       "specificity              0.821684   0.160088   0.83871       0.586207      0.925926      0.757576      1\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2023-05-24 09:04:19  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan\n",
       "    2023-05-24 09:04:19  1 min 17.936 sec  18333 obs/sec     10        1             1760       0.259804         0.233777            0.463894       0.944872        0.774902           6.76923          0.0795455\n",
       "    2023-05-24 09:04:21  1 min 20.517 sec  23149 obs/sec     350       35            61600      0.00425564       0.000715172         0.999856       1               1                  6.76923          0\n",
       "\n",
       "Variable Importances: \n",
       "variable        relative_importance    scaled_importance    percentage\n",
       "--------------  ---------------------  -------------------  --------------------\n",
       "Cinematography  1.0                    1.0                  0.028764766737907455\n",
       "Sound           0.9666975736618042     0.9666975736618042   0.027806830212482907\n",
       "Film Editing    0.9421128630638123     0.9421128630638123   0.02709965674681271\n",
       "fantasy         0.8859196901321411     0.8859196901321411   0.02548327323517029\n",
       "winner_dga      0.8770375847816467     0.8770375847816467   0.0252277815466218\n",
       "year            0.8713605999946594     0.8713605999946594   0.025064484403449463\n",
       "Writing         0.8564401268959045     0.8564401268959045   0.024635300475144555\n",
       "nom_gg_drama    0.8487479090690613     0.8487479090690613   0.024414035623658233\n",
       "animation       0.8429737687110901     0.8429737687110901   0.024247943823149255\n",
       "biography       0.8374502062797546     0.8374502062797546   0.024089059838249622\n",
       "---             ---                    ---                  ---\n",
       "nom_pga         0.6655244827270508     0.6655244827270508   0.019143656504010134\n",
       "nom_sag         0.6598480343818665     0.6598480343818665   0.018980374791461127\n",
       "sci-fi          0.6524936556816101     0.6524936556816101   0.018768827803646016\n",
       "nom_bafta       0.6417699456214905     0.6417699456214905   0.018460362785201724\n",
       "crime           0.6242755055427551     0.6242755055427551   0.017957139297126605\n",
       "winner_pga      0.6173484921455383     0.6173484921455383   0.017757885372565303\n",
       "adventure       0.588136613368988      0.588136613368988    0.016917612493581802\n",
       "musical         0.5724464654922485     0.5724464654922485   0.01646628904982412\n",
       "nom_dga         0.5532149076461792     0.5532149076461792   0.01591309777437536\n",
       "winner_bafta    0.5306445360183716     0.5306445360183716   0.015263866299313589\n",
       "[46 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model = aml.leader\n",
    "top_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model jest na wszystkich danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the leaderboard\n",
    "leaderboard = aml.leaderboard\n",
    "\n",
    "# Get the model ID of the third model (assuming zero-based indexing)\n",
    "third_model_id = leaderboard[2, 'model_id']\n",
    "\n",
    "# Retrieve the model from the third position using the model ID\n",
    "third_model = h2o.get_model(third_model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_1_20230524_85722_model_22\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-12.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-12 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-12 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-12 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table th,\n",
       "#h2o-table-12 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-12 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-12\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 5 002 weights/biases, 68,6 KB, 103 840 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>46</td>\n",
       "<td>Input</td>\n",
       "<td>15.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>50</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>30.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0388930</td>\n",
       "<td>0.1034923</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0099326</td>\n",
       "<td>0.1927573</td>\n",
       "<td>0.4152283</td>\n",
       "<td>0.1329616</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>50</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>30.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0356380</td>\n",
       "<td>0.1158385</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0130971</td>\n",
       "<td>0.1586027</td>\n",
       "<td>0.8645436</td>\n",
       "<td>0.1220017</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0188418</td>\n",
       "<td>0.0968402</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0268669</td>\n",
       "<td>0.7908759</td>\n",
       "<td>-0.0138362</td>\n",
       "<td>0.3820567</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.0002918639572209168\n",
       "RMSE: 0.01708402637614789\n",
       "LogLoss: 0.00258135695067732\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-13.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-13 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-13 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-13 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table th,\n",
       "#h2o-table-13 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-13 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-13\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9935320906464516</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/150.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>26.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/26.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>150.0</td>\n",
       "<td>26.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/176.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-14.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-14 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-14 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-14 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-14 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-14 .h2o-table th,\n",
       "#h2o-table-14 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-14 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-14\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999997</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999997</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999997</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999997</td>\n",
       "<td>25.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>150.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.9935321</td>\n",
       "<td>26.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999997</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999997</td>\n",
       "<td>0.9615385</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.9935321</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-15.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-15 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-15 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-15 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-15 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-15 .h2o-table th,\n",
       "#h2o-table-15 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-15 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-15\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,77 %, avg score: 14,99 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0113636</td>\n",
       "<td>0.9999996</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999997</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999997</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.0769231</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.0769231</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.9999986</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999992</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999995</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.1538462</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.1538462</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0340909</td>\n",
       "<td>0.9999955</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999970</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999986</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.2307692</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.2307692</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.9999896</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999924</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999971</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.3076923</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.3076923</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0511364</td>\n",
       "<td>0.9999699</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999804</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999952</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.3461538</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.3461538</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1022727</td>\n",
       "<td>0.9997540</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998751</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999351</td>\n",
       "<td>0.3461538</td>\n",
       "<td>0.6923077</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.6923077</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1534091</td>\n",
       "<td>0.1728078</td>\n",
       "<td>6.0170940</td>\n",
       "<td>6.5185185</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.9085394</td>\n",
       "<td>0.9629630</td>\n",
       "<td>0.9694699</td>\n",
       "<td>0.3076923</td>\n",
       "<td>1.0</td>\n",
       "<td>501.7094017</td>\n",
       "<td>551.8518519</td>\n",
       "<td>0.9933333</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.0038251</td>\n",
       "<td>0.0</td>\n",
       "<td>4.8888889</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0219737</td>\n",
       "<td>0.7222222</td>\n",
       "<td>0.7325959</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>388.8888889</td>\n",
       "<td>0.9333333</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3011364</td>\n",
       "<td>0.0000652</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3207547</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0008912</td>\n",
       "<td>0.4905660</td>\n",
       "<td>0.4978981</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>232.0754717</td>\n",
       "<td>0.8200000</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4034091</td>\n",
       "<td>0.0000078</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4788732</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000297</td>\n",
       "<td>0.3661972</td>\n",
       "<td>0.3716780</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>147.8873239</td>\n",
       "<td>0.7</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0000016</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000043</td>\n",
       "<td>0.2954545</td>\n",
       "<td>0.2998774</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td>\n",
       "<td>0.5866667</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6022727</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6603774</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.2452830</td>\n",
       "<td>0.2489549</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.0377358</td>\n",
       "<td>0.4666667</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6988636</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4308943</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.2113821</td>\n",
       "<td>0.2145465</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.0894309</td>\n",
       "<td>0.3533333</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8011364</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2482270</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1843972</td>\n",
       "<td>0.1871576</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.8226950</td>\n",
       "<td>0.2333333</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8977273</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1139241</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1645570</td>\n",
       "<td>0.1670204</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.3924051</td>\n",
       "<td>0.12</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1477273</td>\n",
       "<td>0.1499387</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.10366535538522567\n",
       "RMSE: 0.32197104743319027\n",
       "LogLoss: 0.46443296707093845\n",
       "Mean Per-Class Error: 0.25153846153846154\n",
       "AUC: 0.8171794871794872\n",
       "AUCPR: 0.5130330741669865\n",
       "Gini: 0.6343589743589744</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-16.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-16 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-16 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-16 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-16 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-16 .h2o-table th,\n",
       "#h2o-table-16 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-16 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-16\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.15663830936437467</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>138.0</td>\n",
       "<td>12.0</td>\n",
       "<td>0.08</td>\n",
       "<td> (12.0/150.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>11.0</td>\n",
       "<td>15.0</td>\n",
       "<td>0.4231</td>\n",
       "<td> (11.0/26.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>149.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.1307</td>\n",
       "<td> (23.0/176.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-17.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-17 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-17 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-17 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-17 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-17 .h2o-table th,\n",
       "#h2o-table-17 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-17 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-17\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.1566383</td>\n",
       "<td>0.5660377</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0663705</td>\n",
       "<td>0.6071429</td>\n",
       "<td>35.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4022784</td>\n",
       "<td>0.6382979</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4022784</td>\n",
       "<td>0.8920455</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9977479</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0006610</td>\n",
       "<td>1.0</td>\n",
       "<td>122.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9977479</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4022784</td>\n",
       "<td>0.5143528</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0102010</td>\n",
       "<td>0.7066667</td>\n",
       "<td>62.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0663705</td>\n",
       "<td>0.7635897</td>\n",
       "<td>35.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9977479</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9977479</td>\n",
       "<td>25.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000003</td>\n",
       "<td>150.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0006610</td>\n",
       "<td>26.0</td>\n",
       "<td>122.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9977479</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9977479</td>\n",
       "<td>0.9615385</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000003</td>\n",
       "<td>1.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0006610</td>\n",
       "<td>1.0</td>\n",
       "<td>122.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-18.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-18 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-18 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-18 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-18 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-18 .h2o-table th,\n",
       "#h2o-table-18 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-18 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-18\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,77 %, avg score:  9,17 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0113636</td>\n",
       "<td>0.9867128</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974541</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974541</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.0769231</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.0769231</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.9647778</td>\n",
       "<td>3.3846154</td>\n",
       "<td>5.0769231</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9769173</td>\n",
       "<td>0.75</td>\n",
       "<td>0.9871857</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.1153846</td>\n",
       "<td>238.4615385</td>\n",
       "<td>407.6923077</td>\n",
       "<td>0.1087179</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0340909</td>\n",
       "<td>0.8916931</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3846154</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9325579</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9689764</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1153846</td>\n",
       "<td>-100.0</td>\n",
       "<td>238.4615385</td>\n",
       "<td>0.0953846</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.7247166</td>\n",
       "<td>6.7692308</td>\n",
       "<td>4.2307692</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7864977</td>\n",
       "<td>0.625</td>\n",
       "<td>0.9233568</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.1923077</td>\n",
       "<td>576.9230769</td>\n",
       "<td>323.0769231</td>\n",
       "<td>0.1723077</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0511364</td>\n",
       "<td>0.6575481</td>\n",
       "<td>0.0</td>\n",
       "<td>3.7606838</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6739311</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.8956428</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1923077</td>\n",
       "<td>-100.0</td>\n",
       "<td>276.0683761</td>\n",
       "<td>0.1656410</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1022727</td>\n",
       "<td>0.2656580</td>\n",
       "<td>5.2649573</td>\n",
       "<td>4.5128205</td>\n",
       "<td>0.7777778</td>\n",
       "<td>0.4822783</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.6889606</td>\n",
       "<td>0.2692308</td>\n",
       "<td>0.4615385</td>\n",
       "<td>426.4957265</td>\n",
       "<td>351.2820513</td>\n",
       "<td>0.4215385</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1534091</td>\n",
       "<td>0.1538703</td>\n",
       "<td>2.2564103</td>\n",
       "<td>3.7606838</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.1971789</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.5250333</td>\n",
       "<td>0.1153846</td>\n",
       "<td>0.5769231</td>\n",
       "<td>125.6410256</td>\n",
       "<td>276.0683761</td>\n",
       "<td>0.4969231</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.0663705</td>\n",
       "<td>1.5042735</td>\n",
       "<td>3.1965812</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.1118445</td>\n",
       "<td>0.4722222</td>\n",
       "<td>0.4217361</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.6538462</td>\n",
       "<td>50.4273504</td>\n",
       "<td>219.6581197</td>\n",
       "<td>0.5271795</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3011364</td>\n",
       "<td>0.0172974</td>\n",
       "<td>0.3981900</td>\n",
       "<td>2.2989840</td>\n",
       "<td>0.0588235</td>\n",
       "<td>0.0333273</td>\n",
       "<td>0.3396226</td>\n",
       "<td>0.2971522</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.6923077</td>\n",
       "<td>-60.1809955</td>\n",
       "<td>129.8984035</td>\n",
       "<td>0.4589744</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4034091</td>\n",
       "<td>0.0088347</td>\n",
       "<td>0.7521368</td>\n",
       "<td>1.9068256</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.0115442</td>\n",
       "<td>0.2816901</td>\n",
       "<td>0.2247445</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.7692308</td>\n",
       "<td>-24.7863248</td>\n",
       "<td>90.6825569</td>\n",
       "<td>0.4292308</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0037716</td>\n",
       "<td>0.7963801</td>\n",
       "<td>1.6923077</td>\n",
       "<td>0.1176471</td>\n",
       "<td>0.0067207</td>\n",
       "<td>0.25</td>\n",
       "<td>0.1826263</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.8461538</td>\n",
       "<td>-20.3619910</td>\n",
       "<td>69.2307692</td>\n",
       "<td>0.4061538</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6022727</td>\n",
       "<td>0.0013098</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4049347</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0021203</td>\n",
       "<td>0.2075472</td>\n",
       "<td>0.1519743</td>\n",
       "<td>0.0</td>\n",
       "<td>0.8461538</td>\n",
       "<td>-100.0</td>\n",
       "<td>40.4934688</td>\n",
       "<td>0.2861538</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6988636</td>\n",
       "<td>0.0006594</td>\n",
       "<td>1.5927602</td>\n",
       "<td>1.4308943</td>\n",
       "<td>0.2352941</td>\n",
       "<td>0.0009641</td>\n",
       "<td>0.2113821</td>\n",
       "<td>0.1311030</td>\n",
       "<td>0.1538462</td>\n",
       "<td>1.0</td>\n",
       "<td>59.2760181</td>\n",
       "<td>43.0894309</td>\n",
       "<td>0.3533333</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8011364</td>\n",
       "<td>0.0001918</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2482270</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003688</td>\n",
       "<td>0.1843972</td>\n",
       "<td>0.1144135</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.8226950</td>\n",
       "<td>0.2333333</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8977273</td>\n",
       "<td>0.0000629</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1139241</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001277</td>\n",
       "<td>0.1645570</td>\n",
       "<td>0.1021169</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.3924051</td>\n",
       "<td>0.12</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>2.8e-07</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000237</td>\n",
       "<td>0.1477273</td>\n",
       "<td>0.0916756</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-19.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-19 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-19 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-19 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-19 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-19 .h2o-table th,\n",
       "#h2o-table-19 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-19 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-19\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.8806349</td>\n",
       "<td>0.0652379</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.8285714</td>\n",
       "<td>0.8</td>\n",
       "<td>0.9428572</td>\n",
       "<td>0.9428572</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.8479612</td>\n",
       "<td>0.0982881</td>\n",
       "<td>0.9354839</td>\n",
       "<td>0.7988506</td>\n",
       "<td>0.7175926</td>\n",
       "<td>0.9545454</td>\n",
       "<td>0.8333333</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.1193651</td>\n",
       "<td>0.0652379</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.1714286</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0571429</td>\n",
       "<td>0.0571429</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>4.2</td>\n",
       "<td>2.280351</td>\n",
       "<td>4.0</td>\n",
       "<td>6.0</td>\n",
       "<td>7.0</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.6094366</td>\n",
       "<td>0.1107135</td>\n",
       "<td>0.6097561</td>\n",
       "<td>0.5263158</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.8</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.6571429</td>\n",
       "<td>0.1077496</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.5714286</td>\n",
       "<td>0.5333334</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.8</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.7266446</td>\n",
       "<td>0.1509600</td>\n",
       "<td>0.8620689</td>\n",
       "<td>0.625</td>\n",
       "<td>0.5128205</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.8</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>4.0066667</td>\n",
       "<td>3.6946206</td>\n",
       "<td>7.2</td>\n",
       "<td>5.8333335</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>7.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.4649309</td>\n",
       "<td>0.2637554</td>\n",
       "<td>0.3772995</td>\n",
       "<td>0.5116247</td>\n",
       "<td>0.9001822</td>\n",
       "<td>0.24305</td>\n",
       "<td>0.2924979</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.2445943</td>\n",
       "<td>0.1748582</td>\n",
       "<td>0.1290322</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0606061</td>\n",
       "<td>0.2</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.6060845</td>\n",
       "<td>0.1553404</td>\n",
       "<td>0.6956083</td>\n",
       "<td>0.4745548</td>\n",
       "<td>0.4082483</td>\n",
       "<td>0.6853444</td>\n",
       "<td>0.7666667</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.8494653</td>\n",
       "<td>0.1164849</td>\n",
       "<td>0.9354839</td>\n",
       "<td>0.7643678</td>\n",
       "<td>0.6944444</td>\n",
       "<td>0.969697</td>\n",
       "<td>0.8833333</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.1505347</td>\n",
       "<td>0.1164849</td>\n",
       "<td>0.0645161</td>\n",
       "<td>0.2356322</td>\n",
       "<td>0.3055556</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.1166667</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1036406</td>\n",
       "<td>0.0538626</td>\n",
       "<td>0.1079964</td>\n",
       "<td>0.1138983</td>\n",
       "<td>0.1859831</td>\n",
       "<td>0.0552518</td>\n",
       "<td>0.0550734</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.5750192</td>\n",
       "<td>0.1783179</td>\n",
       "<td>0.7038902</td>\n",
       "<td>0.5905984</td>\n",
       "<td>0.4279301</td>\n",
       "<td>0.3657443</td>\n",
       "<td>0.7869329</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.5853968</td>\n",
       "<td>0.1242230</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5714286</td>\n",
       "<td>0.5</td>\n",
       "<td>0.8</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.1530204</td>\n",
       "<td>0.2439249</td>\n",
       "<td>0.0970112</td>\n",
       "<td>0.1981297</td>\n",
       "<td>-0.0547655</td>\n",
       "<td>-0.0255071</td>\n",
       "<td>0.5502338</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.7933334</td>\n",
       "<td>0.2165384</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3134216</td>\n",
       "<td>0.0822153</td>\n",
       "<td>0.3286280</td>\n",
       "<td>0.3374882</td>\n",
       "<td>0.4312576</td>\n",
       "<td>0.2350570</td>\n",
       "<td>0.2346773</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9055973</td>\n",
       "<td>0.0454004</td>\n",
       "<td>0.8709678</td>\n",
       "<td>0.8620689</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.9393939</td>\n",
       "<td>0.9666666</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-20.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-20 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-20 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-20 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-20 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-20 .h2o-table th,\n",
       "#h2o-table-20 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-20 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-20\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2023-05-24 09:09:09</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-24 09:09:09</td>\n",
       "<td> 6 min  8.005 sec</td>\n",
       "<td>33207 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>1</td>\n",
       "<td>1760.0</td>\n",
       "<td>0.2542635</td>\n",
       "<td>0.2367326</td>\n",
       "<td>0.4865137</td>\n",
       "<td>0.9387179</td>\n",
       "<td>0.7675712</td>\n",
       "<td>6.7692308</td>\n",
       "<td>0.0738636</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-24 09:09:12</td>\n",
       "<td> 6 min 10.633 sec</td>\n",
       "<td>38949 obs/sec</td>\n",
       "<td>590.0</td>\n",
       "<td>59</td>\n",
       "<td>103840.0</td>\n",
       "<td>0.0170840</td>\n",
       "<td>0.0025814</td>\n",
       "<td>0.9976819</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.7692308</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-21.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-21 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-21 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-21 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table th,\n",
       "#h2o-table-21 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-21 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-21\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>Cinematography</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0361720</td></tr>\n",
       "<tr><td>winner_sag</td>\n",
       "<td>0.7646658</td>\n",
       "<td>0.7646658</td>\n",
       "<td>0.0276595</td></tr>\n",
       "<tr><td>rating</td>\n",
       "<td>0.7306981</td>\n",
       "<td>0.7306981</td>\n",
       "<td>0.0264308</td></tr>\n",
       "<tr><td>history</td>\n",
       "<td>0.7269079</td>\n",
       "<td>0.7269079</td>\n",
       "<td>0.0262937</td></tr>\n",
       "<tr><td>biography</td>\n",
       "<td>0.7232850</td>\n",
       "<td>0.7232850</td>\n",
       "<td>0.0261627</td></tr>\n",
       "<tr><td>Film Editing</td>\n",
       "<td>0.7223579</td>\n",
       "<td>0.7223579</td>\n",
       "<td>0.0261292</td></tr>\n",
       "<tr><td>winner_dga</td>\n",
       "<td>0.7008595</td>\n",
       "<td>0.7008595</td>\n",
       "<td>0.0253515</td></tr>\n",
       "<tr><td>numVotes</td>\n",
       "<td>0.6862598</td>\n",
       "<td>0.6862598</td>\n",
       "<td>0.0248234</td></tr>\n",
       "<tr><td>year</td>\n",
       "<td>0.6608877</td>\n",
       "<td>0.6608877</td>\n",
       "<td>0.0239057</td></tr>\n",
       "<tr><td>Sound</td>\n",
       "<td>0.6562886</td>\n",
       "<td>0.6562886</td>\n",
       "<td>0.0237393</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>nominations</td>\n",
       "<td>0.5305830</td>\n",
       "<td>0.5305830</td>\n",
       "<td>0.0191923</td></tr>\n",
       "<tr><td>Directing</td>\n",
       "<td>0.5289589</td>\n",
       "<td>0.5289589</td>\n",
       "<td>0.0191335</td></tr>\n",
       "<tr><td>adventure</td>\n",
       "<td>0.5270043</td>\n",
       "<td>0.5270043</td>\n",
       "<td>0.0190628</td></tr>\n",
       "<tr><td>winner_bafta</td>\n",
       "<td>0.5157127</td>\n",
       "<td>0.5157127</td>\n",
       "<td>0.0186544</td></tr>\n",
       "<tr><td>winner_gg_comedy</td>\n",
       "<td>0.5098381</td>\n",
       "<td>0.5098381</td>\n",
       "<td>0.0184419</td></tr>\n",
       "<tr><td>sport</td>\n",
       "<td>0.4981127</td>\n",
       "<td>0.4981127</td>\n",
       "<td>0.0180178</td></tr>\n",
       "<tr><td>nom_gg_comedy</td>\n",
       "<td>0.4789034</td>\n",
       "<td>0.4789034</td>\n",
       "<td>0.0173229</td></tr>\n",
       "<tr><td>musical</td>\n",
       "<td>0.4689341</td>\n",
       "<td>0.4689341</td>\n",
       "<td>0.0169623</td></tr>\n",
       "<tr><td>drama</td>\n",
       "<td>0.4469302</td>\n",
       "<td>0.4469302</td>\n",
       "<td>0.0161664</td></tr>\n",
       "<tr><td>nom_dga</td>\n",
       "<td>0.4176803</td>\n",
       "<td>0.4176803</td>\n",
       "<td>0.0151083</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[46 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_1_20230524_85722_model_22\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 5 002 weights/biases, 68,6 KB, 103 840 training samples, mini-batch size 1\n",
       "    layer    units    type              dropout    l1    l2    mean_rate             rate_rms             momentum    mean_weight            weight_rms           mean_bias              bias_rms\n",
       "--  -------  -------  ----------------  ---------  ----  ----  --------------------  -------------------  ----------  ---------------------  -------------------  ---------------------  -------------------\n",
       "    1        46       Input             15.0\n",
       "    2        50       RectifierDropout  30.0       0.0   0.0   0.038892969792017854  0.10349225997924805  0.0         0.009932569338811648   0.19275730848312378  0.41522828157936453    0.13296157121658325\n",
       "    3        50       RectifierDropout  30.0       0.0   0.0   0.035638015663798435  0.11583846807479858  0.0         -0.013097085671580862  0.15860271453857422  0.8645436029005091     0.12200167775154114\n",
       "    4        2        Softmax                      0.0   0.0   0.018841800816589968  0.09684017300605774  0.0         0.02686685076914728    0.7908759117126465   -0.013836189397350096  0.38205671310424805\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.0002918639572209168\n",
       "RMSE: 0.01708402637614789\n",
       "LogLoss: 0.00258135695067732\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9935320906464516\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      150  0    0        (0.0/150.0)\n",
       "1      0    26   0        (0.0/26.0)\n",
       "Total  150  26   0        (0.0/176.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.993532     1         25\n",
       "max f2                       0.993532     1         25\n",
       "max f0point5                 0.993532     1         25\n",
       "max accuracy                 0.993532     1         25\n",
       "max precision                1            1         0\n",
       "max recall                   0.993532     1         25\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.993532     1         25\n",
       "max min_per_class_accuracy   0.993532     1         25\n",
       "max mean_per_class_accuracy  0.993532     1         25\n",
       "max tns                      1            150       0\n",
       "max fns                      1            25        0\n",
       "max fps                      4.70512e-32  150       175\n",
       "max tps                      0.993532     26        25\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.961538  0\n",
       "max fpr                      4.70512e-32  1         175\n",
       "max tpr                      0.993532     1         25\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,77 %, avg score: 14,99 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0113636                   1                  6.76923  6.76923            1                1            1                           1                   0.0769231       0.0769231                  576.923  576.923            0.0769231\n",
       "2        0.0227273                   0.999999           6.76923  6.76923            1                0.999999     1                           0.999999            0.0769231       0.153846                   576.923  576.923            0.153846\n",
       "3        0.0340909                   0.999995           6.76923  6.76923            1                0.999997     1                           0.999999            0.0769231       0.230769                   576.923  576.923            0.230769\n",
       "4        0.0454545                   0.99999            6.76923  6.76923            1                0.999992     1                           0.999997            0.0769231       0.307692                   576.923  576.923            0.307692\n",
       "5        0.0511364                   0.99997            6.76923  6.76923            1                0.99998      1                           0.999995            0.0384615       0.346154                   576.923  576.923            0.346154\n",
       "6        0.102273                    0.999754           6.76923  6.76923            1                0.999875     1                           0.999935            0.346154        0.692308                   576.923  576.923            0.692308\n",
       "7        0.153409                    0.172808           6.01709  6.51852            0.888889         0.908539     0.962963                    0.96947             0.307692        1                          501.709  551.852            0.993333\n",
       "8        0.204545                    0.00382511         0        4.88889            0                0.0219737    0.722222                    0.732596            0               1                          -100     388.889            0.933333\n",
       "9        0.301136                    6.51623e-05        0        3.32075            0                0.000891208  0.490566                    0.497898            0               1                          -100     232.075            0.82\n",
       "10       0.403409                    7.77671e-06        0        2.47887            0                2.97249e-05  0.366197                    0.371678            0               1                          -100     147.887            0.7\n",
       "11       0.5                         1.62967e-06        0        2                  0                4.2984e-06   0.295455                    0.299877            0               1                          -100     100                0.586667\n",
       "12       0.602273                    1.25093e-07        0        1.66038            0                4.50949e-07  0.245283                    0.248955            0               1                          -100     66.0377            0.466667\n",
       "13       0.698864                    2.0678e-09         0        1.43089            0                3.02965e-08  0.211382                    0.214546            0               1                          -100     43.0894            0.353333\n",
       "14       0.801136                    2.10235e-11        0        1.24823            0                3.98363e-10  0.184397                    0.187158            0               1                          -100     24.8227            0.233333\n",
       "15       0.897727                    4.69443e-18        0        1.11392            0                2.51734e-12  0.164557                    0.16702             0               1                          -100     11.3924            0.12\n",
       "16       1                           4.70512e-32        0        1                  0                2.75527e-19  0.147727                    0.149939            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.10366535538522567\n",
       "RMSE: 0.32197104743319027\n",
       "LogLoss: 0.46443296707093845\n",
       "Mean Per-Class Error: 0.25153846153846154\n",
       "AUC: 0.8171794871794872\n",
       "AUCPR: 0.5130330741669865\n",
       "Gini: 0.6343589743589744\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.15663830936437467\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      138  12   0.08     (12.0/150.0)\n",
       "1      11   15   0.4231   (11.0/26.0)\n",
       "Total  149  27   0.1307   (23.0/176.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.156638     0.566038  26\n",
       "max f2                       0.0663705    0.607143  35\n",
       "max f0point5                 0.402278     0.638298  16\n",
       "max accuracy                 0.402278     0.892045  16\n",
       "max precision                0.997748     1         0\n",
       "max recall                   0.000661022  1         122\n",
       "max specificity              0.997748     1         0\n",
       "max absolute_mcc             0.402278     0.514353  16\n",
       "max min_per_class_accuracy   0.010201     0.706667  62\n",
       "max mean_per_class_accuracy  0.0663705    0.76359   35\n",
       "max tns                      0.997748     150       0\n",
       "max fns                      0.997748     25        0\n",
       "max fps                      2.76754e-07  150       175\n",
       "max tps                      0.000661022  26        122\n",
       "max tnr                      0.997748     1         0\n",
       "max fnr                      0.997748     0.961538  0\n",
       "max fpr                      2.76754e-07  1         175\n",
       "max tpr                      0.000661022  1         122\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,77 %, avg score:  9,17 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0113636                   0.986713           6.76923   6.76923            1                0.997454     1                           0.997454            0.0769231       0.0769231                  576.923   576.923            0.0769231\n",
       "2        0.0227273                   0.964778           3.38462   5.07692            0.5              0.976917     0.75                        0.987186            0.0384615       0.115385                   238.462   407.692            0.108718\n",
       "3        0.0340909                   0.891693           0         3.38462            0                0.932558     0.5                         0.968976            0               0.115385                   -100      238.462            0.0953846\n",
       "4        0.0454545                   0.724717           6.76923   4.23077            1                0.786498     0.625                       0.923357            0.0769231       0.192308                   576.923   323.077            0.172308\n",
       "5        0.0511364                   0.657548           0         3.76068            0                0.673931     0.555556                    0.895643            0               0.192308                   -100      276.068            0.165641\n",
       "6        0.102273                    0.265658           5.26496   4.51282            0.777778         0.482278     0.666667                    0.688961            0.269231        0.461538                   426.496   351.282            0.421538\n",
       "7        0.153409                    0.15387            2.25641   3.76068            0.333333         0.197179     0.555556                    0.525033            0.115385        0.576923                   125.641   276.068            0.496923\n",
       "8        0.204545                    0.0663705          1.50427   3.19658            0.222222         0.111844     0.472222                    0.421736            0.0769231       0.653846                   50.4274   219.658            0.527179\n",
       "9        0.301136                    0.0172974          0.39819   2.29898            0.0588235        0.0333273    0.339623                    0.297152            0.0384615       0.692308                   -60.181   129.898            0.458974\n",
       "10       0.403409                    0.00883467         0.752137  1.90683            0.111111         0.0115442    0.28169                     0.224744            0.0769231       0.769231                   -24.7863  90.6826            0.429231\n",
       "11       0.5                         0.00377158         0.79638   1.69231            0.117647         0.00672068   0.25                        0.182626            0.0769231       0.846154                   -20.362   69.2308            0.406154\n",
       "12       0.602273                    0.0013098          0         1.40493            0                0.00212033   0.207547                    0.151974            0               0.846154                   -100      40.4935            0.286154\n",
       "13       0.698864                    0.00065939         1.59276   1.43089            0.235294         0.000964103  0.211382                    0.131103            0.153846        1                          59.276    43.0894            0.353333\n",
       "14       0.801136                    0.00019184         0         1.24823            0                0.000368839  0.184397                    0.114414            0               1                          -100      24.8227            0.233333\n",
       "15       0.897727                    6.2905e-05         0         1.11392            0                0.000127739  0.164557                    0.102117            0               1                          -100      11.3924            0.12\n",
       "16       1                           2.8e-07            0         1                  0                2.36883e-05  0.147727                    0.0916756           0               1                          -100      0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean      sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.880635  0.0652379  0.888889      0.828571      0.8           0.942857      0.942857\n",
       "auc                      0.847961  0.0982881  0.935484      0.798851      0.717593      0.954545      0.833333\n",
       "err                      0.119365  0.0652379  0.111111      0.171429      0.2           0.0571429     0.0571429\n",
       "err_count                4.2       2.28035    4             6             7             2             2\n",
       "f0point5                 0.609437  0.110714   0.609756      0.526316      0.555556      0.555556      0.8\n",
       "f1                       0.657143  0.10775    0.714286      0.571429      0.533333      0.666667      0.8\n",
       "f2                       0.726645  0.15096    0.862069      0.625         0.512821      0.833333      0.8\n",
       "lift_top_group           4.00667   3.69462    7.2           5.83333       0             0             7\n",
       "logloss                  0.464931  0.263755   0.3773        0.511625      0.900182      0.24305       0.292498\n",
       "max_per_class_error      0.244594  0.174858   0.129032      0.333333      0.5           0.0606061     0.2\n",
       "mcc                      0.606084  0.15534    0.695608      0.474555      0.408248      0.685344      0.766667\n",
       "mean_per_class_accuracy  0.849465  0.116485   0.935484      0.764368      0.694444      0.969697      0.883333\n",
       "mean_per_class_error     0.150535  0.116485   0.0645161     0.235632      0.305556      0.030303      0.116667\n",
       "mse                      0.103641  0.0538626  0.107996      0.113898      0.185983      0.0552518     0.0550734\n",
       "pr_auc                   0.575019  0.178318   0.70389       0.590598      0.42793       0.365744      0.786933\n",
       "precision                0.585397  0.124223   0.555556      0.5           0.571429      0.5           0.8\n",
       "r2                       0.15302   0.243925   0.0970112     0.19813       -0.0547655    -0.0255071    0.550234\n",
       "recall                   0.793333  0.216538   1             0.666667      0.5           1             0.8\n",
       "rmse                     0.313422  0.0822153  0.328628      0.337488      0.431258      0.235057      0.234677\n",
       "specificity              0.905597  0.0454004  0.870968      0.862069      0.888889      0.939394      0.966667\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2023-05-24 09:09:09  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan\n",
       "    2023-05-24 09:09:09  6 min  8.005 sec  33207 obs/sec     10        1             1760       0.254264         0.236733            0.486514       0.938718        0.767571           6.76923          0.0738636\n",
       "    2023-05-24 09:09:12  6 min 10.633 sec  38949 obs/sec     590       59            103840     0.017084         0.00258136          0.997682       1               1                  6.76923          0\n",
       "\n",
       "Variable Importances: \n",
       "variable          relative_importance    scaled_importance    percentage\n",
       "----------------  ---------------------  -------------------  --------------------\n",
       "Cinematography    1.0                    1.0                  0.0361720438363004\n",
       "winner_sag        0.7646657824516296     0.7646657824516296   0.027659524202959293\n",
       "rating            0.7306981086730957     0.7306981086730957   0.02643084401802501\n",
       "history           0.7269079089164734     0.7269079089164734   0.026293744746280132\n",
       "biography         0.7232850193977356     0.7232850193977356   0.026162697427794278\n",
       "Film Editing      0.7223579287528992     0.7223579287528992   0.026129162664349028\n",
       "winner_dga        0.7008594870567322     0.7008594870567322   0.02535152008890313\n",
       "numVotes          0.6862598061561584     0.6862598061561584   0.02482341979137158\n",
       "year              0.6608876585960388     0.6608876585960388   0.023905657357605848\n",
       "Sound             0.6562885642051697     0.6562885642051697   0.023739298713692045\n",
       "---               ---                    ---                  ---\n",
       "nominations       0.5305830240249634     0.5305830240249634   0.019192272403827804\n",
       "Directing         0.5289588570594788     0.5289588570594788   0.019133522965154824\n",
       "adventure         0.5270043015480042     0.5270043015480042   0.01906282269751328\n",
       "winner_bafta      0.5157126784324646     0.5157126784324646   0.018654381611195002\n",
       "winner_gg_comedy  0.5098381042480469     0.5098381042480469   0.018441886256276643\n",
       "sport             0.4981127083301544     0.4981127083301544   0.01801775472113666\n",
       "nom_gg_comedy     0.4789034426212311     0.4789034426212311   0.017322916319850345\n",
       "musical           0.4689340889453888     0.4689340889453888   0.016962304421668194\n",
       "drama             0.4469301998615265     0.4469301998615265   0.016166378781157634\n",
       "nom_dga           0.4176802933216095     0.4176802933216095   0.015108349879588067\n",
       "[46 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 score: 1.00\n",
      "Test F1 score: 0.28\n",
      "Confusion matrix on validation data:\n",
      "[[99  7]\n",
      " [14  4]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Identify predictors and response\n",
    "predictors = train[['rating', 'numVotes', 'worldwide_box_office', 'action', 'adventure', 'animation', 'biography', 'comedy', 'crime', 'documentary', 'drama', 'family', 'fantasy', 'film-noir', 'history', 'horror', 'music', 'musical', 'mystery', 'romance', 'sci-fi', 'sport', 'thriller', 'war', 'western', 'nominations', 'nom_gg_drama', 'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga', 'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga', 'nom_sag', 'winner_sag',  'Acting', 'Production Design', 'Directing', 'VFX', 'Writing', 'Cinematography', 'Sound', 'Film Editing', 'Music']]\n",
    "\n",
    "x = predictors\n",
    "y = train['Oscar_win'].astype('category')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.7, random_state=1)\n",
    "\n",
    "# Calculate the ratio of negatives to positives\n",
    "negative_count = train['Oscar_win'].value_counts()[0]\n",
    "positive_count = train['Oscar_win'].value_counts()[1]\n",
    "ratio = negative_count / positive_count\n",
    "\n",
    "# Adjust the weights in the XGBoost model\n",
    "xgb_model = XGBClassifier(scale_pos_weight=ratio)\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "# Make predictions on training data\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "\n",
    "# Make predictions on testing data\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate F1 score on training data\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate F1 score on testing data\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Print F1 scores\n",
    "print(\"Train F1 score: {:.2f}\".format(train_f1))\n",
    "print(\"Test F1 score: {:.2f}\".format(test_f1))\n",
    "\n",
    "\n",
    "\n",
    "# Print confusion matrix on validation data\n",
    "print(\"Confusion matrix on validation data:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "        C10     rating0    numVotes0    worldwide_box_office0      action0    adventure0    animation0    biography0      comedy0       crime0    documentary0      drama0      family0    fantasy0    film-noir0    history0      horror0      music0     musical0     mystery0      romance0      sci-fi0       sport0    thriller0          war0     western0    nominations0    Oscar_win0    nom_gg_drama0    winner_gg_drama0    nom_gg_comedy0    winner_gg_comedy0    nom_pga0    winner_pga0    nom_bafta0    winner_bafta0    nom_dga0    winner_dga0    nom_sag0    winner_sag0    nom_cannes0    winner_cannes0\n",
      " 1            0.314227    0.386407                 0.209462    -0.0251696     -0.0152674   -0.00567338    0.139222    -0.0820067   -0.0922513      -0.0903216    0.0475568  -0.0425951   -0.0170899   -0.110394     0.0253929  -0.0681248   -0.0102693  -0.0967491   -0.0351218   -0.196358      0.108229    -0.0254172   -0.0359547   -0.0360996    -0.015139        0.0733317    -0.00537012       0.342112            0.102824          0.166098              0.0512977   0.423179       0.132652      0.236108         0.0754091   0.214161       0.0610043   0.30596        0.15723       0.0388851         0.0388851\n",
      " 0.314227     1           0.593096                 0.179044    -0.113108      -0.0230901    0.0401639     0.0460973   -0.162579     0.0194296      -0.0304294   -0.0738244  -0.0244946   -0.0694397   -0.0280892   -0.0445398  -0.0330228    0.0683098   0.00661021  -0.00504493  -0.175171      0.0316074   -0.110307    -0.0780591    0.000717577  -0.0284381       0.192307      0.187489         0.30599             0.157413         -0.0472676            -0.0264947   0.198098       0.127823      0.216438         0.100631    0.243389       0.242703    0.124196       0.0693361     0.0843431         0.0843431\n",
      " 0.386407     0.593096    1                        0.361612    -0.00278305     0.0291351    0.0450236    -0.0287351   -0.0885467    0.0449875      -0.0497313   -0.102784   -0.0199374    0.0182413   -0.0470585   -0.0927261  -0.0218886   -0.0258629  -0.0703792   -0.00320173  -0.164166      0.113466    -0.0445424   -0.00318189  -0.0425826    -0.0433077       0.223754      0.220679         0.263899            0.178136         -0.0101834            -0.0360619   0.390494       0.237977      0.275207         0.129905    0.291197       0.239488    0.260235       0.158354      0.114243          0.114243\n",
      " 0.209462     0.179044    0.361612                 1            0.0508011      0.0955564    0.0612752     0.0136341   -0.00460532   0.00473332     -0.03308     -0.0438607   0.0777249    0.0290886   -0.0382438   -0.02487    -0.0115604    0.0209602   0.0196055   -0.0107505   -0.0872886     0.0439794   -0.00620426   0.0516066    0.00600797   -0.0120651       0.15667       0.0221471        0.100986            0.00951081        0.0769518             0.0818453   0.178783       0.142933      0.16018          0.114084    0.166799       0.105566    0.145468       0.116811     -0.0180256        -0.0180256\n",
      "-0.0251696   -0.113108   -0.00278305               0.0508011    1              0.365221    -0.0151861    -0.0629061    0.0660847    0.151702       -0.0186182    0.0695292   0.010701     0.0588801   -0.0215206    0.064809   -0.0240857   -0.0514339  -0.0449728   -0.0155341   -0.0387451     0.209908    -0.0305611    0.190769     0.158425      0.139141       -0.0195085    -0.00624795       0.0411957           0.0646109        -0.101655             -0.0726385  -0.103234      -0.0435839    -0.0992684       -0.0514339  -0.136629      -0.0657964  -0.0735805     -0.040683     -0.0264118        -0.0264118\n",
      "-0.0152674   -0.0230901   0.0291351                0.0955564    0.365221       1            0.234432     -0.0558372    0.0882695   -0.0280995      -0.0214771    0.0925761   0.277754     0.266076    -0.0248252    0.127267   -0.0277841   -0.0593317   0.0797923    0.0427215   -0.0430774     0.229628    -0.0352538   -0.0126443    0.0251977     0.216469       -0.0225041    -0.0122231        0.0587055           0.0781292        -0.0506905            -0.0264052  -0.119086      -0.0502763    -0.114511        -0.0593317  -0.157609      -0.0758997  -0.0848791     -0.04693      -0.0304674        -0.0304674\n",
      "-0.00567338   0.0401639   0.0450236                0.0612752   -0.0151861      0.234432     1            -0.0244193    0.081835    -0.0198984      -0.00503493   0.0631732   0.360242     0.168324    -0.00581982  -0.0188659  -0.00651348  -0.0139092  -0.012162    -0.0151861   -0.0298124    -0.00972149  -0.00826462  -0.0216273   -0.0169577    -0.0101644      -0.00527569   -0.0283422        0.00618806          0.067648         -0.0274905            -0.0196436  -0.0279175     -0.0117864    -0.0268451       -0.0139092  -0.0369486     -0.0177933  -0.0198984     -0.0110019    -0.00714254       -0.00714254\n",
      " 0.139222     0.0460973  -0.0287351                0.0136341   -0.0629061     -0.0558372   -0.0244193     1            0.00811336   0.0335958       0.127478     0.351047    0.00349862  -0.0700828   -0.0346052    0.318859   -0.0387297    0.213798    0.0283364   -0.090298    -0.000492957  -0.0578049    0.0962037   -0.0271715    0.172543     -0.0604385      -0.0313697     0.030851         0.147937            0.062648         -0.0277523            -0.0510002  -0.166         -0.0700828    -0.159623        -0.0827056  -0.219699      -0.105801   -0.118317      -0.0654183    -0.0424702        -0.0424702\n",
      "-0.0820067   -0.162579   -0.0885467               -0.00460532   0.0660847      0.0882695    0.081835      0.00811336   1            0.0802842      -0.0271021    0.101212    0.169461     0.0857104   -0.0313271   -0.0770651  -0.0350609    0.0531427   0.115602    -0.0817442    0.203786     -0.0523291    0.0601003   -0.0945211   -0.0644559    -0.011837       -0.0283981    -0.0270283       -0.193287           -0.118157          0.25484               0.131011   -0.150275      -0.063444     -0.144503        -0.074871   -0.183557      -0.0957783  -0.107109      -0.0592213    -0.038447         -0.038447\n",
      "-0.0922513    0.0194296   0.0449875                0.00473332   0.151702      -0.0280995   -0.0198984     0.0335958    0.0802842    1              -0.0243955    0.161655   -0.0552361   -0.0165181    0.212308    -0.0647554  -0.0315594   -0.0673938   0.0593309    0.280435    -0.0122787     0.00159334  -0.0400442    0.395716    -0.0821644    -0.00257699     -0.025562     -0.0201996       -0.0498179          -0.0817229         0.00631754            0.033676   -0.135267      -0.0571079    -0.130071        -0.0673938  -0.162337      -0.086213   -0.0964126     -0.053307     -0.0346074        -0.0346074\n",
      "[42 rows x 42 columns]\n",
      "\n",
      "Korelacja między zmienną nom_cannes a winner_cannes: 1.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "# Załadowanie danych do ramki danych H2O\n",
    "data = h2o.import_file(\"../data/processed_results/extended_df.csv\")\n",
    "\n",
    "data = data.drop(['film', 'wiki', 'year', 'winner'], axis=1)\n",
    "# # Sprawdzenie typów kolumn\n",
    "# column_types = data.types\n",
    "\n",
    "# # Wyświetlenie kolumn typu string\n",
    "# string_columns = [column for column, col_type in column_types.items() if col_type == 'string']\n",
    "# print(string_columns)\n",
    "\n",
    "# Obliczenie macierzy korelacji\n",
    "correlations = data.cor(na_rm=True)\n",
    "\n",
    "# Wyświetlenie macierzy korelacji\n",
    "print(correlations)\n",
    "\n",
    "# Wydrukowanie korelacji powyżej progu 0.8\n",
    "threshold = 0.8\n",
    "for row in range(correlations.shape[0]):\n",
    "    for col in range(row + 1, correlations.shape[1]):\n",
    "        correlation = correlations[row, col]\n",
    "        if abs(correlation) > threshold:\n",
    "            print(f\"Korelacja między zmienną {data.col_names[row]} a {data.col_names[col]}: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  C1</th><th style=\"text-align: right;\">  rating</th><th style=\"text-align: right;\">  numVotes</th><th style=\"text-align: right;\">  worldwide_box_office</th><th style=\"text-align: right;\">  action</th><th style=\"text-align: right;\">  adventure</th><th style=\"text-align: right;\">  animation</th><th style=\"text-align: right;\">  biography</th><th style=\"text-align: right;\">  comedy</th><th style=\"text-align: right;\">  crime</th><th style=\"text-align: right;\">  documentary</th><th style=\"text-align: right;\">  drama</th><th style=\"text-align: right;\">  family</th><th style=\"text-align: right;\">  fantasy</th><th style=\"text-align: right;\">  film-noir</th><th style=\"text-align: right;\">  history</th><th style=\"text-align: right;\">  horror</th><th style=\"text-align: right;\">  music</th><th style=\"text-align: right;\">  musical</th><th style=\"text-align: right;\">  mystery</th><th style=\"text-align: right;\">  romance</th><th style=\"text-align: right;\">  sci-fi</th><th style=\"text-align: right;\">  sport</th><th style=\"text-align: right;\">  thriller</th><th style=\"text-align: right;\">  war</th><th style=\"text-align: right;\">  western</th><th style=\"text-align: right;\">  nominations</th><th style=\"text-align: right;\">  Oscar_win</th><th style=\"text-align: right;\">  nom_gg_drama</th><th style=\"text-align: right;\">  winner_gg_drama</th><th style=\"text-align: right;\">  nom_gg_comedy</th><th style=\"text-align: right;\">  winner_gg_comedy</th><th style=\"text-align: right;\">  nom_pga</th><th style=\"text-align: right;\">  winner_pga</th><th style=\"text-align: right;\">  nom_bafta</th><th style=\"text-align: right;\">  winner_bafta</th><th style=\"text-align: right;\">  nom_dga</th><th style=\"text-align: right;\">  winner_dga</th><th style=\"text-align: right;\">  nom_sag</th><th style=\"text-align: right;\">  winner_sag</th><th style=\"text-align: right;\">  nom_cannes</th><th style=\"text-align: right;\">  winner_cannes</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">     7.3</td><td style=\"text-align: right;\">     13576</td><td style=\"text-align: right;\">         746          </td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            7</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">              0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">     5.2</td><td style=\"text-align: right;\">     26223</td><td style=\"text-align: right;\">       79808          </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            7</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">              0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   2</td><td style=\"text-align: right;\">     6.7</td><td style=\"text-align: right;\">      3149</td><td style=\"text-align: right;\">           2.17332e+07</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            7</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">              0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">     5.6</td><td style=\"text-align: right;\">      7605</td><td style=\"text-align: right;\">      223723          </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">              0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   4</td><td style=\"text-align: right;\">     7.4</td><td style=\"text-align: right;\">       391</td><td style=\"text-align: right;\">       42915          </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            7</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">              0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   5</td><td style=\"text-align: right;\">     5.5</td><td style=\"text-align: right;\">      1199</td><td style=\"text-align: right;\">        6344          </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">              0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   6</td><td style=\"text-align: right;\">     7.2</td><td style=\"text-align: right;\">    282275</td><td style=\"text-align: right;\">           2.15294e+08</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            7</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">              0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   9</td><td style=\"text-align: right;\">     6.8</td><td style=\"text-align: right;\">      4322</td><td style=\"text-align: right;\">           1.73959e+08</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            7</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">              0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  10</td><td style=\"text-align: right;\">     6.1</td><td style=\"text-align: right;\">      1318</td><td style=\"text-align: right;\">           1.30259e+07</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            7</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">              0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  11</td><td style=\"text-align: right;\">     6.7</td><td style=\"text-align: right;\">      3366</td><td style=\"text-align: right;\">        6253          </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">              0</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[489 rows x 42 columns]</pre>"
      ],
      "text/plain": [
       "  C1    rating    numVotes    worldwide_box_office    action    adventure    animation    biography    comedy    crime    documentary    drama    family    fantasy    film-noir    history    horror    music    musical    mystery    romance    sci-fi    sport    thriller    war    western    nominations    Oscar_win    nom_gg_drama    winner_gg_drama    nom_gg_comedy    winner_gg_comedy    nom_pga    winner_pga    nom_bafta    winner_bafta    nom_dga    winner_dga    nom_sag    winner_sag    nom_cannes    winner_cannes\n",
       "----  --------  ----------  ----------------------  --------  -----------  -----------  -----------  --------  -------  -------------  -------  --------  ---------  -----------  ---------  --------  -------  ---------  ---------  ---------  --------  -------  ----------  -----  ---------  -------------  -----------  --------------  -----------------  ---------------  ------------------  ---------  ------------  -----------  --------------  ---------  ------------  ---------  ------------  ------------  ---------------\n",
       "   0       7.3       13576           746                   1            0            0            0         0        0              0        1         0          0            0          0         0        0          0          0          1         0        0           0      1          0              7            1               0                  0                0                   0          0             0            0               0          0             0          0             0             0                0\n",
       "   1       5.2       26223         79808                   0            0            0            0         0        0              0        1         0          0            0          0         0        0          0          0          0         0        0           0      0          0              7            0               0                  0                0                   0          0             0            0               0          0             0          0             0             0                0\n",
       "   2       6.7        3149             2.17332e+07         0            0            0            0         0        0              0        1         0          1            0          0         0        0          0          1          0         1        0           1      0          0              7            0               0                  0                0                   0          0             0            0               0          0             0          0             0             0                0\n",
       "   3       5.6        7605        223723                   0            0            0            0         0        0              0        0         0          0            0          0         0        0          0          0          0         0        0           0      0          0              3            1               0                  0                0                   0          0             0            0               0          0             0          0             0             0                0\n",
       "   4       7.4         391         42915                   0            0            0            0         0        1              0        0         0          0            0          0         0        0          0          0          0         0        0           1      0          0              7            0               0                  0                0                   0          0             0            0               0          0             0          0             0             0                0\n",
       "   5       5.5        1199          6344                   0            0            0            0         0        0              0        0         0          0            0          0         0        0          0          0          0         0        0           0      0          0              5            0               0                  0                0                   0          0             0            0               0          0             0          0             0             0                0\n",
       "   6       7.2      282275             2.15294e+08         1            0            0            0         0        0              0        1         0          0            0          1         0        0          0          0          0         0        0           0      1          0              7            0               0                  0                0                   0          0             0            0               0          0             0          0             0             0                0\n",
       "   9       6.8        4322             1.73959e+08         1            0            0            0         1        1              0        0         0          0            0          0         0        0          0          0          0         0        0           0      0          0              7            0               0                  0                0                   0          0             0            0               0          0             0          0             0             0                0\n",
       "  10       6.1        1318             1.30259e+07         0            0            0            0         0        1              0        1         0          0            0          0         0        0          0          0          0         0        0           1      0          0              7            0               0                  0                0                   0          0             0            0               0          0             0          0             0             0                0\n",
       "  11       6.7        3366          6253                   0            0            0            0         0        0              0        0         0          0            0          0         0        0          0          0          0         0        0           0      0          0              4            0               0                  0                0                   0          0             0            0               0          0             0          0             0             0                0\n",
       "[489 rows x 42 columns]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the correlation matrix stored in a variable called 'correlation_matrix'\n",
    "\n",
    "# Convert the correlation matrix to a numeric format\n",
    "correlation_matrix = correlations.as_data_frame().values.astype(float)\n",
    "column_names=correlations.columns\n",
    "\n",
    "# Create a masked array from the correlation matrix to hide the upper triangle\n",
    "masked_corr = np.ma.masked_where(np.triu(np.ones_like(correlation_matrix, dtype=bool)), correlation_matrix)\n",
    "\n",
    "# Set up the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Create the heatmap\n",
    "heatmap = ax.imshow(masked_corr, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = fig.colorbar(heatmap)\n",
    "\n",
    "# Set the axis labels\n",
    "ax.set_xticks(np.arange(correlation_matrix.shape[1]))\n",
    "ax.set_yticks(np.arange(correlation_matrix.shape[0]))\n",
    "ax.set_xticklabels(column_names, rotation=90)\n",
    "ax.set_yticklabels(column_names)\n",
    "\n",
    "# Set the title\n",
    "ax.set_title(\"Correlation Heatmap\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = h2o.load_model('./additional_data/model/DeepLearning_grid_2_AutoML_6_20230519_91906_model_4')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Predict on 2019's films\n",
    "test = full_table.loc[(full_table['year'] == 2021)]\n",
    "\n",
    "# Import a binary outcome train/test set into H2O\n",
    "test = h2o.H2OFrame(test)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">        p0</th><th style=\"text-align: right;\">         p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999976  </td><td style=\"text-align: right;\">2.37118e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.00165605</td><td style=\"text-align: right;\">0.998344   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.995174  </td><td style=\"text-align: right;\">0.00482619 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1         </td><td style=\"text-align: right;\">1.74511e-07</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.995249  </td><td style=\"text-align: right;\">0.00475117 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999972  </td><td style=\"text-align: right;\">2.78123e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999979  </td><td style=\"text-align: right;\">2.0885e-05 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1         </td><td style=\"text-align: right;\">9.07248e-09</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999955  </td><td style=\"text-align: right;\">4.5392e-05 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999999  </td><td style=\"text-align: right;\">1.10776e-06</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 3 columns]</pre>"
      ],
      "text/plain": [
       "  predict          p0           p1\n",
       "---------  ----------  -----------\n",
       "        0  0.999976    2.37118e-05\n",
       "        1  0.00165605  0.998344\n",
       "        0  0.995174    0.00482619\n",
       "        0  1           1.74511e-07\n",
       "        0  0.995249    0.00475117\n",
       "        0  0.999972    2.78123e-05\n",
       "        0  0.999979    2.0885e-05\n",
       "        0  1           9.07248e-09\n",
       "        0  0.999955    4.5392e-05\n",
       "        0  0.999999    1.10776e-06\n",
       "[10 rows x 3 columns]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = top_model.predict(test)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred'] = preds['predict']\n",
    "test['probA'] = preds['p1']\n",
    "test_pd = test.as_data_frame(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>probA</th>\n",
       "      <th>%_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CODA</td>\n",
       "      <td>9.983440e-01</td>\n",
       "      <td>9.903809e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Belfast</td>\n",
       "      <td>4.826187e-03</td>\n",
       "      <td>4.787692e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drive My Car</td>\n",
       "      <td>4.751175e-03</td>\n",
       "      <td>4.713278e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nightmare Alley</td>\n",
       "      <td>4.539204e-05</td>\n",
       "      <td>4.502998e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dune</td>\n",
       "      <td>2.781235e-05</td>\n",
       "      <td>2.759051e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West Side Story</td>\n",
       "      <td>2.371181e-05</td>\n",
       "      <td>2.352268e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>King Richard</td>\n",
       "      <td>2.088495e-05</td>\n",
       "      <td>2.071837e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Power of the Dog</td>\n",
       "      <td>1.107759e-06</td>\n",
       "      <td>1.098923e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Don't Look Up</td>\n",
       "      <td>1.745112e-07</td>\n",
       "      <td>1.731192e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Licorice Pizza</td>\n",
       "      <td>9.072485e-09</td>\n",
       "      <td>9.000120e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    film         probA  %_confidence\n",
       "1                  CODA   9.983440e-01  9.903809e+01\n",
       "2               Belfast   4.826187e-03  4.787692e-01\n",
       "4          Drive My Car   4.751175e-03  4.713278e-01\n",
       "8       Nightmare Alley   4.539204e-05  4.502998e-03\n",
       "5                  Dune   2.781235e-05  2.759051e-03\n",
       "0       West Side Story   2.371181e-05  2.352268e-03\n",
       "6          King Richard   2.088495e-05  2.071837e-03\n",
       "9  The Power of the Dog   1.107759e-06  1.098923e-04\n",
       "3          Don't Look Up  1.745112e-07  1.731192e-05\n",
       "7         Licorice Pizza  9.072485e-09  9.000120e-07"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rankings = test_pd[['film','probA']].sort_values('probA', ascending = False)\n",
    "final_rankings['%_confidence'] = final_rankings['probA']/final_rankings['probA'].sum() * 100\n",
    "final_rankings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And the Oscar goes to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_winner = np.array(final_rankings.reset_index())[0][1].split('(')[0].strip()\n",
    "print(f'And the Oscar goes to...\\n🎉🏆{bp_winner}🏆🎉')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
