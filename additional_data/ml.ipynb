{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-Oscar Prediction with AutoML\n",
    "After out dataframe has been assemlbed (see scraping and table_assembling) notebooks we have the data we need to make predictions on the Best Picture winner. [AutoML](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html) represents a quick, but powerful route though the Machine Learning process. H2O's AutoML runs many models through the dataset and using cross-validation, picks the best one. For my purposes I use it to confirm/compare to the Preferential Balloting Random Forest model I created.\n",
    "If you are gunning to win your office's Oscar pool, scroll down to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators import H2OXGBoostEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'film', 'wiki', 'winner', 'rating', 'numVotes',\n",
       "       'worldwide_box_office', 'action', 'adventure', 'animation', 'biography',\n",
       "       'comedy', 'crime', 'documentary', 'drama', 'family', 'fantasy',\n",
       "       'film-noir', 'history', 'horror', 'music', 'musical', 'mystery',\n",
       "       'romance', 'sci-fi', 'sport', 'thriller', 'war', 'western',\n",
       "       'nominations', 'Oscar_win', 'nom_gg_drama', 'winner_gg_drama',\n",
       "       'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga', 'winner_pga',\n",
       "       'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga', 'nom_sag',\n",
       "       'winner_sag', 'nom_cannes', 'winner_cannes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_table = pd.read_csv('../data/processed_results/extended_df.csv')\n",
    "full_table=full_table.drop('Unnamed: 0', axis=1)\n",
    "full_table.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Using h2o Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'film', 'wiki', 'winner', 'rating', 'numVotes',\n",
       "       'worldwide_box_office', 'action', 'adventure', 'animation', 'biography',\n",
       "       'comedy', 'crime', 'documentary', 'drama', 'family', 'fantasy',\n",
       "       'film-noir', 'history', 'horror', 'music', 'musical', 'mystery',\n",
       "       'romance', 'sci-fi', 'sport', 'thriller', 'war', 'western',\n",
       "       'nominations', 'Oscar_win', 'nom_gg_drama', 'winner_gg_drama',\n",
       "       'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga', 'winner_pga',\n",
       "       'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga', 'nom_sag',\n",
       "       'winner_sag', 'nom_cannes', 'winner_cannes', 'Acting',\n",
       "       'Production Design', 'Directing', 'VFX', 'Writing', 'Cinematography',\n",
       "       'Sound', 'Film Editing', 'Music'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_table = pd.read_csv('../data/processed_results/everything.csv')\n",
    "full_table=full_table.drop('Unnamed: 0', axis=1)\n",
    "full_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode)\n",
      "  Starting server from C:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmpthzeamqv\n",
      "  JVM stdout: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmpthzeamqv\\h2o_Aleksandra_Czaplak_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmpthzeamqv\\h2o_Aleksandra_Czaplak_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>07 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Berlin</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>25 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Aleksandra_Czaplak_iz8chp</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.761 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.2 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------------------\n",
       "H2O_cluster_uptime:         07 secs\n",
       "H2O_cluster_timezone:       Europe/Berlin\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    25 days\n",
       "H2O_cluster_name:           H2O_from_python_Aleksandra_Czaplak_iz8chp\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.761 Gb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.2 final\n",
       "--------------------------  -----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Year of Existance. This data will be used below\n",
    "- golden_globes 1943\n",
    "- pga 1989\n",
    "- bafta 1960\n",
    "- dga 1948\n",
    "- sag 1995\n",
    "- cannes 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I pick a min_year where the awards shows will be relevant\n",
    "min_year = 1995"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O's Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set contains: 176 movies\n"
     ]
    }
   ],
   "source": [
    "# Auto ML uses Cross Validation, so we do not specifiy a validation set\n",
    "train = full_table.loc[((full_table['year'] < 2022) & (full_table['year'] >= min_year))]\n",
    "\n",
    "print('training set contains:', train.shape[0], 'movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'film', 'wiki', 'winner', 'rating', 'numVotes',\n",
       "       'worldwide_box_office', 'action', 'adventure', 'animation', 'biography',\n",
       "       'comedy', 'crime', 'documentary', 'drama', 'family', 'fantasy',\n",
       "       'film-noir', 'history', 'horror', 'music', 'musical', 'mystery',\n",
       "       'romance', 'sci-fi', 'sport', 'thriller', 'war', 'western',\n",
       "       'nominations', 'Oscar_win', 'nom_gg_drama', 'winner_gg_drama',\n",
       "       'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga', 'winner_pga',\n",
       "       'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga', 'nom_sag',\n",
       "       'winner_sag', 'nom_cannes', 'winner_cannes', 'Acting',\n",
       "       'Production Design', 'Directing', 'VFX', 'Writing', 'Cinematography',\n",
       "       'Sound', 'Film Editing', 'Music'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train = train.drop(['index', '[]'], axis=1)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "08:57:22.228: AutoML: XGBoost is not available; skipping it.\n",
      "08:57:22.458: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "█\n",
      "08:57:24.737: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "08:57:24.738: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 176.0.\n",
      "08:57:24.764: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "██\n",
      "08:57:26.950: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "██\n",
      "08:57:28.249: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "08:57:29.742: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "█\n",
      "08:57:31.80: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "██\n",
      "08:57:32.51: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "███\n",
      "08:57:33.200: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "███████████████████████████████████████████████████\n",
      "09:34:17.671: _train param, Dropping bad and constant columns: [nom_cannes, winner_cannes, film-noir, documentary]\n",
      "\n",
      "█| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                            </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th><th style=\"text-align: right;\">  training_time_ms</th><th style=\"text-align: right;\">  predict_time_per_row_ms</th><th>algo        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_5 </td><td style=\"text-align: right;\">0.830513</td><td style=\"text-align: right;\"> 0.695563</td><td style=\"text-align: right;\">0.448287</td><td style=\"text-align: right;\">              0.248974</td><td style=\"text-align: right;\">0.372326</td><td style=\"text-align: right;\">0.138627</td><td style=\"text-align: right;\">              2709</td><td style=\"text-align: right;\">                 0.710977</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_2 </td><td style=\"text-align: right;\">0.823077</td><td style=\"text-align: right;\"> 0.417719</td><td style=\"text-align: right;\">0.39347 </td><td style=\"text-align: right;\">              0.233077</td><td style=\"text-align: right;\">0.344425</td><td style=\"text-align: right;\">0.118629</td><td style=\"text-align: right;\">              2689</td><td style=\"text-align: right;\">                 0.760255</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_22</td><td style=\"text-align: right;\">0.817179</td><td style=\"text-align: right;\"> 0.464433</td><td style=\"text-align: right;\">0.513033</td><td style=\"text-align: right;\">              0.251538</td><td style=\"text-align: right;\">0.321971</td><td style=\"text-align: right;\">0.103665</td><td style=\"text-align: right;\">              2708</td><td style=\"text-align: right;\">                 0.164375</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_5 </td><td style=\"text-align: right;\">0.813077</td><td style=\"text-align: right;\"> 0.654276</td><td style=\"text-align: right;\">0.381339</td><td style=\"text-align: right;\">              0.299231</td><td style=\"text-align: right;\">0.38311 </td><td style=\"text-align: right;\">0.146773</td><td style=\"text-align: right;\">              2062</td><td style=\"text-align: right;\">                 0.109675</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_14</td><td style=\"text-align: right;\">0.809487</td><td style=\"text-align: right;\"> 0.53134 </td><td style=\"text-align: right;\">0.396423</td><td style=\"text-align: right;\">              0.23641 </td><td style=\"text-align: right;\">0.361284</td><td style=\"text-align: right;\">0.130526</td><td style=\"text-align: right;\">              3939</td><td style=\"text-align: right;\">                 0.177956</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_10</td><td style=\"text-align: right;\">0.808846</td><td style=\"text-align: right;\"> 0.738022</td><td style=\"text-align: right;\">0.378064</td><td style=\"text-align: right;\">              0.258205</td><td style=\"text-align: right;\">0.373639</td><td style=\"text-align: right;\">0.139606</td><td style=\"text-align: right;\">              3034</td><td style=\"text-align: right;\">                 0.908088</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_4 </td><td style=\"text-align: right;\">0.802821</td><td style=\"text-align: right;\"> 0.671927</td><td style=\"text-align: right;\">0.381739</td><td style=\"text-align: right;\">              0.212821</td><td style=\"text-align: right;\">0.402897</td><td style=\"text-align: right;\">0.162326</td><td style=\"text-align: right;\">              4143</td><td style=\"text-align: right;\">                 0.270085</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_3 </td><td style=\"text-align: right;\">0.797692</td><td style=\"text-align: right;\"> 0.597201</td><td style=\"text-align: right;\">0.321101</td><td style=\"text-align: right;\">              0.254615</td><td style=\"text-align: right;\">0.400425</td><td style=\"text-align: right;\">0.16034 </td><td style=\"text-align: right;\">              2784</td><td style=\"text-align: right;\">                 0.086429</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_16</td><td style=\"text-align: right;\">0.795128</td><td style=\"text-align: right;\"> 1.49879 </td><td style=\"text-align: right;\">0.359095</td><td style=\"text-align: right;\">              0.273077</td><td style=\"text-align: right;\">0.414024</td><td style=\"text-align: right;\">0.171416</td><td style=\"text-align: right;\">              2630</td><td style=\"text-align: right;\">                 0.117531</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_2 </td><td style=\"text-align: right;\">0.793077</td><td style=\"text-align: right;\"> 0.73027 </td><td style=\"text-align: right;\">0.377618</td><td style=\"text-align: right;\">              0.285641</td><td style=\"text-align: right;\">0.404787</td><td style=\"text-align: right;\">0.163852</td><td style=\"text-align: right;\">              2700</td><td style=\"text-align: right;\">                 0.14276 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_11</td><td style=\"text-align: right;\">0.792564</td><td style=\"text-align: right;\"> 0.386072</td><td style=\"text-align: right;\">0.338971</td><td style=\"text-align: right;\">              0.209487</td><td style=\"text-align: right;\">0.34739 </td><td style=\"text-align: right;\">0.12068 </td><td style=\"text-align: right;\">              2390</td><td style=\"text-align: right;\">                 0.274097</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_12</td><td style=\"text-align: right;\">0.784615</td><td style=\"text-align: right;\"> 0.90519 </td><td style=\"text-align: right;\">0.378051</td><td style=\"text-align: right;\">              0.240513</td><td style=\"text-align: right;\">0.378227</td><td style=\"text-align: right;\">0.143056</td><td style=\"text-align: right;\">              4581</td><td style=\"text-align: right;\">                 0.467057</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_14</td><td style=\"text-align: right;\">0.782051</td><td style=\"text-align: right;\"> 0.412528</td><td style=\"text-align: right;\">0.379142</td><td style=\"text-align: right;\">              0.284103</td><td style=\"text-align: right;\">0.344026</td><td style=\"text-align: right;\">0.118354</td><td style=\"text-align: right;\">              3951</td><td style=\"text-align: right;\">                 0.145976</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_8 </td><td style=\"text-align: right;\">0.781795</td><td style=\"text-align: right;\"> 0.590756</td><td style=\"text-align: right;\">0.372474</td><td style=\"text-align: right;\">              0.274103</td><td style=\"text-align: right;\">0.374488</td><td style=\"text-align: right;\">0.140241</td><td style=\"text-align: right;\">              5329</td><td style=\"text-align: right;\">                 0.138053</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.781026</td><td style=\"text-align: right;\"> 0.360178</td><td style=\"text-align: right;\">0.387828</td><td style=\"text-align: right;\">              0.216154</td><td style=\"text-align: right;\">0.333761</td><td style=\"text-align: right;\">0.111396</td><td style=\"text-align: right;\">                96</td><td style=\"text-align: right;\">                 0.102436</td><td>GLM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_1 </td><td style=\"text-align: right;\">0.779744</td><td style=\"text-align: right;\"> 0.591486</td><td style=\"text-align: right;\">0.406765</td><td style=\"text-align: right;\">              0.261282</td><td style=\"text-align: right;\">0.377667</td><td style=\"text-align: right;\">0.142632</td><td style=\"text-align: right;\">              5603</td><td style=\"text-align: right;\">                 0.190538</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_16</td><td style=\"text-align: right;\">0.779487</td><td style=\"text-align: right;\"> 1.76003 </td><td style=\"text-align: right;\">0.365117</td><td style=\"text-align: right;\">              0.288205</td><td style=\"text-align: right;\">0.430472</td><td style=\"text-align: right;\">0.185306</td><td style=\"text-align: right;\">              2990</td><td style=\"text-align: right;\">                 0.168645</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_1 </td><td style=\"text-align: right;\">0.778205</td><td style=\"text-align: right;\"> 0.637349</td><td style=\"text-align: right;\">0.399865</td><td style=\"text-align: right;\">              0.237179</td><td style=\"text-align: right;\">0.356818</td><td style=\"text-align: right;\">0.127319</td><td style=\"text-align: right;\">              4287</td><td style=\"text-align: right;\">                 0.121014</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_16</td><td style=\"text-align: right;\">0.773077</td><td style=\"text-align: right;\"> 1.10118 </td><td style=\"text-align: right;\">0.355061</td><td style=\"text-align: right;\">              0.248718</td><td style=\"text-align: right;\">0.430749</td><td style=\"text-align: right;\">0.185545</td><td style=\"text-align: right;\">              2940</td><td style=\"text-align: right;\">                 0.184386</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_21</td><td style=\"text-align: right;\">0.769487</td><td style=\"text-align: right;\"> 1.15463 </td><td style=\"text-align: right;\">0.308691</td><td style=\"text-align: right;\">              0.298205</td><td style=\"text-align: right;\">0.421771</td><td style=\"text-align: right;\">0.177891</td><td style=\"text-align: right;\">              2795</td><td style=\"text-align: right;\">                 0.101911</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DRF_1_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.769103</td><td style=\"text-align: right;\"> 0.377327</td><td style=\"text-align: right;\">0.380961</td><td style=\"text-align: right;\">              0.268205</td><td style=\"text-align: right;\">0.329112</td><td style=\"text-align: right;\">0.108315</td><td style=\"text-align: right;\">               184</td><td style=\"text-align: right;\">                 0.082132</td><td>DRF         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_11         </td><td style=\"text-align: right;\">0.763846</td><td style=\"text-align: right;\"> 0.371534</td><td style=\"text-align: right;\">0.279444</td><td style=\"text-align: right;\">              0.28641 </td><td style=\"text-align: right;\">0.339534</td><td style=\"text-align: right;\">0.115283</td><td style=\"text-align: right;\">                60</td><td style=\"text-align: right;\">                 0.10914 </td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_19</td><td style=\"text-align: right;\">0.761795</td><td style=\"text-align: right;\"> 0.773505</td><td style=\"text-align: right;\">0.365195</td><td style=\"text-align: right;\">              0.341026</td><td style=\"text-align: right;\">0.38679 </td><td style=\"text-align: right;\">0.149606</td><td style=\"text-align: right;\">              2386</td><td style=\"text-align: right;\">                 0.178094</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_21         </td><td style=\"text-align: right;\">0.759231</td><td style=\"text-align: right;\"> 0.433061</td><td style=\"text-align: right;\">0.275309</td><td style=\"text-align: right;\">              0.280513</td><td style=\"text-align: right;\">0.362156</td><td style=\"text-align: right;\">0.131157</td><td style=\"text-align: right;\">               120</td><td style=\"text-align: right;\">                 0.401146</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_7 </td><td style=\"text-align: right;\">0.758462</td><td style=\"text-align: right;\"> 0.676088</td><td style=\"text-align: right;\">0.367014</td><td style=\"text-align: right;\">              0.285641</td><td style=\"text-align: right;\">0.414402</td><td style=\"text-align: right;\">0.171729</td><td style=\"text-align: right;\">              5532</td><td style=\"text-align: right;\">                 0.378401</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_2 </td><td style=\"text-align: right;\">0.756923</td><td style=\"text-align: right;\"> 0.555452</td><td style=\"text-align: right;\">0.350468</td><td style=\"text-align: right;\">              0.27641 </td><td style=\"text-align: right;\">0.387615</td><td style=\"text-align: right;\">0.150245</td><td style=\"text-align: right;\">              2591</td><td style=\"text-align: right;\">                 0.139453</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_13         </td><td style=\"text-align: right;\">0.756923</td><td style=\"text-align: right;\"> 0.414042</td><td style=\"text-align: right;\">0.301439</td><td style=\"text-align: right;\">              0.29641 </td><td style=\"text-align: right;\">0.352838</td><td style=\"text-align: right;\">0.124495</td><td style=\"text-align: right;\">               129</td><td style=\"text-align: right;\">                 0.054001</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_2          </td><td style=\"text-align: right;\">0.756795</td><td style=\"text-align: right;\"> 0.400463</td><td style=\"text-align: right;\">0.285598</td><td style=\"text-align: right;\">              0.299744</td><td style=\"text-align: right;\">0.354225</td><td style=\"text-align: right;\">0.125475</td><td style=\"text-align: right;\">                88</td><td style=\"text-align: right;\">                 0.09191 </td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_5 </td><td style=\"text-align: right;\">0.75641 </td><td style=\"text-align: right;\"> 0.745685</td><td style=\"text-align: right;\">0.32153 </td><td style=\"text-align: right;\">              0.335128</td><td style=\"text-align: right;\">0.391403</td><td style=\"text-align: right;\">0.153197</td><td style=\"text-align: right;\">              2803</td><td style=\"text-align: right;\">                 0.350275</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_4 </td><td style=\"text-align: right;\">0.754359</td><td style=\"text-align: right;\"> 0.661384</td><td style=\"text-align: right;\">0.378926</td><td style=\"text-align: right;\">              0.292308</td><td style=\"text-align: right;\">0.394163</td><td style=\"text-align: right;\">0.155365</td><td style=\"text-align: right;\">              5376</td><td style=\"text-align: right;\">                 0.188155</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_17         </td><td style=\"text-align: right;\">0.750897</td><td style=\"text-align: right;\"> 0.408353</td><td style=\"text-align: right;\">0.271268</td><td style=\"text-align: right;\">              0.304103</td><td style=\"text-align: right;\">0.359621</td><td style=\"text-align: right;\">0.129327</td><td style=\"text-align: right;\">                85</td><td style=\"text-align: right;\">                 0.121253</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_12         </td><td style=\"text-align: right;\">0.750513</td><td style=\"text-align: right;\"> 0.408181</td><td style=\"text-align: right;\">0.289041</td><td style=\"text-align: right;\">              0.28641 </td><td style=\"text-align: right;\">0.355011</td><td style=\"text-align: right;\">0.126033</td><td style=\"text-align: right;\">               132</td><td style=\"text-align: right;\">                 0.267484</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_20</td><td style=\"text-align: right;\">0.747692</td><td style=\"text-align: right;\"> 0.456588</td><td style=\"text-align: right;\">0.318082</td><td style=\"text-align: right;\">              0.258718</td><td style=\"text-align: right;\">0.355447</td><td style=\"text-align: right;\">0.126343</td><td style=\"text-align: right;\">              2668</td><td style=\"text-align: right;\">                 0.654688</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_12</td><td style=\"text-align: right;\">0.743077</td><td style=\"text-align: right;\"> 0.832753</td><td style=\"text-align: right;\">0.350161</td><td style=\"text-align: right;\">              0.321538</td><td style=\"text-align: right;\">0.430192</td><td style=\"text-align: right;\">0.185065</td><td style=\"text-align: right;\">              3142</td><td style=\"text-align: right;\">                 0.166638</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_3 </td><td style=\"text-align: right;\">0.743077</td><td style=\"text-align: right;\"> 2.24259 </td><td style=\"text-align: right;\">0.294094</td><td style=\"text-align: right;\">              0.298718</td><td style=\"text-align: right;\">0.465047</td><td style=\"text-align: right;\">0.216268</td><td style=\"text-align: right;\">              2595</td><td style=\"text-align: right;\">                 0.276043</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_3_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.741538</td><td style=\"text-align: right;\"> 0.380115</td><td style=\"text-align: right;\">0.289527</td><td style=\"text-align: right;\">              0.324103</td><td style=\"text-align: right;\">0.342256</td><td style=\"text-align: right;\">0.117139</td><td style=\"text-align: right;\">               152</td><td style=\"text-align: right;\">                 0.055528</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_9          </td><td style=\"text-align: right;\">0.740513</td><td style=\"text-align: right;\"> 0.380416</td><td style=\"text-align: right;\">0.274504</td><td style=\"text-align: right;\">              0.28641 </td><td style=\"text-align: right;\">0.343803</td><td style=\"text-align: right;\">0.118201</td><td style=\"text-align: right;\">                72</td><td style=\"text-align: right;\">                 0.064468</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_8 </td><td style=\"text-align: right;\">0.739744</td><td style=\"text-align: right;\"> 0.748565</td><td style=\"text-align: right;\">0.377619</td><td style=\"text-align: right;\">              0.268974</td><td style=\"text-align: right;\">0.370169</td><td style=\"text-align: right;\">0.137025</td><td style=\"text-align: right;\">              3998</td><td style=\"text-align: right;\">                 0.11151 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_1 </td><td style=\"text-align: right;\">0.739487</td><td style=\"text-align: right;\"> 0.56148 </td><td style=\"text-align: right;\">0.315495</td><td style=\"text-align: right;\">              0.298974</td><td style=\"text-align: right;\">0.380489</td><td style=\"text-align: right;\">0.144772</td><td style=\"text-align: right;\">              2802</td><td style=\"text-align: right;\">                 0.080513</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_19</td><td style=\"text-align: right;\">0.738974</td><td style=\"text-align: right;\"> 0.62602 </td><td style=\"text-align: right;\">0.366896</td><td style=\"text-align: right;\">              0.268974</td><td style=\"text-align: right;\">0.357083</td><td style=\"text-align: right;\">0.127509</td><td style=\"text-align: right;\">              4089</td><td style=\"text-align: right;\">                 0.15411 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_10         </td><td style=\"text-align: right;\">0.738462</td><td style=\"text-align: right;\"> 0.377071</td><td style=\"text-align: right;\">0.294111</td><td style=\"text-align: right;\">              0.290513</td><td style=\"text-align: right;\">0.341778</td><td style=\"text-align: right;\">0.116812</td><td style=\"text-align: right;\">                94</td><td style=\"text-align: right;\">                 0.129367</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_5_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.737179</td><td style=\"text-align: right;\"> 0.434135</td><td style=\"text-align: right;\">0.276889</td><td style=\"text-align: right;\">              0.332564</td><td style=\"text-align: right;\">0.359962</td><td style=\"text-align: right;\">0.129573</td><td style=\"text-align: right;\">               189</td><td style=\"text-align: right;\">                 0.163997</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_1          </td><td style=\"text-align: right;\">0.736154</td><td style=\"text-align: right;\"> 0.381772</td><td style=\"text-align: right;\">0.257161</td><td style=\"text-align: right;\">              0.324103</td><td style=\"text-align: right;\">0.346236</td><td style=\"text-align: right;\">0.119879</td><td style=\"text-align: right;\">                93</td><td style=\"text-align: right;\">                 0.124114</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_19</td><td style=\"text-align: right;\">0.734359</td><td style=\"text-align: right;\"> 0.724492</td><td style=\"text-align: right;\">0.286856</td><td style=\"text-align: right;\">              0.342564</td><td style=\"text-align: right;\">0.38865 </td><td style=\"text-align: right;\">0.151049</td><td style=\"text-align: right;\">              4069</td><td style=\"text-align: right;\">                 0.31668 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_11</td><td style=\"text-align: right;\">0.734103</td><td style=\"text-align: right;\"> 0.585997</td><td style=\"text-align: right;\">0.350118</td><td style=\"text-align: right;\">              0.274872</td><td style=\"text-align: right;\">0.367134</td><td style=\"text-align: right;\">0.134787</td><td style=\"text-align: right;\">              2663</td><td style=\"text-align: right;\">                 0.121672</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_15         </td><td style=\"text-align: right;\">0.73359 </td><td style=\"text-align: right;\"> 0.40042 </td><td style=\"text-align: right;\">0.286015</td><td style=\"text-align: right;\">              0.279487</td><td style=\"text-align: right;\">0.350108</td><td style=\"text-align: right;\">0.122575</td><td style=\"text-align: right;\">                86</td><td style=\"text-align: right;\">                 0.171516</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_4          </td><td style=\"text-align: right;\">0.733205</td><td style=\"text-align: right;\"> 0.37826 </td><td style=\"text-align: right;\">0.248004</td><td style=\"text-align: right;\">              0.292308</td><td style=\"text-align: right;\">0.343261</td><td style=\"text-align: right;\">0.117828</td><td style=\"text-align: right;\">                89</td><td style=\"text-align: right;\">                 0.321691</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_7 </td><td style=\"text-align: right;\">0.731026</td><td style=\"text-align: right;\"> 0.599752</td><td style=\"text-align: right;\">0.344847</td><td style=\"text-align: right;\">              0.306667</td><td style=\"text-align: right;\">0.373629</td><td style=\"text-align: right;\">0.139599</td><td style=\"text-align: right;\">              4315</td><td style=\"text-align: right;\">                 0.123526</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_6 </td><td style=\"text-align: right;\">0.730513</td><td style=\"text-align: right;\"> 0.71592 </td><td style=\"text-align: right;\">0.294893</td><td style=\"text-align: right;\">              0.275128</td><td style=\"text-align: right;\">0.40819 </td><td style=\"text-align: right;\">0.166619</td><td style=\"text-align: right;\">              2868</td><td style=\"text-align: right;\">                 0.107911</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_20</td><td style=\"text-align: right;\">0.729487</td><td style=\"text-align: right;\"> 0.775452</td><td style=\"text-align: right;\">0.345496</td><td style=\"text-align: right;\">              0.311538</td><td style=\"text-align: right;\">0.385905</td><td style=\"text-align: right;\">0.148923</td><td style=\"text-align: right;\">              2881</td><td style=\"text-align: right;\">                 0.102733</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_7          </td><td style=\"text-align: right;\">0.727692</td><td style=\"text-align: right;\"> 0.408609</td><td style=\"text-align: right;\">0.252227</td><td style=\"text-align: right;\">              0.289231</td><td style=\"text-align: right;\">0.358455</td><td style=\"text-align: right;\">0.12849 </td><td style=\"text-align: right;\">                66</td><td style=\"text-align: right;\">                 0.066875</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_11</td><td style=\"text-align: right;\">0.727179</td><td style=\"text-align: right;\"> 0.759333</td><td style=\"text-align: right;\">0.299522</td><td style=\"text-align: right;\">              0.284872</td><td style=\"text-align: right;\">0.383881</td><td style=\"text-align: right;\">0.147364</td><td style=\"text-align: right;\">              2645</td><td style=\"text-align: right;\">                 0.132849</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_8          </td><td style=\"text-align: right;\">0.725641</td><td style=\"text-align: right;\"> 0.433043</td><td style=\"text-align: right;\">0.28079 </td><td style=\"text-align: right;\">              0.295641</td><td style=\"text-align: right;\">0.358929</td><td style=\"text-align: right;\">0.12883 </td><td style=\"text-align: right;\">               131</td><td style=\"text-align: right;\">                 0.089563</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_10</td><td style=\"text-align: right;\">0.721282</td><td style=\"text-align: right;\"> 0.665981</td><td style=\"text-align: right;\">0.341346</td><td style=\"text-align: right;\">              0.324872</td><td style=\"text-align: right;\">0.434704</td><td style=\"text-align: right;\">0.188967</td><td style=\"text-align: right;\">              5331</td><td style=\"text-align: right;\">                 0.139759</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_14</td><td style=\"text-align: right;\">0.72    </td><td style=\"text-align: right;\"> 0.675661</td><td style=\"text-align: right;\">0.337286</td><td style=\"text-align: right;\">              0.33    </td><td style=\"text-align: right;\">0.359504</td><td style=\"text-align: right;\">0.129243</td><td style=\"text-align: right;\">              1856</td><td style=\"text-align: right;\">                 0.082228</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_22         </td><td style=\"text-align: right;\">0.719487</td><td style=\"text-align: right;\"> 0.385287</td><td style=\"text-align: right;\">0.276424</td><td style=\"text-align: right;\">              0.275385</td><td style=\"text-align: right;\">0.342366</td><td style=\"text-align: right;\">0.117214</td><td style=\"text-align: right;\">                69</td><td style=\"text-align: right;\">                 0.067556</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_7 </td><td style=\"text-align: right;\">0.718205</td><td style=\"text-align: right;\"> 0.749389</td><td style=\"text-align: right;\">0.35717 </td><td style=\"text-align: right;\">              0.257949</td><td style=\"text-align: right;\">0.400645</td><td style=\"text-align: right;\">0.160516</td><td style=\"text-align: right;\">              2744</td><td style=\"text-align: right;\">                 0.11812 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_4_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.715641</td><td style=\"text-align: right;\"> 0.394532</td><td style=\"text-align: right;\">0.298985</td><td style=\"text-align: right;\">              0.281282</td><td style=\"text-align: right;\">0.347308</td><td style=\"text-align: right;\">0.120623</td><td style=\"text-align: right;\">               164</td><td style=\"text-align: right;\">                 0.077411</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_20         </td><td style=\"text-align: right;\">0.71359 </td><td style=\"text-align: right;\"> 0.384883</td><td style=\"text-align: right;\">0.245127</td><td style=\"text-align: right;\">              0.308205</td><td style=\"text-align: right;\">0.344086</td><td style=\"text-align: right;\">0.118395</td><td style=\"text-align: right;\">                61</td><td style=\"text-align: right;\">                 0.100552</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_3          </td><td style=\"text-align: right;\">0.711795</td><td style=\"text-align: right;\"> 0.385044</td><td style=\"text-align: right;\">0.302615</td><td style=\"text-align: right;\">              0.333333</td><td style=\"text-align: right;\">0.341844</td><td style=\"text-align: right;\">0.116857</td><td style=\"text-align: right;\">               112</td><td style=\"text-align: right;\">                 0.072263</td><td>GBM         </td></tr>\n",
       "<tr><td>XRT_1_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.711538</td><td style=\"text-align: right;\"> 0.398451</td><td style=\"text-align: right;\">0.268246</td><td style=\"text-align: right;\">              0.313333</td><td style=\"text-align: right;\">0.347068</td><td style=\"text-align: right;\">0.120456</td><td style=\"text-align: right;\">               107</td><td style=\"text-align: right;\">                 0.092367</td><td>DRF         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_12</td><td style=\"text-align: right;\">0.709487</td><td style=\"text-align: right;\"> 0.916957</td><td style=\"text-align: right;\">0.286277</td><td style=\"text-align: right;\">              0.323333</td><td style=\"text-align: right;\">0.411415</td><td style=\"text-align: right;\">0.169262</td><td style=\"text-align: right;\">              3527</td><td style=\"text-align: right;\">                 0.202031</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_5          </td><td style=\"text-align: right;\">0.709231</td><td style=\"text-align: right;\"> 0.397116</td><td style=\"text-align: right;\">0.255828</td><td style=\"text-align: right;\">              0.313077</td><td style=\"text-align: right;\">0.349821</td><td style=\"text-align: right;\">0.122375</td><td style=\"text-align: right;\">               112</td><td style=\"text-align: right;\">                 0.073839</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_1_20230524_85722              </td><td style=\"text-align: right;\">0.707949</td><td style=\"text-align: right;\"> 0.566049</td><td style=\"text-align: right;\">0.253395</td><td style=\"text-align: right;\">              0.335897</td><td style=\"text-align: right;\">0.397394</td><td style=\"text-align: right;\">0.157922</td><td style=\"text-align: right;\">               101</td><td style=\"text-align: right;\">                 0.095452</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_6 </td><td style=\"text-align: right;\">0.706154</td><td style=\"text-align: right;\"> 0.605361</td><td style=\"text-align: right;\">0.32798 </td><td style=\"text-align: right;\">              0.320769</td><td style=\"text-align: right;\">0.365197</td><td style=\"text-align: right;\">0.133369</td><td style=\"text-align: right;\">              4077</td><td style=\"text-align: right;\">                 0.119695</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_10</td><td style=\"text-align: right;\">0.698974</td><td style=\"text-align: right;\"> 0.659814</td><td style=\"text-align: right;\">0.390984</td><td style=\"text-align: right;\">              0.322564</td><td style=\"text-align: right;\">0.391506</td><td style=\"text-align: right;\">0.153277</td><td style=\"text-align: right;\">              4903</td><td style=\"text-align: right;\">                 0.180571</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230524_85722_model_18         </td><td style=\"text-align: right;\">0.695897</td><td style=\"text-align: right;\"> 0.437023</td><td style=\"text-align: right;\">0.276155</td><td style=\"text-align: right;\">              0.327436</td><td style=\"text-align: right;\">0.354882</td><td style=\"text-align: right;\">0.125941</td><td style=\"text-align: right;\">               131</td><td style=\"text-align: right;\">                 0.115914</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_18</td><td style=\"text-align: right;\">0.690769</td><td style=\"text-align: right;\"> 0.613497</td><td style=\"text-align: right;\">0.374577</td><td style=\"text-align: right;\">              0.340769</td><td style=\"text-align: right;\">0.375103</td><td style=\"text-align: right;\">0.140702</td><td style=\"text-align: right;\">              3110</td><td style=\"text-align: right;\">                 0.088781</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_22</td><td style=\"text-align: right;\">0.689744</td><td style=\"text-align: right;\"> 0.71721 </td><td style=\"text-align: right;\">0.351706</td><td style=\"text-align: right;\">              0.277179</td><td style=\"text-align: right;\">0.358253</td><td style=\"text-align: right;\">0.128345</td><td style=\"text-align: right;\">              2609</td><td style=\"text-align: right;\">                 0.150519</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_2_AutoML_1_20230524_85722                       </td><td style=\"text-align: right;\">0.684103</td><td style=\"text-align: right;\"> 0.416181</td><td style=\"text-align: right;\">0.225593</td><td style=\"text-align: right;\">              0.358205</td><td style=\"text-align: right;\">0.358297</td><td style=\"text-align: right;\">0.128377</td><td style=\"text-align: right;\">               126</td><td style=\"text-align: right;\">                 0.042361</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_13</td><td style=\"text-align: right;\">0.683333</td><td style=\"text-align: right;\"> 0.640924</td><td style=\"text-align: right;\">0.283034</td><td style=\"text-align: right;\">              0.341538</td><td style=\"text-align: right;\">0.371735</td><td style=\"text-align: right;\">0.138187</td><td style=\"text-align: right;\">              3901</td><td style=\"text-align: right;\">                 0.172116</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_8 </td><td style=\"text-align: right;\">0.678462</td><td style=\"text-align: right;\"> 0.635846</td><td style=\"text-align: right;\">0.275963</td><td style=\"text-align: right;\">              0.366923</td><td style=\"text-align: right;\">0.395044</td><td style=\"text-align: right;\">0.15606 </td><td style=\"text-align: right;\">              5460</td><td style=\"text-align: right;\">                 0.369481</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_15</td><td style=\"text-align: right;\">0.675385</td><td style=\"text-align: right;\"> 1.6378  </td><td style=\"text-align: right;\">0.284622</td><td style=\"text-align: right;\">              0.34641 </td><td style=\"text-align: right;\">0.520244</td><td style=\"text-align: right;\">0.270654</td><td style=\"text-align: right;\">              2722</td><td style=\"text-align: right;\">                 0.092243</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_9 </td><td style=\"text-align: right;\">0.673077</td><td style=\"text-align: right;\"> 1.01995 </td><td style=\"text-align: right;\">0.218572</td><td style=\"text-align: right;\">              0.319744</td><td style=\"text-align: right;\">0.441642</td><td style=\"text-align: right;\">0.195047</td><td style=\"text-align: right;\">              2933</td><td style=\"text-align: right;\">                 0.081322</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_21</td><td style=\"text-align: right;\">0.669231</td><td style=\"text-align: right;\"> 0.830025</td><td style=\"text-align: right;\">0.295992</td><td style=\"text-align: right;\">              0.356667</td><td style=\"text-align: right;\">0.443183</td><td style=\"text-align: right;\">0.196411</td><td style=\"text-align: right;\">              2636</td><td style=\"text-align: right;\">                 0.060905</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_23</td><td style=\"text-align: right;\">0.668718</td><td style=\"text-align: right;\"> 1.41541 </td><td style=\"text-align: right;\">0.255323</td><td style=\"text-align: right;\">              0.350513</td><td style=\"text-align: right;\">0.468592</td><td style=\"text-align: right;\">0.219579</td><td style=\"text-align: right;\">              2594</td><td style=\"text-align: right;\">                 0.059538</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_21</td><td style=\"text-align: right;\">0.666154</td><td style=\"text-align: right;\"> 0.666535</td><td style=\"text-align: right;\">0.284685</td><td style=\"text-align: right;\">              0.340769</td><td style=\"text-align: right;\">0.404423</td><td style=\"text-align: right;\">0.163558</td><td style=\"text-align: right;\">              2731</td><td style=\"text-align: right;\">                 0.083045</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_20</td><td style=\"text-align: right;\">0.657692</td><td style=\"text-align: right;\"> 0.567925</td><td style=\"text-align: right;\">0.314398</td><td style=\"text-align: right;\">              0.326667</td><td style=\"text-align: right;\">0.356959</td><td style=\"text-align: right;\">0.127419</td><td style=\"text-align: right;\">              2699</td><td style=\"text-align: right;\">                 0.079024</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_13</td><td style=\"text-align: right;\">0.654103</td><td style=\"text-align: right;\"> 1.05637 </td><td style=\"text-align: right;\">0.255971</td><td style=\"text-align: right;\">              0.361538</td><td style=\"text-align: right;\">0.382364</td><td style=\"text-align: right;\">0.146202</td><td style=\"text-align: right;\">              3733</td><td style=\"text-align: right;\">                 0.093792</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_22</td><td style=\"text-align: right;\">0.653077</td><td style=\"text-align: right;\"> 1.30272 </td><td style=\"text-align: right;\">0.200791</td><td style=\"text-align: right;\">              0.33359 </td><td style=\"text-align: right;\">0.464225</td><td style=\"text-align: right;\">0.215505</td><td style=\"text-align: right;\">              2735</td><td style=\"text-align: right;\">                 0.199886</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_17</td><td style=\"text-align: right;\">0.64    </td><td style=\"text-align: right;\"> 0.637143</td><td style=\"text-align: right;\">0.398898</td><td style=\"text-align: right;\">              0.378718</td><td style=\"text-align: right;\">0.346699</td><td style=\"text-align: right;\">0.1202  </td><td style=\"text-align: right;\">              2628</td><td style=\"text-align: right;\">                 0.751002</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_13</td><td style=\"text-align: right;\">0.622308</td><td style=\"text-align: right;\"> 0.840956</td><td style=\"text-align: right;\">0.237018</td><td style=\"text-align: right;\">              0.360513</td><td style=\"text-align: right;\">0.438958</td><td style=\"text-align: right;\">0.192685</td><td style=\"text-align: right;\">              2415</td><td style=\"text-align: right;\">                 0.589494</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_3 </td><td style=\"text-align: right;\">0.620769</td><td style=\"text-align: right;\"> 0.81861 </td><td style=\"text-align: right;\">0.21137 </td><td style=\"text-align: right;\">              0.364103</td><td style=\"text-align: right;\">0.410995</td><td style=\"text-align: right;\">0.168917</td><td style=\"text-align: right;\">              2863</td><td style=\"text-align: right;\">                36.2781  </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_4 </td><td style=\"text-align: right;\">0.614872</td><td style=\"text-align: right;\"> 1.16054 </td><td style=\"text-align: right;\">0.24582 </td><td style=\"text-align: right;\">              0.347949</td><td style=\"text-align: right;\">0.410871</td><td style=\"text-align: right;\">0.168815</td><td style=\"text-align: right;\">              3194</td><td style=\"text-align: right;\">                 0.275344</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_9 </td><td style=\"text-align: right;\">0.591795</td><td style=\"text-align: right;\"> 0.983963</td><td style=\"text-align: right;\">0.285678</td><td style=\"text-align: right;\">              0.35    </td><td style=\"text-align: right;\">0.400895</td><td style=\"text-align: right;\">0.160717</td><td style=\"text-align: right;\">              2777</td><td style=\"text-align: right;\">                 0.11525 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_6 </td><td style=\"text-align: right;\">0.580513</td><td style=\"text-align: right;\"> 0.760781</td><td style=\"text-align: right;\">0.188506</td><td style=\"text-align: right;\">              0.382564</td><td style=\"text-align: right;\">0.379782</td><td style=\"text-align: right;\">0.144234</td><td style=\"text-align: right;\">              4951</td><td style=\"text-align: right;\">                 0.30105 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_15</td><td style=\"text-align: right;\">0.572821</td><td style=\"text-align: right;\"> 0.746677</td><td style=\"text-align: right;\">0.214842</td><td style=\"text-align: right;\">              0.373333</td><td style=\"text-align: right;\">0.371236</td><td style=\"text-align: right;\">0.137816</td><td style=\"text-align: right;\">              2545</td><td style=\"text-align: right;\">                 0.230366</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_15</td><td style=\"text-align: right;\">0.57    </td><td style=\"text-align: right;\"> 0.972834</td><td style=\"text-align: right;\">0.223291</td><td style=\"text-align: right;\">              0.408718</td><td style=\"text-align: right;\">0.401614</td><td style=\"text-align: right;\">0.161294</td><td style=\"text-align: right;\">              2705</td><td style=\"text-align: right;\">                 0.093188</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_18</td><td style=\"text-align: right;\">0.569487</td><td style=\"text-align: right;\"> 0.561799</td><td style=\"text-align: right;\">0.204888</td><td style=\"text-align: right;\">              0.396923</td><td style=\"text-align: right;\">0.372262</td><td style=\"text-align: right;\">0.138579</td><td style=\"text-align: right;\">              2550</td><td style=\"text-align: right;\">                 0.088106</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230524_85722_model_18</td><td style=\"text-align: right;\">0.568718</td><td style=\"text-align: right;\"> 0.897296</td><td style=\"text-align: right;\">0.238073</td><td style=\"text-align: right;\">              0.422051</td><td style=\"text-align: right;\">0.386014</td><td style=\"text-align: right;\">0.149007</td><td style=\"text-align: right;\">              2630</td><td style=\"text-align: right;\">                 0.202487</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230524_85722_model_17</td><td style=\"text-align: right;\">0.504615</td><td style=\"text-align: right;\"> 0.902361</td><td style=\"text-align: right;\">0.160535</td><td style=\"text-align: right;\">              0.422051</td><td style=\"text-align: right;\">0.420276</td><td style=\"text-align: right;\">0.176632</td><td style=\"text-align: right;\">              2376</td><td style=\"text-align: right;\">                 0.103973</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_17</td><td style=\"text-align: right;\">0.499231</td><td style=\"text-align: right;\"> 0.877267</td><td style=\"text-align: right;\">0.191124</td><td style=\"text-align: right;\">              0.458718</td><td style=\"text-align: right;\">0.381507</td><td style=\"text-align: right;\">0.145548</td><td style=\"text-align: right;\">              2457</td><td style=\"text-align: right;\">                 2.07925 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230524_85722_model_9 </td><td style=\"text-align: right;\">0.483077</td><td style=\"text-align: right;\"> 0.605123</td><td style=\"text-align: right;\">0.134492</td><td style=\"text-align: right;\">              0.463333</td><td style=\"text-align: right;\">0.390951</td><td style=\"text-align: right;\">0.152842</td><td style=\"text-align: right;\">              2139</td><td style=\"text-align: right;\">                 0.09187 </td><td>DeepLearning</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[93 rows x 10 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                   auc    logloss     aucpr    mean_per_class_error      rmse       mse    training_time_ms    predict_time_per_row_ms  algo\n",
       "----------------------------------------------------  --------  ---------  --------  ----------------------  --------  --------  ------------------  -------------------------  ------------\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_5   0.830513   0.695563  0.448287                0.248974  0.372326  0.138627                2709                   0.710977  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_2   0.823077   0.417719  0.39347                 0.233077  0.344425  0.118629                2689                   0.760255  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_22  0.817179   0.464433  0.513033                0.251538  0.321971  0.103665                2708                   0.164375  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_5   0.813077   0.654276  0.381339                0.299231  0.38311   0.146773                2062                   0.109675  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_14  0.809487   0.53134   0.396423                0.23641   0.361284  0.130526                3939                   0.177956  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_10  0.808846   0.738022  0.378064                0.258205  0.373639  0.139606                3034                   0.908088  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_4   0.802821   0.671927  0.381739                0.212821  0.402897  0.162326                4143                   0.270085  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_3   0.797692   0.597201  0.321101                0.254615  0.400425  0.16034                 2784                   0.086429  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_16  0.795128   1.49879   0.359095                0.273077  0.414024  0.171416                2630                   0.117531  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_2   0.793077   0.73027   0.377618                0.285641  0.404787  0.163852                2700                   0.14276   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_11  0.792564   0.386072  0.338971                0.209487  0.34739   0.12068                 2390                   0.274097  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_12  0.784615   0.90519   0.378051                0.240513  0.378227  0.143056                4581                   0.467057  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_14  0.782051   0.412528  0.379142                0.284103  0.344026  0.118354                3951                   0.145976  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_8   0.781795   0.590756  0.372474                0.274103  0.374488  0.140241                5329                   0.138053  DeepLearning\n",
       "GLM_1_AutoML_1_20230524_85722                         0.781026   0.360178  0.387828                0.216154  0.333761  0.111396                  96                   0.102436  GLM\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_1   0.779744   0.591486  0.406765                0.261282  0.377667  0.142632                5603                   0.190538  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_16  0.779487   1.76003   0.365117                0.288205  0.430472  0.185306                2990                   0.168645  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_1   0.778205   0.637349  0.399865                0.237179  0.356818  0.127319                4287                   0.121014  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_16  0.773077   1.10118   0.355061                0.248718  0.430749  0.185545                2940                   0.184386  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_21  0.769487   1.15463   0.308691                0.298205  0.421771  0.177891                2795                   0.101911  DeepLearning\n",
       "DRF_1_AutoML_1_20230524_85722                         0.769103   0.377327  0.380961                0.268205  0.329112  0.108315                 184                   0.082132  DRF\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_11           0.763846   0.371534  0.279444                0.28641   0.339534  0.115283                  60                   0.10914   GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_19  0.761795   0.773505  0.365195                0.341026  0.38679   0.149606                2386                   0.178094  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_21           0.759231   0.433061  0.275309                0.280513  0.362156  0.131157                 120                   0.401146  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_7   0.758462   0.676088  0.367014                0.285641  0.414402  0.171729                5532                   0.378401  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_2   0.756923   0.555452  0.350468                0.27641   0.387615  0.150245                2591                   0.139453  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_13           0.756923   0.414042  0.301439                0.29641   0.352838  0.124495                 129                   0.054001  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_2            0.756795   0.400463  0.285598                0.299744  0.354225  0.125475                  88                   0.09191   GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_5   0.75641    0.745685  0.32153                 0.335128  0.391403  0.153197                2803                   0.350275  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_4   0.754359   0.661384  0.378926                0.292308  0.394163  0.155365                5376                   0.188155  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_17           0.750897   0.408353  0.271268                0.304103  0.359621  0.129327                  85                   0.121253  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_12           0.750513   0.408181  0.289041                0.28641   0.355011  0.126033                 132                   0.267484  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_20  0.747692   0.456588  0.318082                0.258718  0.355447  0.126343                2668                   0.654688  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_12  0.743077   0.832753  0.350161                0.321538  0.430192  0.185065                3142                   0.166638  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_3   0.743077   2.24259   0.294094                0.298718  0.465047  0.216268                2595                   0.276043  DeepLearning\n",
       "GBM_3_AutoML_1_20230524_85722                         0.741538   0.380115  0.289527                0.324103  0.342256  0.117139                 152                   0.055528  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_9            0.740513   0.380416  0.274504                0.28641   0.343803  0.118201                  72                   0.064468  GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_8   0.739744   0.748565  0.377619                0.268974  0.370169  0.137025                3998                   0.11151   DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_1   0.739487   0.56148   0.315495                0.298974  0.380489  0.144772                2802                   0.080513  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_19  0.738974   0.62602   0.366896                0.268974  0.357083  0.127509                4089                   0.15411   DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_10           0.738462   0.377071  0.294111                0.290513  0.341778  0.116812                  94                   0.129367  GBM\n",
       "GBM_5_AutoML_1_20230524_85722                         0.737179   0.434135  0.276889                0.332564  0.359962  0.129573                 189                   0.163997  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_1            0.736154   0.381772  0.257161                0.324103  0.346236  0.119879                  93                   0.124114  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_19  0.734359   0.724492  0.286856                0.342564  0.38865   0.151049                4069                   0.31668   DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_11  0.734103   0.585997  0.350118                0.274872  0.367134  0.134787                2663                   0.121672  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_15           0.73359    0.40042   0.286015                0.279487  0.350108  0.122575                  86                   0.171516  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_4            0.733205   0.37826   0.248004                0.292308  0.343261  0.117828                  89                   0.321691  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_7   0.731026   0.599752  0.344847                0.306667  0.373629  0.139599                4315                   0.123526  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_6   0.730513   0.71592   0.294893                0.275128  0.40819   0.166619                2868                   0.107911  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_20  0.729487   0.775452  0.345496                0.311538  0.385905  0.148923                2881                   0.102733  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_7            0.727692   0.408609  0.252227                0.289231  0.358455  0.12849                   66                   0.066875  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_11  0.727179   0.759333  0.299522                0.284872  0.383881  0.147364                2645                   0.132849  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_8            0.725641   0.433043  0.28079                 0.295641  0.358929  0.12883                  131                   0.089563  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_10  0.721282   0.665981  0.341346                0.324872  0.434704  0.188967                5331                   0.139759  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_14  0.72       0.675661  0.337286                0.33      0.359504  0.129243                1856                   0.082228  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_22           0.719487   0.385287  0.276424                0.275385  0.342366  0.117214                  69                   0.067556  GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_7   0.718205   0.749389  0.35717                 0.257949  0.400645  0.160516                2744                   0.11812   DeepLearning\n",
       "GBM_4_AutoML_1_20230524_85722                         0.715641   0.394532  0.298985                0.281282  0.347308  0.120623                 164                   0.077411  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_20           0.71359    0.384883  0.245127                0.308205  0.344086  0.118395                  61                   0.100552  GBM\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_3            0.711795   0.385044  0.302615                0.333333  0.341844  0.116857                 112                   0.072263  GBM\n",
       "XRT_1_AutoML_1_20230524_85722                         0.711538   0.398451  0.268246                0.313333  0.347068  0.120456                 107                   0.092367  DRF\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_12  0.709487   0.916957  0.286277                0.323333  0.411415  0.169262                3527                   0.202031  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_5            0.709231   0.397116  0.255828                0.313077  0.349821  0.122375                 112                   0.073839  GBM\n",
       "DeepLearning_1_AutoML_1_20230524_85722                0.707949   0.566049  0.253395                0.335897  0.397394  0.157922                 101                   0.095452  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_6   0.706154   0.605361  0.32798                 0.320769  0.365197  0.133369                4077                   0.119695  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_10  0.698974   0.659814  0.390984                0.322564  0.391506  0.153277                4903                   0.180571  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230524_85722_model_18           0.695897   0.437023  0.276155                0.327436  0.354882  0.125941                 131                   0.115914  GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_18  0.690769   0.613497  0.374577                0.340769  0.375103  0.140702                3110                   0.088781  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_22  0.689744   0.71721   0.351706                0.277179  0.358253  0.128345                2609                   0.150519  DeepLearning\n",
       "GBM_2_AutoML_1_20230524_85722                         0.684103   0.416181  0.225593                0.358205  0.358297  0.128377                 126                   0.042361  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_13  0.683333   0.640924  0.283034                0.341538  0.371735  0.138187                3901                   0.172116  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_8   0.678462   0.635846  0.275963                0.366923  0.395044  0.15606                 5460                   0.369481  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_15  0.675385   1.6378    0.284622                0.34641   0.520244  0.270654                2722                   0.092243  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_9   0.673077   1.01995   0.218572                0.319744  0.441642  0.195047                2933                   0.081322  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_21  0.669231   0.830025  0.295992                0.356667  0.443183  0.196411                2636                   0.060905  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_23  0.668718   1.41541   0.255323                0.350513  0.468592  0.219579                2594                   0.059538  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_21  0.666154   0.666535  0.284685                0.340769  0.404423  0.163558                2731                   0.083045  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_20  0.657692   0.567925  0.314398                0.326667  0.356959  0.127419                2699                   0.079024  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_13  0.654103   1.05637   0.255971                0.361538  0.382364  0.146202                3733                   0.093792  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_22  0.653077   1.30272   0.200791                0.33359   0.464225  0.215505                2735                   0.199886  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_17  0.64       0.637143  0.398898                0.378718  0.346699  0.1202                  2628                   0.751002  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_13  0.622308   0.840956  0.237018                0.360513  0.438958  0.192685                2415                   0.589494  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_3   0.620769   0.81861   0.21137                 0.364103  0.410995  0.168917                2863                  36.2781    DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_4   0.614872   1.16054   0.24582                 0.347949  0.410871  0.168815                3194                   0.275344  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_9   0.591795   0.983963  0.285678                0.35      0.400895  0.160717                2777                   0.11525   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_6   0.580513   0.760781  0.188506                0.382564  0.379782  0.144234                4951                   0.30105   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_15  0.572821   0.746677  0.214842                0.373333  0.371236  0.137816                2545                   0.230366  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_15  0.57       0.972834  0.223291                0.408718  0.401614  0.161294                2705                   0.093188  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_18  0.569487   0.561799  0.204888                0.396923  0.372262  0.138579                2550                   0.088106  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230524_85722_model_18  0.568718   0.897296  0.238073                0.422051  0.386014  0.149007                2630                   0.202487  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230524_85722_model_17  0.504615   0.902361  0.160535                0.422051  0.420276  0.176632                2376                   0.103973  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_17  0.499231   0.877267  0.191124                0.458718  0.381507  0.145548                2457                   2.07925   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230524_85722_model_9   0.483077   0.605123  0.134492                0.463333  0.390951  0.152842                2139                   0.09187   DeepLearning\n",
       "[93 rows x 10 columns]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.automl import H2OAutoML, get_leaderboard\n",
    "\n",
    "# Import a sample binary outcome train/test set into H2O\n",
    "train1 = h2o.H2OFrame(train)\n",
    "\n",
    "# Identify predictors and response\n",
    "predictors = ['year', 'rating', 'numVotes',\n",
    "       'worldwide_box_office', 'action', 'adventure',\n",
    "       'animation', 'biography', 'comedy', 'crime', 'documentary', 'drama',\n",
    "       'family', 'fantasy', 'film-noir', 'history', 'horror', 'music',\n",
    "       'musical', 'mystery', 'romance', 'sci-fi', 'sport', 'thriller', 'war',\n",
    "       'western', 'nominations', 'nom_gg_drama',\n",
    "       'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga',\n",
    "       'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga',\n",
    "       'nom_sag', 'winner_sag', 'nom_cannes', 'winner_cannes','Acting',\n",
    "       'Production Design', 'Directing', 'VFX', 'Writing', 'Cinematography',\n",
    "       'Sound', 'Film Editing', 'Music']\n",
    "\n",
    "x = predictors\n",
    "y = 'Oscar_win'\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train1[y] = train1[y].asfactor()\n",
    "\n",
    "# Run AutoML for 100 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=100, seed=1\n",
    "                , keep_cross_validation_predictions= True\n",
    "               , exclude_algos = ['StackedEnsemble'])\n",
    "\n",
    "aml.train(x=x, y=y, training_frame=train1)\n",
    "\n",
    "# AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "\n",
    "# Optionally edd extra model information to the leaderboard\n",
    "lb = get_leaderboard(aml, extra_columns='ALL')\n",
    "\n",
    "# Print all rows (instead of default 10 rows)\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a sample binary outcome train/test set into H2O\n",
    "train1 = h2o.H2OFrame(train)\n",
    "\n",
    "# Identify predictors and response\n",
    "predictors = ['year', 'rating', 'numVotes',\n",
    "       'worldwide_box_office', 'action', 'adventure',\n",
    "       'animation', 'biography', 'comedy', 'crime', 'documentary', 'drama',\n",
    "       'family', 'fantasy', 'film-noir', 'history', 'horror', 'music',\n",
    "       'musical', 'mystery', 'romance', 'sci-fi', 'sport', 'thriller', 'war',\n",
    "       'western', 'nominations', 'nom_gg_drama',\n",
    "       'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga',\n",
    "       'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga',\n",
    "       'nom_sag', 'winner_sag', 'nom_cannes', 'winner_cannes']\n",
    "\n",
    "x = predictors\n",
    "y = 'Oscar_win'\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train1[y] = train1[y].asfactor()\n",
    "\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train1, test = train1.split_frame(ratios=[0.8])\n",
    "\n",
    "# Define the XGBoost estimator\n",
    "xgboost = H2OXGBoostEstimator()\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgboost.train(x=x, y=y, training_frame=train1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "performance = xgboost.model_performance(test_data=test)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_1_20230524_85722_model_5\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 15 002 weights/biases, 187,0 KB, 61 600 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>46</td>\n",
       "<td>Input</td>\n",
       "<td>10.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>100</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>40.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0240016</td>\n",
       "<td>0.0330112</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0086950</td>\n",
       "<td>0.1495203</td>\n",
       "<td>0.3626150</td>\n",
       "<td>0.0869916</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>100</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>40.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0412028</td>\n",
       "<td>0.1104845</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0231518</td>\n",
       "<td>0.1138108</td>\n",
       "<td>0.8343524</td>\n",
       "<td>0.0980829</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0117487</td>\n",
       "<td>0.0094979</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0413580</td>\n",
       "<td>0.5311203</td>\n",
       "<td>0.0047554</td>\n",
       "<td>0.0053207</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 1.811046872184211e-05\n",
       "RMSE: 0.0042556396372157865\n",
       "LogLoss: 0.0007151719579600746\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9929139937321374</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/150.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>26.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/26.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>150.0</td>\n",
       "<td>26.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/176.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999996</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999996</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999996</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999996</td>\n",
       "<td>25.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>150.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.9929140</td>\n",
       "<td>26.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999996</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999996</td>\n",
       "<td>0.9615385</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.9929140</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,77 %, avg score: 14,82 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0113636</td>\n",
       "<td>0.9999977</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999988</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999988</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.0769231</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.0769231</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.9999946</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999966</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999977</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.1538462</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.1538462</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0340909</td>\n",
       "<td>0.9999896</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999919</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999958</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.2307692</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.2307692</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.9999804</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999842</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999929</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.3076923</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.3076923</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0511364</td>\n",
       "<td>0.9999783</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999789</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999913</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.3461538</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.3461538</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1022727</td>\n",
       "<td>0.9996659</td>\n",
       "<td>6.7692308</td>\n",
       "<td>6.7692308</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998545</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999229</td>\n",
       "<td>0.3461538</td>\n",
       "<td>0.6923077</td>\n",
       "<td>576.9230769</td>\n",
       "<td>576.9230769</td>\n",
       "<td>0.6923077</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1534091</td>\n",
       "<td>0.0417790</td>\n",
       "<td>6.0170940</td>\n",
       "<td>6.5185185</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.8921820</td>\n",
       "<td>0.9629630</td>\n",
       "<td>0.9640093</td>\n",
       "<td>0.3076923</td>\n",
       "<td>1.0</td>\n",
       "<td>501.7094017</td>\n",
       "<td>551.8518519</td>\n",
       "<td>0.9933333</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.0011363</td>\n",
       "<td>0.0</td>\n",
       "<td>4.8888889</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0061911</td>\n",
       "<td>0.7222222</td>\n",
       "<td>0.7245547</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>388.8888889</td>\n",
       "<td>0.9333333</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3011364</td>\n",
       "<td>0.0000876</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3207547</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002847</td>\n",
       "<td>0.4905660</td>\n",
       "<td>0.4922417</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>232.0754717</td>\n",
       "<td>0.8200000</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4034091</td>\n",
       "<td>0.0000140</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4788732</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000406</td>\n",
       "<td>0.3661972</td>\n",
       "<td>0.3674583</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>147.8873239</td>\n",
       "<td>0.7</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0000037</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000076</td>\n",
       "<td>0.2954545</td>\n",
       "<td>0.2964735</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td>\n",
       "<td>0.5866667</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6022727</td>\n",
       "<td>0.0000009</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6603774</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000018</td>\n",
       "<td>0.2452830</td>\n",
       "<td>0.2461293</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.0377358</td>\n",
       "<td>0.4666667</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6988636</td>\n",
       "<td>0.0000002</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4308943</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.2113821</td>\n",
       "<td>0.2121115</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.0894309</td>\n",
       "<td>0.3533333</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8011364</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2482270</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.1843972</td>\n",
       "<td>0.1850334</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.8226950</td>\n",
       "<td>0.2333333</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8977273</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1139241</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1645570</td>\n",
       "<td>0.1651248</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.3924051</td>\n",
       "<td>0.12</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1477273</td>\n",
       "<td>0.1482370</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.138626542100689\n",
       "RMSE: 0.37232585473035446\n",
       "LogLoss: 0.6955626030444713\n",
       "Mean Per-Class Error: 0.248974358974359\n",
       "AUC: 0.8305128205128205\n",
       "AUCPR: 0.4482871529081092\n",
       "Gini: 0.661025641025641</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.07940738509974507</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>133.0</td>\n",
       "<td>17.0</td>\n",
       "<td>0.1133</td>\n",
       "<td> (17.0/150.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>10.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.3846</td>\n",
       "<td> (10.0/26.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>143.0</td>\n",
       "<td>33.0</td>\n",
       "<td>0.1534</td>\n",
       "<td> (27.0/176.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.0794074</td>\n",
       "<td>0.5423729</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0029275</td>\n",
       "<td>0.6686047</td>\n",
       "<td>67.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.0794074</td>\n",
       "<td>0.5063291</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9937201</td>\n",
       "<td>0.8636364</td>\n",
       "<td>7.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999841</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000017</td>\n",
       "<td>1.0</td>\n",
       "<td>147.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999841</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.0794074</td>\n",
       "<td>0.4564103</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0079099</td>\n",
       "<td>0.7466667</td>\n",
       "<td>57.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0029275</td>\n",
       "<td>0.7923077</td>\n",
       "<td>67.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999841</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999841</td>\n",
       "<td>25.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>150.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0000017</td>\n",
       "<td>26.0</td>\n",
       "<td>147.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999841</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999841</td>\n",
       "<td>0.9615385</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0000017</td>\n",
       "<td>1.0</td>\n",
       "<td>147.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,77 %, avg score: 11,76 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0113636</td>\n",
       "<td>0.9992442</td>\n",
       "<td>3.3846154</td>\n",
       "<td>3.3846154</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9999827</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9999827</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.0384615</td>\n",
       "<td>238.4615385</td>\n",
       "<td>238.4615385</td>\n",
       "<td>0.0317949</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.9963245</td>\n",
       "<td>3.3846154</td>\n",
       "<td>3.3846154</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9983397</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9991612</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.0769231</td>\n",
       "<td>238.4615385</td>\n",
       "<td>238.4615385</td>\n",
       "<td>0.0635897</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0340909</td>\n",
       "<td>0.9943115</td>\n",
       "<td>3.3846154</td>\n",
       "<td>3.3846154</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9947086</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9976770</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.1153846</td>\n",
       "<td>238.4615385</td>\n",
       "<td>238.4615385</td>\n",
       "<td>0.0953846</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.9937201</td>\n",
       "<td>6.7692308</td>\n",
       "<td>4.2307692</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9938094</td>\n",
       "<td>0.625</td>\n",
       "<td>0.9967101</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.1923077</td>\n",
       "<td>576.9230769</td>\n",
       "<td>323.0769231</td>\n",
       "<td>0.1723077</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0511364</td>\n",
       "<td>0.9763412</td>\n",
       "<td>0.0</td>\n",
       "<td>3.7606838</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9775552</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.9945818</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1923077</td>\n",
       "<td>-100.0</td>\n",
       "<td>276.0683761</td>\n",
       "<td>0.1656410</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1022727</td>\n",
       "<td>0.5301438</td>\n",
       "<td>2.2564103</td>\n",
       "<td>3.0085470</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.8899175</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.9422496</td>\n",
       "<td>0.1153846</td>\n",
       "<td>0.3076923</td>\n",
       "<td>125.6410256</td>\n",
       "<td>200.8547009</td>\n",
       "<td>0.2410256</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1534091</td>\n",
       "<td>0.1361475</td>\n",
       "<td>3.7606838</td>\n",
       "<td>3.2592593</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.2673719</td>\n",
       "<td>0.4814815</td>\n",
       "<td>0.7172904</td>\n",
       "<td>0.1923077</td>\n",
       "<td>0.5</td>\n",
       "<td>276.0683761</td>\n",
       "<td>225.9259259</td>\n",
       "<td>0.4066667</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.0516889</td>\n",
       "<td>2.2564103</td>\n",
       "<td>3.0085470</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.0889868</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.5602145</td>\n",
       "<td>0.1153846</td>\n",
       "<td>0.6153846</td>\n",
       "<td>125.6410256</td>\n",
       "<td>200.8547009</td>\n",
       "<td>0.4820513</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3011364</td>\n",
       "<td>0.0101030</td>\n",
       "<td>0.3981900</td>\n",
       "<td>2.1712627</td>\n",
       "<td>0.0588235</td>\n",
       "<td>0.0244045</td>\n",
       "<td>0.3207547</td>\n",
       "<td>0.3883509</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.6538462</td>\n",
       "<td>-60.1809955</td>\n",
       "<td>117.1262700</td>\n",
       "<td>0.4138462</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4034091</td>\n",
       "<td>0.0025541</td>\n",
       "<td>2.2564103</td>\n",
       "<td>2.1928494</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.0053476</td>\n",
       "<td>0.3239437</td>\n",
       "<td>0.2912515</td>\n",
       "<td>0.2307692</td>\n",
       "<td>0.8846154</td>\n",
       "<td>125.6410256</td>\n",
       "<td>119.2849404</td>\n",
       "<td>0.5646154</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0004614</td>\n",
       "<td>0.0</td>\n",
       "<td>1.7692308</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010518</td>\n",
       "<td>0.2613636</td>\n",
       "<td>0.2351902</td>\n",
       "<td>0.0</td>\n",
       "<td>0.8846154</td>\n",
       "<td>-100.0</td>\n",
       "<td>76.9230769</td>\n",
       "<td>0.4512821</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6022727</td>\n",
       "<td>0.0001360</td>\n",
       "<td>0.7521368</td>\n",
       "<td>1.5965167</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.0002748</td>\n",
       "<td>0.2358491</td>\n",
       "<td>0.1952989</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.9615385</td>\n",
       "<td>-24.7863248</td>\n",
       "<td>59.6516691</td>\n",
       "<td>0.4215385</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6988636</td>\n",
       "<td>0.0000380</td>\n",
       "<td>0.0</td>\n",
       "<td>1.3758599</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000686</td>\n",
       "<td>0.2032520</td>\n",
       "<td>0.1683158</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9615385</td>\n",
       "<td>-100.0</td>\n",
       "<td>37.5859912</td>\n",
       "<td>0.3082051</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8011364</td>\n",
       "<td>3.63e-06</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2002182</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000158</td>\n",
       "<td>0.1773050</td>\n",
       "<td>0.1468307</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9615385</td>\n",
       "<td>-100.0</td>\n",
       "<td>20.0218221</td>\n",
       "<td>0.1882051</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8977273</td>\n",
       "<td>6.15e-07</td>\n",
       "<td>0.3981900</td>\n",
       "<td>1.1139241</td>\n",
       "<td>0.0588235</td>\n",
       "<td>0.0000018</td>\n",
       "<td>0.1645570</td>\n",
       "<td>0.1310327</td>\n",
       "<td>0.0384615</td>\n",
       "<td>1.0</td>\n",
       "<td>-60.1809955</td>\n",
       "<td>11.3924051</td>\n",
       "<td>0.12</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000002</td>\n",
       "<td>0.1477273</td>\n",
       "<td>0.1176316</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.8179365</td>\n",
       "<td>0.1352280</td>\n",
       "<td>0.8611111</td>\n",
       "<td>0.6285715</td>\n",
       "<td>0.8285714</td>\n",
       "<td>0.7714286</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.8202349</td>\n",
       "<td>0.1284522</td>\n",
       "<td>0.8967742</td>\n",
       "<td>0.6724138</td>\n",
       "<td>0.7592593</td>\n",
       "<td>0.7727272</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.1820635</td>\n",
       "<td>0.1352280</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.3714286</td>\n",
       "<td>0.1714286</td>\n",
       "<td>0.2285714</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>6.4</td>\n",
       "<td>4.7222877</td>\n",
       "<td>5.0</td>\n",
       "<td>13.0</td>\n",
       "<td>6.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.5512977</td>\n",
       "<td>0.2959919</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.3378378</td>\n",
       "<td>0.625</td>\n",
       "<td>0.2380952</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.6012422</td>\n",
       "<td>0.2567396</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.4347826</td>\n",
       "<td>0.5714286</td>\n",
       "<td>0.3333333</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.7049922</td>\n",
       "<td>0.2042226</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.6097561</td>\n",
       "<td>0.5263158</td>\n",
       "<td>0.5555556</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>3.715</td>\n",
       "<td>3.5698214</td>\n",
       "<td>7.2</td>\n",
       "<td>0.0</td>\n",
       "<td>4.375</td>\n",
       "<td>0.0</td>\n",
       "<td>7.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.6949008</td>\n",
       "<td>0.3962450</td>\n",
       "<td>0.8113807</td>\n",
       "<td>0.9612369</td>\n",
       "<td>1.13753</td>\n",
       "<td>0.3410734</td>\n",
       "<td>0.2232830</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.2635015</td>\n",
       "<td>0.1992759</td>\n",
       "<td>0.1612903</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2424243</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.5655490</td>\n",
       "<td>0.2724567</td>\n",
       "<td>0.6475762</td>\n",
       "<td>0.3163644</td>\n",
       "<td>0.4745548</td>\n",
       "<td>0.3892495</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.8441752</td>\n",
       "<td>0.1288534</td>\n",
       "<td>0.9193549</td>\n",
       "<td>0.7097701</td>\n",
       "<td>0.712963</td>\n",
       "<td>0.8787879</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.1558248</td>\n",
       "<td>0.1288534</td>\n",
       "<td>0.0806452</td>\n",
       "<td>0.2902299</td>\n",
       "<td>0.2870370</td>\n",
       "<td>0.1212121</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1384705</td>\n",
       "<td>0.0635008</td>\n",
       "<td>0.1659251</td>\n",
       "<td>0.2009354</td>\n",
       "<td>0.1840445</td>\n",
       "<td>0.0602929</td>\n",
       "<td>0.0811549</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.5103099</td>\n",
       "<td>0.3483282</td>\n",
       "<td>0.562232</td>\n",
       "<td>0.2474944</td>\n",
       "<td>0.6306249</td>\n",
       "<td>0.1111981</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.5321569</td>\n",
       "<td>0.3181961</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2941177</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.2</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>-0.1255176</td>\n",
       "<td>0.3053708</td>\n",
       "<td>-0.3873475</td>\n",
       "<td>-0.414631</td>\n",
       "<td>-0.0437708</td>\n",
       "<td>-0.1190736</td>\n",
       "<td>0.3372348</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.8666667</td>\n",
       "<td>0.2173067</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3630049</td>\n",
       "<td>0.0915014</td>\n",
       "<td>0.4073390</td>\n",
       "<td>0.4482581</td>\n",
       "<td>0.4290041</td>\n",
       "<td>0.2455462</td>\n",
       "<td>0.2848770</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.8216836</td>\n",
       "<td>0.1600876</td>\n",
       "<td>0.8387096</td>\n",
       "<td>0.5862069</td>\n",
       "<td>0.9259259</td>\n",
       "<td>0.7575757</td>\n",
       "<td>1.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-10.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-10 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-10 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-10 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table th,\n",
       "#h2o-table-10 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2023-05-24 09:04:19</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-24 09:04:19</td>\n",
       "<td> 1 min 17.936 sec</td>\n",
       "<td>18333 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>1</td>\n",
       "<td>1760.0</td>\n",
       "<td>0.2598035</td>\n",
       "<td>0.2337768</td>\n",
       "<td>0.4638937</td>\n",
       "<td>0.9448718</td>\n",
       "<td>0.7749020</td>\n",
       "<td>6.7692308</td>\n",
       "<td>0.0795455</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-24 09:04:21</td>\n",
       "<td> 1 min 20.517 sec</td>\n",
       "<td>23149 obs/sec</td>\n",
       "<td>350.0</td>\n",
       "<td>35</td>\n",
       "<td>61600.0</td>\n",
       "<td>0.0042556</td>\n",
       "<td>0.0007152</td>\n",
       "<td>0.9998562</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.7692308</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-11.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-11 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-11 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-11 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table th,\n",
       "#h2o-table-11 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>Cinematography</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0287648</td></tr>\n",
       "<tr><td>Sound</td>\n",
       "<td>0.9666976</td>\n",
       "<td>0.9666976</td>\n",
       "<td>0.0278068</td></tr>\n",
       "<tr><td>Film Editing</td>\n",
       "<td>0.9421129</td>\n",
       "<td>0.9421129</td>\n",
       "<td>0.0270997</td></tr>\n",
       "<tr><td>fantasy</td>\n",
       "<td>0.8859197</td>\n",
       "<td>0.8859197</td>\n",
       "<td>0.0254833</td></tr>\n",
       "<tr><td>winner_dga</td>\n",
       "<td>0.8770376</td>\n",
       "<td>0.8770376</td>\n",
       "<td>0.0252278</td></tr>\n",
       "<tr><td>year</td>\n",
       "<td>0.8713606</td>\n",
       "<td>0.8713606</td>\n",
       "<td>0.0250645</td></tr>\n",
       "<tr><td>Writing</td>\n",
       "<td>0.8564401</td>\n",
       "<td>0.8564401</td>\n",
       "<td>0.0246353</td></tr>\n",
       "<tr><td>nom_gg_drama</td>\n",
       "<td>0.8487479</td>\n",
       "<td>0.8487479</td>\n",
       "<td>0.0244140</td></tr>\n",
       "<tr><td>animation</td>\n",
       "<td>0.8429738</td>\n",
       "<td>0.8429738</td>\n",
       "<td>0.0242479</td></tr>\n",
       "<tr><td>biography</td>\n",
       "<td>0.8374502</td>\n",
       "<td>0.8374502</td>\n",
       "<td>0.0240891</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>nom_pga</td>\n",
       "<td>0.6655245</td>\n",
       "<td>0.6655245</td>\n",
       "<td>0.0191437</td></tr>\n",
       "<tr><td>nom_sag</td>\n",
       "<td>0.6598480</td>\n",
       "<td>0.6598480</td>\n",
       "<td>0.0189804</td></tr>\n",
       "<tr><td>sci-fi</td>\n",
       "<td>0.6524937</td>\n",
       "<td>0.6524937</td>\n",
       "<td>0.0187688</td></tr>\n",
       "<tr><td>nom_bafta</td>\n",
       "<td>0.6417699</td>\n",
       "<td>0.6417699</td>\n",
       "<td>0.0184604</td></tr>\n",
       "<tr><td>crime</td>\n",
       "<td>0.6242755</td>\n",
       "<td>0.6242755</td>\n",
       "<td>0.0179571</td></tr>\n",
       "<tr><td>winner_pga</td>\n",
       "<td>0.6173485</td>\n",
       "<td>0.6173485</td>\n",
       "<td>0.0177579</td></tr>\n",
       "<tr><td>adventure</td>\n",
       "<td>0.5881366</td>\n",
       "<td>0.5881366</td>\n",
       "<td>0.0169176</td></tr>\n",
       "<tr><td>musical</td>\n",
       "<td>0.5724465</td>\n",
       "<td>0.5724465</td>\n",
       "<td>0.0164663</td></tr>\n",
       "<tr><td>nom_dga</td>\n",
       "<td>0.5532149</td>\n",
       "<td>0.5532149</td>\n",
       "<td>0.0159131</td></tr>\n",
       "<tr><td>winner_bafta</td>\n",
       "<td>0.5306445</td>\n",
       "<td>0.5306445</td>\n",
       "<td>0.0152639</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[46 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_1_20230524_85722_model_5\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 15 002 weights/biases, 187,0 KB, 61 600 training samples, mini-batch size 1\n",
       "    layer    units    type              dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight           weight_rms           mean_bias             bias_rms\n",
       "--  -------  -------  ----------------  ---------  ----  ----  --------------------  --------------------  ----------  --------------------  -------------------  --------------------  --------------------\n",
       "    1        46       Input             10.0\n",
       "    2        100      RectifierDropout  40.0       0.0   0.0   0.024001602752263273  0.033011242747306824  0.0         0.008695049894723406  0.14952033758163452  0.36261498813666504   0.0869915783405304\n",
       "    3        100      RectifierDropout  40.0       0.0   0.0   0.0412027502400917    0.11048451066017151   0.0         -0.02315176722473684  0.11381083726882935  0.8343523728225254    0.09808292984962463\n",
       "    4        2        Softmax                      0.0   0.0   0.011748650879599153  0.009497851133346558  0.0         -0.04135797238530358  0.5311203002929688   0.004755425862202034  0.005320673808455467\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 1.811046872184211e-05\n",
       "RMSE: 0.0042556396372157865\n",
       "LogLoss: 0.0007151719579600746\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9929139937321374\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      150  0    0        (0.0/150.0)\n",
       "1      0    26   0        (0.0/26.0)\n",
       "Total  150  26   0        (0.0/176.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.992914     1         25\n",
       "max f2                       0.992914     1         25\n",
       "max f0point5                 0.992914     1         25\n",
       "max accuracy                 0.992914     1         25\n",
       "max precision                1            1         0\n",
       "max recall                   0.992914     1         25\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.992914     1         25\n",
       "max min_per_class_accuracy   0.992914     1         25\n",
       "max mean_per_class_accuracy  0.992914     1         25\n",
       "max tns                      1            150       0\n",
       "max fns                      1            25        0\n",
       "max fps                      4.66436e-18  150       175\n",
       "max tps                      0.992914     26        25\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.961538  0\n",
       "max fpr                      4.66436e-18  1         175\n",
       "max tpr                      0.992914     1         25\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,77 %, avg score: 14,82 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0113636                   0.999998           6.76923  6.76923            1                0.999999     1                           0.999999            0.0769231       0.0769231                  576.923  576.923            0.0769231\n",
       "2        0.0227273                   0.999995           6.76923  6.76923            1                0.999997     1                           0.999998            0.0769231       0.153846                   576.923  576.923            0.153846\n",
       "3        0.0340909                   0.99999            6.76923  6.76923            1                0.999992     1                           0.999996            0.0769231       0.230769                   576.923  576.923            0.230769\n",
       "4        0.0454545                   0.99998            6.76923  6.76923            1                0.999984     1                           0.999993            0.0769231       0.307692                   576.923  576.923            0.307692\n",
       "5        0.0511364                   0.999978           6.76923  6.76923            1                0.999979     1                           0.999991            0.0384615       0.346154                   576.923  576.923            0.346154\n",
       "6        0.102273                    0.999666           6.76923  6.76923            1                0.999854     1                           0.999923            0.346154        0.692308                   576.923  576.923            0.692308\n",
       "7        0.153409                    0.041779           6.01709  6.51852            0.888889         0.892182     0.962963                    0.964009            0.307692        1                          501.709  551.852            0.993333\n",
       "8        0.204545                    0.00113631         0        4.88889            0                0.00619106   0.722222                    0.724555            0               1                          -100     388.889            0.933333\n",
       "9        0.301136                    8.75713e-05        0        3.32075            0                0.000284727  0.490566                    0.492242            0               1                          -100     232.075            0.82\n",
       "10       0.403409                    1.4011e-05         0        2.47887            0                4.05564e-05  0.366197                    0.367458            0               1                          -100     147.887            0.7\n",
       "11       0.5                         3.73337e-06        0        2                  0                7.64592e-06  0.295455                    0.296474            0               1                          -100     100                0.586667\n",
       "12       0.602273                    9.25663e-07        0        1.66038            0                1.77168e-06  0.245283                    0.246129            0               1                          -100     66.0377            0.466667\n",
       "13       0.698864                    1.8219e-07         0        1.43089            0                4.7178e-07   0.211382                    0.212111            0               1                          -100     43.0894            0.353333\n",
       "14       0.801136                    3.32252e-09        0        1.24823            0                6.22435e-08  0.184397                    0.185033            0               1                          -100     24.8227            0.233333\n",
       "15       0.897727                    4.50653e-11        0        1.11392            0                9.49407e-10  0.164557                    0.165125            0               1                          -100     11.3924            0.12\n",
       "16       1                           4.66436e-18        0        1                  0                5.87157e-12  0.147727                    0.148237            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.138626542100689\n",
       "RMSE: 0.37232585473035446\n",
       "LogLoss: 0.6955626030444713\n",
       "Mean Per-Class Error: 0.248974358974359\n",
       "AUC: 0.8305128205128205\n",
       "AUCPR: 0.4482871529081092\n",
       "Gini: 0.661025641025641\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.07940738509974507\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      133  17   0.1133   (17.0/150.0)\n",
       "1      10   16   0.3846   (10.0/26.0)\n",
       "Total  143  33   0.1534   (27.0/176.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.0794074    0.542373  32\n",
       "max f2                       0.00292745   0.668605  67\n",
       "max f0point5                 0.0794074    0.506329  32\n",
       "max accuracy                 0.99372      0.863636  7\n",
       "max precision                0.999984     1         0\n",
       "max recall                   1.67547e-06  1         147\n",
       "max specificity              0.999984     1         0\n",
       "max absolute_mcc             0.0794074    0.45641   32\n",
       "max min_per_class_accuracy   0.00790987   0.746667  57\n",
       "max mean_per_class_accuracy  0.00292745   0.792308  67\n",
       "max tns                      0.999984     150       0\n",
       "max fns                      0.999984     25        0\n",
       "max fps                      1.11845e-09  150       175\n",
       "max tps                      1.67547e-06  26        147\n",
       "max tnr                      0.999984     1         0\n",
       "max fnr                      0.999984     0.961538  0\n",
       "max fpr                      1.11845e-09  1         175\n",
       "max tpr                      1.67547e-06  1         147\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,77 %, avg score: 11,76 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0113636                   0.999244           3.38462   3.38462            0.5              0.999983     0.5                         0.999983            0.0384615       0.0384615                  238.462   238.462            0.0317949\n",
       "2        0.0227273                   0.996324           3.38462   3.38462            0.5              0.99834      0.5                         0.999161            0.0384615       0.0769231                  238.462   238.462            0.0635897\n",
       "3        0.0340909                   0.994311           3.38462   3.38462            0.5              0.994709     0.5                         0.997677            0.0384615       0.115385                   238.462   238.462            0.0953846\n",
       "4        0.0454545                   0.99372            6.76923   4.23077            1                0.993809     0.625                       0.99671             0.0769231       0.192308                   576.923   323.077            0.172308\n",
       "5        0.0511364                   0.976341           0         3.76068            0                0.977555     0.555556                    0.994582            0               0.192308                   -100      276.068            0.165641\n",
       "6        0.102273                    0.530144           2.25641   3.00855            0.333333         0.889917     0.444444                    0.94225             0.115385        0.307692                   125.641   200.855            0.241026\n",
       "7        0.153409                    0.136148           3.76068   3.25926            0.555556         0.267372     0.481481                    0.71729             0.192308        0.5                        276.068   225.926            0.406667\n",
       "8        0.204545                    0.0516889          2.25641   3.00855            0.333333         0.0889868    0.444444                    0.560214            0.115385        0.615385                   125.641   200.855            0.482051\n",
       "9        0.301136                    0.010103           0.39819   2.17126            0.0588235        0.0244045    0.320755                    0.388351            0.0384615       0.653846                   -60.181   117.126            0.413846\n",
       "10       0.403409                    0.00255415         2.25641   2.19285            0.333333         0.00534765   0.323944                    0.291251            0.230769        0.884615                   125.641   119.285            0.564615\n",
       "11       0.5                         0.00046136         0         1.76923            0                0.00105179   0.261364                    0.23519             0               0.884615                   -100      76.9231            0.451282\n",
       "12       0.602273                    0.00013598         0.752137  1.59652            0.111111         0.000274824  0.235849                    0.195299            0.0769231       0.961538                   -24.7863  59.6517            0.421538\n",
       "13       0.698864                    3.802e-05          0         1.37586            0                6.85518e-05  0.203252                    0.168316            0               0.961538                   -100      37.586             0.308205\n",
       "14       0.801136                    3.63e-06           0         1.20022            0                1.58306e-05  0.177305                    0.146831            0               0.961538                   -100      20.0218            0.188205\n",
       "15       0.897727                    6.15e-07           0.39819   1.11392            0.0588235        1.76706e-06  0.164557                    0.131033            0.0384615       1                          -60.181   11.3924            0.12\n",
       "16       1                           0                  0         1                  0                1.96111e-07  0.147727                    0.117632            0               1                          -100      0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean       sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.817936   0.135228   0.861111      0.628571      0.828571      0.771429      1\n",
       "auc                      0.820235   0.128452   0.896774      0.672414      0.759259      0.772727      1\n",
       "err                      0.182063   0.135228   0.138889      0.371429      0.171429      0.228571      0\n",
       "err_count                6.4        4.72229    5             13            6             8             0\n",
       "f0point5                 0.551298   0.295992   0.555556      0.337838      0.625         0.238095      1\n",
       "f1                       0.601242   0.25674    0.666667      0.434783      0.571429      0.333333      1\n",
       "f2                       0.704992   0.204223   0.833333      0.609756      0.526316      0.555556      1\n",
       "lift_top_group           3.715      3.56982    7.2           0             4.375         0             7\n",
       "logloss                  0.694901   0.396245   0.811381      0.961237      1.13753       0.341073      0.223283\n",
       "max_per_class_error      0.263502   0.199276   0.16129       0.413793      0.5           0.242424      0\n",
       "mcc                      0.565549   0.272457   0.647576      0.316364      0.474555      0.389249      1\n",
       "mean_per_class_accuracy  0.844175   0.128853   0.919355      0.70977       0.712963      0.878788      1\n",
       "mean_per_class_error     0.155825   0.128853   0.0806452     0.29023       0.287037      0.121212      0\n",
       "mse                      0.138471   0.0635008  0.165925      0.200935      0.184044      0.0602929     0.0811549\n",
       "pr_auc                   0.51031    0.348328   0.562232      0.247494      0.630625      0.111198      1\n",
       "precision                0.532157   0.318196   0.5           0.294118      0.666667      0.2           1\n",
       "r2                       -0.125518  0.305371   -0.387348     -0.414631     -0.0437708    -0.119074     0.337235\n",
       "recall                   0.866667   0.217307   1             0.833333      0.5           1             1\n",
       "rmse                     0.363005   0.0915014  0.407339      0.448258      0.429004      0.245546      0.284877\n",
       "specificity              0.821684   0.160088   0.83871       0.586207      0.925926      0.757576      1\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2023-05-24 09:04:19  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan\n",
       "    2023-05-24 09:04:19  1 min 17.936 sec  18333 obs/sec     10        1             1760       0.259804         0.233777            0.463894       0.944872        0.774902           6.76923          0.0795455\n",
       "    2023-05-24 09:04:21  1 min 20.517 sec  23149 obs/sec     350       35            61600      0.00425564       0.000715172         0.999856       1               1                  6.76923          0\n",
       "\n",
       "Variable Importances: \n",
       "variable        relative_importance    scaled_importance    percentage\n",
       "--------------  ---------------------  -------------------  --------------------\n",
       "Cinematography  1.0                    1.0                  0.028764766737907455\n",
       "Sound           0.9666975736618042     0.9666975736618042   0.027806830212482907\n",
       "Film Editing    0.9421128630638123     0.9421128630638123   0.02709965674681271\n",
       "fantasy         0.8859196901321411     0.8859196901321411   0.02548327323517029\n",
       "winner_dga      0.8770375847816467     0.8770375847816467   0.0252277815466218\n",
       "year            0.8713605999946594     0.8713605999946594   0.025064484403449463\n",
       "Writing         0.8564401268959045     0.8564401268959045   0.024635300475144555\n",
       "nom_gg_drama    0.8487479090690613     0.8487479090690613   0.024414035623658233\n",
       "animation       0.8429737687110901     0.8429737687110901   0.024247943823149255\n",
       "biography       0.8374502062797546     0.8374502062797546   0.024089059838249622\n",
       "---             ---                    ---                  ---\n",
       "nom_pga         0.6655244827270508     0.6655244827270508   0.019143656504010134\n",
       "nom_sag         0.6598480343818665     0.6598480343818665   0.018980374791461127\n",
       "sci-fi          0.6524936556816101     0.6524936556816101   0.018768827803646016\n",
       "nom_bafta       0.6417699456214905     0.6417699456214905   0.018460362785201724\n",
       "crime           0.6242755055427551     0.6242755055427551   0.017957139297126605\n",
       "winner_pga      0.6173484921455383     0.6173484921455383   0.017757885372565303\n",
       "adventure       0.588136613368988      0.588136613368988    0.016917612493581802\n",
       "musical         0.5724464654922485     0.5724464654922485   0.01646628904982412\n",
       "nom_dga         0.5532149076461792     0.5532149076461792   0.01591309777437536\n",
       "winner_bafta    0.5306445360183716     0.5306445360183716   0.015263866299313589\n",
       "[46 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model = aml.leader\n",
    "top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "H2OResponseError",
     "evalue": "Server error water.exceptions.H2OIllegalArgumentException:\n  Error: Illegal argument: dir of function: importModel: water.api.FSIOException: FS IO Failure: \n accessed path : file:/c:/Users/Aleksandra%20Czaplak/Desktop/oscars_ml/oscar_predictions/additional_data/./additional_data/model/DeepLearning_grid_2_AutoML_6_20230519_91906_model_4 msg: File not found\n  Request: POST /99/Models.bin/\n    data: {'dir': './additional_data/model/DeepLearning_grid_2_AutoML_6_20230519_91906_model_4'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mH2OResponseError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Aleksandra Czaplak\\Desktop\\oscars_ml\\oscar_predictions\\additional_data\\ml.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Aleksandra%20Czaplak/Desktop/oscars_ml/oscar_predictions/additional_data/ml.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m h2o\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39m./additional_data/model/DeepLearning_grid_2_AutoML_6_20230519_91906_model_4\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\h2o\\h2o.py:1581\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m   1558\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[39mLoad a saved H2O model from disk. (Note that ensemble binary models can now be loaded using this method.)\u001b[39;00m\n\u001b[0;32m   1560\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1578\u001b[0m \u001b[39m>>> h2o.load_model(model)\u001b[39;00m\n\u001b[0;32m   1579\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1580\u001b[0m assert_is_type(path, \u001b[39mstr\u001b[39m)\n\u001b[1;32m-> 1581\u001b[0m res \u001b[39m=\u001b[39m api(\u001b[39m\"\u001b[39;49m\u001b[39mPOST /99/Models.bin/\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m, data\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mdir\u001b[39;49m\u001b[39m\"\u001b[39;49m: path})\n\u001b[0;32m   1582\u001b[0m \u001b[39mreturn\u001b[39;00m get_model(res[\u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmodel_id\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\h2o\\h2o.py:124\u001b[0m, in \u001b[0;36mapi\u001b[1;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m# type checks are performed in H2OConnection class\u001b[39;00m\n\u001b[0;32m    123\u001b[0m _check_connection()\n\u001b[1;32m--> 124\u001b[0m \u001b[39mreturn\u001b[39;00m h2oconn\u001b[39m.\u001b[39;49mrequest(endpoint, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, filename\u001b[39m=\u001b[39;49mfilename, save_to\u001b[39m=\u001b[39;49msave_to)\n",
      "File \u001b[1;32mc:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\h2o\\backend\\connection.py:499\u001b[0m, in \u001b[0;36mH2OConnection.request\u001b[1;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[0;32m    497\u001b[0m         save_to \u001b[39m=\u001b[39m save_to(resp)\n\u001b[0;32m    498\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_end_transaction(start_time, resp)\n\u001b[1;32m--> 499\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_response(resp, save_to)\n\u001b[0;32m    501\u001b[0m \u001b[39mexcept\u001b[39;00m (requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mConnectionError, requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mHTTPError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    502\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_server \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_server\u001b[39m.\u001b[39mis_running():\n",
      "File \u001b[1;32mc:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\h2o\\backend\\connection.py:853\u001b[0m, in \u001b[0;36mH2OConnection._process_response\u001b[1;34m(response, save_to)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39mif\u001b[39;00m status_code \u001b[39min\u001b[39;00m {\u001b[39m400\u001b[39m, \u001b[39m404\u001b[39m, \u001b[39m412\u001b[39m} \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(data, H2OErrorV3):\n\u001b[0;32m    852\u001b[0m     data\u001b[39m.\u001b[39mshow_stacktrace \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 853\u001b[0m     \u001b[39mraise\u001b[39;00m H2OResponseError(data)\n\u001b[0;32m    855\u001b[0m \u001b[39m# Server errors (notably 500 = \"Server Error\")\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39m# Note that it is possible to receive valid H2OErrorV3 object in this case, however it merely means the server\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[39m# did not provide the correct status code.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39mraise\u001b[39;00m H2OServerError(\u001b[39m\"\u001b[39m\u001b[39mHTTP \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (status_code, response\u001b[39m.\u001b[39mreason, data))\n",
      "\u001b[1;31mH2OResponseError\u001b[0m: Server error water.exceptions.H2OIllegalArgumentException:\n  Error: Illegal argument: dir of function: importModel: water.api.FSIOException: FS IO Failure: \n accessed path : file:/c:/Users/Aleksandra%20Czaplak/Desktop/oscars_ml/oscar_predictions/additional_data/./additional_data/model/DeepLearning_grid_2_AutoML_6_20230519_91906_model_4 msg: File not found\n  Request: POST /99/Models.bin/\n    data: {'dir': './additional_data/model/DeepLearning_grid_2_AutoML_6_20230519_91906_model_4'}\n"
     ]
    }
   ],
   "source": [
    "model = h2o.load_model('./additional_data/model/DeepLearning_grid_2_AutoML_6_20230519_91906_model_4')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Predict on 2019's films\n",
    "test = full_table.loc[(full_table['year'] == 2021)]\n",
    "\n",
    "# Import a binary outcome train/test set into H2O\n",
    "test = h2o.H2OFrame(test)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">        p0</th><th style=\"text-align: right;\">         p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999976  </td><td style=\"text-align: right;\">2.37118e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.00165605</td><td style=\"text-align: right;\">0.998344   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.995174  </td><td style=\"text-align: right;\">0.00482619 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1         </td><td style=\"text-align: right;\">1.74511e-07</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.995249  </td><td style=\"text-align: right;\">0.00475117 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999972  </td><td style=\"text-align: right;\">2.78123e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999979  </td><td style=\"text-align: right;\">2.0885e-05 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1         </td><td style=\"text-align: right;\">9.07248e-09</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999955  </td><td style=\"text-align: right;\">4.5392e-05 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999999  </td><td style=\"text-align: right;\">1.10776e-06</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 3 columns]</pre>"
      ],
      "text/plain": [
       "  predict          p0           p1\n",
       "---------  ----------  -----------\n",
       "        0  0.999976    2.37118e-05\n",
       "        1  0.00165605  0.998344\n",
       "        0  0.995174    0.00482619\n",
       "        0  1           1.74511e-07\n",
       "        0  0.995249    0.00475117\n",
       "        0  0.999972    2.78123e-05\n",
       "        0  0.999979    2.0885e-05\n",
       "        0  1           9.07248e-09\n",
       "        0  0.999955    4.5392e-05\n",
       "        0  0.999999    1.10776e-06\n",
       "[10 rows x 3 columns]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = top_model.predict(test)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred'] = preds['predict']\n",
    "test['probA'] = preds['p1']\n",
    "test_pd = test.as_data_frame(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>probA</th>\n",
       "      <th>%_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CODA</td>\n",
       "      <td>9.983440e-01</td>\n",
       "      <td>9.903809e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Belfast</td>\n",
       "      <td>4.826187e-03</td>\n",
       "      <td>4.787692e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drive My Car</td>\n",
       "      <td>4.751175e-03</td>\n",
       "      <td>4.713278e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nightmare Alley</td>\n",
       "      <td>4.539204e-05</td>\n",
       "      <td>4.502998e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dune</td>\n",
       "      <td>2.781235e-05</td>\n",
       "      <td>2.759051e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West Side Story</td>\n",
       "      <td>2.371181e-05</td>\n",
       "      <td>2.352268e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>King Richard</td>\n",
       "      <td>2.088495e-05</td>\n",
       "      <td>2.071837e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Power of the Dog</td>\n",
       "      <td>1.107759e-06</td>\n",
       "      <td>1.098923e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Don't Look Up</td>\n",
       "      <td>1.745112e-07</td>\n",
       "      <td>1.731192e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Licorice Pizza</td>\n",
       "      <td>9.072485e-09</td>\n",
       "      <td>9.000120e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    film         probA  %_confidence\n",
       "1                  CODA   9.983440e-01  9.903809e+01\n",
       "2               Belfast   4.826187e-03  4.787692e-01\n",
       "4          Drive My Car   4.751175e-03  4.713278e-01\n",
       "8       Nightmare Alley   4.539204e-05  4.502998e-03\n",
       "5                  Dune   2.781235e-05  2.759051e-03\n",
       "0       West Side Story   2.371181e-05  2.352268e-03\n",
       "6          King Richard   2.088495e-05  2.071837e-03\n",
       "9  The Power of the Dog   1.107759e-06  1.098923e-04\n",
       "3          Don't Look Up  1.745112e-07  1.731192e-05\n",
       "7         Licorice Pizza  9.072485e-09  9.000120e-07"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rankings = test_pd[['film','probA']].sort_values('probA', ascending = False)\n",
    "final_rankings['%_confidence'] = final_rankings['probA']/final_rankings['probA'].sum() * 100\n",
    "final_rankings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And the Oscar goes to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_winner = np.array(final_rankings.reset_index())[0][1].split('(')[0].strip()\n",
    "print(f'And the Oscar goes to...\\n🎉🏆{bp_winner}🏆🎉')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
