{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-Oscar Prediction with AutoML\n",
    "After out dataframe has been assemlbed (see scraping and table_assembling) notebooks we have the data we need to make predictions on the Best Picture winner. [AutoML](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html) represents a quick, but powerful route though the Machine Learning process. H2O's AutoML runs many models through the dataset and using cross-validation, picks the best one. For my purposes I use it to confirm/compare to the Preferential Balloting Random Forest model I created.\n",
    "If you are gunning to win your office's Oscar pool, scroll down to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h2o"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Using h2o Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>film</th>\n",
       "      <th>wiki</th>\n",
       "      <th>winner</th>\n",
       "      <th>rating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>worldwide_box_office</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_pga</th>\n",
       "      <th>winner_pga</th>\n",
       "      <th>nom_bafta</th>\n",
       "      <th>winner_bafta</th>\n",
       "      <th>nom_dga</th>\n",
       "      <th>winner_dga</th>\n",
       "      <th>nom_sag</th>\n",
       "      <th>winner_sag</th>\n",
       "      <th>nom_cannes</th>\n",
       "      <th>winner_cannes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1927</td>\n",
       "      <td>Wings</td>\n",
       "      <td>/wiki/Wings_(1927_film)</td>\n",
       "      <td>True</td>\n",
       "      <td>7.3</td>\n",
       "      <td>13576.0</td>\n",
       "      <td>$746</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1927</td>\n",
       "      <td>7th Heaven</td>\n",
       "      <td>/wiki/7th_Heaven_(1927_film)</td>\n",
       "      <td>False</td>\n",
       "      <td>5.2</td>\n",
       "      <td>26223.0</td>\n",
       "      <td>$79,808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1927</td>\n",
       "      <td>The Racket</td>\n",
       "      <td>/wiki/The_Racket_(1928_film)</td>\n",
       "      <td>False</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3149.0</td>\n",
       "      <td>$21,733,230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1928</td>\n",
       "      <td>The Broadway Melody</td>\n",
       "      <td>/wiki/The_Broadway_Melody</td>\n",
       "      <td>True</td>\n",
       "      <td>5.6</td>\n",
       "      <td>7605.0</td>\n",
       "      <td>$223,723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1928</td>\n",
       "      <td>Alibi</td>\n",
       "      <td>/wiki/Alibi_(1929_film)</td>\n",
       "      <td>False</td>\n",
       "      <td>7.4</td>\n",
       "      <td>391.0</td>\n",
       "      <td>$42,915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2022</td>\n",
       "      <td>The Fabelmans</td>\n",
       "      <td>/wiki/The_Fabelmans</td>\n",
       "      <td>False</td>\n",
       "      <td>7.6</td>\n",
       "      <td>85709.0</td>\n",
       "      <td>$45,164,110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2022</td>\n",
       "      <td>Tár</td>\n",
       "      <td>/wiki/T%C3%A1r</td>\n",
       "      <td>False</td>\n",
       "      <td>7.5</td>\n",
       "      <td>69684.0</td>\n",
       "      <td>$27,541,681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>2022</td>\n",
       "      <td>Top Gun: Maverick</td>\n",
       "      <td>/wiki/Top_Gun:_Maverick</td>\n",
       "      <td>False</td>\n",
       "      <td>8.3</td>\n",
       "      <td>577408.0</td>\n",
       "      <td>$1,493,491,858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>2022</td>\n",
       "      <td>Triangle of Sadness</td>\n",
       "      <td>/wiki/Triangle_of_Sadness</td>\n",
       "      <td>False</td>\n",
       "      <td>7.3</td>\n",
       "      <td>128812.0</td>\n",
       "      <td>$25,615,870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>2022</td>\n",
       "      <td>Women Talking</td>\n",
       "      <td>/wiki/Women_Talking_(film)</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>29341.0</td>\n",
       "      <td>$8,954,708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year                 film                          wiki  winner  rating  \\\n",
       "0    1927               Wings        /wiki/Wings_(1927_film)    True     7.3   \n",
       "1    1927          7th Heaven   /wiki/7th_Heaven_(1927_film)   False     5.2   \n",
       "2    1927          The Racket   /wiki/The_Racket_(1928_film)   False     6.7   \n",
       "3    1928  The Broadway Melody     /wiki/The_Broadway_Melody    True     5.6   \n",
       "4    1928               Alibi        /wiki/Alibi_(1929_film)   False     7.4   \n",
       "..    ...                  ...                           ...     ...     ...   \n",
       "546  2022        The Fabelmans           /wiki/The_Fabelmans   False     7.6   \n",
       "547  2022                  Tár                /wiki/T%C3%A1r   False     7.5   \n",
       "548  2022    Top Gun: Maverick       /wiki/Top_Gun:_Maverick   False     8.3   \n",
       "549  2022  Triangle of Sadness     /wiki/Triangle_of_Sadness   False     7.3   \n",
       "550  2022       Women Talking     /wiki/Women_Talking_(film)   False     6.9   \n",
       "\n",
       "     numVotes worldwide_box_office  Action  Adventure  Animation  ...  \\\n",
       "0     13576.0                 $746       0          0          0  ...   \n",
       "1     26223.0              $79,808       0          0          0  ...   \n",
       "2      3149.0          $21,733,230       0          0          0  ...   \n",
       "3      7605.0             $223,723       0          0          0  ...   \n",
       "4       391.0              $42,915       0          0          0  ...   \n",
       "..        ...                  ...     ...        ...        ...  ...   \n",
       "546   85709.0          $45,164,110       0          0          0  ...   \n",
       "547   69684.0          $27,541,681       0          0          0  ...   \n",
       "548  577408.0       $1,493,491,858       0          0          0  ...   \n",
       "549  128812.0          $25,615,870       0          0          0  ...   \n",
       "550   29341.0           $8,954,708       0          0          0  ...   \n",
       "\n",
       "     nom_pga  winner_pga  nom_bafta  winner_bafta  nom_dga  winner_dga  \\\n",
       "0          0           0          0             0        0           0   \n",
       "1          0           0          0             0        0           0   \n",
       "2          0           0          0             0        0           0   \n",
       "3          0           0          0             0        0           0   \n",
       "4          0           0          0             0        0           0   \n",
       "..       ...         ...        ...           ...      ...         ...   \n",
       "546        1           0          0             0        1           0   \n",
       "547        1           0          1             0        1           0   \n",
       "548        1           0          0             0        1           0   \n",
       "549        0           0          0             0        0           0   \n",
       "550        0           0          0             0        0           0   \n",
       "\n",
       "     nom_sag  winner_sag  nom_cannes  winner_cannes  \n",
       "0          0           0           0              0  \n",
       "1          0           0           0              0  \n",
       "2          0           0           0              0  \n",
       "3          0           0           0              0  \n",
       "4          0           0           0              0  \n",
       "..       ...         ...         ...            ...  \n",
       "546        1           0           0              0  \n",
       "547        0           0           0              0  \n",
       "548        0           0           0              0  \n",
       "549        0           0           1              1  \n",
       "550        0           0           0              0  \n",
       "\n",
       "[551 rows x 72 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_table = pd.read_csv('../data/processed_results/extended_df.csv')\n",
    "full_table=full_table.drop('Unnamed: 0', axis=1)\n",
    "full_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.371-b11, mixed mode)\n",
      "  Starting server from C:\\Users\\aczaplak.MPD1\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\ACZAPL~1.MPD\\AppData\\Local\\Temp\\tmp11dqmq52\n",
      "  JVM stdout: C:\\Users\\ACZAPL~1.MPD\\AppData\\Local\\Temp\\tmp11dqmq52\\h2o_aczaplak_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\ACZAPL~1.MPD\\AppData\\Local\\Temp\\tmp11dqmq52\\h2o_aczaplak_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>08 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Belgrade</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>19 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_aczaplak_wkb9zy</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.752 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.9 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -------------------------------\n",
       "H2O_cluster_uptime:         08 secs\n",
       "H2O_cluster_timezone:       Europe/Belgrade\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    19 days\n",
       "H2O_cluster_name:           H2O_from_python_aczaplak_wkb9zy\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.752 Gb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.9 final\n",
       "--------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Year of Existance. This data will be used below\n",
    "- golden_globes 1943\n",
    "- pga 1989\n",
    "- bafta 1960\n",
    "- dga 1948\n",
    "- sag 1995\n",
    "- cannes 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I pick a min_year where the awards shows will be relevant\n",
    "min_year = 1995"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O's Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set contains: 184 movies\n"
     ]
    }
   ],
   "source": [
    "# Auto ML uses Cross Validation, so we do not specifiy a validation set\n",
    "train = full_table.loc[((full_table['year'] < 2022) & (full_table['year'] >= min_year))]\n",
    "\n",
    "print('training set contains:', train.shape[0], 'movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'film', 'wiki', 'winner', 'rating', 'numVotes',\n",
       "       'worldwide_box_office', 'Action', 'Adventure', 'Animation', 'Biography',\n",
       "       'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy',\n",
       "       'Film-Noir', 'Game-Show', 'History', 'Horror', 'Music', 'Musical',\n",
       "       'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
       "       'Talk-Show', 'Thriller', 'War', 'Western', 'action', 'adventure',\n",
       "       'animation', 'biography', 'comedy', 'crime', 'documentary', 'drama',\n",
       "       'family', 'fantasy', 'film-noir', 'history', 'horror', 'music',\n",
       "       'musical', 'mystery', 'romance', 'sci-fi', 'sport', 'thriller', 'war',\n",
       "       'western', 'nominations', 'Oscar_win', 'nom_gg_drama',\n",
       "       'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga',\n",
       "       'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga',\n",
       "       'nom_sag', 'winner_sag', 'nom_cannes', 'winner_cannes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train = train.drop(['index', '[]'], axis=1)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:08:32.296: AutoML: XGBoost is not available; skipping it.\n",
      "16:08:32.571: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n",
      "███\n",
      "16:08:34.435: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "16:08:34.435: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 184.0.\n",
      "16:08:34.444: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "16:08:36.827: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n",
      "██\n",
      "16:08:38.310: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n",
      "██\n",
      "16:08:39.426: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "16:08:40.559: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n",
      "██\n",
      "16:08:41.447: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n",
      "██\n",
      "16:08:42.610: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n",
      "████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      "16:38:22.981: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                             </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">    aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th><th style=\"text-align: right;\">  training_time_ms</th><th style=\"text-align: right;\">  predict_time_per_row_ms</th><th>algo        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_4 </td><td style=\"text-align: right;\">0.727766</td><td style=\"text-align: right;\"> 0.680794</td><td style=\"text-align: right;\">0.29176  </td><td style=\"text-align: right;\">              0.292876</td><td style=\"text-align: right;\">0.395659</td><td style=\"text-align: right;\">0.156546</td><td style=\"text-align: right;\">              5261</td><td style=\"text-align: right;\">                 0.129583</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_1 </td><td style=\"text-align: right;\">0.707714</td><td style=\"text-align: right;\"> 0.717919</td><td style=\"text-align: right;\">0.407089 </td><td style=\"text-align: right;\">              0.361996</td><td style=\"text-align: right;\">0.370955</td><td style=\"text-align: right;\">0.137608</td><td style=\"text-align: right;\">             10546</td><td style=\"text-align: right;\">                 0.102322</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_23</td><td style=\"text-align: right;\">0.687662</td><td style=\"text-align: right;\"> 1.00964 </td><td style=\"text-align: right;\">0.257296 </td><td style=\"text-align: right;\">              0.306558</td><td style=\"text-align: right;\">0.491412</td><td style=\"text-align: right;\">0.241486</td><td style=\"text-align: right;\">              3660</td><td style=\"text-align: right;\">                 0.042359</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_7 </td><td style=\"text-align: right;\">0.673036</td><td style=\"text-align: right;\"> 0.711369</td><td style=\"text-align: right;\">0.247073 </td><td style=\"text-align: right;\">              0.319533</td><td style=\"text-align: right;\">0.400961</td><td style=\"text-align: right;\">0.16077 </td><td style=\"text-align: right;\">              9201</td><td style=\"text-align: right;\">                 0.053295</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_14</td><td style=\"text-align: right;\">0.664544</td><td style=\"text-align: right;\"> 0.751402</td><td style=\"text-align: right;\">0.234738 </td><td style=\"text-align: right;\">              0.319297</td><td style=\"text-align: right;\">0.38431 </td><td style=\"text-align: right;\">0.147694</td><td style=\"text-align: right;\">              3788</td><td style=\"text-align: right;\">                 0.082997</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_15</td><td style=\"text-align: right;\">0.660415</td><td style=\"text-align: right;\"> 1.94678 </td><td style=\"text-align: right;\">0.248945 </td><td style=\"text-align: right;\">              0.342062</td><td style=\"text-align: right;\">0.458766</td><td style=\"text-align: right;\">0.210466</td><td style=\"text-align: right;\">              2643</td><td style=\"text-align: right;\">                 0.043961</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_16</td><td style=\"text-align: right;\">0.64803 </td><td style=\"text-align: right;\"> 1.65277 </td><td style=\"text-align: right;\">0.333943 </td><td style=\"text-align: right;\">              0.356806</td><td style=\"text-align: right;\">0.395622</td><td style=\"text-align: right;\">0.156517</td><td style=\"text-align: right;\">              2735</td><td style=\"text-align: right;\">                 0.082518</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_8 </td><td style=\"text-align: right;\">0.643548</td><td style=\"text-align: right;\"> 0.712609</td><td style=\"text-align: right;\">0.237042 </td><td style=\"text-align: right;\">              0.374499</td><td style=\"text-align: right;\">0.400227</td><td style=\"text-align: right;\">0.160181</td><td style=\"text-align: right;\">              9149</td><td style=\"text-align: right;\">                 0.070535</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_19</td><td style=\"text-align: right;\">0.63883 </td><td style=\"text-align: right;\"> 0.813923</td><td style=\"text-align: right;\">0.185431 </td><td style=\"text-align: right;\">              0.354565</td><td style=\"text-align: right;\">0.403464</td><td style=\"text-align: right;\">0.162783</td><td style=\"text-align: right;\">              5334</td><td style=\"text-align: right;\">                 0.146382</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_14</td><td style=\"text-align: right;\">0.627978</td><td style=\"text-align: right;\"> 0.575585</td><td style=\"text-align: right;\">0.225945 </td><td style=\"text-align: right;\">              0.373909</td><td style=\"text-align: right;\">0.373781</td><td style=\"text-align: right;\">0.139712</td><td style=\"text-align: right;\">              6699</td><td style=\"text-align: right;\">                 0.067032</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_20</td><td style=\"text-align: right;\">0.620193</td><td style=\"text-align: right;\"> 0.690526</td><td style=\"text-align: right;\">0.180322 </td><td style=\"text-align: right;\">              0.323071</td><td style=\"text-align: right;\">0.405073</td><td style=\"text-align: right;\">0.164084</td><td style=\"text-align: right;\">              2643</td><td style=\"text-align: right;\">                 0.053767</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_3 </td><td style=\"text-align: right;\">0.616537</td><td style=\"text-align: right;\"> 2.30988 </td><td style=\"text-align: right;\">0.273739 </td><td style=\"text-align: right;\">              0.375914</td><td style=\"text-align: right;\">0.456821</td><td style=\"text-align: right;\">0.208686</td><td style=\"text-align: right;\">              3057</td><td style=\"text-align: right;\">                 0.077927</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_21</td><td style=\"text-align: right;\">0.613588</td><td style=\"text-align: right;\"> 1.37477 </td><td style=\"text-align: right;\">0.221378 </td><td style=\"text-align: right;\">              0.376622</td><td style=\"text-align: right;\">0.466448</td><td style=\"text-align: right;\">0.217574</td><td style=\"text-align: right;\">              2525</td><td style=\"text-align: right;\">                 0.071228</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_14</td><td style=\"text-align: right;\">0.605096</td><td style=\"text-align: right;\"> 0.856076</td><td style=\"text-align: right;\">0.188419 </td><td style=\"text-align: right;\">              0.358575</td><td style=\"text-align: right;\">0.408442</td><td style=\"text-align: right;\">0.166824</td><td style=\"text-align: right;\">              2795</td><td style=\"text-align: right;\">                 0.05473 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_19</td><td style=\"text-align: right;\">0.605096</td><td style=\"text-align: right;\"> 1.05866 </td><td style=\"text-align: right;\">0.239588 </td><td style=\"text-align: right;\">              0.406346</td><td style=\"text-align: right;\">0.417917</td><td style=\"text-align: right;\">0.174655</td><td style=\"text-align: right;\">              3991</td><td style=\"text-align: right;\">                 0.075436</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_17         </td><td style=\"text-align: right;\">0.604152</td><td style=\"text-align: right;\"> 0.480954</td><td style=\"text-align: right;\">0.197919 </td><td style=\"text-align: right;\">              0.359165</td><td style=\"text-align: right;\">0.376248</td><td style=\"text-align: right;\">0.141563</td><td style=\"text-align: right;\">               102</td><td style=\"text-align: right;\">                 0.069247</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_19</td><td style=\"text-align: right;\">0.596603</td><td style=\"text-align: right;\"> 0.871236</td><td style=\"text-align: right;\">0.213128 </td><td style=\"text-align: right;\">              0.373319</td><td style=\"text-align: right;\">0.39454 </td><td style=\"text-align: right;\">0.155662</td><td style=\"text-align: right;\">              4044</td><td style=\"text-align: right;\">                 0.094547</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_6 </td><td style=\"text-align: right;\">0.596367</td><td style=\"text-align: right;\"> 1.16    </td><td style=\"text-align: right;\">0.211252 </td><td style=\"text-align: right;\">              0.407761</td><td style=\"text-align: right;\">0.448466</td><td style=\"text-align: right;\">0.201122</td><td style=\"text-align: right;\">              3992</td><td style=\"text-align: right;\">                 0.079726</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DRF_1_AutoML_1_20230517_160832                       </td><td style=\"text-align: right;\">0.587757</td><td style=\"text-align: right;\"> 0.494573</td><td style=\"text-align: right;\">0.168243 </td><td style=\"text-align: right;\">              0.394315</td><td style=\"text-align: right;\">0.375985</td><td style=\"text-align: right;\">0.141364</td><td style=\"text-align: right;\">               228</td><td style=\"text-align: right;\">                 0.043497</td><td>DRF         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_16</td><td style=\"text-align: right;\">0.585751</td><td style=\"text-align: right;\"> 1.42513 </td><td style=\"text-align: right;\">0.22808  </td><td style=\"text-align: right;\">              0.401982</td><td style=\"text-align: right;\">0.434664</td><td style=\"text-align: right;\">0.188933</td><td style=\"text-align: right;\">              5027</td><td style=\"text-align: right;\">                 0.141608</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_9 </td><td style=\"text-align: right;\">0.582685</td><td style=\"text-align: right;\"> 0.891934</td><td style=\"text-align: right;\">0.187682 </td><td style=\"text-align: right;\">              0.391248</td><td style=\"text-align: right;\">0.418697</td><td style=\"text-align: right;\">0.175307</td><td style=\"text-align: right;\">              3780</td><td style=\"text-align: right;\">                 0.064132</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_10</td><td style=\"text-align: right;\">0.579382</td><td style=\"text-align: right;\"> 1.00456 </td><td style=\"text-align: right;\">0.239048 </td><td style=\"text-align: right;\">              0.388063</td><td style=\"text-align: right;\">0.441741</td><td style=\"text-align: right;\">0.195135</td><td style=\"text-align: right;\">              5118</td><td style=\"text-align: right;\">                 0.050657</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_13</td><td style=\"text-align: right;\">0.578674</td><td style=\"text-align: right;\"> 1.00687 </td><td style=\"text-align: right;\">0.284805 </td><td style=\"text-align: right;\">              0.378509</td><td style=\"text-align: right;\">0.473368</td><td style=\"text-align: right;\">0.224077</td><td style=\"text-align: right;\">              5054</td><td style=\"text-align: right;\">                 0.098441</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_11</td><td style=\"text-align: right;\">0.575843</td><td style=\"text-align: right;\"> 0.869951</td><td style=\"text-align: right;\">0.174531 </td><td style=\"text-align: right;\">              0.412126</td><td style=\"text-align: right;\">0.412098</td><td style=\"text-align: right;\">0.169825</td><td style=\"text-align: right;\">              2574</td><td style=\"text-align: right;\">                 0.066667</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_18</td><td style=\"text-align: right;\">0.552961</td><td style=\"text-align: right;\"> 0.67846 </td><td style=\"text-align: right;\">0.164475 </td><td style=\"text-align: right;\">              0.421798</td><td style=\"text-align: right;\">0.407549</td><td style=\"text-align: right;\">0.166096</td><td style=\"text-align: right;\">              3593</td><td style=\"text-align: right;\">                 0.055938</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_12</td><td style=\"text-align: right;\">0.549186</td><td style=\"text-align: right;\"> 1.12109 </td><td style=\"text-align: right;\">0.175211 </td><td style=\"text-align: right;\">              0.412361</td><td style=\"text-align: right;\">0.41133 </td><td style=\"text-align: right;\">0.169193</td><td style=\"text-align: right;\">              4147</td><td style=\"text-align: right;\">                 0.063155</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_22</td><td style=\"text-align: right;\">0.54494 </td><td style=\"text-align: right;\"> 1.64752 </td><td style=\"text-align: right;\">0.183587 </td><td style=\"text-align: right;\">              0.418731</td><td style=\"text-align: right;\">0.48115 </td><td style=\"text-align: right;\">0.231506</td><td style=\"text-align: right;\">              3797</td><td style=\"text-align: right;\">                 0.061803</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_12</td><td style=\"text-align: right;\">0.54376 </td><td style=\"text-align: right;\"> 1.10845 </td><td style=\"text-align: right;\">0.171843 </td><td style=\"text-align: right;\">              0.428875</td><td style=\"text-align: right;\">0.418997</td><td style=\"text-align: right;\">0.175558</td><td style=\"text-align: right;\">              3935</td><td style=\"text-align: right;\">                 0.058846</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_13         </td><td style=\"text-align: right;\">0.538099</td><td style=\"text-align: right;\"> 0.537599</td><td style=\"text-align: right;\">0.17226  </td><td style=\"text-align: right;\">              0.389833</td><td style=\"text-align: right;\">0.379201</td><td style=\"text-align: right;\">0.143794</td><td style=\"text-align: right;\">               173</td><td style=\"text-align: right;\">                 0.037794</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_5 </td><td style=\"text-align: right;\">0.537863</td><td style=\"text-align: right;\"> 0.78653 </td><td style=\"text-align: right;\">0.17999  </td><td style=\"text-align: right;\">              0.4159  </td><td style=\"text-align: right;\">0.392435</td><td style=\"text-align: right;\">0.154006</td><td style=\"text-align: right;\">              4062</td><td style=\"text-align: right;\">                 0.069647</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_7 </td><td style=\"text-align: right;\">0.536211</td><td style=\"text-align: right;\"> 0.874942</td><td style=\"text-align: right;\">0.166452 </td><td style=\"text-align: right;\">              0.444326</td><td style=\"text-align: right;\">0.404248</td><td style=\"text-align: right;\">0.163416</td><td style=\"text-align: right;\">              8649</td><td style=\"text-align: right;\">                 0.074521</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_3          </td><td style=\"text-align: right;\">0.535975</td><td style=\"text-align: right;\"> 0.468633</td><td style=\"text-align: right;\">0.167338 </td><td style=\"text-align: right;\">              0.41472 </td><td style=\"text-align: right;\">0.368171</td><td style=\"text-align: right;\">0.13555 </td><td style=\"text-align: right;\">                91</td><td style=\"text-align: right;\">                 0.058354</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_20</td><td style=\"text-align: right;\">0.535504</td><td style=\"text-align: right;\"> 1.09401 </td><td style=\"text-align: right;\">0.179197 </td><td style=\"text-align: right;\">              0.44987 </td><td style=\"text-align: right;\">0.419918</td><td style=\"text-align: right;\">0.176331</td><td style=\"text-align: right;\">              2653</td><td style=\"text-align: right;\">                 0.051954</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_2_AutoML_1_20230517_160832                       </td><td style=\"text-align: right;\">0.533381</td><td style=\"text-align: right;\"> 0.493571</td><td style=\"text-align: right;\">0.156776 </td><td style=\"text-align: right;\">              0.42109 </td><td style=\"text-align: right;\">0.378121</td><td style=\"text-align: right;\">0.142976</td><td style=\"text-align: right;\">               193</td><td style=\"text-align: right;\">                 0.032305</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_5 </td><td style=\"text-align: right;\">0.523237</td><td style=\"text-align: right;\"> 1.19908 </td><td style=\"text-align: right;\">0.166575 </td><td style=\"text-align: right;\">              0.471338</td><td style=\"text-align: right;\">0.399278</td><td style=\"text-align: right;\">0.159423</td><td style=\"text-align: right;\">              2633</td><td style=\"text-align: right;\">                 0.081373</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_5 </td><td style=\"text-align: right;\">0.521113</td><td style=\"text-align: right;\"> 1.21765 </td><td style=\"text-align: right;\">0.162626 </td><td style=\"text-align: right;\">              0.421326</td><td style=\"text-align: right;\">0.425863</td><td style=\"text-align: right;\">0.181359</td><td style=\"text-align: right;\">              2685</td><td style=\"text-align: right;\">                 0.070148</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_21         </td><td style=\"text-align: right;\">0.52017 </td><td style=\"text-align: right;\"> 0.534379</td><td style=\"text-align: right;\">0.167537 </td><td style=\"text-align: right;\">              0.410946</td><td style=\"text-align: right;\">0.37994 </td><td style=\"text-align: right;\">0.144354</td><td style=\"text-align: right;\">               149</td><td style=\"text-align: right;\">                 0.033403</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_8 </td><td style=\"text-align: right;\">0.519934</td><td style=\"text-align: right;\"> 1.01548 </td><td style=\"text-align: right;\">0.174406 </td><td style=\"text-align: right;\">              0.42687 </td><td style=\"text-align: right;\">0.409466</td><td style=\"text-align: right;\">0.167663</td><td style=\"text-align: right;\">             10804</td><td style=\"text-align: right;\">                 0.119982</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_3 </td><td style=\"text-align: right;\">0.516631</td><td style=\"text-align: right;\"> 0.997053</td><td style=\"text-align: right;\">0.17663  </td><td style=\"text-align: right;\">              0.407761</td><td style=\"text-align: right;\">0.396605</td><td style=\"text-align: right;\">0.157295</td><td style=\"text-align: right;\">              2617</td><td style=\"text-align: right;\">                 0.042277</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_10         </td><td style=\"text-align: right;\">0.512857</td><td style=\"text-align: right;\"> 0.481216</td><td style=\"text-align: right;\">0.164423 </td><td style=\"text-align: right;\">              0.427459</td><td style=\"text-align: right;\">0.370537</td><td style=\"text-align: right;\">0.137298</td><td style=\"text-align: right;\">               102</td><td style=\"text-align: right;\">                 0.04933 </td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_3_AutoML_1_20230517_160832                       </td><td style=\"text-align: right;\">0.509082</td><td style=\"text-align: right;\"> 0.506015</td><td style=\"text-align: right;\">0.146222 </td><td style=\"text-align: right;\">              0.426044</td><td style=\"text-align: right;\">0.382335</td><td style=\"text-align: right;\">0.14618 </td><td style=\"text-align: right;\">               148</td><td style=\"text-align: right;\">                 0.032479</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_1 </td><td style=\"text-align: right;\">0.500118</td><td style=\"text-align: right;\"> 1.1528  </td><td style=\"text-align: right;\">0.240332 </td><td style=\"text-align: right;\">              0.402807</td><td style=\"text-align: right;\">0.403966</td><td style=\"text-align: right;\">0.163188</td><td style=\"text-align: right;\">              5306</td><td style=\"text-align: right;\">                 0.071989</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_20</td><td style=\"text-align: right;\">0.497523</td><td style=\"text-align: right;\"> 0.611617</td><td style=\"text-align: right;\">0.139555 </td><td style=\"text-align: right;\">              0.447747</td><td style=\"text-align: right;\">0.407379</td><td style=\"text-align: right;\">0.165958</td><td style=\"text-align: right;\">              2620</td><td style=\"text-align: right;\">                 0.044033</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_2 </td><td style=\"text-align: right;\">0.492097</td><td style=\"text-align: right;\"> 1.37162 </td><td style=\"text-align: right;\">0.157325 </td><td style=\"text-align: right;\">              0.416726</td><td style=\"text-align: right;\">0.419678</td><td style=\"text-align: right;\">0.17613 </td><td style=\"text-align: right;\">              2631</td><td style=\"text-align: right;\">                 0.064501</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_13</td><td style=\"text-align: right;\">0.491154</td><td style=\"text-align: right;\"> 1.08224 </td><td style=\"text-align: right;\">0.195242 </td><td style=\"text-align: right;\">              0.433829</td><td style=\"text-align: right;\">0.37028 </td><td style=\"text-align: right;\">0.137107</td><td style=\"text-align: right;\">              5103</td><td style=\"text-align: right;\">                 0.060801</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_17</td><td style=\"text-align: right;\">0.489502</td><td style=\"text-align: right;\"> 1.00617 </td><td style=\"text-align: right;\">0.168319 </td><td style=\"text-align: right;\">              0.42628 </td><td style=\"text-align: right;\">0.433451</td><td style=\"text-align: right;\">0.18788 </td><td style=\"text-align: right;\">              4602</td><td style=\"text-align: right;\">                 0.041117</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_9 </td><td style=\"text-align: right;\">0.487143</td><td style=\"text-align: right;\"> 1.66533 </td><td style=\"text-align: right;\">0.139263 </td><td style=\"text-align: right;\">              0.438311</td><td style=\"text-align: right;\">0.48001 </td><td style=\"text-align: right;\">0.230409</td><td style=\"text-align: right;\">              5064</td><td style=\"text-align: right;\">                 0.064782</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_1_20230517_160832              </td><td style=\"text-align: right;\">0.486435</td><td style=\"text-align: right;\"> 0.746502</td><td style=\"text-align: right;\">0.132931 </td><td style=\"text-align: right;\">              0.436778</td><td style=\"text-align: right;\">0.454255</td><td style=\"text-align: right;\">0.206348</td><td style=\"text-align: right;\">               116</td><td style=\"text-align: right;\">                 0.038763</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_21</td><td style=\"text-align: right;\">0.484076</td><td style=\"text-align: right;\"> 0.84487 </td><td style=\"text-align: right;\">0.135634 </td><td style=\"text-align: right;\">              0.446332</td><td style=\"text-align: right;\">0.4577  </td><td style=\"text-align: right;\">0.20949 </td><td style=\"text-align: right;\">              2582</td><td style=\"text-align: right;\">                 0.058256</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_4 </td><td style=\"text-align: right;\">0.483841</td><td style=\"text-align: right;\"> 1.18706 </td><td style=\"text-align: right;\">0.149138 </td><td style=\"text-align: right;\">              0.4205  </td><td style=\"text-align: right;\">0.444523</td><td style=\"text-align: right;\">0.1976  </td><td style=\"text-align: right;\">              5553</td><td style=\"text-align: right;\">                 0.074783</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_9          </td><td style=\"text-align: right;\">0.479358</td><td style=\"text-align: right;\"> 0.490572</td><td style=\"text-align: right;\">0.142713 </td><td style=\"text-align: right;\">              0.422269</td><td style=\"text-align: right;\">0.377738</td><td style=\"text-align: right;\">0.142686</td><td style=\"text-align: right;\">                75</td><td style=\"text-align: right;\">                 0.034747</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_1 </td><td style=\"text-align: right;\">0.479358</td><td style=\"text-align: right;\"> 1.06724 </td><td style=\"text-align: right;\">0.170789 </td><td style=\"text-align: right;\">              0.464968</td><td style=\"text-align: right;\">0.436469</td><td style=\"text-align: right;\">0.190505</td><td style=\"text-align: right;\">              5124</td><td style=\"text-align: right;\">                 0.053053</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_4 </td><td style=\"text-align: right;\">0.479122</td><td style=\"text-align: right;\"> 1.74944 </td><td style=\"text-align: right;\">0.137861 </td><td style=\"text-align: right;\">              0.490446</td><td style=\"text-align: right;\">0.441515</td><td style=\"text-align: right;\">0.194936</td><td style=\"text-align: right;\">              5182</td><td style=\"text-align: right;\">                 0.038475</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_2          </td><td style=\"text-align: right;\">0.476527</td><td style=\"text-align: right;\"> 0.515459</td><td style=\"text-align: right;\">0.149057 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.382837</td><td style=\"text-align: right;\">0.146564</td><td style=\"text-align: right;\">                84</td><td style=\"text-align: right;\">                 0.036107</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_12         </td><td style=\"text-align: right;\">0.473225</td><td style=\"text-align: right;\"> 0.553308</td><td style=\"text-align: right;\">0.139832 </td><td style=\"text-align: right;\">              0.469214</td><td style=\"text-align: right;\">0.387915</td><td style=\"text-align: right;\">0.150478</td><td style=\"text-align: right;\">               110</td><td style=\"text-align: right;\">                 0.024951</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_4_AutoML_1_20230517_160832                       </td><td style=\"text-align: right;\">0.472989</td><td style=\"text-align: right;\"> 0.511462</td><td style=\"text-align: right;\">0.143562 </td><td style=\"text-align: right;\">              0.435008</td><td style=\"text-align: right;\">0.379819</td><td style=\"text-align: right;\">0.144262</td><td style=\"text-align: right;\">               149</td><td style=\"text-align: right;\">                 0.024652</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_22         </td><td style=\"text-align: right;\">0.471809</td><td style=\"text-align: right;\"> 0.474344</td><td style=\"text-align: right;\">0.132059 </td><td style=\"text-align: right;\">              0.490446</td><td style=\"text-align: right;\">0.373419</td><td style=\"text-align: right;\">0.139441</td><td style=\"text-align: right;\">                88</td><td style=\"text-align: right;\">                 0.03984 </td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_8 </td><td style=\"text-align: right;\">0.470394</td><td style=\"text-align: right;\"> 1.42363 </td><td style=\"text-align: right;\">0.242253 </td><td style=\"text-align: right;\">              0.420146</td><td style=\"text-align: right;\">0.447773</td><td style=\"text-align: right;\">0.200501</td><td style=\"text-align: right;\">             15552</td><td style=\"text-align: right;\">                 0.043504</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_3 </td><td style=\"text-align: right;\">0.468271</td><td style=\"text-align: right;\"> 0.912474</td><td style=\"text-align: right;\">0.144145 </td><td style=\"text-align: right;\">              0.457891</td><td style=\"text-align: right;\">0.390869</td><td style=\"text-align: right;\">0.152778</td><td style=\"text-align: right;\">              2639</td><td style=\"text-align: right;\">                 0.04746 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_12</td><td style=\"text-align: right;\">0.46426 </td><td style=\"text-align: right;\"> 1.16401 </td><td style=\"text-align: right;\">0.146614 </td><td style=\"text-align: right;\">              0.437839</td><td style=\"text-align: right;\">0.427122</td><td style=\"text-align: right;\">0.182433</td><td style=\"text-align: right;\">              5415</td><td style=\"text-align: right;\">                 0.076118</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_2 </td><td style=\"text-align: right;\">0.463553</td><td style=\"text-align: right;\"> 0.890709</td><td style=\"text-align: right;\">0.157747 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.408096</td><td style=\"text-align: right;\">0.166542</td><td style=\"text-align: right;\">              2483</td><td style=\"text-align: right;\">                 0.04583 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_15         </td><td style=\"text-align: right;\">0.460014</td><td style=\"text-align: right;\"> 0.518431</td><td style=\"text-align: right;\">0.128203 </td><td style=\"text-align: right;\">              0.46084 </td><td style=\"text-align: right;\">0.383803</td><td style=\"text-align: right;\">0.147305</td><td style=\"text-align: right;\">               125</td><td style=\"text-align: right;\">                 0.051073</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_7          </td><td style=\"text-align: right;\">0.455532</td><td style=\"text-align: right;\"> 0.501124</td><td style=\"text-align: right;\">0.133072 </td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.381879</td><td style=\"text-align: right;\">0.145831</td><td style=\"text-align: right;\">                79</td><td style=\"text-align: right;\">                 0.030169</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_13</td><td style=\"text-align: right;\">0.454352</td><td style=\"text-align: right;\"> 0.898342</td><td style=\"text-align: right;\">0.136369 </td><td style=\"text-align: right;\">              0.481717</td><td style=\"text-align: right;\">0.382615</td><td style=\"text-align: right;\">0.146394</td><td style=\"text-align: right;\">              5237</td><td style=\"text-align: right;\">                 0.056924</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230517_160832_model_16</td><td style=\"text-align: right;\">0.451757</td><td style=\"text-align: right;\"> 2.29745 </td><td style=\"text-align: right;\">0.138748 </td><td style=\"text-align: right;\">              0.490446</td><td style=\"text-align: right;\">0.453083</td><td style=\"text-align: right;\">0.205284</td><td style=\"text-align: right;\">              2778</td><td style=\"text-align: right;\">                 0.05854 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_21</td><td style=\"text-align: right;\">0.449398</td><td style=\"text-align: right;\"> 0.940052</td><td style=\"text-align: right;\">0.134524 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.440962</td><td style=\"text-align: right;\">0.194448</td><td style=\"text-align: right;\">              2616</td><td style=\"text-align: right;\">                 0.052482</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_7 </td><td style=\"text-align: right;\">0.449163</td><td style=\"text-align: right;\"> 0.97981 </td><td style=\"text-align: right;\">0.17991  </td><td style=\"text-align: right;\">              0.420736</td><td style=\"text-align: right;\">0.407345</td><td style=\"text-align: right;\">0.16593 </td><td style=\"text-align: right;\">              8478</td><td style=\"text-align: right;\">                 0.084016</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_10</td><td style=\"text-align: right;\">0.444916</td><td style=\"text-align: right;\"> 0.913033</td><td style=\"text-align: right;\">0.145101 </td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.408973</td><td style=\"text-align: right;\">0.167259</td><td style=\"text-align: right;\">              5518</td><td style=\"text-align: right;\">                 0.100652</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_5          </td><td style=\"text-align: right;\">0.444798</td><td style=\"text-align: right;\"> 0.517864</td><td style=\"text-align: right;\">0.131112 </td><td style=\"text-align: right;\">              0.443383</td><td style=\"text-align: right;\">0.382914</td><td style=\"text-align: right;\">0.146623</td><td style=\"text-align: right;\">                98</td><td style=\"text-align: right;\">                 0.022499</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_2 </td><td style=\"text-align: right;\">0.44468 </td><td style=\"text-align: right;\"> 0.654847</td><td style=\"text-align: right;\">0.143605 </td><td style=\"text-align: right;\">              0.484076</td><td style=\"text-align: right;\">0.377724</td><td style=\"text-align: right;\">0.142676</td><td style=\"text-align: right;\">              3665</td><td style=\"text-align: right;\">                 0.059526</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_6 </td><td style=\"text-align: right;\">0.432177</td><td style=\"text-align: right;\"> 0.925578</td><td style=\"text-align: right;\">0.215623 </td><td style=\"text-align: right;\">              0.436424</td><td style=\"text-align: right;\">0.358662</td><td style=\"text-align: right;\">0.128638</td><td style=\"text-align: right;\">             10213</td><td style=\"text-align: right;\">                 0.10997 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_10</td><td style=\"text-align: right;\">0.429818</td><td style=\"text-align: right;\"> 1.36531 </td><td style=\"text-align: right;\">0.130144 </td><td style=\"text-align: right;\">              0.493631</td><td style=\"text-align: right;\">0.453011</td><td style=\"text-align: right;\">0.205219</td><td style=\"text-align: right;\">              5377</td><td style=\"text-align: right;\">                 0.083947</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_1          </td><td style=\"text-align: right;\">0.428403</td><td style=\"text-align: right;\"> 0.500272</td><td style=\"text-align: right;\">0.126236 </td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.377023</td><td style=\"text-align: right;\">0.142146</td><td style=\"text-align: right;\">                98</td><td style=\"text-align: right;\">                 0.023326</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_17</td><td style=\"text-align: right;\">0.425808</td><td style=\"text-align: right;\"> 0.784547</td><td style=\"text-align: right;\">0.125302 </td><td style=\"text-align: right;\">              0.493631</td><td style=\"text-align: right;\">0.383995</td><td style=\"text-align: right;\">0.147452</td><td style=\"text-align: right;\">              3647</td><td style=\"text-align: right;\">                 0.049925</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_5_AutoML_1_20230517_160832                       </td><td style=\"text-align: right;\">0.41472 </td><td style=\"text-align: right;\"> 0.575528</td><td style=\"text-align: right;\">0.144189 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.387267</td><td style=\"text-align: right;\">0.149976</td><td style=\"text-align: right;\">               109</td><td style=\"text-align: right;\">                 0.033661</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_11</td><td style=\"text-align: right;\">0.411654</td><td style=\"text-align: right;\"> 1.26974 </td><td style=\"text-align: right;\">0.11683  </td><td style=\"text-align: right;\">              0.489266</td><td style=\"text-align: right;\">0.425947</td><td style=\"text-align: right;\">0.181431</td><td style=\"text-align: right;\">              2627</td><td style=\"text-align: right;\">                 0.046707</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_6 </td><td style=\"text-align: right;\">0.407643</td><td style=\"text-align: right;\"> 0.934306</td><td style=\"text-align: right;\">0.119785 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.392381</td><td style=\"text-align: right;\">0.153963</td><td style=\"text-align: right;\">              5243</td><td style=\"text-align: right;\">                 0.082196</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_18</td><td style=\"text-align: right;\">0.390422</td><td style=\"text-align: right;\"> 1.11118 </td><td style=\"text-align: right;\">0.119721 </td><td style=\"text-align: right;\">              0.487261</td><td style=\"text-align: right;\">0.384885</td><td style=\"text-align: right;\">0.148137</td><td style=\"text-align: right;\">              4795</td><td style=\"text-align: right;\">                 0.0408  </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_11</td><td style=\"text-align: right;\">0.386176</td><td style=\"text-align: right;\"> 0.733369</td><td style=\"text-align: right;\">0.121341 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.389382</td><td style=\"text-align: right;\">0.151618</td><td style=\"text-align: right;\">              2589</td><td style=\"text-align: right;\">                 0.063695</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_15</td><td style=\"text-align: right;\">0.382637</td><td style=\"text-align: right;\"> 1.17844 </td><td style=\"text-align: right;\">0.113316 </td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.38868 </td><td style=\"text-align: right;\">0.151072</td><td style=\"text-align: right;\">              2666</td><td style=\"text-align: right;\">                 0.109121</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_15</td><td style=\"text-align: right;\">0.380986</td><td style=\"text-align: right;\"> 1.41802 </td><td style=\"text-align: right;\">0.11367  </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.446597</td><td style=\"text-align: right;\">0.199449</td><td style=\"text-align: right;\">              2668</td><td style=\"text-align: right;\">                 0.059841</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_4          </td><td style=\"text-align: right;\">0.374381</td><td style=\"text-align: right;\"> 0.491893</td><td style=\"text-align: right;\">0.110061 </td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.37681 </td><td style=\"text-align: right;\">0.141985</td><td style=\"text-align: right;\">                76</td><td style=\"text-align: right;\">                 0.034177</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_8          </td><td style=\"text-align: right;\">0.372729</td><td style=\"text-align: right;\"> 0.595315</td><td style=\"text-align: right;\">0.119759 </td><td style=\"text-align: right;\">              0.493631</td><td style=\"text-align: right;\">0.392748</td><td style=\"text-align: right;\">0.154251</td><td style=\"text-align: right;\">               161</td><td style=\"text-align: right;\">                 0.04897 </td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230517_160832_model_22</td><td style=\"text-align: right;\">0.368955</td><td style=\"text-align: right;\"> 1.1096  </td><td style=\"text-align: right;\">0.109806 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.409749</td><td style=\"text-align: right;\">0.167895</td><td style=\"text-align: right;\">              3933</td><td style=\"text-align: right;\">                 0.058801</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_18         </td><td style=\"text-align: right;\">0.366832</td><td style=\"text-align: right;\"> 0.596957</td><td style=\"text-align: right;\">0.117026 </td><td style=\"text-align: right;\">              0.480892</td><td style=\"text-align: right;\">0.386634</td><td style=\"text-align: right;\">0.149486</td><td style=\"text-align: right;\">               151</td><td style=\"text-align: right;\">                 0.052817</td><td>GBM         </td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20230517_160832                       </td><td style=\"text-align: right;\">0.344893</td><td style=\"text-align: right;\"> 0.477983</td><td style=\"text-align: right;\">0.107925 </td><td style=\"text-align: right;\">              0.493631</td><td style=\"text-align: right;\">0.374864</td><td style=\"text-align: right;\">0.140523</td><td style=\"text-align: right;\">                83</td><td style=\"text-align: right;\">                 0.036779</td><td>GLM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_20         </td><td style=\"text-align: right;\">0.283793</td><td style=\"text-align: right;\"> 0.503699</td><td style=\"text-align: right;\">0.101192 </td><td style=\"text-align: right;\">              0.493631</td><td style=\"text-align: right;\">0.377142</td><td style=\"text-align: right;\">0.142236</td><td style=\"text-align: right;\">                72</td><td style=\"text-align: right;\">                 0.044912</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_22</td><td style=\"text-align: right;\">0.281906</td><td style=\"text-align: right;\"> 1.36079 </td><td style=\"text-align: right;\">0.095807 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.383224</td><td style=\"text-align: right;\">0.146861</td><td style=\"text-align: right;\">              3858</td><td style=\"text-align: right;\">                 0.054315</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_18</td><td style=\"text-align: right;\">0.281198</td><td style=\"text-align: right;\"> 0.753328</td><td style=\"text-align: right;\">0.113006 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.377534</td><td style=\"text-align: right;\">0.142532</td><td style=\"text-align: right;\">              3963</td><td style=\"text-align: right;\">                 0.056891</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230517_160832_model_11         </td><td style=\"text-align: right;\">0.278603</td><td style=\"text-align: right;\"> 0.486507</td><td style=\"text-align: right;\">0.100319 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.373086</td><td style=\"text-align: right;\">0.139194</td><td style=\"text-align: right;\">                70</td><td style=\"text-align: right;\">                 0.030315</td><td>GBM         </td></tr>\n",
       "<tr><td>XRT_1_AutoML_1_20230517_160832                       </td><td style=\"text-align: right;\">0.267988</td><td style=\"text-align: right;\"> 0.482301</td><td style=\"text-align: right;\">0.0989997</td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.380137</td><td style=\"text-align: right;\">0.144504</td><td style=\"text-align: right;\">               102</td><td style=\"text-align: right;\">                 0.044252</td><td>DRF         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_9 </td><td style=\"text-align: right;\">0.253362</td><td style=\"text-align: right;\"> 1.08297 </td><td style=\"text-align: right;\">0.0948494</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.414355</td><td style=\"text-align: right;\">0.17169 </td><td style=\"text-align: right;\">              2664</td><td style=\"text-align: right;\">                 0.046514</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230517_160832_model_17</td><td style=\"text-align: right;\">0.242038</td><td style=\"text-align: right;\"> 1.24204 </td><td style=\"text-align: right;\">0.091688 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.383798</td><td style=\"text-align: right;\">0.147301</td><td style=\"text-align: right;\">              3973</td><td style=\"text-align: right;\">                 0.054339</td><td>DeepLearning</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[93 rows x 10 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                    auc    logloss      aucpr    mean_per_class_error      rmse       mse    training_time_ms    predict_time_per_row_ms  algo\n",
       "-----------------------------------------------------  --------  ---------  ---------  ----------------------  --------  --------  ------------------  -------------------------  ------------\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_4   0.727766   0.680794  0.29176                  0.292876  0.395659  0.156546                5261                   0.129583  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_1   0.707714   0.717919  0.407089                 0.361996  0.370955  0.137608               10546                   0.102322  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_23  0.687662   1.00964   0.257296                 0.306558  0.491412  0.241486                3660                   0.042359  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_7   0.673036   0.711369  0.247073                 0.319533  0.400961  0.16077                 9201                   0.053295  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_14  0.664544   0.751402  0.234738                 0.319297  0.38431   0.147694                3788                   0.082997  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_15  0.660415   1.94678   0.248945                 0.342062  0.458766  0.210466                2643                   0.043961  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_16  0.64803    1.65277   0.333943                 0.356806  0.395622  0.156517                2735                   0.082518  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_8   0.643548   0.712609  0.237042                 0.374499  0.400227  0.160181                9149                   0.070535  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_19  0.63883    0.813923  0.185431                 0.354565  0.403464  0.162783                5334                   0.146382  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_14  0.627978   0.575585  0.225945                 0.373909  0.373781  0.139712                6699                   0.067032  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_20  0.620193   0.690526  0.180322                 0.323071  0.405073  0.164084                2643                   0.053767  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_3   0.616537   2.30988   0.273739                 0.375914  0.456821  0.208686                3057                   0.077927  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_21  0.613588   1.37477   0.221378                 0.376622  0.466448  0.217574                2525                   0.071228  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_14  0.605096   0.856076  0.188419                 0.358575  0.408442  0.166824                2795                   0.05473   DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_19  0.605096   1.05866   0.239588                 0.406346  0.417917  0.174655                3991                   0.075436  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_17           0.604152   0.480954  0.197919                 0.359165  0.376248  0.141563                 102                   0.069247  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_19  0.596603   0.871236  0.213128                 0.373319  0.39454   0.155662                4044                   0.094547  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_6   0.596367   1.16      0.211252                 0.407761  0.448466  0.201122                3992                   0.079726  DeepLearning\n",
       "DRF_1_AutoML_1_20230517_160832                         0.587757   0.494573  0.168243                 0.394315  0.375985  0.141364                 228                   0.043497  DRF\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_16  0.585751   1.42513   0.22808                  0.401982  0.434664  0.188933                5027                   0.141608  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_9   0.582685   0.891934  0.187682                 0.391248  0.418697  0.175307                3780                   0.064132  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_10  0.579382   1.00456   0.239048                 0.388063  0.441741  0.195135                5118                   0.050657  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_13  0.578674   1.00687   0.284805                 0.378509  0.473368  0.224077                5054                   0.098441  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_11  0.575843   0.869951  0.174531                 0.412126  0.412098  0.169825                2574                   0.066667  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_18  0.552961   0.67846   0.164475                 0.421798  0.407549  0.166096                3593                   0.055938  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_12  0.549186   1.12109   0.175211                 0.412361  0.41133   0.169193                4147                   0.063155  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_22  0.54494    1.64752   0.183587                 0.418731  0.48115   0.231506                3797                   0.061803  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_12  0.54376    1.10845   0.171843                 0.428875  0.418997  0.175558                3935                   0.058846  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_13           0.538099   0.537599  0.17226                  0.389833  0.379201  0.143794                 173                   0.037794  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_5   0.537863   0.78653   0.17999                  0.4159    0.392435  0.154006                4062                   0.069647  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_7   0.536211   0.874942  0.166452                 0.444326  0.404248  0.163416                8649                   0.074521  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_3            0.535975   0.468633  0.167338                 0.41472   0.368171  0.13555                   91                   0.058354  GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_20  0.535504   1.09401   0.179197                 0.44987   0.419918  0.176331                2653                   0.051954  DeepLearning\n",
       "GBM_2_AutoML_1_20230517_160832                         0.533381   0.493571  0.156776                 0.42109   0.378121  0.142976                 193                   0.032305  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_5   0.523237   1.19908   0.166575                 0.471338  0.399278  0.159423                2633                   0.081373  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_5   0.521113   1.21765   0.162626                 0.421326  0.425863  0.181359                2685                   0.070148  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_21           0.52017    0.534379  0.167537                 0.410946  0.37994   0.144354                 149                   0.033403  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_8   0.519934   1.01548   0.174406                 0.42687   0.409466  0.167663               10804                   0.119982  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_3   0.516631   0.997053  0.17663                  0.407761  0.396605  0.157295                2617                   0.042277  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_10           0.512857   0.481216  0.164423                 0.427459  0.370537  0.137298                 102                   0.04933   GBM\n",
       "GBM_3_AutoML_1_20230517_160832                         0.509082   0.506015  0.146222                 0.426044  0.382335  0.14618                  148                   0.032479  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_1   0.500118   1.1528    0.240332                 0.402807  0.403966  0.163188                5306                   0.071989  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_20  0.497523   0.611617  0.139555                 0.447747  0.407379  0.165958                2620                   0.044033  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_2   0.492097   1.37162   0.157325                 0.416726  0.419678  0.17613                 2631                   0.064501  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_13  0.491154   1.08224   0.195242                 0.433829  0.37028   0.137107                5103                   0.060801  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_17  0.489502   1.00617   0.168319                 0.42628   0.433451  0.18788                 4602                   0.041117  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_9   0.487143   1.66533   0.139263                 0.438311  0.48001   0.230409                5064                   0.064782  DeepLearning\n",
       "DeepLearning_1_AutoML_1_20230517_160832                0.486435   0.746502  0.132931                 0.436778  0.454255  0.206348                 116                   0.038763  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_21  0.484076   0.84487   0.135634                 0.446332  0.4577    0.20949                 2582                   0.058256  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_4   0.483841   1.18706   0.149138                 0.4205    0.444523  0.1976                  5553                   0.074783  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_9            0.479358   0.490572  0.142713                 0.422269  0.377738  0.142686                  75                   0.034747  GBM\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_1   0.479358   1.06724   0.170789                 0.464968  0.436469  0.190505                5124                   0.053053  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_4   0.479122   1.74944   0.137861                 0.490446  0.441515  0.194936                5182                   0.038475  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_2            0.476527   0.515459  0.149057                 0.5       0.382837  0.146564                  84                   0.036107  GBM\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_12           0.473225   0.553308  0.139832                 0.469214  0.387915  0.150478                 110                   0.024951  GBM\n",
       "GBM_4_AutoML_1_20230517_160832                         0.472989   0.511462  0.143562                 0.435008  0.379819  0.144262                 149                   0.024652  GBM\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_22           0.471809   0.474344  0.132059                 0.490446  0.373419  0.139441                  88                   0.03984   GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_8   0.470394   1.42363   0.242253                 0.420146  0.447773  0.200501               15552                   0.043504  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_3   0.468271   0.912474  0.144145                 0.457891  0.390869  0.152778                2639                   0.04746   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_12  0.46426    1.16401   0.146614                 0.437839  0.427122  0.182433                5415                   0.076118  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_2   0.463553   0.890709  0.157747                 0.5       0.408096  0.166542                2483                   0.04583   DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_15           0.460014   0.518431  0.128203                 0.46084   0.383803  0.147305                 125                   0.051073  GBM\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_7            0.455532   0.501124  0.133072                 0.496815  0.381879  0.145831                  79                   0.030169  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_13  0.454352   0.898342  0.136369                 0.481717  0.382615  0.146394                5237                   0.056924  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230517_160832_model_16  0.451757   2.29745   0.138748                 0.490446  0.453083  0.205284                2778                   0.05854   DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_21  0.449398   0.940052  0.134524                 0.5       0.440962  0.194448                2616                   0.052482  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_7   0.449163   0.97981   0.17991                  0.420736  0.407345  0.16593                 8478                   0.084016  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_10  0.444916   0.913033  0.145101                 0.496815  0.408973  0.167259                5518                   0.100652  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_5            0.444798   0.517864  0.131112                 0.443383  0.382914  0.146623                  98                   0.022499  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_2   0.44468    0.654847  0.143605                 0.484076  0.377724  0.142676                3665                   0.059526  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_6   0.432177   0.925578  0.215623                 0.436424  0.358662  0.128638               10213                   0.10997   DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_10  0.429818   1.36531   0.130144                 0.493631  0.453011  0.205219                5377                   0.083947  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_1            0.428403   0.500272  0.126236                 0.496815  0.377023  0.142146                  98                   0.023326  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_17  0.425808   0.784547  0.125302                 0.493631  0.383995  0.147452                3647                   0.049925  DeepLearning\n",
       "GBM_5_AutoML_1_20230517_160832                         0.41472    0.575528  0.144189                 0.5       0.387267  0.149976                 109                   0.033661  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_11  0.411654   1.26974   0.11683                  0.489266  0.425947  0.181431                2627                   0.046707  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_6   0.407643   0.934306  0.119785                 0.5       0.392381  0.153963                5243                   0.082196  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_18  0.390422   1.11118   0.119721                 0.487261  0.384885  0.148137                4795                   0.0408    DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_11  0.386176   0.733369  0.121341                 0.5       0.389382  0.151618                2589                   0.063695  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_15  0.382637   1.17844   0.113316                 0.496815  0.38868   0.151072                2666                   0.109121  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_15  0.380986   1.41802   0.11367                  0.5       0.446597  0.199449                2668                   0.059841  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_4            0.374381   0.491893  0.110061                 0.496815  0.37681   0.141985                  76                   0.034177  GBM\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_8            0.372729   0.595315  0.119759                 0.493631  0.392748  0.154251                 161                   0.04897   GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230517_160832_model_22  0.368955   1.1096    0.109806                 0.5       0.409749  0.167895                3933                   0.058801  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_18           0.366832   0.596957  0.117026                 0.480892  0.386634  0.149486                 151                   0.052817  GBM\n",
       "GLM_1_AutoML_1_20230517_160832                         0.344893   0.477983  0.107925                 0.493631  0.374864  0.140523                  83                   0.036779  GLM\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_20           0.283793   0.503699  0.101192                 0.493631  0.377142  0.142236                  72                   0.044912  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_22  0.281906   1.36079   0.095807                 0.5       0.383224  0.146861                3858                   0.054315  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_18  0.281198   0.753328  0.113006                 0.5       0.377534  0.142532                3963                   0.056891  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230517_160832_model_11           0.278603   0.486507  0.100319                 0.5       0.373086  0.139194                  70                   0.030315  GBM\n",
       "XRT_1_AutoML_1_20230517_160832                         0.267988   0.482301  0.0989997                0.496815  0.380137  0.144504                 102                   0.044252  DRF\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_9   0.253362   1.08297   0.0948494                0.5       0.414355  0.17169                 2664                   0.046514  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230517_160832_model_17  0.242038   1.24204   0.091688                 0.5       0.383798  0.147301                3973                   0.054339  DeepLearning\n",
       "[93 rows x 10 columns]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.automl import H2OAutoML, get_leaderboard\n",
    "\n",
    "# Import a sample binary outcome train/test set into H2O\n",
    "train1 = h2o.H2OFrame(train)\n",
    "\n",
    "# Identify predictors and response\n",
    "predictors = ['year', 'film', 'wiki', 'rating', 'numVotes',\n",
    "       'worldwide_box_office', 'Action', 'Adventure', 'Animation', 'Biography',\n",
    "       'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy',\n",
    "       'Film-Noir', 'Game-Show', 'History', 'Horror', 'Music', 'Musical',\n",
    "       'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
    "       'Talk-Show', 'Thriller', 'War', 'Western', 'action', 'adventure',\n",
    "       'animation', 'biography', 'comedy', 'crime', 'documentary', 'drama',\n",
    "       'family', 'fantasy', 'film-noir', 'history', 'horror', 'music',\n",
    "       'musical', 'mystery', 'romance', 'sci-fi', 'sport', 'thriller', 'war',\n",
    "       'western', 'nominations', 'nom_gg_drama',\n",
    "       'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga',\n",
    "       'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga',\n",
    "       'nom_sag', 'winner_sag', 'nom_cannes', 'winner_cannes']\n",
    "\n",
    "x = predictors\n",
    "y = 'Oscar_win'\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train1[y] = train1[y].asfactor()\n",
    "\n",
    "# Run AutoML for 100 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=100, seed=1\n",
    "                , keep_cross_validation_predictions= True\n",
    "               , exclude_algos = ['StackedEnsemble'])\n",
    "\n",
    "aml.train(x=x, y=y, training_frame=train1)\n",
    "\n",
    "# AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "\n",
    "# Optionally edd extra model information to the leaderboard\n",
    "lb = get_leaderboard(aml, extra_columns='ALL')\n",
    "\n",
    "# Print all rows (instead of default 10 rows)\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_1_20230517_160832_model_4\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 16 402 weights/biases, 205,0 KB, 57 040 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>60</td>\n",
       "<td>Input</td>\n",
       "<td>10.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>100</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0214945</td>\n",
       "<td>0.0326449</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0016446</td>\n",
       "<td>0.1146021</td>\n",
       "<td>0.4955985</td>\n",
       "<td>0.0536342</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>100</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0246817</td>\n",
       "<td>0.0591674</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0018280</td>\n",
       "<td>0.1061949</td>\n",
       "<td>0.9973500</td>\n",
       "<td>0.0138586</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0075015</td>\n",
       "<td>0.0172336</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0276262</td>\n",
       "<td>0.5713830</td>\n",
       "<td>-0.0001904</td>\n",
       "<td>0.0063683</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.0013157007635092753\n",
       "RMSE: 0.03627258969951381\n",
       "LogLoss: 0.008036088363151436\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6689686039884123</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>157.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/157.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/27.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>157.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/184.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.6689686</td>\n",
       "<td>1.0</td>\n",
       "<td>24.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.6689686</td>\n",
       "<td>1.0</td>\n",
       "<td>24.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6689686</td>\n",
       "<td>1.0</td>\n",
       "<td>24.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6689686</td>\n",
       "<td>1.0</td>\n",
       "<td>24.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.6689686</td>\n",
       "<td>1.0</td>\n",
       "<td>24.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.6689686</td>\n",
       "<td>1.0</td>\n",
       "<td>24.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.6689686</td>\n",
       "<td>1.0</td>\n",
       "<td>24.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.6689686</td>\n",
       "<td>1.0</td>\n",
       "<td>24.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>157.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>26.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>157.0</td>\n",
       "<td>181.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.6689686</td>\n",
       "<td>27.0</td>\n",
       "<td>24.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9629630</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>181.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.6689686</td>\n",
       "<td>1.0</td>\n",
       "<td>24.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,67 %, avg score: 14,82 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0108696</td>\n",
       "<td>1.0000000</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.0740741</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.0740741</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0217391</td>\n",
       "<td>0.9999996</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.1481481</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.1481481</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0326087</td>\n",
       "<td>0.9999994</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999994</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999998</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2222222</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.2222222</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0434783</td>\n",
       "<td>0.9999961</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999979</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999993</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2962963</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.2962963</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0543478</td>\n",
       "<td>0.9999894</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999928</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999980</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.3703704</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.3703704</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1032609</td>\n",
       "<td>0.9988282</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996592</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998375</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.7037037</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.7037037</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1521739</td>\n",
       "<td>0.2187884</td>\n",
       "<td>6.0576132</td>\n",
       "<td>6.5714286</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.8560821</td>\n",
       "<td>0.9642857</td>\n",
       "<td>0.9536304</td>\n",
       "<td>0.2962963</td>\n",
       "<td>1.0</td>\n",
       "<td>505.7613169</td>\n",
       "<td>557.1428571</td>\n",
       "<td>0.9936306</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2010870</td>\n",
       "<td>0.0086375</td>\n",
       "<td>0.0</td>\n",
       "<td>4.9729730</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0529419</td>\n",
       "<td>0.7297297</td>\n",
       "<td>0.7345440</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>397.2972973</td>\n",
       "<td>0.9363057</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989130</td>\n",
       "<td>0.0010967</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3454545</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0041216</td>\n",
       "<td>0.4909091</td>\n",
       "<td>0.4954967</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>234.5454545</td>\n",
       "<td>0.8216561</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4021739</td>\n",
       "<td>0.0002643</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4864865</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0006405</td>\n",
       "<td>0.3648649</td>\n",
       "<td>0.3684390</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>148.6486486</td>\n",
       "<td>0.7006369</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0000820</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001745</td>\n",
       "<td>0.2934783</td>\n",
       "<td>0.2963873</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td>\n",
       "<td>0.5859873</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5978261</td>\n",
       "<td>0.0000240</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6727273</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000473</td>\n",
       "<td>0.2454545</td>\n",
       "<td>0.2478953</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2727273</td>\n",
       "<td>0.4713376</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010870</td>\n",
       "<td>0.0000020</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4263566</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000101</td>\n",
       "<td>0.2093023</td>\n",
       "<td>0.2113850</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6356589</td>\n",
       "<td>0.3503185</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7989130</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2517007</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000011</td>\n",
       "<td>0.1836735</td>\n",
       "<td>0.1855013</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1700680</td>\n",
       "<td>0.2356688</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8967391</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1151515</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000002</td>\n",
       "<td>0.1636364</td>\n",
       "<td>0.1652648</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.5151515</td>\n",
       "<td>0.1210191</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1467391</td>\n",
       "<td>0.1481994</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.15654629375876308\n",
       "RMSE: 0.3956593152685314\n",
       "LogLoss: 0.6807944444708204\n",
       "Mean Per-Class Error: 0.2928756782259967\n",
       "AUC: 0.7277659825430526\n",
       "AUCPR: 0.2917598632058581\n",
       "Gini: 0.45553196508610516</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2646394520105035</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>129.0</td>\n",
       "<td>28.0</td>\n",
       "<td>0.1783</td>\n",
       "<td> (28.0/157.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>11.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.4074</td>\n",
       "<td> (11.0/27.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>140.0</td>\n",
       "<td>44.0</td>\n",
       "<td>0.212</td>\n",
       "<td> (39.0/184.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2646395</td>\n",
       "<td>0.4507042</td>\n",
       "<td>43.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0120228</td>\n",
       "<td>0.5454545</td>\n",
       "<td>111.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3216408</td>\n",
       "<td>0.4010695</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9999064</td>\n",
       "<td>0.8532609</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999064</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000284</td>\n",
       "<td>1.0</td>\n",
       "<td>171.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999565</td>\n",
       "<td>0.9936306</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2646395</td>\n",
       "<td>0.3436390</td>\n",
       "<td>43.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0980590</td>\n",
       "<td>0.6666667</td>\n",
       "<td>69.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2646395</td>\n",
       "<td>0.7071243</td>\n",
       "<td>43.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999565</td>\n",
       "<td>156.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999565</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000017</td>\n",
       "<td>157.0</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0000284</td>\n",
       "<td>27.0</td>\n",
       "<td>171.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999565</td>\n",
       "<td>0.9936306</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999565</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000017</td>\n",
       "<td>1.0</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0000284</td>\n",
       "<td>1.0</td>\n",
       "<td>171.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,67 %, avg score: 19,54 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0108696</td>\n",
       "<td>0.9988691</td>\n",
       "<td>3.4074074</td>\n",
       "<td>3.4074074</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9999314</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9999314</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.0370370</td>\n",
       "<td>240.7407407</td>\n",
       "<td>240.7407407</td>\n",
       "<td>0.0306676</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0217391</td>\n",
       "<td>0.9957014</td>\n",
       "<td>0.0</td>\n",
       "<td>1.7037037</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9982266</td>\n",
       "<td>0.25</td>\n",
       "<td>0.999079</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0370370</td>\n",
       "<td>-100.0</td>\n",
       "<td>70.3703704</td>\n",
       "<td>0.0179288</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0326087</td>\n",
       "<td>0.9886823</td>\n",
       "<td>6.8148148</td>\n",
       "<td>3.4074074</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9921123</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9967568</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.1111111</td>\n",
       "<td>581.4814815</td>\n",
       "<td>240.7407407</td>\n",
       "<td>0.0920028</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0434783</td>\n",
       "<td>0.9794933</td>\n",
       "<td>0.0</td>\n",
       "<td>2.5555556</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9847626</td>\n",
       "<td>0.375</td>\n",
       "<td>0.9937582</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1111111</td>\n",
       "<td>-100.0</td>\n",
       "<td>155.5555556</td>\n",
       "<td>0.0792640</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0543478</td>\n",
       "<td>0.9684632</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0444444</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9716103</td>\n",
       "<td>0.3</td>\n",
       "<td>0.9893287</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1111111</td>\n",
       "<td>-100.0</td>\n",
       "<td>104.4444444</td>\n",
       "<td>0.0665251</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1032609</td>\n",
       "<td>0.7567447</td>\n",
       "<td>3.0288066</td>\n",
       "<td>2.5107212</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.8826603</td>\n",
       "<td>0.3684211</td>\n",
       "<td>0.9388015</td>\n",
       "<td>0.1481481</td>\n",
       "<td>0.2592593</td>\n",
       "<td>202.8806584</td>\n",
       "<td>151.0721248</td>\n",
       "<td>0.1828261</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1521739</td>\n",
       "<td>0.5519356</td>\n",
       "<td>1.5144033</td>\n",
       "<td>2.1904762</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.6115891</td>\n",
       "<td>0.3214286</td>\n",
       "<td>0.8336261</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.3333333</td>\n",
       "<td>51.4403292</td>\n",
       "<td>119.0476190</td>\n",
       "<td>0.2123142</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2010870</td>\n",
       "<td>0.3798985</td>\n",
       "<td>3.0288066</td>\n",
       "<td>2.3943944</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.4564636</td>\n",
       "<td>0.3513514</td>\n",
       "<td>0.7418839</td>\n",
       "<td>0.1481481</td>\n",
       "<td>0.4814815</td>\n",
       "<td>202.8806584</td>\n",
       "<td>139.4394394</td>\n",
       "<td>0.3286152</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989130</td>\n",
       "<td>0.1901348</td>\n",
       "<td>1.5144033</td>\n",
       "<td>2.1063973</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.2589926</td>\n",
       "<td>0.3090909</td>\n",
       "<td>0.5838467</td>\n",
       "<td>0.1481481</td>\n",
       "<td>0.6296296</td>\n",
       "<td>51.4403292</td>\n",
       "<td>110.6397306</td>\n",
       "<td>0.3875914</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4021739</td>\n",
       "<td>0.0832035</td>\n",
       "<td>0.3586745</td>\n",
       "<td>1.6576577</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.1223019</td>\n",
       "<td>0.2432432</td>\n",
       "<td>0.4653420</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.6666667</td>\n",
       "<td>-64.1325536</td>\n",
       "<td>65.7657658</td>\n",
       "<td>0.3099788</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0306377</td>\n",
       "<td>0.7572016</td>\n",
       "<td>1.4814815</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.0531623</td>\n",
       "<td>0.2173913</td>\n",
       "<td>0.3846981</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.7407407</td>\n",
       "<td>-24.2798354</td>\n",
       "<td>48.1481481</td>\n",
       "<td>0.2821420</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5978261</td>\n",
       "<td>0.0126479</td>\n",
       "<td>1.1358025</td>\n",
       "<td>1.4249158</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.0195067</td>\n",
       "<td>0.2090909</td>\n",
       "<td>0.3249395</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.8518519</td>\n",
       "<td>13.5802469</td>\n",
       "<td>42.4915825</td>\n",
       "<td>0.2977117</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010870</td>\n",
       "<td>0.0044954</td>\n",
       "<td>0.3586745</td>\n",
       "<td>1.2678725</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.0080190</td>\n",
       "<td>0.1860465</td>\n",
       "<td>0.2782613</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.8888889</td>\n",
       "<td>-64.1325536</td>\n",
       "<td>26.7872524</td>\n",
       "<td>0.2200991</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7989130</td>\n",
       "<td>0.0009370</td>\n",
       "<td>0.7572016</td>\n",
       "<td>1.2053414</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.0026726</td>\n",
       "<td>0.1768707</td>\n",
       "<td>0.2445158</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.9629630</td>\n",
       "<td>-24.2798354</td>\n",
       "<td>20.5341396</td>\n",
       "<td>0.1922623</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8967391</td>\n",
       "<td>0.0000946</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0738496</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004465</td>\n",
       "<td>0.1575758</td>\n",
       "<td>0.2178900</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9629630</td>\n",
       "<td>-100.0</td>\n",
       "<td>7.3849607</td>\n",
       "<td>0.0776126</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>1.65e-06</td>\n",
       "<td>0.3586745</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.0000283</td>\n",
       "<td>0.1467391</td>\n",
       "<td>0.1953934</td>\n",
       "<td>0.0370370</td>\n",
       "<td>1.0</td>\n",
       "<td>-64.1325536</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.6642643</td>\n",
       "<td>0.2266661</td>\n",
       "<td>0.2972973</td>\n",
       "<td>0.7837838</td>\n",
       "<td>0.7297297</td>\n",
       "<td>0.6216216</td>\n",
       "<td>0.8888889</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.6431072</td>\n",
       "<td>0.2132166</td>\n",
       "<td>0.2777778</td>\n",
       "<td>0.6714286</td>\n",
       "<td>0.7147059</td>\n",
       "<td>0.7156863</td>\n",
       "<td>0.8359375</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.3357357</td>\n",
       "<td>0.2266661</td>\n",
       "<td>0.7027027</td>\n",
       "<td>0.2162162</td>\n",
       "<td>0.2702703</td>\n",
       "<td>0.3783784</td>\n",
       "<td>0.1111111</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>12.4</td>\n",
       "<td>8.414273</td>\n",
       "<td>26.0</td>\n",
       "<td>8.0</td>\n",
       "<td>10.0</td>\n",
       "<td>14.0</td>\n",
       "<td>4.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.3220161</td>\n",
       "<td>0.2730214</td>\n",
       "<td>0.0458716</td>\n",
       "<td>0.1470588</td>\n",
       "<td>0.7058824</td>\n",
       "<td>0.2112676</td>\n",
       "<td>0.5</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.3554622</td>\n",
       "<td>0.2508013</td>\n",
       "<td>0.0714286</td>\n",
       "<td>0.2</td>\n",
       "<td>0.7058824</td>\n",
       "<td>0.3</td>\n",
       "<td>0.5</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.4393828</td>\n",
       "<td>0.2086822</td>\n",
       "<td>0.1612903</td>\n",
       "<td>0.3125</td>\n",
       "<td>0.7058824</td>\n",
       "<td>0.5172414</td>\n",
       "<td>0.5</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>0.4352941</td>\n",
       "<td>0.9733472</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.1764705</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.6786211</td>\n",
       "<td>0.3705543</td>\n",
       "<td>0.7415181</td>\n",
       "<td>0.3405579</td>\n",
       "<td>1.1631782</td>\n",
       "<td>0.8691218</td>\n",
       "<td>0.2787296</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.4856209</td>\n",
       "<td>0.1569410</td>\n",
       "<td>0.7222222</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2941177</td>\n",
       "<td>0.4117647</td>\n",
       "<td>0.5</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.2963581</td>\n",
       "<td>0.1591727</td>\n",
       "<td>0.1014301</td>\n",
       "<td>0.1647883</td>\n",
       "<td>0.4558823</td>\n",
       "<td>0.3221897</td>\n",
       "<td>0.4375</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.7059395</td>\n",
       "<td>0.0633415</td>\n",
       "<td>0.6388889</td>\n",
       "<td>0.65</td>\n",
       "<td>0.7279412</td>\n",
       "<td>0.7941176</td>\n",
       "<td>0.71875</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.2940605</td>\n",
       "<td>0.0633415</td>\n",
       "<td>0.3611111</td>\n",
       "<td>0.35</td>\n",
       "<td>0.2720588</td>\n",
       "<td>0.2058824</td>\n",
       "<td>0.28125</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1561583</td>\n",
       "<td>0.0761156</td>\n",
       "<td>0.1595304</td>\n",
       "<td>0.0781754</td>\n",
       "<td>0.2549186</td>\n",
       "<td>0.2033981</td>\n",
       "<td>0.0847691</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.2434206</td>\n",
       "<td>0.2734772</td>\n",
       "<td>0.0187515</td>\n",
       "<td>0.0753728</td>\n",
       "<td>0.6928003</td>\n",
       "<td>0.1231779</td>\n",
       "<td>0.3070005</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.308878</td>\n",
       "<td>0.2825687</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.125</td>\n",
       "<td>0.7058824</td>\n",
       "<td>0.1764706</td>\n",
       "<td>0.5</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>-1.4420208</td>\n",
       "<td>2.1544316</td>\n",
       "<td>-5.0665855</td>\n",
       "<td>-0.5288878</td>\n",
       "<td>-0.0264223</td>\n",
       "<td>-1.7299213</td>\n",
       "<td>0.1417132</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.7411765</td>\n",
       "<td>0.2507773</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5</td>\n",
       "<td>0.7058824</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3852108</td>\n",
       "<td>0.0985581</td>\n",
       "<td>0.3994125</td>\n",
       "<td>0.2795987</td>\n",
       "<td>0.5048947</td>\n",
       "<td>0.4509968</td>\n",
       "<td>0.2911513</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.6707026</td>\n",
       "<td>0.2526745</td>\n",
       "<td>0.2777778</td>\n",
       "<td>0.8</td>\n",
       "<td>0.75</td>\n",
       "<td>0.5882353</td>\n",
       "<td>0.9375</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-10.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-10 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-10 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-10 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table th,\n",
       "#h2o-table-10 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2023-05-17 16:18:22</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-17 16:18:22</td>\n",
       "<td> 1 min 21.217 sec</td>\n",
       "<td>10395 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>1</td>\n",
       "<td>1840.0</td>\n",
       "<td>0.2618196</td>\n",
       "<td>0.3019938</td>\n",
       "<td>0.4525096</td>\n",
       "<td>0.8766218</td>\n",
       "<td>0.7288698</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0760870</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-17 16:18:27</td>\n",
       "<td> 1 min 26.268 sec</td>\n",
       "<td>10941 obs/sec</td>\n",
       "<td>310.0</td>\n",
       "<td>31</td>\n",
       "<td>57040.0</td>\n",
       "<td>0.0362726</td>\n",
       "<td>0.0080361</td>\n",
       "<td>0.9894918</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-11.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-11 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-11 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-11 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table th,\n",
       "#h2o-table-11 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>rating</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0203214</td></tr>\n",
       "<tr><td>history</td>\n",
       "<td>0.9418703</td>\n",
       "<td>0.9418703</td>\n",
       "<td>0.0191401</td></tr>\n",
       "<tr><td>year</td>\n",
       "<td>0.9267902</td>\n",
       "<td>0.9267902</td>\n",
       "<td>0.0188337</td></tr>\n",
       "<tr><td>winner_dga</td>\n",
       "<td>0.9249073</td>\n",
       "<td>0.9249073</td>\n",
       "<td>0.0187954</td></tr>\n",
       "<tr><td>numVotes</td>\n",
       "<td>0.9177409</td>\n",
       "<td>0.9177409</td>\n",
       "<td>0.0186498</td></tr>\n",
       "<tr><td>drama</td>\n",
       "<td>0.9001114</td>\n",
       "<td>0.9001114</td>\n",
       "<td>0.0182915</td></tr>\n",
       "<tr><td>comedy</td>\n",
       "<td>0.8966504</td>\n",
       "<td>0.8966504</td>\n",
       "<td>0.0182212</td></tr>\n",
       "<tr><td>Action</td>\n",
       "<td>0.8904843</td>\n",
       "<td>0.8904843</td>\n",
       "<td>0.0180959</td></tr>\n",
       "<tr><td>Sci-Fi</td>\n",
       "<td>0.8891483</td>\n",
       "<td>0.8891483</td>\n",
       "<td>0.0180687</td></tr>\n",
       "<tr><td>Documentary</td>\n",
       "<td>0.8787389</td>\n",
       "<td>0.8787389</td>\n",
       "<td>0.0178572</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>Drama</td>\n",
       "<td>0.7611824</td>\n",
       "<td>0.7611824</td>\n",
       "<td>0.0154683</td></tr>\n",
       "<tr><td>Western</td>\n",
       "<td>0.7610842</td>\n",
       "<td>0.7610842</td>\n",
       "<td>0.0154663</td></tr>\n",
       "<tr><td>Music</td>\n",
       "<td>0.7608458</td>\n",
       "<td>0.7608458</td>\n",
       "<td>0.0154614</td></tr>\n",
       "<tr><td>Mystery</td>\n",
       "<td>0.7587873</td>\n",
       "<td>0.7587873</td>\n",
       "<td>0.0154196</td></tr>\n",
       "<tr><td>nom_gg_drama</td>\n",
       "<td>0.7566208</td>\n",
       "<td>0.7566208</td>\n",
       "<td>0.0153756</td></tr>\n",
       "<tr><td>musical</td>\n",
       "<td>0.7531514</td>\n",
       "<td>0.7531514</td>\n",
       "<td>0.0153051</td></tr>\n",
       "<tr><td>Talk-Show</td>\n",
       "<td>0.7475410</td>\n",
       "<td>0.7475410</td>\n",
       "<td>0.0151911</td></tr>\n",
       "<tr><td>crime</td>\n",
       "<td>0.7424588</td>\n",
       "<td>0.7424588</td>\n",
       "<td>0.0150878</td></tr>\n",
       "<tr><td>sci-fi</td>\n",
       "<td>0.7208604</td>\n",
       "<td>0.7208604</td>\n",
       "<td>0.0146489</td></tr>\n",
       "<tr><td>Short</td>\n",
       "<td>0.7073084</td>\n",
       "<td>0.7073084</td>\n",
       "<td>0.0143735</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[60 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_1_20230517_160832_model_4\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 16 402 weights/biases, 205,0 KB, 57 040 training samples, mini-batch size 1\n",
       "    layer    units    type              dropout    l1    l2    mean_rate             rate_rms             momentum    mean_weight             weight_rms           mean_bias               bias_rms\n",
       "--  -------  -------  ----------------  ---------  ----  ----  --------------------  -------------------  ----------  ----------------------  -------------------  ----------------------  --------------------\n",
       "    1        60       Input             10.0\n",
       "    2        100      RectifierDropout  0.0        0.0   0.0   0.02149445718031105   0.0326448529958725   0.0         0.0016446201505411107   0.11460211873054504  0.4955984703253772      0.0536341518163681\n",
       "    3        100      RectifierDropout  0.0        0.0   0.0   0.024681739731851848  0.05916735529899597  0.0         -0.0018280174089241427  0.1061948835849762   0.9973499979376966      0.013858620077371597\n",
       "    4        2        Softmax                      0.0   0.0   0.007501548861619085  0.01723358780145645  0.0         0.027626219384837895    0.571382999420166    -0.0001903927322003127  0.006368305534124374\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.0013157007635092753\n",
       "RMSE: 0.03627258969951381\n",
       "LogLoss: 0.008036088363151436\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6689686039884123\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      157  0    0        (0.0/157.0)\n",
       "1      0    27   0        (0.0/27.0)\n",
       "Total  157  27   0        (0.0/184.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.668969     1         24\n",
       "max f2                       0.668969     1         24\n",
       "max f0point5                 0.668969     1         24\n",
       "max accuracy                 0.668969     1         24\n",
       "max precision                1            1         0\n",
       "max recall                   0.668969     1         24\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.668969     1         24\n",
       "max min_per_class_accuracy   0.668969     1         24\n",
       "max mean_per_class_accuracy  0.668969     1         24\n",
       "max tns                      1            157       0\n",
       "max fns                      1            26        0\n",
       "max fps                      1.53053e-14  157       181\n",
       "max tps                      0.668969     27        24\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.962963  0\n",
       "max fpr                      1.53053e-14  1         181\n",
       "max tpr                      0.668969     1         24\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,67 %, avg score: 14,82 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0108696                   1                  6.81481  6.81481            1                1            1                           1                   0.0740741       0.0740741                  581.481  581.481            0.0740741\n",
       "2        0.0217391                   1                  6.81481  6.81481            1                1            1                           1                   0.0740741       0.148148                   581.481  581.481            0.148148\n",
       "3        0.0326087                   0.999999           6.81481  6.81481            1                0.999999     1                           1                   0.0740741       0.222222                   581.481  581.481            0.222222\n",
       "4        0.0434783                   0.999996           6.81481  6.81481            1                0.999998     1                           0.999999            0.0740741       0.296296                   581.481  581.481            0.296296\n",
       "5        0.0543478                   0.999989           6.81481  6.81481            1                0.999993     1                           0.999998            0.0740741       0.37037                    581.481  581.481            0.37037\n",
       "6        0.103261                    0.998828           6.81481  6.81481            1                0.999659     1                           0.999838            0.333333        0.703704                   581.481  581.481            0.703704\n",
       "7        0.152174                    0.218788           6.05761  6.57143            0.888889         0.856082     0.964286                    0.95363             0.296296        1                          505.761  557.143            0.993631\n",
       "8        0.201087                    0.00863751         0        4.97297            0                0.0529419    0.72973                     0.734544            0               1                          -100     397.297            0.936306\n",
       "9        0.298913                    0.00109666         0        3.34545            0                0.00412161   0.490909                    0.495497            0               1                          -100     234.545            0.821656\n",
       "10       0.402174                    0.000264335        0        2.48649            0                0.00064052   0.364865                    0.368439            0               1                          -100     148.649            0.700637\n",
       "11       0.5                         8.19814e-05        0        2                  0                0.000174482  0.293478                    0.296387            0               1                          -100     100                0.585987\n",
       "12       0.597826                    2.40246e-05        0        1.67273            0                4.7268e-05   0.245455                    0.247895            0               1                          -100     67.2727            0.471338\n",
       "13       0.701087                    2.0233e-06         0        1.42636            0                1.00597e-05  0.209302                    0.211385            0               1                          -100     42.6357            0.350318\n",
       "14       0.798913                    4.68544e-07        0        1.2517             0                1.12575e-06  0.183673                    0.185501            0               1                          -100     25.1701            0.235669\n",
       "15       0.896739                    3.08317e-08        0        1.11515            0                1.67216e-07  0.163636                    0.165265            0               1                          -100     11.5152            0.121019\n",
       "16       1                           1.53053e-14        0        1                  0                5.12191e-09  0.146739                    0.148199            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.15654629375876308\n",
       "RMSE: 0.3956593152685314\n",
       "LogLoss: 0.6807944444708204\n",
       "Mean Per-Class Error: 0.2928756782259967\n",
       "AUC: 0.7277659825430526\n",
       "AUCPR: 0.2917598632058581\n",
       "Gini: 0.45553196508610516\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2646394520105035\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      129  28   0.1783   (28.0/157.0)\n",
       "1      11   16   0.4074   (11.0/27.0)\n",
       "Total  140  44   0.212    (39.0/184.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.264639     0.450704  43\n",
       "max f2                       0.0120228    0.545455  111\n",
       "max f0point5                 0.321641     0.40107   39\n",
       "max accuracy                 0.999906     0.853261  1\n",
       "max precision                0.999906     0.5       1\n",
       "max recall                   2.84499e-05  1         171\n",
       "max specificity              0.999957     0.993631  0\n",
       "max absolute_mcc             0.264639     0.343639  43\n",
       "max min_per_class_accuracy   0.098059     0.666667  69\n",
       "max mean_per_class_accuracy  0.264639     0.707124  43\n",
       "max tns                      0.999957     156       0\n",
       "max fns                      0.999957     27        0\n",
       "max fps                      1.6518e-06   157       183\n",
       "max tps                      2.84499e-05  27        171\n",
       "max tnr                      0.999957     0.993631  0\n",
       "max fnr                      0.999957     1         0\n",
       "max fpr                      1.6518e-06   1         183\n",
       "max tpr                      2.84499e-05  1         171\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,67 %, avg score: 19,54 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0108696                   0.998869           3.40741   3.40741            0.5              0.999931     0.5                         0.999931            0.037037        0.037037                   240.741   240.741            0.0306676\n",
       "2        0.0217391                   0.995701           0         1.7037             0                0.998227     0.25                        0.999079            0               0.037037                   -100      70.3704            0.0179288\n",
       "3        0.0326087                   0.988682           6.81481   3.40741            1                0.992112     0.5                         0.996757            0.0740741       0.111111                   581.481   240.741            0.0920028\n",
       "4        0.0434783                   0.979493           0         2.55556            0                0.984763     0.375                       0.993758            0               0.111111                   -100      155.556            0.079264\n",
       "5        0.0543478                   0.968463           0         2.04444            0                0.97161      0.3                         0.989329            0               0.111111                   -100      104.444            0.0665251\n",
       "6        0.103261                    0.756745           3.02881   2.51072            0.444444         0.88266      0.368421                    0.938802            0.148148        0.259259                   202.881   151.072            0.182826\n",
       "7        0.152174                    0.551936           1.5144    2.19048            0.222222         0.611589     0.321429                    0.833626            0.0740741       0.333333                   51.4403   119.048            0.212314\n",
       "8        0.201087                    0.379898           3.02881   2.39439            0.444444         0.456464     0.351351                    0.741884            0.148148        0.481481                   202.881   139.439            0.328615\n",
       "9        0.298913                    0.190135           1.5144    2.1064             0.222222         0.258993     0.309091                    0.583847            0.148148        0.62963                    51.4403   110.64             0.387591\n",
       "10       0.402174                    0.0832035          0.358674  1.65766            0.0526316        0.122302     0.243243                    0.465342            0.037037        0.666667                   -64.1326  65.7658            0.309979\n",
       "11       0.5                         0.0306377          0.757202  1.48148            0.111111         0.0531623    0.217391                    0.384698            0.0740741       0.740741                   -24.2798  48.1481            0.282142\n",
       "12       0.597826                    0.0126479          1.1358    1.42492            0.166667         0.0195067    0.209091                    0.32494             0.111111        0.851852                   13.5802   42.4916            0.297712\n",
       "13       0.701087                    0.00449543         0.358674  1.26787            0.0526316        0.00801898   0.186047                    0.278261            0.037037        0.888889                   -64.1326  26.7873            0.220099\n",
       "14       0.798913                    0.000937016        0.757202  1.20534            0.111111         0.00267263   0.176871                    0.244516            0.0740741       0.962963                   -24.2798  20.5341            0.192262\n",
       "15       0.896739                    9.4571e-05         0         1.07385            0                0.000446523  0.157576                    0.21789             0               0.962963                   -100      7.38496            0.0776126\n",
       "16       1                           1.65e-06           0.358674  1                  0.0526316        2.83274e-05  0.146739                    0.195393            0.037037        1                          -64.1326  0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean      sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.664264  0.226666   0.297297      0.783784      0.72973       0.621622      0.888889\n",
       "auc                      0.643107  0.213217   0.277778      0.671429      0.714706      0.715686      0.835938\n",
       "err                      0.335736  0.226666   0.702703      0.216216      0.27027       0.378378      0.111111\n",
       "err_count                12.4      8.41427    26            8             10            14            4\n",
       "f0point5                 0.322016  0.273021   0.0458716     0.147059      0.705882      0.211268      0.5\n",
       "f1                       0.355462  0.250801   0.0714286     0.2           0.705882      0.3           0.5\n",
       "f2                       0.439383  0.208682   0.16129       0.3125        0.705882      0.517241      0.5\n",
       "lift_top_group           0.435294  0.973347   0             0             2.17647       0             0\n",
       "logloss                  0.678621  0.370554   0.741518      0.340558      1.16318       0.869122      0.27873\n",
       "max_per_class_error      0.485621  0.156941   0.722222      0.5           0.294118      0.411765      0.5\n",
       "mcc                      0.296358  0.159173   0.10143       0.164788      0.455882      0.32219       0.4375\n",
       "mean_per_class_accuracy  0.70594   0.0633415  0.638889      0.65          0.727941      0.794118      0.71875\n",
       "mean_per_class_error     0.29406   0.0633415  0.361111      0.35          0.272059      0.205882      0.28125\n",
       "mse                      0.156158  0.0761156  0.15953       0.0781754     0.254919      0.203398      0.0847691\n",
       "pr_auc                   0.243421  0.273477   0.0187515     0.0753728     0.6928        0.123178      0.307001\n",
       "precision                0.308878  0.282569   0.037037      0.125         0.705882      0.176471      0.5\n",
       "r2                       -1.44202  2.15443    -5.06659      -0.528888     -0.0264223    -1.72992      0.141713\n",
       "recall                   0.741177  0.250777   1             0.5           0.705882      1             0.5\n",
       "rmse                     0.385211  0.0985581  0.399413      0.279599      0.504895      0.450997      0.291151\n",
       "specificity              0.670703  0.252674   0.277778      0.8           0.75          0.588235      0.9375\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2023-05-17 16:18:22  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan\n",
       "    2023-05-17 16:18:22  1 min 21.217 sec  10395 obs/sec     10        1             1840       0.26182          0.301994            0.45251        0.876622        0.72887            6.81481          0.076087\n",
       "    2023-05-17 16:18:27  1 min 26.268 sec  10941 obs/sec     310       31            57040      0.0362726        0.00803609          0.989492       1               1                  6.81481          0\n",
       "\n",
       "Variable Importances: \n",
       "variable      relative_importance    scaled_importance    percentage\n",
       "------------  ---------------------  -------------------  --------------------\n",
       "rating        1.0                    1.0                  0.020321377976583118\n",
       "history       0.9418702721595764     0.9418702721595764   0.019140101805461964\n",
       "year          0.9267902374267578     0.9267902374267578   0.018833654719756357\n",
       "winner_dga    0.9249073266983032     0.9249073266983032   0.018795391379147267\n",
       "numVotes      0.9177409410476685     0.9177409410476685   0.018649760547614757\n",
       "drama         0.9001114368438721     0.9001114368438721   0.01829150472914965\n",
       "comedy        0.8966504335403442     0.8966504335403442   0.018221172372840457\n",
       "Action        0.8904842734336853     0.8904842734336853   0.018095867502648914\n",
       "Sci-Fi        0.8891482949256897     0.8891482949256897   0.01806871857841934\n",
       "Documentary   0.8787388801574707     0.8787388801574707   0.017857184926399337\n",
       "---           ---                    ---                  ---\n",
       "Drama         0.761182427406311      0.761182427406311    0.015468275816456687\n",
       "Western       0.7610841989517212     0.7610841989517212   0.015466279678902912\n",
       "Music         0.7608458399772644     0.7608458399772644   0.015461435896088865\n",
       "Mystery       0.7587872743606567     0.7587872743606567   0.015419603006104182\n",
       "nom_gg_drama  0.7566208243370056     0.7566208243370056   0.015375577756306191\n",
       "musical       0.7531514167785645     0.7531514167785645   0.015305074613956294\n",
       "Talk-Show     0.7475410103797913     0.7475410103797913   0.015191063424924583\n",
       "crime         0.7424587607383728     0.7424587607383728   0.015087785108989964\n",
       "sci-fi        0.7208604216575623     0.7208604216575623   0.014648877096862406\n",
       "Short         0.7073084115982056     0.7073084115982056   0.014373481578103763\n",
       "[60 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model = aml.leader\n",
    "top_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Predict on 2019's films\n",
    "test = full_table.loc[(full_table['year'] == 2021)]\n",
    "\n",
    "# Import a binary outcome train/test set into H2O\n",
    "test = h2o.H2OFrame(test)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">        p0</th><th style=\"text-align: right;\">         p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999976  </td><td style=\"text-align: right;\">2.37118e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.00165605</td><td style=\"text-align: right;\">0.998344   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.995174  </td><td style=\"text-align: right;\">0.00482619 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1         </td><td style=\"text-align: right;\">1.74511e-07</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.995249  </td><td style=\"text-align: right;\">0.00475117 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999972  </td><td style=\"text-align: right;\">2.78123e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999979  </td><td style=\"text-align: right;\">2.0885e-05 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1         </td><td style=\"text-align: right;\">9.07248e-09</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999955  </td><td style=\"text-align: right;\">4.5392e-05 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999999  </td><td style=\"text-align: right;\">1.10776e-06</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 3 columns]</pre>"
      ],
      "text/plain": [
       "  predict          p0           p1\n",
       "---------  ----------  -----------\n",
       "        0  0.999976    2.37118e-05\n",
       "        1  0.00165605  0.998344\n",
       "        0  0.995174    0.00482619\n",
       "        0  1           1.74511e-07\n",
       "        0  0.995249    0.00475117\n",
       "        0  0.999972    2.78123e-05\n",
       "        0  0.999979    2.0885e-05\n",
       "        0  1           9.07248e-09\n",
       "        0  0.999955    4.5392e-05\n",
       "        0  0.999999    1.10776e-06\n",
       "[10 rows x 3 columns]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = top_model.predict(test)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred'] = preds['predict']\n",
    "test['probA'] = preds['p1']\n",
    "test_pd = test.as_data_frame(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>probA</th>\n",
       "      <th>%_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CODA</td>\n",
       "      <td>9.983440e-01</td>\n",
       "      <td>9.903809e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Belfast</td>\n",
       "      <td>4.826187e-03</td>\n",
       "      <td>4.787692e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drive My Car</td>\n",
       "      <td>4.751175e-03</td>\n",
       "      <td>4.713278e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nightmare Alley</td>\n",
       "      <td>4.539204e-05</td>\n",
       "      <td>4.502998e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dune</td>\n",
       "      <td>2.781235e-05</td>\n",
       "      <td>2.759051e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West Side Story</td>\n",
       "      <td>2.371181e-05</td>\n",
       "      <td>2.352268e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>King Richard</td>\n",
       "      <td>2.088495e-05</td>\n",
       "      <td>2.071837e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Power of the Dog</td>\n",
       "      <td>1.107759e-06</td>\n",
       "      <td>1.098923e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Don't Look Up</td>\n",
       "      <td>1.745112e-07</td>\n",
       "      <td>1.731192e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Licorice Pizza</td>\n",
       "      <td>9.072485e-09</td>\n",
       "      <td>9.000120e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    film         probA  %_confidence\n",
       "1                  CODA   9.983440e-01  9.903809e+01\n",
       "2               Belfast   4.826187e-03  4.787692e-01\n",
       "4          Drive My Car   4.751175e-03  4.713278e-01\n",
       "8       Nightmare Alley   4.539204e-05  4.502998e-03\n",
       "5                  Dune   2.781235e-05  2.759051e-03\n",
       "0       West Side Story   2.371181e-05  2.352268e-03\n",
       "6          King Richard   2.088495e-05  2.071837e-03\n",
       "9  The Power of the Dog   1.107759e-06  1.098923e-04\n",
       "3          Don't Look Up  1.745112e-07  1.731192e-05\n",
       "7         Licorice Pizza  9.072485e-09  9.000120e-07"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rankings = test_pd[['film','probA']].sort_values('probA', ascending = False)\n",
    "final_rankings['%_confidence'] = final_rankings['probA']/final_rankings['probA'].sum() * 100\n",
    "final_rankings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And the Oscar goes to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And the Oscar goes to...\n",
      "🎉🏆1917🏆🎉\n"
     ]
    }
   ],
   "source": [
    "bp_winner = np.array(final_rankings.reset_index())[0][1].split('(')[0].strip()\n",
    "print(f'And the Oscar goes to...\\n🎉🏆{bp_winner}🏆🎉')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
