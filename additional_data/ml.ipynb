{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-Oscar Prediction with AutoML\n",
    "After out dataframe has been assemlbed (see scraping and table_assembling) notebooks we have the data we need to make predictions on the Best Picture winner. [AutoML](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html) represents a quick, but powerful route though the Machine Learning process. H2O's AutoML runs many models through the dataset and using cross-validation, picks the best one. For my purposes I use it to confirm/compare to the Preferential Balloting Random Forest model I created.\n",
    "If you are gunning to win your office's Oscar pool, scroll down to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h2o"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Using h2o Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>film</th>\n",
       "      <th>wiki</th>\n",
       "      <th>winner</th>\n",
       "      <th>rating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>worldwide_box_office</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_pga</th>\n",
       "      <th>winner_pga</th>\n",
       "      <th>nom_bafta</th>\n",
       "      <th>winner_bafta</th>\n",
       "      <th>nom_dga</th>\n",
       "      <th>winner_dga</th>\n",
       "      <th>nom_sag</th>\n",
       "      <th>winner_sag</th>\n",
       "      <th>nom_cannes</th>\n",
       "      <th>winner_cannes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1927</td>\n",
       "      <td>Wings</td>\n",
       "      <td>/wiki/Wings_(1927_film)</td>\n",
       "      <td>True</td>\n",
       "      <td>7.3</td>\n",
       "      <td>13576.0</td>\n",
       "      <td>$746</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1927</td>\n",
       "      <td>7th Heaven</td>\n",
       "      <td>/wiki/7th_Heaven_(1927_film)</td>\n",
       "      <td>False</td>\n",
       "      <td>5.2</td>\n",
       "      <td>26223.0</td>\n",
       "      <td>$79,808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1927</td>\n",
       "      <td>The Racket</td>\n",
       "      <td>/wiki/The_Racket_(1928_film)</td>\n",
       "      <td>False</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3149.0</td>\n",
       "      <td>$21,733,230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1928</td>\n",
       "      <td>The Broadway Melody</td>\n",
       "      <td>/wiki/The_Broadway_Melody</td>\n",
       "      <td>True</td>\n",
       "      <td>5.6</td>\n",
       "      <td>7605.0</td>\n",
       "      <td>$223,723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1928</td>\n",
       "      <td>Alibi</td>\n",
       "      <td>/wiki/Alibi_(1929_film)</td>\n",
       "      <td>False</td>\n",
       "      <td>7.4</td>\n",
       "      <td>391.0</td>\n",
       "      <td>$42,915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2022</td>\n",
       "      <td>The Fabelmans</td>\n",
       "      <td>/wiki/The_Fabelmans</td>\n",
       "      <td>False</td>\n",
       "      <td>7.6</td>\n",
       "      <td>85709.0</td>\n",
       "      <td>$45,164,110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2022</td>\n",
       "      <td>TÃ¡r</td>\n",
       "      <td>/wiki/T%C3%A1r</td>\n",
       "      <td>False</td>\n",
       "      <td>7.5</td>\n",
       "      <td>69684.0</td>\n",
       "      <td>$27,541,681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>2022</td>\n",
       "      <td>Top Gun: Maverick</td>\n",
       "      <td>/wiki/Top_Gun:_Maverick</td>\n",
       "      <td>False</td>\n",
       "      <td>8.3</td>\n",
       "      <td>577408.0</td>\n",
       "      <td>$1,493,491,858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>2022</td>\n",
       "      <td>Triangle of Sadness</td>\n",
       "      <td>/wiki/Triangle_of_Sadness</td>\n",
       "      <td>False</td>\n",
       "      <td>7.3</td>\n",
       "      <td>128812.0</td>\n",
       "      <td>$25,615,870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>2022</td>\n",
       "      <td>Women Talking</td>\n",
       "      <td>/wiki/Women_Talking_(film)</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>29341.0</td>\n",
       "      <td>$8,954,708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551 rows Ã 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year                 film                          wiki  winner  rating  \\\n",
       "0    1927               Wings        /wiki/Wings_(1927_film)    True     7.3   \n",
       "1    1927          7th Heaven   /wiki/7th_Heaven_(1927_film)   False     5.2   \n",
       "2    1927          The Racket   /wiki/The_Racket_(1928_film)   False     6.7   \n",
       "3    1928  The Broadway Melody     /wiki/The_Broadway_Melody    True     5.6   \n",
       "4    1928               Alibi        /wiki/Alibi_(1929_film)   False     7.4   \n",
       "..    ...                  ...                           ...     ...     ...   \n",
       "546  2022        The Fabelmans           /wiki/The_Fabelmans   False     7.6   \n",
       "547  2022                  TÃ¡r                /wiki/T%C3%A1r   False     7.5   \n",
       "548  2022    Top Gun: Maverick       /wiki/Top_Gun:_Maverick   False     8.3   \n",
       "549  2022  Triangle of Sadness     /wiki/Triangle_of_Sadness   False     7.3   \n",
       "550  2022       Women Talking     /wiki/Women_Talking_(film)   False     6.9   \n",
       "\n",
       "     numVotes worldwide_box_office  Action  Adventure  Animation  ...  \\\n",
       "0     13576.0                 $746       0          0          0  ...   \n",
       "1     26223.0              $79,808       0          0          0  ...   \n",
       "2      3149.0          $21,733,230       0          0          0  ...   \n",
       "3      7605.0             $223,723       0          0          0  ...   \n",
       "4       391.0              $42,915       0          0          0  ...   \n",
       "..        ...                  ...     ...        ...        ...  ...   \n",
       "546   85709.0          $45,164,110       0          0          0  ...   \n",
       "547   69684.0          $27,541,681       0          0          0  ...   \n",
       "548  577408.0       $1,493,491,858       0          0          0  ...   \n",
       "549  128812.0          $25,615,870       0          0          0  ...   \n",
       "550   29341.0           $8,954,708       0          0          0  ...   \n",
       "\n",
       "     nom_pga  winner_pga  nom_bafta  winner_bafta  nom_dga  winner_dga  \\\n",
       "0          0           0          0             0        0           0   \n",
       "1          0           0          0             0        0           0   \n",
       "2          0           0          0             0        0           0   \n",
       "3          0           0          0             0        0           0   \n",
       "4          0           0          0             0        0           0   \n",
       "..       ...         ...        ...           ...      ...         ...   \n",
       "546        1           0          0             0        1           0   \n",
       "547        1           0          1             0        1           0   \n",
       "548        1           0          0             0        1           0   \n",
       "549        0           0          0             0        0           0   \n",
       "550        0           0          0             0        0           0   \n",
       "\n",
       "     nom_sag  winner_sag  nom_cannes  winner_cannes  \n",
       "0          0           0           0              0  \n",
       "1          0           0           0              0  \n",
       "2          0           0           0              0  \n",
       "3          0           0           0              0  \n",
       "4          0           0           0              0  \n",
       "..       ...         ...         ...            ...  \n",
       "546        1           0           0              0  \n",
       "547        0           0           0              0  \n",
       "548        0           0           0              0  \n",
       "549        0           0           1              1  \n",
       "550        0           0           0              0  \n",
       "\n",
       "[551 rows x 72 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_table = pd.read_csv('../data/processed_results/extended_df.csv')\n",
    "full_table=full_table.drop('Unnamed: 0', axis=1)\n",
    "full_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 day 17 hours 8 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Belgrade</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>20 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_aczaplak_wkb9zy</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.524 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.9 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -------------------------------\n",
       "H2O_cluster_uptime:         1 day 17 hours 8 mins\n",
       "H2O_cluster_timezone:       Europe/Belgrade\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    20 days\n",
       "H2O_cluster_name:           H2O_from_python_aczaplak_wkb9zy\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.524 Gb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.9 final\n",
       "--------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Year of Existance. This data will be used below\n",
    "- golden_globes 1943\n",
    "- pga 1989\n",
    "- bafta 1960\n",
    "- dga 1948\n",
    "- sag 1995\n",
    "- cannes 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I pick a min_year where the awards shows will be relevant\n",
    "min_year = 1995"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O's Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set contains: 184 movies\n"
     ]
    }
   ],
   "source": [
    "# Auto ML uses Cross Validation, so we do not specifiy a validation set\n",
    "train = full_table.loc[((full_table['year'] < 2022) & (full_table['year'] >= min_year))]\n",
    "\n",
    "print('training set contains:', train.shape[0], 'movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'film', 'wiki', 'winner', 'rating', 'numVotes',\n",
       "       'worldwide_box_office', 'Action', 'Adventure', 'Animation', 'Biography',\n",
       "       'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy',\n",
       "       'Film-Noir', 'Game-Show', 'History', 'Horror', 'Music', 'Musical',\n",
       "       'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
       "       'Talk-Show', 'Thriller', 'War', 'Western', 'action', 'adventure',\n",
       "       'animation', 'biography', 'comedy', 'crime', 'documentary', 'drama',\n",
       "       'family', 'fantasy', 'film-noir', 'history', 'horror', 'music',\n",
       "       'musical', 'mystery', 'romance', 'sci-fi', 'sport', 'thriller', 'war',\n",
       "       'western', 'nominations', 'Oscar_win', 'nom_gg_drama',\n",
       "       'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga',\n",
       "       'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga',\n",
       "       'nom_sag', 'winner_sag', 'nom_cannes', 'winner_cannes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train = train.drop(['index', '[]'], axis=1)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| (done) 100%\n",
      "AutoML progress: |â\n",
      "09:19:06.887: AutoML: XGBoost is not available; skipping it.\n",
      "09:19:06.903: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "09:19:07.410: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "09:19:07.410: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 184.0.\n",
      "09:19:07.417: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "09:19:08.228: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "09:19:08.913: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "09:19:09.506: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "09:19:10.137: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "09:19:10.494: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "09:19:10.958: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n",
      "ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| (done) 100%\n",
      "\n",
      "09:48:19.756: _train param, Dropping bad and constant columns: [Film-Noir, Sport, Horror, winner_cannes, worldwide_box_office, wiki, nom_cannes, film, film-noir, documentary]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                            </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">    aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th><th style=\"text-align: right;\">  training_time_ms</th><th style=\"text-align: right;\">  predict_time_per_row_ms</th><th>algo        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_4 </td><td style=\"text-align: right;\">0.700873</td><td style=\"text-align: right;\"> 0.674915</td><td style=\"text-align: right;\">0.28838  </td><td style=\"text-align: right;\">              0.334277</td><td style=\"text-align: right;\">0.4014  </td><td style=\"text-align: right;\">0.161122</td><td style=\"text-align: right;\">              5273</td><td style=\"text-align: right;\">                 0.182118</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_3 </td><td style=\"text-align: right;\">0.674923</td><td style=\"text-align: right;\"> 2.39876 </td><td style=\"text-align: right;\">0.2879   </td><td style=\"text-align: right;\">              0.335221</td><td style=\"text-align: right;\">0.440234</td><td style=\"text-align: right;\">0.193806</td><td style=\"text-align: right;\">              3483</td><td style=\"text-align: right;\">                 0.100092</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_7 </td><td style=\"text-align: right;\">0.673508</td><td style=\"text-align: right;\"> 0.687366</td><td style=\"text-align: right;\">0.254215 </td><td style=\"text-align: right;\">              0.327908</td><td style=\"text-align: right;\">0.398665</td><td style=\"text-align: right;\">0.158934</td><td style=\"text-align: right;\">              8082</td><td style=\"text-align: right;\">                 0.062039</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_19</td><td style=\"text-align: right;\">0.6728  </td><td style=\"text-align: right;\"> 0.738511</td><td style=\"text-align: right;\">0.201342 </td><td style=\"text-align: right;\">              0.297594</td><td style=\"text-align: right;\">0.394644</td><td style=\"text-align: right;\">0.155744</td><td style=\"text-align: right;\">              5373</td><td style=\"text-align: right;\">                 0.091604</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_15</td><td style=\"text-align: right;\">0.66419 </td><td style=\"text-align: right;\"> 1.86933 </td><td style=\"text-align: right;\">0.286557 </td><td style=\"text-align: right;\">              0.344067</td><td style=\"text-align: right;\">0.443692</td><td style=\"text-align: right;\">0.196863</td><td style=\"text-align: right;\">              2558</td><td style=\"text-align: right;\">                 0.055437</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_14</td><td style=\"text-align: right;\">0.661005</td><td style=\"text-align: right;\"> 0.906602</td><td style=\"text-align: right;\">0.221235 </td><td style=\"text-align: right;\">              0.299009</td><td style=\"text-align: right;\">0.40559 </td><td style=\"text-align: right;\">0.164503</td><td style=\"text-align: right;\">              4761</td><td style=\"text-align: right;\">                 0.073049</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_8 </td><td style=\"text-align: right;\">0.643312</td><td style=\"text-align: right;\"> 0.734009</td><td style=\"text-align: right;\">0.217925 </td><td style=\"text-align: right;\">              0.358575</td><td style=\"text-align: right;\">0.397667</td><td style=\"text-align: right;\">0.158139</td><td style=\"text-align: right;\">             10236</td><td style=\"text-align: right;\">                 0.064391</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_23</td><td style=\"text-align: right;\">0.63482 </td><td style=\"text-align: right;\"> 1.02315 </td><td style=\"text-align: right;\">0.205258 </td><td style=\"text-align: right;\">              0.34218 </td><td style=\"text-align: right;\">0.514426</td><td style=\"text-align: right;\">0.264634</td><td style=\"text-align: right;\">              3730</td><td style=\"text-align: right;\">                 0.076604</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_14</td><td style=\"text-align: right;\">0.633876</td><td style=\"text-align: right;\"> 0.887214</td><td style=\"text-align: right;\">0.213518 </td><td style=\"text-align: right;\">              0.36058 </td><td style=\"text-align: right;\">0.394216</td><td style=\"text-align: right;\">0.155406</td><td style=\"text-align: right;\">              2718</td><td style=\"text-align: right;\">                 0.060776</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_20</td><td style=\"text-align: right;\">0.627506</td><td style=\"text-align: right;\"> 0.489866</td><td style=\"text-align: right;\">0.19211  </td><td style=\"text-align: right;\">              0.336046</td><td style=\"text-align: right;\">0.384056</td><td style=\"text-align: right;\">0.147499</td><td style=\"text-align: right;\">              2643</td><td style=\"text-align: right;\">                 0.062382</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_22</td><td style=\"text-align: right;\">0.612173</td><td style=\"text-align: right;\"> 1.70417 </td><td style=\"text-align: right;\">0.262181 </td><td style=\"text-align: right;\">              0.386294</td><td style=\"text-align: right;\">0.454271</td><td style=\"text-align: right;\">0.206362</td><td style=\"text-align: right;\">              2685</td><td style=\"text-align: right;\">                 0.067229</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_16</td><td style=\"text-align: right;\">0.610993</td><td style=\"text-align: right;\"> 1.67159 </td><td style=\"text-align: right;\">0.236975 </td><td style=\"text-align: right;\">              0.396438</td><td style=\"text-align: right;\">0.407384</td><td style=\"text-align: right;\">0.165962</td><td style=\"text-align: right;\">              2835</td><td style=\"text-align: right;\">                 0.070271</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_17         </td><td style=\"text-align: right;\">0.604152</td><td style=\"text-align: right;\"> 0.480954</td><td style=\"text-align: right;\">0.197919 </td><td style=\"text-align: right;\">              0.359165</td><td style=\"text-align: right;\">0.376248</td><td style=\"text-align: right;\">0.141563</td><td style=\"text-align: right;\">                63</td><td style=\"text-align: right;\">                 0.057698</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_12</td><td style=\"text-align: right;\">0.596603</td><td style=\"text-align: right;\"> 0.917358</td><td style=\"text-align: right;\">0.232735 </td><td style=\"text-align: right;\">              0.363529</td><td style=\"text-align: right;\">0.396063</td><td style=\"text-align: right;\">0.156866</td><td style=\"text-align: right;\">              5314</td><td style=\"text-align: right;\">                 0.084921</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_1 </td><td style=\"text-align: right;\">0.594244</td><td style=\"text-align: right;\"> 0.893567</td><td style=\"text-align: right;\">0.277517 </td><td style=\"text-align: right;\">              0.37214 </td><td style=\"text-align: right;\">0.411529</td><td style=\"text-align: right;\">0.169356</td><td style=\"text-align: right;\">             10669</td><td style=\"text-align: right;\">                 0.086296</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_4 </td><td style=\"text-align: right;\">0.58811 </td><td style=\"text-align: right;\"> 1.23908 </td><td style=\"text-align: right;\">0.237879 </td><td style=\"text-align: right;\">              0.392663</td><td style=\"text-align: right;\">0.400575</td><td style=\"text-align: right;\">0.16046 </td><td style=\"text-align: right;\">              5466</td><td style=\"text-align: right;\">                 0.085235</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DRF_1_AutoML_6_20230519_91906                       </td><td style=\"text-align: right;\">0.587757</td><td style=\"text-align: right;\"> 0.494573</td><td style=\"text-align: right;\">0.168243 </td><td style=\"text-align: right;\">              0.394315</td><td style=\"text-align: right;\">0.375985</td><td style=\"text-align: right;\">0.141364</td><td style=\"text-align: right;\">               159</td><td style=\"text-align: right;\">                 0.048635</td><td>DRF         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_5 </td><td style=\"text-align: right;\">0.585044</td><td style=\"text-align: right;\"> 1.13918 </td><td style=\"text-align: right;\">0.175643 </td><td style=\"text-align: right;\">              0.405284</td><td style=\"text-align: right;\">0.430957</td><td style=\"text-align: right;\">0.185724</td><td style=\"text-align: right;\">              2682</td><td style=\"text-align: right;\">                 0.066398</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_19</td><td style=\"text-align: right;\">0.575136</td><td style=\"text-align: right;\"> 1.15358 </td><td style=\"text-align: right;\">0.21706  </td><td style=\"text-align: right;\">              0.41991 </td><td style=\"text-align: right;\">0.430196</td><td style=\"text-align: right;\">0.185069</td><td style=\"text-align: right;\">              4009</td><td style=\"text-align: right;\">                 0.065386</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_3 </td><td style=\"text-align: right;\">0.574192</td><td style=\"text-align: right;\"> 0.75626 </td><td style=\"text-align: right;\">0.233209 </td><td style=\"text-align: right;\">              0.373319</td><td style=\"text-align: right;\">0.385194</td><td style=\"text-align: right;\">0.148375</td><td style=\"text-align: right;\">              2850</td><td style=\"text-align: right;\">                 0.084038</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_5 </td><td style=\"text-align: right;\">0.570418</td><td style=\"text-align: right;\"> 1.15078 </td><td style=\"text-align: right;\">0.197242 </td><td style=\"text-align: right;\">              0.402925</td><td style=\"text-align: right;\">0.396499</td><td style=\"text-align: right;\">0.157212</td><td style=\"text-align: right;\">              3294</td><td style=\"text-align: right;\">                 0.070762</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_10</td><td style=\"text-align: right;\">0.56971 </td><td style=\"text-align: right;\"> 0.714581</td><td style=\"text-align: right;\">0.202099 </td><td style=\"text-align: right;\">              0.41189 </td><td style=\"text-align: right;\">0.406788</td><td style=\"text-align: right;\">0.165477</td><td style=\"text-align: right;\">              5379</td><td style=\"text-align: right;\">                 0.081101</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_21</td><td style=\"text-align: right;\">0.567115</td><td style=\"text-align: right;\"> 1.37668 </td><td style=\"text-align: right;\">0.177227 </td><td style=\"text-align: right;\">              0.418259</td><td style=\"text-align: right;\">0.467823</td><td style=\"text-align: right;\">0.218858</td><td style=\"text-align: right;\">              2760</td><td style=\"text-align: right;\">                 0.055284</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_10</td><td style=\"text-align: right;\">0.561925</td><td style=\"text-align: right;\"> 1.0454  </td><td style=\"text-align: right;\">0.226951 </td><td style=\"text-align: right;\">              0.380278</td><td style=\"text-align: right;\">0.447107</td><td style=\"text-align: right;\">0.199905</td><td style=\"text-align: right;\">              5121</td><td style=\"text-align: right;\">                 0.058797</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_11</td><td style=\"text-align: right;\">0.561217</td><td style=\"text-align: right;\"> 0.933277</td><td style=\"text-align: right;\">0.171962 </td><td style=\"text-align: right;\">              0.41531 </td><td style=\"text-align: right;\">0.420975</td><td style=\"text-align: right;\">0.17722 </td><td style=\"text-align: right;\">              2575</td><td style=\"text-align: right;\">                 0.055357</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_9 </td><td style=\"text-align: right;\">0.560038</td><td style=\"text-align: right;\"> 0.932666</td><td style=\"text-align: right;\">0.173474 </td><td style=\"text-align: right;\">              0.394433</td><td style=\"text-align: right;\">0.427112</td><td style=\"text-align: right;\">0.182425</td><td style=\"text-align: right;\">              3826</td><td style=\"text-align: right;\">                 0.060392</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_20</td><td style=\"text-align: right;\">0.557207</td><td style=\"text-align: right;\"> 0.721224</td><td style=\"text-align: right;\">0.159512 </td><td style=\"text-align: right;\">              0.379807</td><td style=\"text-align: right;\">0.415177</td><td style=\"text-align: right;\">0.172372</td><td style=\"text-align: right;\">              2727</td><td style=\"text-align: right;\">                 0.058033</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_14</td><td style=\"text-align: right;\">0.557207</td><td style=\"text-align: right;\"> 0.685522</td><td style=\"text-align: right;\">0.153305 </td><td style=\"text-align: right;\">              0.394315</td><td style=\"text-align: right;\">0.400449</td><td style=\"text-align: right;\">0.160359</td><td style=\"text-align: right;\">             10402</td><td style=\"text-align: right;\">                 0.085694</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_13</td><td style=\"text-align: right;\">0.556971</td><td style=\"text-align: right;\"> 1.04612 </td><td style=\"text-align: right;\">0.242303 </td><td style=\"text-align: right;\">              0.408351</td><td style=\"text-align: right;\">0.484946</td><td style=\"text-align: right;\">0.235173</td><td style=\"text-align: right;\">              5076</td><td style=\"text-align: right;\">                 0.052818</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_12</td><td style=\"text-align: right;\">0.554612</td><td style=\"text-align: right;\"> 1.0737  </td><td style=\"text-align: right;\">0.17192  </td><td style=\"text-align: right;\">              0.403987</td><td style=\"text-align: right;\">0.426228</td><td style=\"text-align: right;\">0.18167 </td><td style=\"text-align: right;\">              3996</td><td style=\"text-align: right;\">                 0.057093</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_16</td><td style=\"text-align: right;\">0.55414 </td><td style=\"text-align: right;\"> 1.38063 </td><td style=\"text-align: right;\">0.180802 </td><td style=\"text-align: right;\">              0.401982</td><td style=\"text-align: right;\">0.427464</td><td style=\"text-align: right;\">0.182725</td><td style=\"text-align: right;\">              3842</td><td style=\"text-align: right;\">                 0.085055</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_21</td><td style=\"text-align: right;\">0.553904</td><td style=\"text-align: right;\"> 0.915577</td><td style=\"text-align: right;\">0.176803 </td><td style=\"text-align: right;\">              0.403987</td><td style=\"text-align: right;\">0.455387</td><td style=\"text-align: right;\">0.207377</td><td style=\"text-align: right;\">              2775</td><td style=\"text-align: right;\">                 0.053564</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_6 </td><td style=\"text-align: right;\">0.550602</td><td style=\"text-align: right;\"> 1.08121 </td><td style=\"text-align: right;\">0.228348 </td><td style=\"text-align: right;\">              0.407172</td><td style=\"text-align: right;\">0.443553</td><td style=\"text-align: right;\">0.196739</td><td style=\"text-align: right;\">              3858</td><td style=\"text-align: right;\">                 0.060616</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_21</td><td style=\"text-align: right;\">0.549658</td><td style=\"text-align: right;\"> 0.701544</td><td style=\"text-align: right;\">0.228975 </td><td style=\"text-align: right;\">              0.397028</td><td style=\"text-align: right;\">0.41345 </td><td style=\"text-align: right;\">0.170941</td><td style=\"text-align: right;\">              3153</td><td style=\"text-align: right;\">                 0.058045</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_1 </td><td style=\"text-align: right;\">0.548007</td><td style=\"text-align: right;\"> 1.00725 </td><td style=\"text-align: right;\">0.232231 </td><td style=\"text-align: right;\">              0.380278</td><td style=\"text-align: right;\">0.411686</td><td style=\"text-align: right;\">0.169485</td><td style=\"text-align: right;\">              5278</td><td style=\"text-align: right;\">                 0.062729</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_20</td><td style=\"text-align: right;\">0.545176</td><td style=\"text-align: right;\"> 1.09455 </td><td style=\"text-align: right;\">0.174024 </td><td style=\"text-align: right;\">              0.406582</td><td style=\"text-align: right;\">0.417265</td><td style=\"text-align: right;\">0.17411 </td><td style=\"text-align: right;\">              2633</td><td style=\"text-align: right;\">                 0.059724</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_13         </td><td style=\"text-align: right;\">0.538099</td><td style=\"text-align: right;\"> 0.537599</td><td style=\"text-align: right;\">0.17226  </td><td style=\"text-align: right;\">              0.389833</td><td style=\"text-align: right;\">0.379201</td><td style=\"text-align: right;\">0.143794</td><td style=\"text-align: right;\">               150</td><td style=\"text-align: right;\">                 0.053355</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_3          </td><td style=\"text-align: right;\">0.535975</td><td style=\"text-align: right;\"> 0.468633</td><td style=\"text-align: right;\">0.167338 </td><td style=\"text-align: right;\">              0.41472 </td><td style=\"text-align: right;\">0.368171</td><td style=\"text-align: right;\">0.13555 </td><td style=\"text-align: right;\">                63</td><td style=\"text-align: right;\">                 0.040533</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_2_AutoML_6_20230519_91906                       </td><td style=\"text-align: right;\">0.533381</td><td style=\"text-align: right;\"> 0.493571</td><td style=\"text-align: right;\">0.156776 </td><td style=\"text-align: right;\">              0.42109 </td><td style=\"text-align: right;\">0.378121</td><td style=\"text-align: right;\">0.142976</td><td style=\"text-align: right;\">               101</td><td style=\"text-align: right;\">                 0.045943</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_12</td><td style=\"text-align: right;\">0.531021</td><td style=\"text-align: right;\"> 1.23444 </td><td style=\"text-align: right;\">0.154145 </td><td style=\"text-align: right;\">              0.416254</td><td style=\"text-align: right;\">0.442761</td><td style=\"text-align: right;\">0.196037</td><td style=\"text-align: right;\">              4058</td><td style=\"text-align: right;\">                 0.117958</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_19</td><td style=\"text-align: right;\">0.528427</td><td style=\"text-align: right;\"> 1.07879 </td><td style=\"text-align: right;\">0.18048  </td><td style=\"text-align: right;\">              0.408587</td><td style=\"text-align: right;\">0.412406</td><td style=\"text-align: right;\">0.170079</td><td style=\"text-align: right;\">              4264</td><td style=\"text-align: right;\">                 0.066203</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_16</td><td style=\"text-align: right;\">0.522293</td><td style=\"text-align: right;\"> 2.11936 </td><td style=\"text-align: right;\">0.167293 </td><td style=\"text-align: right;\">              0.427459</td><td style=\"text-align: right;\">0.444914</td><td style=\"text-align: right;\">0.197949</td><td style=\"text-align: right;\">              2801</td><td style=\"text-align: right;\">                 0.058905</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_21         </td><td style=\"text-align: right;\">0.52017 </td><td style=\"text-align: right;\"> 0.534379</td><td style=\"text-align: right;\">0.167537 </td><td style=\"text-align: right;\">              0.410946</td><td style=\"text-align: right;\">0.37994 </td><td style=\"text-align: right;\">0.144354</td><td style=\"text-align: right;\">               108</td><td style=\"text-align: right;\">                 0.068473</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_6_20230519_91906              </td><td style=\"text-align: right;\">0.519934</td><td style=\"text-align: right;\"> 0.706439</td><td style=\"text-align: right;\">0.14074  </td><td style=\"text-align: right;\">              0.409295</td><td style=\"text-align: right;\">0.449234</td><td style=\"text-align: right;\">0.201811</td><td style=\"text-align: right;\">                55</td><td style=\"text-align: right;\">                 0.061221</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_10         </td><td style=\"text-align: right;\">0.512857</td><td style=\"text-align: right;\"> 0.481216</td><td style=\"text-align: right;\">0.164423 </td><td style=\"text-align: right;\">              0.427459</td><td style=\"text-align: right;\">0.370537</td><td style=\"text-align: right;\">0.137298</td><td style=\"text-align: right;\">                66</td><td style=\"text-align: right;\">                 0.042112</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_8 </td><td style=\"text-align: right;\">0.511205</td><td style=\"text-align: right;\"> 1.17516 </td><td style=\"text-align: right;\">0.14073  </td><td style=\"text-align: right;\">              0.439962</td><td style=\"text-align: right;\">0.428525</td><td style=\"text-align: right;\">0.183634</td><td style=\"text-align: right;\">             10563</td><td style=\"text-align: right;\">                 0.091352</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_3_AutoML_6_20230519_91906                       </td><td style=\"text-align: right;\">0.509082</td><td style=\"text-align: right;\"> 0.506015</td><td style=\"text-align: right;\">0.146222 </td><td style=\"text-align: right;\">              0.426044</td><td style=\"text-align: right;\">0.382335</td><td style=\"text-align: right;\">0.14618 </td><td style=\"text-align: right;\">               110</td><td style=\"text-align: right;\">                 0.047039</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_18</td><td style=\"text-align: right;\">0.506959</td><td style=\"text-align: right;\"> 0.712036</td><td style=\"text-align: right;\">0.147192 </td><td style=\"text-align: right;\">              0.44468 </td><td style=\"text-align: right;\">0.411546</td><td style=\"text-align: right;\">0.16937 </td><td style=\"text-align: right;\">              2489</td><td style=\"text-align: right;\">                 0.04717 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_3 </td><td style=\"text-align: right;\">0.505544</td><td style=\"text-align: right;\"> 0.925622</td><td style=\"text-align: right;\">0.189739 </td><td style=\"text-align: right;\">              0.403397</td><td style=\"text-align: right;\">0.386596</td><td style=\"text-align: right;\">0.149456</td><td style=\"text-align: right;\">              2623</td><td style=\"text-align: right;\">                 0.055245</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_13</td><td style=\"text-align: right;\">0.505544</td><td style=\"text-align: right;\"> 0.833206</td><td style=\"text-align: right;\">0.146699 </td><td style=\"text-align: right;\">              0.45624 </td><td style=\"text-align: right;\">0.383134</td><td style=\"text-align: right;\">0.146792</td><td style=\"text-align: right;\">              5111</td><td style=\"text-align: right;\">                 0.056679</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_8 </td><td style=\"text-align: right;\">0.502949</td><td style=\"text-align: right;\"> 1.20814 </td><td style=\"text-align: right;\">0.156675 </td><td style=\"text-align: right;\">              0.410946</td><td style=\"text-align: right;\">0.428433</td><td style=\"text-align: right;\">0.183554</td><td style=\"text-align: right;\">             15499</td><td style=\"text-align: right;\">                 0.059174</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_17</td><td style=\"text-align: right;\">0.497051</td><td style=\"text-align: right;\"> 0.982437</td><td style=\"text-align: right;\">0.190869 </td><td style=\"text-align: right;\">              0.435834</td><td style=\"text-align: right;\">0.420642</td><td style=\"text-align: right;\">0.17694 </td><td style=\"text-align: right;\">              4498</td><td style=\"text-align: right;\">                 0.054133</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_7 </td><td style=\"text-align: right;\">0.493984</td><td style=\"text-align: right;\"> 0.924932</td><td style=\"text-align: right;\">0.147722 </td><td style=\"text-align: right;\">              0.431824</td><td style=\"text-align: right;\">0.41464 </td><td style=\"text-align: right;\">0.171926</td><td style=\"text-align: right;\">             10731</td><td style=\"text-align: right;\">                 0.076694</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_9 </td><td style=\"text-align: right;\">0.484548</td><td style=\"text-align: right;\"> 1.68247 </td><td style=\"text-align: right;\">0.135198 </td><td style=\"text-align: right;\">              0.441496</td><td style=\"text-align: right;\">0.486566</td><td style=\"text-align: right;\">0.236746</td><td style=\"text-align: right;\">              3688</td><td style=\"text-align: right;\">                 0.048777</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_1 </td><td style=\"text-align: right;\">0.481481</td><td style=\"text-align: right;\"> 1.11763 </td><td style=\"text-align: right;\">0.183329 </td><td style=\"text-align: right;\">              0.461783</td><td style=\"text-align: right;\">0.45106 </td><td style=\"text-align: right;\">0.203455</td><td style=\"text-align: right;\">              5136</td><td style=\"text-align: right;\">                 0.05746 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_5 </td><td style=\"text-align: right;\">0.48101 </td><td style=\"text-align: right;\"> 0.952661</td><td style=\"text-align: right;\">0.133865 </td><td style=\"text-align: right;\">              0.473933</td><td style=\"text-align: right;\">0.429733</td><td style=\"text-align: right;\">0.18467 </td><td style=\"text-align: right;\">              2674</td><td style=\"text-align: right;\">                 0.108752</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_9          </td><td style=\"text-align: right;\">0.479358</td><td style=\"text-align: right;\"> 0.490572</td><td style=\"text-align: right;\">0.142713 </td><td style=\"text-align: right;\">              0.422269</td><td style=\"text-align: right;\">0.377738</td><td style=\"text-align: right;\">0.142686</td><td style=\"text-align: right;\">                52</td><td style=\"text-align: right;\">                 0.056842</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_2          </td><td style=\"text-align: right;\">0.476527</td><td style=\"text-align: right;\"> 0.515459</td><td style=\"text-align: right;\">0.149057 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.382837</td><td style=\"text-align: right;\">0.146564</td><td style=\"text-align: right;\">                61</td><td style=\"text-align: right;\">                 0.038221</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_4 </td><td style=\"text-align: right;\">0.476056</td><td style=\"text-align: right;\"> 1.70655 </td><td style=\"text-align: right;\">0.130322 </td><td style=\"text-align: right;\">              0.477117</td><td style=\"text-align: right;\">0.454891</td><td style=\"text-align: right;\">0.206926</td><td style=\"text-align: right;\">              4113</td><td style=\"text-align: right;\">                 0.052773</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_12         </td><td style=\"text-align: right;\">0.473225</td><td style=\"text-align: right;\"> 0.553308</td><td style=\"text-align: right;\">0.139832 </td><td style=\"text-align: right;\">              0.469214</td><td style=\"text-align: right;\">0.387915</td><td style=\"text-align: right;\">0.150478</td><td style=\"text-align: right;\">                87</td><td style=\"text-align: right;\">                 0.039436</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_4_AutoML_6_20230519_91906                       </td><td style=\"text-align: right;\">0.472989</td><td style=\"text-align: right;\"> 0.511462</td><td style=\"text-align: right;\">0.143562 </td><td style=\"text-align: right;\">              0.435008</td><td style=\"text-align: right;\">0.379819</td><td style=\"text-align: right;\">0.144262</td><td style=\"text-align: right;\">               113</td><td style=\"text-align: right;\">                 0.044878</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_22         </td><td style=\"text-align: right;\">0.471809</td><td style=\"text-align: right;\"> 0.474344</td><td style=\"text-align: right;\">0.132059 </td><td style=\"text-align: right;\">              0.490446</td><td style=\"text-align: right;\">0.373419</td><td style=\"text-align: right;\">0.139441</td><td style=\"text-align: right;\">                75</td><td style=\"text-align: right;\">                 0.037957</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_15         </td><td style=\"text-align: right;\">0.460014</td><td style=\"text-align: right;\"> 0.518431</td><td style=\"text-align: right;\">0.128203 </td><td style=\"text-align: right;\">              0.46084 </td><td style=\"text-align: right;\">0.383803</td><td style=\"text-align: right;\">0.147305</td><td style=\"text-align: right;\">                94</td><td style=\"text-align: right;\">                 0.04863 </td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_7 </td><td style=\"text-align: right;\">0.456004</td><td style=\"text-align: right;\"> 0.981318</td><td style=\"text-align: right;\">0.225043 </td><td style=\"text-align: right;\">              0.418141</td><td style=\"text-align: right;\">0.428992</td><td style=\"text-align: right;\">0.184034</td><td style=\"text-align: right;\">             10077</td><td style=\"text-align: right;\">                 0.067702</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_7          </td><td style=\"text-align: right;\">0.455532</td><td style=\"text-align: right;\"> 0.501124</td><td style=\"text-align: right;\">0.133072 </td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.381879</td><td style=\"text-align: right;\">0.145831</td><td style=\"text-align: right;\">                72</td><td style=\"text-align: right;\">                 0.044319</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_2 </td><td style=\"text-align: right;\">0.455296</td><td style=\"text-align: right;\"> 0.856374</td><td style=\"text-align: right;\">0.136278 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.404838</td><td style=\"text-align: right;\">0.163894</td><td style=\"text-align: right;\">              2599</td><td style=\"text-align: right;\">                 0.062623</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_5          </td><td style=\"text-align: right;\">0.444798</td><td style=\"text-align: right;\"> 0.517864</td><td style=\"text-align: right;\">0.131112 </td><td style=\"text-align: right;\">              0.443383</td><td style=\"text-align: right;\">0.382914</td><td style=\"text-align: right;\">0.146623</td><td style=\"text-align: right;\">                78</td><td style=\"text-align: right;\">                 0.046477</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_6_20230519_91906_model_2 </td><td style=\"text-align: right;\">0.433829</td><td style=\"text-align: right;\"> 1.48324 </td><td style=\"text-align: right;\">0.120774 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.441344</td><td style=\"text-align: right;\">0.194784</td><td style=\"text-align: right;\">              2562</td><td style=\"text-align: right;\">                 0.058215</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_22</td><td style=\"text-align: right;\">0.430054</td><td style=\"text-align: right;\"> 1.0738  </td><td style=\"text-align: right;\">0.126928 </td><td style=\"text-align: right;\">              0.484076</td><td style=\"text-align: right;\">0.399562</td><td style=\"text-align: right;\">0.15965 </td><td style=\"text-align: right;\">              4768</td><td style=\"text-align: right;\">                 0.051089</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_1          </td><td style=\"text-align: right;\">0.428403</td><td style=\"text-align: right;\"> 0.500272</td><td style=\"text-align: right;\">0.126236 </td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.377023</td><td style=\"text-align: right;\">0.142146</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">                 0.047138</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_6 </td><td style=\"text-align: right;\">0.4159  </td><td style=\"text-align: right;\"> 0.950711</td><td style=\"text-align: right;\">0.120456 </td><td style=\"text-align: right;\">              0.484076</td><td style=\"text-align: right;\">0.390168</td><td style=\"text-align: right;\">0.152231</td><td style=\"text-align: right;\">              7439</td><td style=\"text-align: right;\">                 0.067638</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_5_AutoML_6_20230519_91906                       </td><td style=\"text-align: right;\">0.41472 </td><td style=\"text-align: right;\"> 0.575528</td><td style=\"text-align: right;\">0.144189 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.387267</td><td style=\"text-align: right;\">0.149976</td><td style=\"text-align: right;\">                70</td><td style=\"text-align: right;\">                 0.040058</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_10</td><td style=\"text-align: right;\">0.410474</td><td style=\"text-align: right;\"> 1.38852 </td><td style=\"text-align: right;\">0.126877 </td><td style=\"text-align: right;\">              0.493631</td><td style=\"text-align: right;\">0.44722 </td><td style=\"text-align: right;\">0.200006</td><td style=\"text-align: right;\">              4173</td><td style=\"text-align: right;\">                 0.073872</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_13</td><td style=\"text-align: right;\">0.40552 </td><td style=\"text-align: right;\"> 1.21327 </td><td style=\"text-align: right;\">0.200436 </td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.363732</td><td style=\"text-align: right;\">0.132301</td><td style=\"text-align: right;\">              5137</td><td style=\"text-align: right;\">                 0.067272</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_22</td><td style=\"text-align: right;\">0.388535</td><td style=\"text-align: right;\"> 1.20237 </td><td style=\"text-align: right;\">0.111915 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.390732</td><td style=\"text-align: right;\">0.152672</td><td style=\"text-align: right;\">              5050</td><td style=\"text-align: right;\">                 0.062674</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_17</td><td style=\"text-align: right;\">0.388535</td><td style=\"text-align: right;\"> 0.857598</td><td style=\"text-align: right;\">0.116645 </td><td style=\"text-align: right;\">              0.496226</td><td style=\"text-align: right;\">0.383365</td><td style=\"text-align: right;\">0.146969</td><td style=\"text-align: right;\">              3636</td><td style=\"text-align: right;\">                 0.056389</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_4          </td><td style=\"text-align: right;\">0.374381</td><td style=\"text-align: right;\"> 0.491893</td><td style=\"text-align: right;\">0.110061 </td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.37681 </td><td style=\"text-align: right;\">0.141985</td><td style=\"text-align: right;\">                50</td><td style=\"text-align: right;\">                 0.042811</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_8          </td><td style=\"text-align: right;\">0.372729</td><td style=\"text-align: right;\"> 0.595315</td><td style=\"text-align: right;\">0.119759 </td><td style=\"text-align: right;\">              0.493631</td><td style=\"text-align: right;\">0.392748</td><td style=\"text-align: right;\">0.154251</td><td style=\"text-align: right;\">               124</td><td style=\"text-align: right;\">                 0.054235</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_2 </td><td style=\"text-align: right;\">0.372494</td><td style=\"text-align: right;\"> 0.719005</td><td style=\"text-align: right;\">0.110393 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.412954</td><td style=\"text-align: right;\">0.170531</td><td style=\"text-align: right;\">              2530</td><td style=\"text-align: right;\">                 0.067569</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_18         </td><td style=\"text-align: right;\">0.366832</td><td style=\"text-align: right;\"> 0.596957</td><td style=\"text-align: right;\">0.117026 </td><td style=\"text-align: right;\">              0.480892</td><td style=\"text-align: right;\">0.386634</td><td style=\"text-align: right;\">0.149486</td><td style=\"text-align: right;\">               105</td><td style=\"text-align: right;\">                 0.049273</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_15</td><td style=\"text-align: right;\">0.366596</td><td style=\"text-align: right;\"> 1.43444 </td><td style=\"text-align: right;\">0.11218  </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.450561</td><td style=\"text-align: right;\">0.203005</td><td style=\"text-align: right;\">              2672</td><td style=\"text-align: right;\">                 0.062729</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_11</td><td style=\"text-align: right;\">0.36518 </td><td style=\"text-align: right;\"> 0.678052</td><td style=\"text-align: right;\">0.115183 </td><td style=\"text-align: right;\">              0.487261</td><td style=\"text-align: right;\">0.404592</td><td style=\"text-align: right;\">0.163695</td><td style=\"text-align: right;\">              2507</td><td style=\"text-align: right;\">                 0.063464</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_11</td><td style=\"text-align: right;\">0.362586</td><td style=\"text-align: right;\"> 1.41463 </td><td style=\"text-align: right;\">0.107378 </td><td style=\"text-align: right;\">              0.489266</td><td style=\"text-align: right;\">0.442679</td><td style=\"text-align: right;\">0.195965</td><td style=\"text-align: right;\">              2470</td><td style=\"text-align: right;\">                 0.058054</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_6_20230519_91906_model_18</td><td style=\"text-align: right;\">0.36235 </td><td style=\"text-align: right;\"> 1.10172 </td><td style=\"text-align: right;\">0.112196 </td><td style=\"text-align: right;\">              0.490446</td><td style=\"text-align: right;\">0.385201</td><td style=\"text-align: right;\">0.14838 </td><td style=\"text-align: right;\">              7271</td><td style=\"text-align: right;\">                 0.057366</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_6 </td><td style=\"text-align: right;\">0.361406</td><td style=\"text-align: right;\"> 0.842644</td><td style=\"text-align: right;\">0.106956 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.389703</td><td style=\"text-align: right;\">0.151868</td><td style=\"text-align: right;\">              9046</td><td style=\"text-align: right;\">                 0.081352</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GLM_1_AutoML_6_20230519_91906                       </td><td style=\"text-align: right;\">0.344893</td><td style=\"text-align: right;\"> 0.477983</td><td style=\"text-align: right;\">0.107925 </td><td style=\"text-align: right;\">              0.493631</td><td style=\"text-align: right;\">0.374864</td><td style=\"text-align: right;\">0.140523</td><td style=\"text-align: right;\">                39</td><td style=\"text-align: right;\">                 0.040054</td><td>GLM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_15</td><td style=\"text-align: right;\">0.319651</td><td style=\"text-align: right;\"> 1.31544 </td><td style=\"text-align: right;\">0.100551 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.395236</td><td style=\"text-align: right;\">0.156212</td><td style=\"text-align: right;\">              2572</td><td style=\"text-align: right;\">                 0.069148</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_20         </td><td style=\"text-align: right;\">0.283793</td><td style=\"text-align: right;\"> 0.503699</td><td style=\"text-align: right;\">0.101192 </td><td style=\"text-align: right;\">              0.493631</td><td style=\"text-align: right;\">0.377142</td><td style=\"text-align: right;\">0.142236</td><td style=\"text-align: right;\">               263</td><td style=\"text-align: right;\">                 0.049039</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_6_20230519_91906_model_11         </td><td style=\"text-align: right;\">0.278603</td><td style=\"text-align: right;\"> 0.486507</td><td style=\"text-align: right;\">0.100319 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.373086</td><td style=\"text-align: right;\">0.139194</td><td style=\"text-align: right;\">                41</td><td style=\"text-align: right;\">                 0.042584</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_9 </td><td style=\"text-align: right;\">0.27129 </td><td style=\"text-align: right;\"> 0.986206</td><td style=\"text-align: right;\">0.0978479</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.403883</td><td style=\"text-align: right;\">0.163121</td><td style=\"text-align: right;\">              3423</td><td style=\"text-align: right;\">                 0.061447</td><td>DeepLearning</td></tr>\n",
       "<tr><td>XRT_1_AutoML_6_20230519_91906                       </td><td style=\"text-align: right;\">0.267988</td><td style=\"text-align: right;\"> 0.482301</td><td style=\"text-align: right;\">0.0989997</td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.380137</td><td style=\"text-align: right;\">0.144504</td><td style=\"text-align: right;\">                59</td><td style=\"text-align: right;\">                 0.040642</td><td>DRF         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_17</td><td style=\"text-align: right;\">0.244869</td><td style=\"text-align: right;\"> 1.19157 </td><td style=\"text-align: right;\">0.092536 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.38327 </td><td style=\"text-align: right;\">0.146896</td><td style=\"text-align: right;\">              4898</td><td style=\"text-align: right;\">                 0.061345</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_6_20230519_91906_model_18</td><td style=\"text-align: right;\">0.223166</td><td style=\"text-align: right;\"> 0.858963</td><td style=\"text-align: right;\">0.0918215</td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.383404</td><td style=\"text-align: right;\">0.146999</td><td style=\"text-align: right;\">              5071</td><td style=\"text-align: right;\">                 0.060825</td><td>DeepLearning</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[93 rows x 10 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                   auc    logloss      aucpr    mean_per_class_error      rmse       mse    training_time_ms    predict_time_per_row_ms  algo\n",
       "----------------------------------------------------  --------  ---------  ---------  ----------------------  --------  --------  ------------------  -------------------------  ------------\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_4   0.700873   0.674915  0.28838                  0.334277  0.4014    0.161122                5273                   0.182118  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_3   0.674923   2.39876   0.2879                   0.335221  0.440234  0.193806                3483                   0.100092  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_7   0.673508   0.687366  0.254215                 0.327908  0.398665  0.158934                8082                   0.062039  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_19  0.6728     0.738511  0.201342                 0.297594  0.394644  0.155744                5373                   0.091604  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_15  0.66419    1.86933   0.286557                 0.344067  0.443692  0.196863                2558                   0.055437  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_14  0.661005   0.906602  0.221235                 0.299009  0.40559   0.164503                4761                   0.073049  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_8   0.643312   0.734009  0.217925                 0.358575  0.397667  0.158139               10236                   0.064391  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_23  0.63482    1.02315   0.205258                 0.34218   0.514426  0.264634                3730                   0.076604  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_14  0.633876   0.887214  0.213518                 0.36058   0.394216  0.155406                2718                   0.060776  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_20  0.627506   0.489866  0.19211                  0.336046  0.384056  0.147499                2643                   0.062382  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_22  0.612173   1.70417   0.262181                 0.386294  0.454271  0.206362                2685                   0.067229  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_16  0.610993   1.67159   0.236975                 0.396438  0.407384  0.165962                2835                   0.070271  DeepLearning\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_17           0.604152   0.480954  0.197919                 0.359165  0.376248  0.141563                  63                   0.057698  GBM\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_12  0.596603   0.917358  0.232735                 0.363529  0.396063  0.156866                5314                   0.084921  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_1   0.594244   0.893567  0.277517                 0.37214   0.411529  0.169356               10669                   0.086296  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_4   0.58811    1.23908   0.237879                 0.392663  0.400575  0.16046                 5466                   0.085235  DeepLearning\n",
       "DRF_1_AutoML_6_20230519_91906                         0.587757   0.494573  0.168243                 0.394315  0.375985  0.141364                 159                   0.048635  DRF\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_5   0.585044   1.13918   0.175643                 0.405284  0.430957  0.185724                2682                   0.066398  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_19  0.575136   1.15358   0.21706                  0.41991   0.430196  0.185069                4009                   0.065386  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_3   0.574192   0.75626   0.233209                 0.373319  0.385194  0.148375                2850                   0.084038  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_5   0.570418   1.15078   0.197242                 0.402925  0.396499  0.157212                3294                   0.070762  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_10  0.56971    0.714581  0.202099                 0.41189   0.406788  0.165477                5379                   0.081101  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_21  0.567115   1.37668   0.177227                 0.418259  0.467823  0.218858                2760                   0.055284  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_10  0.561925   1.0454    0.226951                 0.380278  0.447107  0.199905                5121                   0.058797  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_11  0.561217   0.933277  0.171962                 0.41531   0.420975  0.17722                 2575                   0.055357  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_9   0.560038   0.932666  0.173474                 0.394433  0.427112  0.182425                3826                   0.060392  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_20  0.557207   0.721224  0.159512                 0.379807  0.415177  0.172372                2727                   0.058033  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_14  0.557207   0.685522  0.153305                 0.394315  0.400449  0.160359               10402                   0.085694  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_13  0.556971   1.04612   0.242303                 0.408351  0.484946  0.235173                5076                   0.052818  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_12  0.554612   1.0737    0.17192                  0.403987  0.426228  0.18167                 3996                   0.057093  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_16  0.55414    1.38063   0.180802                 0.401982  0.427464  0.182725                3842                   0.085055  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_21  0.553904   0.915577  0.176803                 0.403987  0.455387  0.207377                2775                   0.053564  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_6   0.550602   1.08121   0.228348                 0.407172  0.443553  0.196739                3858                   0.060616  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_21  0.549658   0.701544  0.228975                 0.397028  0.41345   0.170941                3153                   0.058045  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_1   0.548007   1.00725   0.232231                 0.380278  0.411686  0.169485                5278                   0.062729  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_20  0.545176   1.09455   0.174024                 0.406582  0.417265  0.17411                 2633                   0.059724  DeepLearning\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_13           0.538099   0.537599  0.17226                  0.389833  0.379201  0.143794                 150                   0.053355  GBM\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_3            0.535975   0.468633  0.167338                 0.41472   0.368171  0.13555                   63                   0.040533  GBM\n",
       "GBM_2_AutoML_6_20230519_91906                         0.533381   0.493571  0.156776                 0.42109   0.378121  0.142976                 101                   0.045943  GBM\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_12  0.531021   1.23444   0.154145                 0.416254  0.442761  0.196037                4058                   0.117958  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_19  0.528427   1.07879   0.18048                  0.408587  0.412406  0.170079                4264                   0.066203  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_16  0.522293   2.11936   0.167293                 0.427459  0.444914  0.197949                2801                   0.058905  DeepLearning\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_21           0.52017    0.534379  0.167537                 0.410946  0.37994   0.144354                 108                   0.068473  GBM\n",
       "DeepLearning_1_AutoML_6_20230519_91906                0.519934   0.706439  0.14074                  0.409295  0.449234  0.201811                  55                   0.061221  DeepLearning\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_10           0.512857   0.481216  0.164423                 0.427459  0.370537  0.137298                  66                   0.042112  GBM\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_8   0.511205   1.17516   0.14073                  0.439962  0.428525  0.183634               10563                   0.091352  DeepLearning\n",
       "GBM_3_AutoML_6_20230519_91906                         0.509082   0.506015  0.146222                 0.426044  0.382335  0.14618                  110                   0.047039  GBM\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_18  0.506959   0.712036  0.147192                 0.44468   0.411546  0.16937                 2489                   0.04717   DeepLearning\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_3   0.505544   0.925622  0.189739                 0.403397  0.386596  0.149456                2623                   0.055245  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_13  0.505544   0.833206  0.146699                 0.45624   0.383134  0.146792                5111                   0.056679  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_8   0.502949   1.20814   0.156675                 0.410946  0.428433  0.183554               15499                   0.059174  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_17  0.497051   0.982437  0.190869                 0.435834  0.420642  0.17694                 4498                   0.054133  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_7   0.493984   0.924932  0.147722                 0.431824  0.41464   0.171926               10731                   0.076694  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_9   0.484548   1.68247   0.135198                 0.441496  0.486566  0.236746                3688                   0.048777  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_1   0.481481   1.11763   0.183329                 0.461783  0.45106   0.203455                5136                   0.05746   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_5   0.48101    0.952661  0.133865                 0.473933  0.429733  0.18467                 2674                   0.108752  DeepLearning\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_9            0.479358   0.490572  0.142713                 0.422269  0.377738  0.142686                  52                   0.056842  GBM\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_2            0.476527   0.515459  0.149057                 0.5       0.382837  0.146564                  61                   0.038221  GBM\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_4   0.476056   1.70655   0.130322                 0.477117  0.454891  0.206926                4113                   0.052773  DeepLearning\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_12           0.473225   0.553308  0.139832                 0.469214  0.387915  0.150478                  87                   0.039436  GBM\n",
       "GBM_4_AutoML_6_20230519_91906                         0.472989   0.511462  0.143562                 0.435008  0.379819  0.144262                 113                   0.044878  GBM\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_22           0.471809   0.474344  0.132059                 0.490446  0.373419  0.139441                  75                   0.037957  GBM\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_15           0.460014   0.518431  0.128203                 0.46084   0.383803  0.147305                  94                   0.04863   GBM\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_7   0.456004   0.981318  0.225043                 0.418141  0.428992  0.184034               10077                   0.067702  DeepLearning\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_7            0.455532   0.501124  0.133072                 0.496815  0.381879  0.145831                  72                   0.044319  GBM\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_2   0.455296   0.856374  0.136278                 0.5       0.404838  0.163894                2599                   0.062623  DeepLearning\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_5            0.444798   0.517864  0.131112                 0.443383  0.382914  0.146623                  78                   0.046477  GBM\n",
       "DeepLearning_grid_1_AutoML_6_20230519_91906_model_2   0.433829   1.48324   0.120774                 0.5       0.441344  0.194784                2562                   0.058215  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_22  0.430054   1.0738    0.126928                 0.484076  0.399562  0.15965                 4768                   0.051089  DeepLearning\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_1            0.428403   0.500272  0.126236                 0.496815  0.377023  0.142146                  64                   0.047138  GBM\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_6   0.4159     0.950711  0.120456                 0.484076  0.390168  0.152231                7439                   0.067638  DeepLearning\n",
       "GBM_5_AutoML_6_20230519_91906                         0.41472    0.575528  0.144189                 0.5       0.387267  0.149976                  70                   0.040058  GBM\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_10  0.410474   1.38852   0.126877                 0.493631  0.44722   0.200006                4173                   0.073872  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_13  0.40552    1.21327   0.200436                 0.496815  0.363732  0.132301                5137                   0.067272  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_22  0.388535   1.20237   0.111915                 0.5       0.390732  0.152672                5050                   0.062674  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_17  0.388535   0.857598  0.116645                 0.496226  0.383365  0.146969                3636                   0.056389  DeepLearning\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_4            0.374381   0.491893  0.110061                 0.496815  0.37681   0.141985                  50                   0.042811  GBM\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_8            0.372729   0.595315  0.119759                 0.493631  0.392748  0.154251                 124                   0.054235  GBM\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_2   0.372494   0.719005  0.110393                 0.5       0.412954  0.170531                2530                   0.067569  DeepLearning\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_18           0.366832   0.596957  0.117026                 0.480892  0.386634  0.149486                 105                   0.049273  GBM\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_15  0.366596   1.43444   0.11218                  0.5       0.450561  0.203005                2672                   0.062729  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_11  0.36518    0.678052  0.115183                 0.487261  0.404592  0.163695                2507                   0.063464  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_11  0.362586   1.41463   0.107378                 0.489266  0.442679  0.195965                2470                   0.058054  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_6_20230519_91906_model_18  0.36235    1.10172   0.112196                 0.490446  0.385201  0.14838                 7271                   0.057366  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_6   0.361406   0.842644  0.106956                 0.5       0.389703  0.151868                9046                   0.081352  DeepLearning\n",
       "GLM_1_AutoML_6_20230519_91906                         0.344893   0.477983  0.107925                 0.493631  0.374864  0.140523                  39                   0.040054  GLM\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_15  0.319651   1.31544   0.100551                 0.5       0.395236  0.156212                2572                   0.069148  DeepLearning\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_20           0.283793   0.503699  0.101192                 0.493631  0.377142  0.142236                 263                   0.049039  GBM\n",
       "GBM_grid_1_AutoML_6_20230519_91906_model_11           0.278603   0.486507  0.100319                 0.5       0.373086  0.139194                  41                   0.042584  GBM\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_9   0.27129    0.986206  0.0978479                0.5       0.403883  0.163121                3423                   0.061447  DeepLearning\n",
       "XRT_1_AutoML_6_20230519_91906                         0.267988   0.482301  0.0989997                0.496815  0.380137  0.144504                  59                   0.040642  DRF\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_17  0.244869   1.19157   0.092536                 0.5       0.38327   0.146896                4898                   0.061345  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_6_20230519_91906_model_18  0.223166   0.858963  0.0918215                0.496815  0.383404  0.146999                5071                   0.060825  DeepLearning\n",
       "[93 rows x 10 columns]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.automl import H2OAutoML, get_leaderboard\n",
    "\n",
    "# Import a sample binary outcome train/test set into H2O\n",
    "train1 = h2o.H2OFrame(train)\n",
    "\n",
    "# Identify predictors and response\n",
    "predictors = ['year', 'film', 'wiki', 'rating', 'numVotes',\n",
    "       'worldwide_box_office', 'Action', 'Adventure', 'Animation', 'Biography',\n",
    "       'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy',\n",
    "       'Film-Noir', 'Game-Show', 'History', 'Horror', 'Music', 'Musical',\n",
    "       'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
    "       'Talk-Show', 'Thriller', 'War', 'Western', 'action', 'adventure',\n",
    "       'animation', 'biography', 'comedy', 'crime', 'documentary', 'drama',\n",
    "       'family', 'fantasy', 'film-noir', 'history', 'horror', 'music',\n",
    "       'musical', 'mystery', 'romance', 'sci-fi', 'sport', 'thriller', 'war',\n",
    "       'western', 'nominations', 'nom_gg_drama',\n",
    "       'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy', 'nom_pga',\n",
    "       'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga',\n",
    "       'nom_sag', 'winner_sag', 'nom_cannes', 'winner_cannes']\n",
    "\n",
    "x = predictors\n",
    "y = 'Oscar_win'\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train1[y] = train1[y].asfactor()\n",
    "\n",
    "# Run AutoML for 100 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=100, seed=1\n",
    "                , keep_cross_validation_predictions= True\n",
    "               , exclude_algos = ['StackedEnsemble'])\n",
    "\n",
    "aml.train(x=x, y=y, training_frame=train1)\n",
    "\n",
    "# AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "\n",
    "# Optionally edd extra model information to the leaderboard\n",
    "lb = get_leaderboard(aml, extra_columns='ALL')\n",
    "\n",
    "# Print all rows (instead of default 10 rows)\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.as_data_frame().to_csv('./model/leaderboard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_6_20230519_91906_model_4\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 16Â 402 weights/biases, 205,0 KB, 55Â 200 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>60</td>\n",
       "<td>Input</td>\n",
       "<td>10.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>100</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0121955</td>\n",
       "<td>0.0202474</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0023191</td>\n",
       "<td>0.1146670</td>\n",
       "<td>0.4935305</td>\n",
       "<td>0.0545734</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>100</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0138785</td>\n",
       "<td>0.0499915</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0016267</td>\n",
       "<td>0.1058400</td>\n",
       "<td>0.9973973</td>\n",
       "<td>0.0153334</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0027545</td>\n",
       "<td>0.0077586</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0276430</td>\n",
       "<td>0.5707517</td>\n",
       "<td>-0.0001731</td>\n",
       "<td>0.0079408</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.004111662465069766\n",
       "RMSE: 0.06412224625720597\n",
       "LogLoss: 0.013626588173579179\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2125439532782935</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>157.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/157.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/27.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>157.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/184.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>157.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>26.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>157.0</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.2125440</td>\n",
       "<td>27.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9629630</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,67 %, avg score: 14,05 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0108696</td>\n",
       "<td>0.9999991</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.0740741</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.0740741</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0217391</td>\n",
       "<td>0.9999972</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999988</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999994</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.1481481</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.1481481</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0326087</td>\n",
       "<td>0.9999925</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999946</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999978</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2222222</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.2222222</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0434783</td>\n",
       "<td>0.9999749</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999848</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999945</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2962963</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.2962963</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0543478</td>\n",
       "<td>0.9999688</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999695</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999895</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.3703704</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.3703704</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1032609</td>\n",
       "<td>0.9916950</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9969527</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9985510</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.7037037</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.7037037</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1521739</td>\n",
       "<td>0.0443215</td>\n",
       "<td>6.0576132</td>\n",
       "<td>6.5714286</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.7413653</td>\n",
       "<td>0.9642857</td>\n",
       "<td>0.9158842</td>\n",
       "<td>0.2962963</td>\n",
       "<td>1.0</td>\n",
       "<td>505.7613169</td>\n",
       "<td>557.1428571</td>\n",
       "<td>0.9936306</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2010870</td>\n",
       "<td>0.0052221</td>\n",
       "<td>0.0</td>\n",
       "<td>4.9729730</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0181363</td>\n",
       "<td>0.7297297</td>\n",
       "<td>0.6975131</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>397.2972973</td>\n",
       "<td>0.9363057</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989130</td>\n",
       "<td>0.0008355</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3454545</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0021285</td>\n",
       "<td>0.4909091</td>\n",
       "<td>0.4699327</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>234.5454545</td>\n",
       "<td>0.8216561</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4021739</td>\n",
       "<td>0.0002182</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4864865</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004668</td>\n",
       "<td>0.3648649</td>\n",
       "<td>0.3493941</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>148.6486486</td>\n",
       "<td>0.7006369</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0000543</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001089</td>\n",
       "<td>0.2934783</td>\n",
       "<td>0.2810557</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td>\n",
       "<td>0.5859873</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5978261</td>\n",
       "<td>0.0000086</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6727273</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000256</td>\n",
       "<td>0.2454545</td>\n",
       "<td>0.2350690</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2727273</td>\n",
       "<td>0.4713376</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010870</td>\n",
       "<td>0.0000008</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4263566</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000032</td>\n",
       "<td>0.2093023</td>\n",
       "<td>0.2004469</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6356589</td>\n",
       "<td>0.3503185</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7989130</td>\n",
       "<td>0.0000002</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2517007</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.1836735</td>\n",
       "<td>0.1759024</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1700680</td>\n",
       "<td>0.2356688</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8967391</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1151515</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.1636364</td>\n",
       "<td>0.1567131</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.5151515</td>\n",
       "<td>0.1210191</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1467391</td>\n",
       "<td>0.1405307</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.16112171557684316\n",
       "RMSE: 0.40139969553656013\n",
       "LogLoss: 0.6749148423554983\n",
       "Mean Per-Class Error: 0.334276952111347\n",
       "AUC: 0.7008728473696627\n",
       "AUCPR: 0.28837964750621486\n",
       "Gini: 0.4017456947393254</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.08978481850166033</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>116.0</td>\n",
       "<td>41.0</td>\n",
       "<td>0.2611</td>\n",
       "<td> (41.0/157.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>11.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.4074</td>\n",
       "<td> (11.0/27.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>127.0</td>\n",
       "<td>57.0</td>\n",
       "<td>0.2826</td>\n",
       "<td> (52.0/184.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.0897848</td>\n",
       "<td>0.3809524</td>\n",
       "<td>56.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0070806</td>\n",
       "<td>0.5504587</td>\n",
       "<td>109.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9944485</td>\n",
       "<td>0.3488372</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9944485</td>\n",
       "<td>0.8641304</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9944485</td>\n",
       "<td>0.75</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000149</td>\n",
       "<td>1.0</td>\n",
       "<td>167.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999750</td>\n",
       "<td>0.9936306</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9944485</td>\n",
       "<td>0.2541470</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0585908</td>\n",
       "<td>0.6296296</td>\n",
       "<td>65.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0070806</td>\n",
       "<td>0.6705591</td>\n",
       "<td>109.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999750</td>\n",
       "<td>156.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999750</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000002</td>\n",
       "<td>157.0</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0000149</td>\n",
       "<td>27.0</td>\n",
       "<td>167.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999750</td>\n",
       "<td>0.9936306</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999750</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000002</td>\n",
       "<td>1.0</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0000149</td>\n",
       "<td>1.0</td>\n",
       "<td>167.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,67 %, avg score: 15,86 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0108696</td>\n",
       "<td>0.9960648</td>\n",
       "<td>3.4074074</td>\n",
       "<td>3.4074074</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9998862</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9998862</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.0370370</td>\n",
       "<td>240.7407407</td>\n",
       "<td>240.7407407</td>\n",
       "<td>0.0306676</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0217391</td>\n",
       "<td>0.9823911</td>\n",
       "<td>6.8148148</td>\n",
       "<td>5.1111111</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9948744</td>\n",
       "<td>0.75</td>\n",
       "<td>0.9973803</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.1111111</td>\n",
       "<td>581.4814815</td>\n",
       "<td>411.1111111</td>\n",
       "<td>0.1047417</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0326087</td>\n",
       "<td>0.9509251</td>\n",
       "<td>0.0</td>\n",
       "<td>3.4074074</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9660521</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9869375</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1111111</td>\n",
       "<td>-100.0</td>\n",
       "<td>240.7407407</td>\n",
       "<td>0.0920028</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0434783</td>\n",
       "<td>0.9315180</td>\n",
       "<td>0.0</td>\n",
       "<td>2.5555556</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9401785</td>\n",
       "<td>0.375</td>\n",
       "<td>0.9752478</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1111111</td>\n",
       "<td>-100.0</td>\n",
       "<td>155.5555556</td>\n",
       "<td>0.0792640</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0543478</td>\n",
       "<td>0.9074002</td>\n",
       "<td>3.4074074</td>\n",
       "<td>2.7259259</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9164244</td>\n",
       "<td>0.4</td>\n",
       "<td>0.9634831</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.1481481</td>\n",
       "<td>240.7407407</td>\n",
       "<td>172.5925926</td>\n",
       "<td>0.1099316</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1032609</td>\n",
       "<td>0.6757347</td>\n",
       "<td>1.5144033</td>\n",
       "<td>2.1520468</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.8341610</td>\n",
       "<td>0.3157895</td>\n",
       "<td>0.9022253</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2222222</td>\n",
       "<td>51.4403292</td>\n",
       "<td>115.2046784</td>\n",
       "<td>0.1394197</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1521739</td>\n",
       "<td>0.3926170</td>\n",
       "<td>1.5144033</td>\n",
       "<td>1.9470899</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.5123107</td>\n",
       "<td>0.2857143</td>\n",
       "<td>0.7768956</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2962963</td>\n",
       "<td>51.4403292</td>\n",
       "<td>94.7089947</td>\n",
       "<td>0.1689078</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2010870</td>\n",
       "<td>0.2404608</td>\n",
       "<td>1.5144033</td>\n",
       "<td>1.8418418</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.3070301</td>\n",
       "<td>0.2702703</td>\n",
       "<td>0.6626040</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.3703704</td>\n",
       "<td>51.4403292</td>\n",
       "<td>84.1841842</td>\n",
       "<td>0.1983958</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989130</td>\n",
       "<td>0.0926710</td>\n",
       "<td>1.8930041</td>\n",
       "<td>1.8585859</td>\n",
       "<td>0.2777778</td>\n",
       "<td>0.1596262</td>\n",
       "<td>0.2727273</td>\n",
       "<td>0.4979931</td>\n",
       "<td>0.1851852</td>\n",
       "<td>0.5555556</td>\n",
       "<td>89.3004115</td>\n",
       "<td>85.8585859</td>\n",
       "<td>0.3007785</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4021739</td>\n",
       "<td>0.0337576</td>\n",
       "<td>0.7173489</td>\n",
       "<td>1.5655656</td>\n",
       "<td>0.1052632</td>\n",
       "<td>0.0603639</td>\n",
       "<td>0.2297297</td>\n",
       "<td>0.3856288</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.6296296</td>\n",
       "<td>-28.2651072</td>\n",
       "<td>56.5565566</td>\n",
       "<td>0.2665723</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0138235</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2592593</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0208630</td>\n",
       "<td>0.1847826</td>\n",
       "<td>0.3142616</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6296296</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9259259</td>\n",
       "<td>0.1519226</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5978261</td>\n",
       "<td>0.0069735</td>\n",
       "<td>2.6502058</td>\n",
       "<td>1.4868687</td>\n",
       "<td>0.3888889</td>\n",
       "<td>0.0098130</td>\n",
       "<td>0.2181818</td>\n",
       "<td>0.2644427</td>\n",
       "<td>0.2592593</td>\n",
       "<td>0.8888889</td>\n",
       "<td>165.0205761</td>\n",
       "<td>48.6868687</td>\n",
       "<td>0.3411182</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010870</td>\n",
       "<td>0.0020432</td>\n",
       "<td>0.3586745</td>\n",
       "<td>1.3207005</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.0039830</td>\n",
       "<td>0.1937984</td>\n",
       "<td>0.2260804</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.9259259</td>\n",
       "<td>-64.1325536</td>\n",
       "<td>32.0700546</td>\n",
       "<td>0.2635055</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7989130</td>\n",
       "<td>0.0006716</td>\n",
       "<td>0.3786008</td>\n",
       "<td>1.2053414</td>\n",
       "<td>0.0555556</td>\n",
       "<td>0.0010680</td>\n",
       "<td>0.1768707</td>\n",
       "<td>0.1985279</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.9629630</td>\n",
       "<td>-62.1399177</td>\n",
       "<td>20.5341396</td>\n",
       "<td>0.1922623</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8967391</td>\n",
       "<td>0.0000174</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0738496</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002737</td>\n",
       "<td>0.1575758</td>\n",
       "<td>0.1769002</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9629630</td>\n",
       "<td>-100.0</td>\n",
       "<td>7.3849607</td>\n",
       "<td>0.0776126</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>2.1e-07</td>\n",
       "<td>0.3586745</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.0000069</td>\n",
       "<td>0.1467391</td>\n",
       "<td>0.1586340</td>\n",
       "<td>0.0370370</td>\n",
       "<td>1.0</td>\n",
       "<td>-64.1325536</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.6103604</td>\n",
       "<td>0.2760548</td>\n",
       "<td>0.1621622</td>\n",
       "<td>0.6486486</td>\n",
       "<td>0.6216216</td>\n",
       "<td>0.7027027</td>\n",
       "<td>0.9166667</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.5889639</td>\n",
       "<td>0.2575010</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.7285714</td>\n",
       "<td>0.6764706</td>\n",
       "<td>0.627451</td>\n",
       "<td>0.7734375</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.3896397</td>\n",
       "<td>0.2760548</td>\n",
       "<td>0.8378378</td>\n",
       "<td>0.3513514</td>\n",
       "<td>0.3783784</td>\n",
       "<td>0.2972973</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>14.4</td>\n",
       "<td>10.237187</td>\n",
       "<td>31.0</td>\n",
       "<td>13.0</td>\n",
       "<td>14.0</td>\n",
       "<td>11.0</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.3245264</td>\n",
       "<td>0.2700964</td>\n",
       "<td>0.0387597</td>\n",
       "<td>0.1612903</td>\n",
       "<td>0.6015037</td>\n",
       "<td>0.1960784</td>\n",
       "<td>0.625</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.3659295</td>\n",
       "<td>0.2603306</td>\n",
       "<td>0.0606061</td>\n",
       "<td>0.2352941</td>\n",
       "<td>0.6956522</td>\n",
       "<td>0.2666667</td>\n",
       "<td>0.5714286</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.4682792</td>\n",
       "<td>0.2463321</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4347826</td>\n",
       "<td>0.8247423</td>\n",
       "<td>0.4166667</td>\n",
       "<td>0.5263158</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.235294</td>\n",
       "<td>3.897253</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.1764705</td>\n",
       "<td>0.0</td>\n",
       "<td>9.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.6734661</td>\n",
       "<td>0.361121</td>\n",
       "<td>0.7400852</td>\n",
       "<td>0.3361628</td>\n",
       "<td>1.2487259</td>\n",
       "<td>0.6354479</td>\n",
       "<td>0.4069091</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.5431746</td>\n",
       "<td>0.2167311</td>\n",
       "<td>0.8611111</td>\n",
       "<td>0.3714286</td>\n",
       "<td>0.65</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.5</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.2916214</td>\n",
       "<td>0.1720953</td>\n",
       "<td>0.0658808</td>\n",
       "<td>0.2894988</td>\n",
       "<td>0.352494</td>\n",
       "<td>0.2172315</td>\n",
       "<td>0.5330018</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.6899936</td>\n",
       "<td>0.0921086</td>\n",
       "<td>0.5694444</td>\n",
       "<td>0.8142857</td>\n",
       "<td>0.6455882</td>\n",
       "<td>0.6862745</td>\n",
       "<td>0.734375</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.3100064</td>\n",
       "<td>0.0921086</td>\n",
       "<td>0.4305556</td>\n",
       "<td>0.1857143</td>\n",
       "<td>0.3544118</td>\n",
       "<td>0.3137255</td>\n",
       "<td>0.265625</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1607539</td>\n",
       "<td>0.0944096</td>\n",
       "<td>0.1534706</td>\n",
       "<td>0.0618375</td>\n",
       "<td>0.3029934</td>\n",
       "<td>0.1924010</td>\n",
       "<td>0.0930667</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.2708051</td>\n",
       "<td>0.2862613</td>\n",
       "<td>0.0157904</td>\n",
       "<td>0.0890943</td>\n",
       "<td>0.6624087</td>\n",
       "<td>0.0992538</td>\n",
       "<td>0.4874786</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.3099282</td>\n",
       "<td>0.2806683</td>\n",
       "<td>0.03125</td>\n",
       "<td>0.1333333</td>\n",
       "<td>0.5517241</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.6666667</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>-1.3580256</td>\n",
       "<td>2.047342</td>\n",
       "<td>-4.8361444</td>\n",
       "<td>-0.2093654</td>\n",
       "<td>-0.2199942</td>\n",
       "<td>-1.5823238</td>\n",
       "<td>0.0576999</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.8215686</td>\n",
       "<td>0.2265958</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9411765</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.5</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3869154</td>\n",
       "<td>0.1175284</td>\n",
       "<td>0.3917532</td>\n",
       "<td>0.2486715</td>\n",
       "<td>0.5504484</td>\n",
       "<td>0.4386354</td>\n",
       "<td>0.3050683</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.5584185</td>\n",
       "<td>0.3219015</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.6285715</td>\n",
       "<td>0.35</td>\n",
       "<td>0.7058824</td>\n",
       "<td>0.96875</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-10.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-10 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-10 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-10 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table th,\n",
       "#h2o-table-10 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2023-05-19 09:28:38</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-19 09:28:38</td>\n",
       "<td> 1 min 23.320 sec</td>\n",
       "<td>10887 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>1</td>\n",
       "<td>1840.0</td>\n",
       "<td>0.2657217</td>\n",
       "<td>0.2685060</td>\n",
       "<td>0.4360685</td>\n",
       "<td>0.8841708</td>\n",
       "<td>0.7660384</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0760870</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-19 09:28:43</td>\n",
       "<td> 1 min 28.373 sec</td>\n",
       "<td>10625 obs/sec</td>\n",
       "<td>300.0</td>\n",
       "<td>30</td>\n",
       "<td>55200.0</td>\n",
       "<td>0.0641222</td>\n",
       "<td>0.0136266</td>\n",
       "<td>0.9671610</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-11.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-11 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-11 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-11 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table th,\n",
       "#h2o-table-11 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>year</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0194952</td></tr>\n",
       "<tr><td>history</td>\n",
       "<td>0.9998528</td>\n",
       "<td>0.9998528</td>\n",
       "<td>0.0194923</td></tr>\n",
       "<tr><td>rating</td>\n",
       "<td>0.9985384</td>\n",
       "<td>0.9985384</td>\n",
       "<td>0.0194667</td></tr>\n",
       "<tr><td>Sci-Fi</td>\n",
       "<td>0.9443295</td>\n",
       "<td>0.9443295</td>\n",
       "<td>0.0184099</td></tr>\n",
       "<tr><td>winner_dga</td>\n",
       "<td>0.9440570</td>\n",
       "<td>0.9440570</td>\n",
       "<td>0.0184046</td></tr>\n",
       "<tr><td>numVotes</td>\n",
       "<td>0.9394366</td>\n",
       "<td>0.9394366</td>\n",
       "<td>0.0183145</td></tr>\n",
       "<tr><td>drama</td>\n",
       "<td>0.9341662</td>\n",
       "<td>0.9341662</td>\n",
       "<td>0.0182118</td></tr>\n",
       "<tr><td>winner_gg_drama</td>\n",
       "<td>0.9233915</td>\n",
       "<td>0.9233915</td>\n",
       "<td>0.0180017</td></tr>\n",
       "<tr><td>Action</td>\n",
       "<td>0.9217670</td>\n",
       "<td>0.9217670</td>\n",
       "<td>0.0179700</td></tr>\n",
       "<tr><td>Documentary</td>\n",
       "<td>0.9186912</td>\n",
       "<td>0.9186912</td>\n",
       "<td>0.0179101</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>winner_gg_comedy</td>\n",
       "<td>0.7938606</td>\n",
       "<td>0.7938606</td>\n",
       "<td>0.0154765</td></tr>\n",
       "<tr><td>Drama</td>\n",
       "<td>0.7931880</td>\n",
       "<td>0.7931880</td>\n",
       "<td>0.0154634</td></tr>\n",
       "<tr><td>musical</td>\n",
       "<td>0.7928636</td>\n",
       "<td>0.7928636</td>\n",
       "<td>0.0154570</td></tr>\n",
       "<tr><td>Music</td>\n",
       "<td>0.7867764</td>\n",
       "<td>0.7867764</td>\n",
       "<td>0.0153384</td></tr>\n",
       "<tr><td>Mystery</td>\n",
       "<td>0.7800037</td>\n",
       "<td>0.7800037</td>\n",
       "<td>0.0152063</td></tr>\n",
       "<tr><td>nom_gg_drama</td>\n",
       "<td>0.7744615</td>\n",
       "<td>0.7744615</td>\n",
       "<td>0.0150983</td></tr>\n",
       "<tr><td>adventure</td>\n",
       "<td>0.7726149</td>\n",
       "<td>0.7726149</td>\n",
       "<td>0.0150623</td></tr>\n",
       "<tr><td>crime</td>\n",
       "<td>0.7580563</td>\n",
       "<td>0.7580563</td>\n",
       "<td>0.0147785</td></tr>\n",
       "<tr><td>sci-fi</td>\n",
       "<td>0.7489484</td>\n",
       "<td>0.7489484</td>\n",
       "<td>0.0146009</td></tr>\n",
       "<tr><td>Short</td>\n",
       "<td>0.7402181</td>\n",
       "<td>0.7402181</td>\n",
       "<td>0.0144307</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[60 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_6_20230519_91906_model_4\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 16Â 402 weights/biases, 205,0 KB, 55Â 200 training samples, mini-batch size 1\n",
       "    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms           mean_bias                bias_rms\n",
       "--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  -------------------  -----------------------  --------------------\n",
       "    1        60       Input             10.0\n",
       "    2        100      RectifierDropout  0.0        0.0   0.0   0.012195518964182459   0.02024739980697632   0.0         0.0023191050170753443  0.11466699838638306  0.49353053754016796      0.05457335710525513\n",
       "    3        100      RectifierDropout  0.0        0.0   0.0   0.013878522963631257   0.049991458654403687  0.0         -0.001626654772080201  0.10583999752998352  0.9973973050687307       0.015333399176597595\n",
       "    4        2        Softmax                      0.0   0.0   0.0027545143297174946  0.007758587598800659  0.0         0.027643022865522653   0.5707516670227051   -0.00017305792290297876  0.007940754294395447\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.004111662465069766\n",
       "RMSE: 0.06412224625720597\n",
       "LogLoss: 0.013626588173579179\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2125439532782935\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      157  0    0        (0.0/157.0)\n",
       "1      0    27   0        (0.0/27.0)\n",
       "Total  157  27   0        (0.0/184.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.212544     1         26\n",
       "max f2                       0.212544     1         26\n",
       "max f0point5                 0.212544     1         26\n",
       "max accuracy                 0.212544     1         26\n",
       "max precision                1            1         0\n",
       "max recall                   0.212544     1         26\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.212544     1         26\n",
       "max min_per_class_accuracy   0.212544     1         26\n",
       "max mean_per_class_accuracy  0.212544     1         26\n",
       "max tns                      1            157       0\n",
       "max fns                      1            26        0\n",
       "max fps                      7.8358e-15   157       183\n",
       "max tps                      0.212544     27        26\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.962963  0\n",
       "max fpr                      7.8358e-15   1         183\n",
       "max tpr                      0.212544     1         26\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,67 %, avg score: 14,05 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0108696                   0.999999           6.81481  6.81481            1                1            1                           1                   0.0740741       0.0740741                  581.481  581.481            0.0740741\n",
       "2        0.0217391                   0.999997           6.81481  6.81481            1                0.999999     1                           0.999999            0.0740741       0.148148                   581.481  581.481            0.148148\n",
       "3        0.0326087                   0.999992           6.81481  6.81481            1                0.999995     1                           0.999998            0.0740741       0.222222                   581.481  581.481            0.222222\n",
       "4        0.0434783                   0.999975           6.81481  6.81481            1                0.999985     1                           0.999995            0.0740741       0.296296                   581.481  581.481            0.296296\n",
       "5        0.0543478                   0.999969           6.81481  6.81481            1                0.999969     1                           0.99999             0.0740741       0.37037                    581.481  581.481            0.37037\n",
       "6        0.103261                    0.991695           6.81481  6.81481            1                0.996953     1                           0.998551            0.333333        0.703704                   581.481  581.481            0.703704\n",
       "7        0.152174                    0.0443215          6.05761  6.57143            0.888889         0.741365     0.964286                    0.915884            0.296296        1                          505.761  557.143            0.993631\n",
       "8        0.201087                    0.00522207         0        4.97297            0                0.0181363    0.72973                     0.697513            0               1                          -100     397.297            0.936306\n",
       "9        0.298913                    0.000835545        0        3.34545            0                0.00212847   0.490909                    0.469933            0               1                          -100     234.545            0.821656\n",
       "10       0.402174                    0.000218207        0        2.48649            0                0.000466826  0.364865                    0.349394            0               1                          -100     148.649            0.700637\n",
       "11       0.5                         5.4297e-05         0        2                  0                0.000108872  0.293478                    0.281056            0               1                          -100     100                0.585987\n",
       "12       0.597826                    8.64369e-06        0        1.67273            0                2.55536e-05  0.245455                    0.235069            0               1                          -100     67.2727            0.471338\n",
       "13       0.701087                    8.38175e-07        0        1.42636            0                3.21457e-06  0.209302                    0.200447            0               1                          -100     42.6357            0.350318\n",
       "14       0.798913                    1.58885e-07        0        1.2517             0                4.54315e-07  0.183673                    0.175902            0               1                          -100     25.1701            0.235669\n",
       "15       0.896739                    5.55254e-09        0        1.11515            0                5.76097e-08  0.163636                    0.156713            0               1                          -100     11.5152            0.121019\n",
       "16       1                           7.8358e-15         0        1                  0                1.22137e-09  0.146739                    0.140531            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.16112171557684316\n",
       "RMSE: 0.40139969553656013\n",
       "LogLoss: 0.6749148423554983\n",
       "Mean Per-Class Error: 0.334276952111347\n",
       "AUC: 0.7008728473696627\n",
       "AUCPR: 0.28837964750621486\n",
       "Gini: 0.4017456947393254\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.08978481850166033\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      116  41   0.2611   (41.0/157.0)\n",
       "1      11   16   0.4074   (11.0/27.0)\n",
       "Total  127  57   0.2826   (52.0/184.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.0897848    0.380952  56\n",
       "max f2                       0.00708063   0.550459  109\n",
       "max f0point5                 0.994448     0.348837  3\n",
       "max accuracy                 0.994448     0.86413   3\n",
       "max precision                0.994448     0.75      3\n",
       "max recall                   1.48736e-05  1         167\n",
       "max specificity              0.999975     0.993631  0\n",
       "max absolute_mcc             0.994448     0.254147  3\n",
       "max min_per_class_accuracy   0.0585908    0.62963   65\n",
       "max mean_per_class_accuracy  0.00708063   0.670559  109\n",
       "max tns                      0.999975     156       0\n",
       "max fns                      0.999975     27        0\n",
       "max fps                      2.05766e-07  157       183\n",
       "max tps                      1.48736e-05  27        167\n",
       "max tnr                      0.999975     0.993631  0\n",
       "max fnr                      0.999975     1         0\n",
       "max fpr                      2.05766e-07  1         183\n",
       "max tpr                      1.48736e-05  1         167\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,67 %, avg score: 15,86 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0108696                   0.996065           3.40741   3.40741            0.5              0.999886     0.5                         0.999886            0.037037        0.037037                   240.741   240.741            0.0306676\n",
       "2        0.0217391                   0.982391           6.81481   5.11111            1                0.994874     0.75                        0.99738             0.0740741       0.111111                   581.481   411.111            0.104742\n",
       "3        0.0326087                   0.950925           0         3.40741            0                0.966052     0.5                         0.986938            0               0.111111                   -100      240.741            0.0920028\n",
       "4        0.0434783                   0.931518           0         2.55556            0                0.940179     0.375                       0.975248            0               0.111111                   -100      155.556            0.079264\n",
       "5        0.0543478                   0.9074             3.40741   2.72593            0.5              0.916424     0.4                         0.963483            0.037037        0.148148                   240.741   172.593            0.109932\n",
       "6        0.103261                    0.675735           1.5144    2.15205            0.222222         0.834161     0.315789                    0.902225            0.0740741       0.222222                   51.4403   115.205            0.13942\n",
       "7        0.152174                    0.392617           1.5144    1.94709            0.222222         0.512311     0.285714                    0.776896            0.0740741       0.296296                   51.4403   94.709             0.168908\n",
       "8        0.201087                    0.240461           1.5144    1.84184            0.222222         0.30703      0.27027                     0.662604            0.0740741       0.37037                    51.4403   84.1842            0.198396\n",
       "9        0.298913                    0.092671           1.893     1.85859            0.277778         0.159626     0.272727                    0.497993            0.185185        0.555556                   89.3004   85.8586            0.300778\n",
       "10       0.402174                    0.0337576          0.717349  1.56557            0.105263         0.0603639    0.22973                     0.385629            0.0740741       0.62963                    -28.2651  56.5566            0.266572\n",
       "11       0.5                         0.0138235          0         1.25926            0                0.020863     0.184783                    0.314262            0               0.62963                    -100      25.9259            0.151923\n",
       "12       0.597826                    0.00697349         2.65021   1.48687            0.388889         0.00981296   0.218182                    0.264443            0.259259        0.888889                   165.021   48.6869            0.341118\n",
       "13       0.701087                    0.00204317         0.358674  1.3207             0.0526316        0.00398299   0.193798                    0.22608             0.037037        0.925926                   -64.1326  32.0701            0.263506\n",
       "14       0.798913                    0.00067156         0.378601  1.20534            0.0555556        0.00106803   0.176871                    0.198528            0.037037        0.962963                   -62.1399  20.5341            0.192262\n",
       "15       0.896739                    1.7367e-05         0         1.07385            0                0.000273677  0.157576                    0.1769              0               0.962963                   -100      7.38496            0.0776126\n",
       "16       1                           2.1e-07            0.358674  1                  0.0526316        6.85895e-06  0.146739                    0.158634            0.037037        1                          -64.1326  0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean      sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.61036   0.276055   0.162162      0.648649      0.621622      0.702703      0.916667\n",
       "auc                      0.588964  0.257501   0.138889      0.728571      0.676471      0.627451      0.773438\n",
       "err                      0.38964   0.276055   0.837838      0.351351      0.378378      0.297297      0.0833333\n",
       "err_count                14.4      10.2372    31            13            14            11            3\n",
       "f0point5                 0.324526  0.270096   0.0387597     0.16129       0.601504      0.196078      0.625\n",
       "f1                       0.36593   0.260331   0.0606061     0.235294      0.695652      0.266667      0.571429\n",
       "f2                       0.468279  0.246332   0.138889      0.434783      0.824742      0.416667      0.526316\n",
       "lift_top_group           2.23529   3.89725    0             0             2.17647       0             9\n",
       "logloss                  0.673466  0.361121   0.740085      0.336163      1.24873       0.635448      0.406909\n",
       "max_per_class_error      0.543175  0.216731   0.861111      0.371429      0.65          0.333333      0.5\n",
       "mcc                      0.291621  0.172095   0.0658808     0.289499      0.352494      0.217232      0.533002\n",
       "mean_per_class_accuracy  0.689994  0.0921086  0.569444      0.814286      0.645588      0.686275      0.734375\n",
       "mean_per_class_error     0.310006  0.0921086  0.430556      0.185714      0.354412      0.313725      0.265625\n",
       "mse                      0.160754  0.0944096  0.153471      0.0618375     0.302993      0.192401      0.0930667\n",
       "pr_auc                   0.270805  0.286261   0.0157904     0.0890943     0.662409      0.0992538     0.487479\n",
       "precision                0.309928  0.280668   0.03125       0.133333      0.551724      0.166667      0.666667\n",
       "r2                       -1.35803  2.04734    -4.83614      -0.209365     -0.219994     -1.58232      0.0576999\n",
       "recall                   0.821569  0.226596   1             1             0.941176      0.666667      0.5\n",
       "rmse                     0.386915  0.117528   0.391753      0.248672      0.550448      0.438635      0.305068\n",
       "specificity              0.558419  0.321902   0.138889      0.628571      0.35          0.705882      0.96875\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2023-05-19 09:28:38  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan\n",
       "    2023-05-19 09:28:38  1 min 23.320 sec  10887 obs/sec     10        1             1840       0.265722         0.268506            0.436068       0.884171        0.766038           6.81481          0.076087\n",
       "    2023-05-19 09:28:43  1 min 28.373 sec  10625 obs/sec     300       30            55200      0.0641222        0.0136266           0.967161       1               1                  6.81481          0\n",
       "\n",
       "Variable Importances: \n",
       "variable          relative_importance    scaled_importance    percentage\n",
       "----------------  ---------------------  -------------------  --------------------\n",
       "year              1.0                    1.0                  0.01949521562693404\n",
       "history           0.9998527765274048     0.9998527765274048   0.01949234547359045\n",
       "rating            0.9985383749008179     0.9985383749008179   0.019466720930459744\n",
       "Sci-Fi            0.9443295001983643     0.9443295001983643   0.018409907229241962\n",
       "winner_dga        0.9440569877624512     0.9440569877624512   0.018404594540542815\n",
       "numVotes          0.9394365549087524     0.9394365549087524   0.018314518205770187\n",
       "drama             0.9341661930084229     0.9341661930084229   0.018211771364091283\n",
       "winner_gg_drama   0.9233915209770203     0.9233915209770203   0.018001716809529594\n",
       "Action            0.921766996383667      0.921766996383667    0.017970046352290915\n",
       "Documentary       0.9186911582946777     0.9186911582946777   0.017910082225512533\n",
       "---               ---                    ---                  ---\n",
       "winner_gg_comedy  0.7938606142997742     0.7938606142997742   0.015476483853504412\n",
       "Drama             0.7931879758834839     0.7931879758834839   0.015463370622539874\n",
       "musical           0.7928636074066162     0.7928636074066162   0.01545704698914076\n",
       "Music             0.7867763638496399     0.7867763638496399   0.01533837486342384\n",
       "Mystery           0.7800036668777466     0.7800036668777466   0.015206339675580898\n",
       "nom_gg_drama      0.7744615077972412     0.7744615077972412   0.015098294089267675\n",
       "adventure         0.7726148962974548     0.7726148962974548   0.015062293999900164\n",
       "crime             0.7580563426017761     0.7580563426017761   0.014778471856386609\n",
       "sci-fi            0.7489483952522278     0.7489483952522278   0.014600910458888401\n",
       "Short             0.7402181029319763     0.7402181029319763   0.014430711527618933\n",
       "[60 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model = aml.leader\n",
    "top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\aczaplak.MPD1\\\\repos\\\\oscar_predictions\\\\additional_data\\\\additional_data\\\\model.zip\\\\DeepLearning_grid_2_AutoML_6_20230519_91906_model_4'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.save_model(top_model, './additional_data/model.zip' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = h2o.load_model('./additional_data/model.zip/DeepLearning_grid_2_AutoML_6_20230519_91906_model_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_6_20230519_91906_model_4\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-12.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-12 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-12 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-12 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table th,\n",
       "#h2o-table-12 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-12 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-12\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 16Â 402 weights/biases, 205,0 KB, 55Â 200 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>60</td>\n",
       "<td>Input</td>\n",
       "<td>10.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>100</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0121955</td>\n",
       "<td>0.0202474</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0023191</td>\n",
       "<td>0.1146670</td>\n",
       "<td>0.4935305</td>\n",
       "<td>0.0545734</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>100</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0138785</td>\n",
       "<td>0.0499915</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0016267</td>\n",
       "<td>0.1058400</td>\n",
       "<td>0.9973973</td>\n",
       "<td>0.0153334</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0027545</td>\n",
       "<td>0.0077586</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0276430</td>\n",
       "<td>0.5707517</td>\n",
       "<td>-0.0001731</td>\n",
       "<td>0.0079408</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.004111662465069766\n",
       "RMSE: 0.06412224625720597\n",
       "LogLoss: 0.013626588173579179\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-13.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-13 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-13 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-13 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table th,\n",
       "#h2o-table-13 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-13 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-13\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2125439532782935</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>157.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/157.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/27.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>157.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/184.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-14.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-14 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-14 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-14 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-14 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-14 .h2o-table th,\n",
       "#h2o-table-14 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-14 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-14\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>157.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>26.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>157.0</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.2125440</td>\n",
       "<td>27.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9629630</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.2125440</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-15.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-15 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-15 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-15 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-15 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-15 .h2o-table th,\n",
       "#h2o-table-15 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-15 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-15\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,67 %, avg score: 14,05 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0108696</td>\n",
       "<td>0.9999991</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.0740741</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.0740741</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0217391</td>\n",
       "<td>0.9999972</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999988</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999994</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.1481481</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.1481481</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0326087</td>\n",
       "<td>0.9999925</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999946</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999978</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2222222</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.2222222</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0434783</td>\n",
       "<td>0.9999749</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999848</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999945</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2962963</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.2962963</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0543478</td>\n",
       "<td>0.9999688</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999695</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999895</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.3703704</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.3703704</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1032609</td>\n",
       "<td>0.9916950</td>\n",
       "<td>6.8148148</td>\n",
       "<td>6.8148148</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9969527</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9985510</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.7037037</td>\n",
       "<td>581.4814815</td>\n",
       "<td>581.4814815</td>\n",
       "<td>0.7037037</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1521739</td>\n",
       "<td>0.0443215</td>\n",
       "<td>6.0576132</td>\n",
       "<td>6.5714286</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.7413653</td>\n",
       "<td>0.9642857</td>\n",
       "<td>0.9158842</td>\n",
       "<td>0.2962963</td>\n",
       "<td>1.0</td>\n",
       "<td>505.7613169</td>\n",
       "<td>557.1428571</td>\n",
       "<td>0.9936306</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2010870</td>\n",
       "<td>0.0052221</td>\n",
       "<td>0.0</td>\n",
       "<td>4.9729730</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0181363</td>\n",
       "<td>0.7297297</td>\n",
       "<td>0.6975131</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>397.2972973</td>\n",
       "<td>0.9363057</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989130</td>\n",
       "<td>0.0008355</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3454545</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0021285</td>\n",
       "<td>0.4909091</td>\n",
       "<td>0.4699327</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>234.5454545</td>\n",
       "<td>0.8216561</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4021739</td>\n",
       "<td>0.0002182</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4864865</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004668</td>\n",
       "<td>0.3648649</td>\n",
       "<td>0.3493941</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>148.6486486</td>\n",
       "<td>0.7006369</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0000543</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001089</td>\n",
       "<td>0.2934783</td>\n",
       "<td>0.2810557</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td>\n",
       "<td>0.5859873</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5978261</td>\n",
       "<td>0.0000086</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6727273</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000256</td>\n",
       "<td>0.2454545</td>\n",
       "<td>0.2350690</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2727273</td>\n",
       "<td>0.4713376</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010870</td>\n",
       "<td>0.0000008</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4263566</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000032</td>\n",
       "<td>0.2093023</td>\n",
       "<td>0.2004469</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6356589</td>\n",
       "<td>0.3503185</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7989130</td>\n",
       "<td>0.0000002</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2517007</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.1836735</td>\n",
       "<td>0.1759024</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1700680</td>\n",
       "<td>0.2356688</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8967391</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1151515</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.1636364</td>\n",
       "<td>0.1567131</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.5151515</td>\n",
       "<td>0.1210191</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1467391</td>\n",
       "<td>0.1405307</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.16112171557684316\n",
       "RMSE: 0.40139969553656013\n",
       "LogLoss: 0.6749148423554983\n",
       "Mean Per-Class Error: 0.334276952111347\n",
       "AUC: 0.7008728473696627\n",
       "AUCPR: 0.28837964750621486\n",
       "Gini: 0.4017456947393254</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-16.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-16 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-16 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-16 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-16 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-16 .h2o-table th,\n",
       "#h2o-table-16 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-16 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-16\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.08978481850166033</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>116.0</td>\n",
       "<td>41.0</td>\n",
       "<td>0.2611</td>\n",
       "<td> (41.0/157.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>11.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.4074</td>\n",
       "<td> (11.0/27.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>127.0</td>\n",
       "<td>57.0</td>\n",
       "<td>0.2826</td>\n",
       "<td> (52.0/184.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-17.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-17 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-17 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-17 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-17 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-17 .h2o-table th,\n",
       "#h2o-table-17 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-17 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-17\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.0897848</td>\n",
       "<td>0.3809524</td>\n",
       "<td>56.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0070806</td>\n",
       "<td>0.5504587</td>\n",
       "<td>109.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9944485</td>\n",
       "<td>0.3488372</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9944485</td>\n",
       "<td>0.8641304</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9944485</td>\n",
       "<td>0.75</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000149</td>\n",
       "<td>1.0</td>\n",
       "<td>167.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999750</td>\n",
       "<td>0.9936306</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9944485</td>\n",
       "<td>0.2541470</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0585908</td>\n",
       "<td>0.6296296</td>\n",
       "<td>65.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0070806</td>\n",
       "<td>0.6705591</td>\n",
       "<td>109.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999750</td>\n",
       "<td>156.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999750</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000002</td>\n",
       "<td>157.0</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0000149</td>\n",
       "<td>27.0</td>\n",
       "<td>167.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999750</td>\n",
       "<td>0.9936306</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999750</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000002</td>\n",
       "<td>1.0</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0000149</td>\n",
       "<td>1.0</td>\n",
       "<td>167.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-18.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-18 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-18 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-18 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-18 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-18 .h2o-table th,\n",
       "#h2o-table-18 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-18 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-18\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,67 %, avg score: 15,86 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0108696</td>\n",
       "<td>0.9960648</td>\n",
       "<td>3.4074074</td>\n",
       "<td>3.4074074</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9998862</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9998862</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.0370370</td>\n",
       "<td>240.7407407</td>\n",
       "<td>240.7407407</td>\n",
       "<td>0.0306676</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0217391</td>\n",
       "<td>0.9823911</td>\n",
       "<td>6.8148148</td>\n",
       "<td>5.1111111</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9948744</td>\n",
       "<td>0.75</td>\n",
       "<td>0.9973803</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.1111111</td>\n",
       "<td>581.4814815</td>\n",
       "<td>411.1111111</td>\n",
       "<td>0.1047417</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0326087</td>\n",
       "<td>0.9509251</td>\n",
       "<td>0.0</td>\n",
       "<td>3.4074074</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9660521</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9869375</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1111111</td>\n",
       "<td>-100.0</td>\n",
       "<td>240.7407407</td>\n",
       "<td>0.0920028</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0434783</td>\n",
       "<td>0.9315180</td>\n",
       "<td>0.0</td>\n",
       "<td>2.5555556</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9401785</td>\n",
       "<td>0.375</td>\n",
       "<td>0.9752478</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1111111</td>\n",
       "<td>-100.0</td>\n",
       "<td>155.5555556</td>\n",
       "<td>0.0792640</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0543478</td>\n",
       "<td>0.9074002</td>\n",
       "<td>3.4074074</td>\n",
       "<td>2.7259259</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9164244</td>\n",
       "<td>0.4</td>\n",
       "<td>0.9634831</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.1481481</td>\n",
       "<td>240.7407407</td>\n",
       "<td>172.5925926</td>\n",
       "<td>0.1099316</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1032609</td>\n",
       "<td>0.6757347</td>\n",
       "<td>1.5144033</td>\n",
       "<td>2.1520468</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.8341610</td>\n",
       "<td>0.3157895</td>\n",
       "<td>0.9022253</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2222222</td>\n",
       "<td>51.4403292</td>\n",
       "<td>115.2046784</td>\n",
       "<td>0.1394197</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1521739</td>\n",
       "<td>0.3926170</td>\n",
       "<td>1.5144033</td>\n",
       "<td>1.9470899</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.5123107</td>\n",
       "<td>0.2857143</td>\n",
       "<td>0.7768956</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2962963</td>\n",
       "<td>51.4403292</td>\n",
       "<td>94.7089947</td>\n",
       "<td>0.1689078</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2010870</td>\n",
       "<td>0.2404608</td>\n",
       "<td>1.5144033</td>\n",
       "<td>1.8418418</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.3070301</td>\n",
       "<td>0.2702703</td>\n",
       "<td>0.6626040</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.3703704</td>\n",
       "<td>51.4403292</td>\n",
       "<td>84.1841842</td>\n",
       "<td>0.1983958</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989130</td>\n",
       "<td>0.0926710</td>\n",
       "<td>1.8930041</td>\n",
       "<td>1.8585859</td>\n",
       "<td>0.2777778</td>\n",
       "<td>0.1596262</td>\n",
       "<td>0.2727273</td>\n",
       "<td>0.4979931</td>\n",
       "<td>0.1851852</td>\n",
       "<td>0.5555556</td>\n",
       "<td>89.3004115</td>\n",
       "<td>85.8585859</td>\n",
       "<td>0.3007785</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4021739</td>\n",
       "<td>0.0337576</td>\n",
       "<td>0.7173489</td>\n",
       "<td>1.5655656</td>\n",
       "<td>0.1052632</td>\n",
       "<td>0.0603639</td>\n",
       "<td>0.2297297</td>\n",
       "<td>0.3856288</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.6296296</td>\n",
       "<td>-28.2651072</td>\n",
       "<td>56.5565566</td>\n",
       "<td>0.2665723</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0138235</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2592593</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0208630</td>\n",
       "<td>0.1847826</td>\n",
       "<td>0.3142616</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6296296</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9259259</td>\n",
       "<td>0.1519226</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5978261</td>\n",
       "<td>0.0069735</td>\n",
       "<td>2.6502058</td>\n",
       "<td>1.4868687</td>\n",
       "<td>0.3888889</td>\n",
       "<td>0.0098130</td>\n",
       "<td>0.2181818</td>\n",
       "<td>0.2644427</td>\n",
       "<td>0.2592593</td>\n",
       "<td>0.8888889</td>\n",
       "<td>165.0205761</td>\n",
       "<td>48.6868687</td>\n",
       "<td>0.3411182</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010870</td>\n",
       "<td>0.0020432</td>\n",
       "<td>0.3586745</td>\n",
       "<td>1.3207005</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.0039830</td>\n",
       "<td>0.1937984</td>\n",
       "<td>0.2260804</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.9259259</td>\n",
       "<td>-64.1325536</td>\n",
       "<td>32.0700546</td>\n",
       "<td>0.2635055</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7989130</td>\n",
       "<td>0.0006716</td>\n",
       "<td>0.3786008</td>\n",
       "<td>1.2053414</td>\n",
       "<td>0.0555556</td>\n",
       "<td>0.0010680</td>\n",
       "<td>0.1768707</td>\n",
       "<td>0.1985279</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.9629630</td>\n",
       "<td>-62.1399177</td>\n",
       "<td>20.5341396</td>\n",
       "<td>0.1922623</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8967391</td>\n",
       "<td>0.0000174</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0738496</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002737</td>\n",
       "<td>0.1575758</td>\n",
       "<td>0.1769002</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9629630</td>\n",
       "<td>-100.0</td>\n",
       "<td>7.3849607</td>\n",
       "<td>0.0776126</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>2.1e-07</td>\n",
       "<td>0.3586745</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.0000069</td>\n",
       "<td>0.1467391</td>\n",
       "<td>0.1586340</td>\n",
       "<td>0.0370370</td>\n",
       "<td>1.0</td>\n",
       "<td>-64.1325536</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-19.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-19 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-19 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-19 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-19 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-19 .h2o-table th,\n",
       "#h2o-table-19 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-19 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-19\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.6103604</td>\n",
       "<td>0.2760548</td>\n",
       "<td>0.1621622</td>\n",
       "<td>0.6486486</td>\n",
       "<td>0.6216216</td>\n",
       "<td>0.7027027</td>\n",
       "<td>0.9166667</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.5889639</td>\n",
       "<td>0.2575010</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.7285714</td>\n",
       "<td>0.6764706</td>\n",
       "<td>0.627451</td>\n",
       "<td>0.7734375</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.3896397</td>\n",
       "<td>0.2760548</td>\n",
       "<td>0.8378378</td>\n",
       "<td>0.3513514</td>\n",
       "<td>0.3783784</td>\n",
       "<td>0.2972973</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>14.4</td>\n",
       "<td>10.237187</td>\n",
       "<td>31.0</td>\n",
       "<td>13.0</td>\n",
       "<td>14.0</td>\n",
       "<td>11.0</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.3245264</td>\n",
       "<td>0.2700964</td>\n",
       "<td>0.0387597</td>\n",
       "<td>0.1612903</td>\n",
       "<td>0.6015037</td>\n",
       "<td>0.1960784</td>\n",
       "<td>0.625</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.3659295</td>\n",
       "<td>0.2603306</td>\n",
       "<td>0.0606061</td>\n",
       "<td>0.2352941</td>\n",
       "<td>0.6956522</td>\n",
       "<td>0.2666667</td>\n",
       "<td>0.5714286</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.4682792</td>\n",
       "<td>0.2463321</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4347826</td>\n",
       "<td>0.8247423</td>\n",
       "<td>0.4166667</td>\n",
       "<td>0.5263158</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.235294</td>\n",
       "<td>3.897253</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.1764705</td>\n",
       "<td>0.0</td>\n",
       "<td>9.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.6734661</td>\n",
       "<td>0.361121</td>\n",
       "<td>0.7400852</td>\n",
       "<td>0.3361628</td>\n",
       "<td>1.2487259</td>\n",
       "<td>0.6354479</td>\n",
       "<td>0.4069091</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.5431746</td>\n",
       "<td>0.2167311</td>\n",
       "<td>0.8611111</td>\n",
       "<td>0.3714286</td>\n",
       "<td>0.65</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.5</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.2916214</td>\n",
       "<td>0.1720953</td>\n",
       "<td>0.0658808</td>\n",
       "<td>0.2894988</td>\n",
       "<td>0.352494</td>\n",
       "<td>0.2172315</td>\n",
       "<td>0.5330018</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.6899936</td>\n",
       "<td>0.0921086</td>\n",
       "<td>0.5694444</td>\n",
       "<td>0.8142857</td>\n",
       "<td>0.6455882</td>\n",
       "<td>0.6862745</td>\n",
       "<td>0.734375</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.3100064</td>\n",
       "<td>0.0921086</td>\n",
       "<td>0.4305556</td>\n",
       "<td>0.1857143</td>\n",
       "<td>0.3544118</td>\n",
       "<td>0.3137255</td>\n",
       "<td>0.265625</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1607539</td>\n",
       "<td>0.0944096</td>\n",
       "<td>0.1534706</td>\n",
       "<td>0.0618375</td>\n",
       "<td>0.3029934</td>\n",
       "<td>0.1924010</td>\n",
       "<td>0.0930667</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.2708051</td>\n",
       "<td>0.2862613</td>\n",
       "<td>0.0157904</td>\n",
       "<td>0.0890943</td>\n",
       "<td>0.6624087</td>\n",
       "<td>0.0992538</td>\n",
       "<td>0.4874786</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.3099282</td>\n",
       "<td>0.2806683</td>\n",
       "<td>0.03125</td>\n",
       "<td>0.1333333</td>\n",
       "<td>0.5517241</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.6666667</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>-1.3580256</td>\n",
       "<td>2.047342</td>\n",
       "<td>-4.8361444</td>\n",
       "<td>-0.2093654</td>\n",
       "<td>-0.2199942</td>\n",
       "<td>-1.5823238</td>\n",
       "<td>0.0576999</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.8215686</td>\n",
       "<td>0.2265958</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9411765</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.5</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3869154</td>\n",
       "<td>0.1175284</td>\n",
       "<td>0.3917532</td>\n",
       "<td>0.2486715</td>\n",
       "<td>0.5504484</td>\n",
       "<td>0.4386354</td>\n",
       "<td>0.3050683</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.5584185</td>\n",
       "<td>0.3219015</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.6285715</td>\n",
       "<td>0.35</td>\n",
       "<td>0.7058824</td>\n",
       "<td>0.96875</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-20.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-20 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-20 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-20 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-20 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-20 .h2o-table th,\n",
       "#h2o-table-20 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-20 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-20\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2023-05-19 09:28:38</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-19 09:28:38</td>\n",
       "<td> 1 min 23.320 sec</td>\n",
       "<td>10887 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>1</td>\n",
       "<td>1840.0</td>\n",
       "<td>0.2657217</td>\n",
       "<td>0.2685060</td>\n",
       "<td>0.4360685</td>\n",
       "<td>0.8841708</td>\n",
       "<td>0.7660384</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0760870</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-19 09:28:43</td>\n",
       "<td> 1 min 28.373 sec</td>\n",
       "<td>10625 obs/sec</td>\n",
       "<td>300.0</td>\n",
       "<td>30</td>\n",
       "<td>55200.0</td>\n",
       "<td>0.0641222</td>\n",
       "<td>0.0136266</td>\n",
       "<td>0.9671610</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.8148148</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-21.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-21 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-21 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-21 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table th,\n",
       "#h2o-table-21 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-21 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-21\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>year</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0194952</td></tr>\n",
       "<tr><td>history</td>\n",
       "<td>0.9998528</td>\n",
       "<td>0.9998528</td>\n",
       "<td>0.0194923</td></tr>\n",
       "<tr><td>rating</td>\n",
       "<td>0.9985384</td>\n",
       "<td>0.9985384</td>\n",
       "<td>0.0194667</td></tr>\n",
       "<tr><td>Sci-Fi</td>\n",
       "<td>0.9443295</td>\n",
       "<td>0.9443295</td>\n",
       "<td>0.0184099</td></tr>\n",
       "<tr><td>winner_dga</td>\n",
       "<td>0.9440570</td>\n",
       "<td>0.9440570</td>\n",
       "<td>0.0184046</td></tr>\n",
       "<tr><td>numVotes</td>\n",
       "<td>0.9394366</td>\n",
       "<td>0.9394366</td>\n",
       "<td>0.0183145</td></tr>\n",
       "<tr><td>drama</td>\n",
       "<td>0.9341662</td>\n",
       "<td>0.9341662</td>\n",
       "<td>0.0182118</td></tr>\n",
       "<tr><td>winner_gg_drama</td>\n",
       "<td>0.9233915</td>\n",
       "<td>0.9233915</td>\n",
       "<td>0.0180017</td></tr>\n",
       "<tr><td>Action</td>\n",
       "<td>0.9217670</td>\n",
       "<td>0.9217670</td>\n",
       "<td>0.0179700</td></tr>\n",
       "<tr><td>Documentary</td>\n",
       "<td>0.9186912</td>\n",
       "<td>0.9186912</td>\n",
       "<td>0.0179101</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>winner_gg_comedy</td>\n",
       "<td>0.7938606</td>\n",
       "<td>0.7938606</td>\n",
       "<td>0.0154765</td></tr>\n",
       "<tr><td>Drama</td>\n",
       "<td>0.7931880</td>\n",
       "<td>0.7931880</td>\n",
       "<td>0.0154634</td></tr>\n",
       "<tr><td>musical</td>\n",
       "<td>0.7928636</td>\n",
       "<td>0.7928636</td>\n",
       "<td>0.0154570</td></tr>\n",
       "<tr><td>Music</td>\n",
       "<td>0.7867764</td>\n",
       "<td>0.7867764</td>\n",
       "<td>0.0153384</td></tr>\n",
       "<tr><td>Mystery</td>\n",
       "<td>0.7800037</td>\n",
       "<td>0.7800037</td>\n",
       "<td>0.0152063</td></tr>\n",
       "<tr><td>nom_gg_drama</td>\n",
       "<td>0.7744615</td>\n",
       "<td>0.7744615</td>\n",
       "<td>0.0150983</td></tr>\n",
       "<tr><td>adventure</td>\n",
       "<td>0.7726149</td>\n",
       "<td>0.7726149</td>\n",
       "<td>0.0150623</td></tr>\n",
       "<tr><td>crime</td>\n",
       "<td>0.7580563</td>\n",
       "<td>0.7580563</td>\n",
       "<td>0.0147785</td></tr>\n",
       "<tr><td>sci-fi</td>\n",
       "<td>0.7489484</td>\n",
       "<td>0.7489484</td>\n",
       "<td>0.0146009</td></tr>\n",
       "<tr><td>Short</td>\n",
       "<td>0.7402181</td>\n",
       "<td>0.7402181</td>\n",
       "<td>0.0144307</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[60 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_2_AutoML_6_20230519_91906_model_4\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 16Â 402 weights/biases, 205,0 KB, 55Â 200 training samples, mini-batch size 1\n",
       "    layer    units    type              dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight            weight_rms           mean_bias                bias_rms\n",
       "--  -------  -------  ----------------  ---------  ----  ----  ---------------------  --------------------  ----------  ---------------------  -------------------  -----------------------  --------------------\n",
       "    1        60       Input             10.0\n",
       "    2        100      RectifierDropout  0.0        0.0   0.0   0.012195518964182459   0.02024739980697632   0.0         0.0023191050170753443  0.11466699838638306  0.49353053754016796      0.05457335710525513\n",
       "    3        100      RectifierDropout  0.0        0.0   0.0   0.013878522963631257   0.049991458654403687  0.0         -0.001626654772080201  0.10583999752998352  0.9973973050687307       0.015333399176597595\n",
       "    4        2        Softmax                      0.0   0.0   0.0027545143297174946  0.007758587598800659  0.0         0.027643022865522653   0.5707516670227051   -0.00017305792290297876  0.007940754294395447\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.004111662465069766\n",
       "RMSE: 0.06412224625720597\n",
       "LogLoss: 0.013626588173579179\n",
       "Mean Per-Class Error: 0.0\n",
       "AUC: 1.0\n",
       "AUCPR: 1.0\n",
       "Gini: 1.0\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2125439532782935\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      157  0    0        (0.0/157.0)\n",
       "1      0    27   0        (0.0/27.0)\n",
       "Total  157  27   0        (0.0/184.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.212544     1         26\n",
       "max f2                       0.212544     1         26\n",
       "max f0point5                 0.212544     1         26\n",
       "max accuracy                 0.212544     1         26\n",
       "max precision                1            1         0\n",
       "max recall                   0.212544     1         26\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.212544     1         26\n",
       "max min_per_class_accuracy   0.212544     1         26\n",
       "max mean_per_class_accuracy  0.212544     1         26\n",
       "max tns                      1            157       0\n",
       "max fns                      1            26        0\n",
       "max fps                      7.8358e-15   157       183\n",
       "max tps                      0.212544     27        26\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.962963  0\n",
       "max fpr                      7.8358e-15   1         183\n",
       "max tpr                      0.212544     1         26\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,67 %, avg score: 14,05 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0108696                   0.999999           6.81481  6.81481            1                1            1                           1                   0.0740741       0.0740741                  581.481  581.481            0.0740741\n",
       "2        0.0217391                   0.999997           6.81481  6.81481            1                0.999999     1                           0.999999            0.0740741       0.148148                   581.481  581.481            0.148148\n",
       "3        0.0326087                   0.999992           6.81481  6.81481            1                0.999995     1                           0.999998            0.0740741       0.222222                   581.481  581.481            0.222222\n",
       "4        0.0434783                   0.999975           6.81481  6.81481            1                0.999985     1                           0.999995            0.0740741       0.296296                   581.481  581.481            0.296296\n",
       "5        0.0543478                   0.999969           6.81481  6.81481            1                0.999969     1                           0.99999             0.0740741       0.37037                    581.481  581.481            0.37037\n",
       "6        0.103261                    0.991695           6.81481  6.81481            1                0.996953     1                           0.998551            0.333333        0.703704                   581.481  581.481            0.703704\n",
       "7        0.152174                    0.0443215          6.05761  6.57143            0.888889         0.741365     0.964286                    0.915884            0.296296        1                          505.761  557.143            0.993631\n",
       "8        0.201087                    0.00522207         0        4.97297            0                0.0181363    0.72973                     0.697513            0               1                          -100     397.297            0.936306\n",
       "9        0.298913                    0.000835545        0        3.34545            0                0.00212847   0.490909                    0.469933            0               1                          -100     234.545            0.821656\n",
       "10       0.402174                    0.000218207        0        2.48649            0                0.000466826  0.364865                    0.349394            0               1                          -100     148.649            0.700637\n",
       "11       0.5                         5.4297e-05         0        2                  0                0.000108872  0.293478                    0.281056            0               1                          -100     100                0.585987\n",
       "12       0.597826                    8.64369e-06        0        1.67273            0                2.55536e-05  0.245455                    0.235069            0               1                          -100     67.2727            0.471338\n",
       "13       0.701087                    8.38175e-07        0        1.42636            0                3.21457e-06  0.209302                    0.200447            0               1                          -100     42.6357            0.350318\n",
       "14       0.798913                    1.58885e-07        0        1.2517             0                4.54315e-07  0.183673                    0.175902            0               1                          -100     25.1701            0.235669\n",
       "15       0.896739                    5.55254e-09        0        1.11515            0                5.76097e-08  0.163636                    0.156713            0               1                          -100     11.5152            0.121019\n",
       "16       1                           7.8358e-15         0        1                  0                1.22137e-09  0.146739                    0.140531            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.16112171557684316\n",
       "RMSE: 0.40139969553656013\n",
       "LogLoss: 0.6749148423554983\n",
       "Mean Per-Class Error: 0.334276952111347\n",
       "AUC: 0.7008728473696627\n",
       "AUCPR: 0.28837964750621486\n",
       "Gini: 0.4017456947393254\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.08978481850166033\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      116  41   0.2611   (41.0/157.0)\n",
       "1      11   16   0.4074   (11.0/27.0)\n",
       "Total  127  57   0.2826   (52.0/184.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.0897848    0.380952  56\n",
       "max f2                       0.00708063   0.550459  109\n",
       "max f0point5                 0.994448     0.348837  3\n",
       "max accuracy                 0.994448     0.86413   3\n",
       "max precision                0.994448     0.75      3\n",
       "max recall                   1.48736e-05  1         167\n",
       "max specificity              0.999975     0.993631  0\n",
       "max absolute_mcc             0.994448     0.254147  3\n",
       "max min_per_class_accuracy   0.0585908    0.62963   65\n",
       "max mean_per_class_accuracy  0.00708063   0.670559  109\n",
       "max tns                      0.999975     156       0\n",
       "max fns                      0.999975     27        0\n",
       "max fps                      2.05766e-07  157       183\n",
       "max tps                      1.48736e-05  27        167\n",
       "max tnr                      0.999975     0.993631  0\n",
       "max fnr                      0.999975     1         0\n",
       "max fpr                      2.05766e-07  1         183\n",
       "max tpr                      1.48736e-05  1         167\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,67 %, avg score: 15,86 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0108696                   0.996065           3.40741   3.40741            0.5              0.999886     0.5                         0.999886            0.037037        0.037037                   240.741   240.741            0.0306676\n",
       "2        0.0217391                   0.982391           6.81481   5.11111            1                0.994874     0.75                        0.99738             0.0740741       0.111111                   581.481   411.111            0.104742\n",
       "3        0.0326087                   0.950925           0         3.40741            0                0.966052     0.5                         0.986938            0               0.111111                   -100      240.741            0.0920028\n",
       "4        0.0434783                   0.931518           0         2.55556            0                0.940179     0.375                       0.975248            0               0.111111                   -100      155.556            0.079264\n",
       "5        0.0543478                   0.9074             3.40741   2.72593            0.5              0.916424     0.4                         0.963483            0.037037        0.148148                   240.741   172.593            0.109932\n",
       "6        0.103261                    0.675735           1.5144    2.15205            0.222222         0.834161     0.315789                    0.902225            0.0740741       0.222222                   51.4403   115.205            0.13942\n",
       "7        0.152174                    0.392617           1.5144    1.94709            0.222222         0.512311     0.285714                    0.776896            0.0740741       0.296296                   51.4403   94.709             0.168908\n",
       "8        0.201087                    0.240461           1.5144    1.84184            0.222222         0.30703      0.27027                     0.662604            0.0740741       0.37037                    51.4403   84.1842            0.198396\n",
       "9        0.298913                    0.092671           1.893     1.85859            0.277778         0.159626     0.272727                    0.497993            0.185185        0.555556                   89.3004   85.8586            0.300778\n",
       "10       0.402174                    0.0337576          0.717349  1.56557            0.105263         0.0603639    0.22973                     0.385629            0.0740741       0.62963                    -28.2651  56.5566            0.266572\n",
       "11       0.5                         0.0138235          0         1.25926            0                0.020863     0.184783                    0.314262            0               0.62963                    -100      25.9259            0.151923\n",
       "12       0.597826                    0.00697349         2.65021   1.48687            0.388889         0.00981296   0.218182                    0.264443            0.259259        0.888889                   165.021   48.6869            0.341118\n",
       "13       0.701087                    0.00204317         0.358674  1.3207             0.0526316        0.00398299   0.193798                    0.22608             0.037037        0.925926                   -64.1326  32.0701            0.263506\n",
       "14       0.798913                    0.00067156         0.378601  1.20534            0.0555556        0.00106803   0.176871                    0.198528            0.037037        0.962963                   -62.1399  20.5341            0.192262\n",
       "15       0.896739                    1.7367e-05         0         1.07385            0                0.000273677  0.157576                    0.1769              0               0.962963                   -100      7.38496            0.0776126\n",
       "16       1                           2.1e-07            0.358674  1                  0.0526316        6.85895e-06  0.146739                    0.158634            0.037037        1                          -64.1326  0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean      sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.61036   0.276055   0.162162      0.648649      0.621622      0.702703      0.916667\n",
       "auc                      0.588964  0.257501   0.138889      0.728571      0.676471      0.627451      0.773438\n",
       "err                      0.38964   0.276055   0.837838      0.351351      0.378378      0.297297      0.0833333\n",
       "err_count                14.4      10.2372    31            13            14            11            3\n",
       "f0point5                 0.324526  0.270096   0.0387597     0.16129       0.601504      0.196078      0.625\n",
       "f1                       0.36593   0.260331   0.0606061     0.235294      0.695652      0.266667      0.571429\n",
       "f2                       0.468279  0.246332   0.138889      0.434783      0.824742      0.416667      0.526316\n",
       "lift_top_group           2.23529   3.89725    0             0             2.17647       0             9\n",
       "logloss                  0.673466  0.361121   0.740085      0.336163      1.24873       0.635448      0.406909\n",
       "max_per_class_error      0.543175  0.216731   0.861111      0.371429      0.65          0.333333      0.5\n",
       "mcc                      0.291621  0.172095   0.0658808     0.289499      0.352494      0.217232      0.533002\n",
       "mean_per_class_accuracy  0.689994  0.0921086  0.569444      0.814286      0.645588      0.686275      0.734375\n",
       "mean_per_class_error     0.310006  0.0921086  0.430556      0.185714      0.354412      0.313725      0.265625\n",
       "mse                      0.160754  0.0944096  0.153471      0.0618375     0.302993      0.192401      0.0930667\n",
       "pr_auc                   0.270805  0.286261   0.0157904     0.0890943     0.662409      0.0992538     0.487479\n",
       "precision                0.309928  0.280668   0.03125       0.133333      0.551724      0.166667      0.666667\n",
       "r2                       -1.35803  2.04734    -4.83614      -0.209365     -0.219994     -1.58232      0.0576999\n",
       "recall                   0.821569  0.226596   1             1             0.941176      0.666667      0.5\n",
       "rmse                     0.386915  0.117528   0.391753      0.248672      0.550448      0.438635      0.305068\n",
       "specificity              0.558419  0.321902   0.138889      0.628571      0.35          0.705882      0.96875\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2023-05-19 09:28:38  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan                nan              nan\n",
       "    2023-05-19 09:28:38  1 min 23.320 sec  10887 obs/sec     10        1             1840       0.265722         0.268506            0.436068       0.884171        0.766038           6.81481          0.076087\n",
       "    2023-05-19 09:28:43  1 min 28.373 sec  10625 obs/sec     300       30            55200      0.0641222        0.0136266           0.967161       1               1                  6.81481          0\n",
       "\n",
       "Variable Importances: \n",
       "variable          relative_importance    scaled_importance    percentage\n",
       "----------------  ---------------------  -------------------  --------------------\n",
       "year              1.0                    1.0                  0.01949521562693404\n",
       "history           0.9998527765274048     0.9998527765274048   0.01949234547359045\n",
       "rating            0.9985383749008179     0.9985383749008179   0.019466720930459744\n",
       "Sci-Fi            0.9443295001983643     0.9443295001983643   0.018409907229241962\n",
       "winner_dga        0.9440569877624512     0.9440569877624512   0.018404594540542815\n",
       "numVotes          0.9394365549087524     0.9394365549087524   0.018314518205770187\n",
       "drama             0.9341661930084229     0.9341661930084229   0.018211771364091283\n",
       "winner_gg_drama   0.9233915209770203     0.9233915209770203   0.018001716809529594\n",
       "Action            0.921766996383667      0.921766996383667    0.017970046352290915\n",
       "Documentary       0.9186911582946777     0.9186911582946777   0.017910082225512533\n",
       "---               ---                    ---                  ---\n",
       "winner_gg_comedy  0.7938606142997742     0.7938606142997742   0.015476483853504412\n",
       "Drama             0.7931879758834839     0.7931879758834839   0.015463370622539874\n",
       "musical           0.7928636074066162     0.7928636074066162   0.01545704698914076\n",
       "Music             0.7867763638496399     0.7867763638496399   0.01533837486342384\n",
       "Mystery           0.7800036668777466     0.7800036668777466   0.015206339675580898\n",
       "nom_gg_drama      0.7744615077972412     0.7744615077972412   0.015098294089267675\n",
       "adventure         0.7726148962974548     0.7726148962974548   0.015062293999900164\n",
       "crime             0.7580563426017761     0.7580563426017761   0.014778471856386609\n",
       "sci-fi            0.7489483952522278     0.7489483952522278   0.014600910458888401\n",
       "Short             0.7402181029319763     0.7402181029319763   0.014430711527618933\n",
       "[60 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Predict on 2019's films\n",
    "test = full_table.loc[(full_table['year'] == 2021)]\n",
    "\n",
    "# Import a binary outcome train/test set into H2O\n",
    "test = h2o.H2OFrame(test)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |ââââââââââââââââââââââââââââââââââââââââââââââ| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">        p0</th><th style=\"text-align: right;\">         p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999976  </td><td style=\"text-align: right;\">2.37118e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.00165605</td><td style=\"text-align: right;\">0.998344   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.995174  </td><td style=\"text-align: right;\">0.00482619 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1         </td><td style=\"text-align: right;\">1.74511e-07</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.995249  </td><td style=\"text-align: right;\">0.00475117 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999972  </td><td style=\"text-align: right;\">2.78123e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999979  </td><td style=\"text-align: right;\">2.0885e-05 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1         </td><td style=\"text-align: right;\">9.07248e-09</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999955  </td><td style=\"text-align: right;\">4.5392e-05 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999999  </td><td style=\"text-align: right;\">1.10776e-06</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 3 columns]</pre>"
      ],
      "text/plain": [
       "  predict          p0           p1\n",
       "---------  ----------  -----------\n",
       "        0  0.999976    2.37118e-05\n",
       "        1  0.00165605  0.998344\n",
       "        0  0.995174    0.00482619\n",
       "        0  1           1.74511e-07\n",
       "        0  0.995249    0.00475117\n",
       "        0  0.999972    2.78123e-05\n",
       "        0  0.999979    2.0885e-05\n",
       "        0  1           9.07248e-09\n",
       "        0  0.999955    4.5392e-05\n",
       "        0  0.999999    1.10776e-06\n",
       "[10 rows x 3 columns]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = top_model.predict(test)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred'] = preds['predict']\n",
    "test['probA'] = preds['p1']\n",
    "test_pd = test.as_data_frame(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>probA</th>\n",
       "      <th>%_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CODA</td>\n",
       "      <td>9.983440e-01</td>\n",
       "      <td>9.903809e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Belfast</td>\n",
       "      <td>4.826187e-03</td>\n",
       "      <td>4.787692e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drive My Car</td>\n",
       "      <td>4.751175e-03</td>\n",
       "      <td>4.713278e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nightmare Alley</td>\n",
       "      <td>4.539204e-05</td>\n",
       "      <td>4.502998e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dune</td>\n",
       "      <td>2.781235e-05</td>\n",
       "      <td>2.759051e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West Side Story</td>\n",
       "      <td>2.371181e-05</td>\n",
       "      <td>2.352268e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>King Richard</td>\n",
       "      <td>2.088495e-05</td>\n",
       "      <td>2.071837e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Power of the Dog</td>\n",
       "      <td>1.107759e-06</td>\n",
       "      <td>1.098923e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Don't Look Up</td>\n",
       "      <td>1.745112e-07</td>\n",
       "      <td>1.731192e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Licorice Pizza</td>\n",
       "      <td>9.072485e-09</td>\n",
       "      <td>9.000120e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    film         probA  %_confidence\n",
       "1                  CODA   9.983440e-01  9.903809e+01\n",
       "2               Belfast   4.826187e-03  4.787692e-01\n",
       "4          Drive My Car   4.751175e-03  4.713278e-01\n",
       "8       Nightmare Alley   4.539204e-05  4.502998e-03\n",
       "5                  Dune   2.781235e-05  2.759051e-03\n",
       "0       West Side Story   2.371181e-05  2.352268e-03\n",
       "6          King Richard   2.088495e-05  2.071837e-03\n",
       "9  The Power of the Dog   1.107759e-06  1.098923e-04\n",
       "3          Don't Look Up  1.745112e-07  1.731192e-05\n",
       "7         Licorice Pizza  9.072485e-09  9.000120e-07"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rankings = test_pd[['film','probA']].sort_values('probA', ascending = False)\n",
    "final_rankings['%_confidence'] = final_rankings['probA']/final_rankings['probA'].sum() * 100\n",
    "final_rankings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And the Oscar goes to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And the Oscar goes to...\n",
      "ðð1917ðð\n"
     ]
    }
   ],
   "source": [
    "bp_winner = np.array(final_rankings.reset_index())[0][1].split('(')[0].strip()\n",
    "print(f'And the Oscar goes to...\\nðð{bp_winner}ðð')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
