{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-Oscar Prediction with AutoML\n",
    "After out dataframe has been assemlbed (see scraping and table_assembling) notebooks we have the data we need to make predictions on the Best Picture winner. [AutoML](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html) represents a quick, but powerful route though the Machine Learning process. H2O's AutoML runs many models through the dataset and using cross-validation, picks the best one. For my purposes I use it to confirm/compare to the Preferential Balloting Random Forest model I created.\n",
    "If you are gunning to win your office's Oscar pool, scroll down to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h2o"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Using h2o Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table = pd.read_csv('./data/processed_results/osc_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) Client VM (build 25.371-b11, mixed mode)\n",
      "  Starting server from C:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmpzura6fy_\n",
      "  JVM stdout: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmpzura6fy_\\h2o_Aleksandra_Czaplak_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\ALEKSA~1\\AppData\\Local\\Temp\\tmpzura6fy_\\h2o_Aleksandra_Czaplak_started_from_python.err\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aleksandra Czaplak\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\h2o\\backend\\server.py:386: UserWarning:   You have a 32-bit version of Java. H2O works best with 64-bit Java.\n",
      "  Please download the latest 64-bit Java SE JDK from Oracle.\n",
      "\n",
      "  warn(\"  You have a 32-bit version of Java. H2O works best with 64-bit Java.\\n\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>09 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Berlin</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>20 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Aleksandra_Czaplak_jr4fw3</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>241.3 Mb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.2 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------------------\n",
       "H2O_cluster_uptime:         09 secs\n",
       "H2O_cluster_timezone:       Europe/Berlin\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    20 days\n",
       "H2O_cluster_name:           H2O_from_python_Aleksandra_Czaplak_jr4fw3\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    241.3 Mb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.2 final\n",
       "--------------------------  -----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Year of Existance. This data will be used below\n",
    "- golden_globes 1943\n",
    "- pga 1989\n",
    "- bafta 1960\n",
    "- dga 1948\n",
    "- sag 1995\n",
    "- cannes 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I pick a min_year where the awards shows will be relevant\n",
    "min_year = 1995"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O's Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set contains: 186 movies\n"
     ]
    }
   ],
   "source": [
    "# Auto ML uses Cross Validation, so we do not specifiy a validation set\n",
    "train = full_table.loc[((full_table['year'] < 2022) & (full_table['year'] >= min_year))]\n",
    "\n",
    "print('training set contains:', train.shape[0], 'movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'film', 'wiki', 'winner', 'nominations', 'Oscar_win',\n",
       "       'nom_gg_drama', 'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy',\n",
       "       'nom_pga', 'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga',\n",
       "       'winner_dga', 'nom_sag', 'winner_sag', 'nom_cannes', 'winner_cannes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop('Unnamed: 0', axis=1)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "15:20:00.900: AutoML: XGBoost is not available; skipping it.\n",
      "15:20:00.988: _train param, Dropping bad and constant columns: [winner_cannes, nom_cannes]\n",
      "\n",
      "\n",
      "15:20:02.91: _train param, Dropping bad and constant columns: [winner_cannes, nom_cannes]\n",
      "15:20:02.91: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 186.0.\n",
      "15:20:02.98: _train param, Dropping bad and constant columns: [winner_cannes, nom_cannes]\n",
      "\n",
      "██\n",
      "15:20:03.329: _train param, Dropping bad and constant columns: [winner_cannes, nom_cannes]\n",
      "\n",
      "█\n",
      "15:20:03.995: _train param, Dropping bad and constant columns: [winner_cannes, nom_cannes]\n",
      "\n",
      "█\n",
      "15:20:04.626: _train param, Dropping bad and constant columns: [winner_cannes, nom_cannes]\n",
      "\n",
      "██\n",
      "15:20:05.417: _train param, Dropping bad and constant columns: [winner_cannes, nom_cannes]\n",
      "\n",
      "███\n",
      "15:20:06.12: _train param, Dropping bad and constant columns: [winner_cannes, nom_cannes]\n",
      "15:20:06.570: _train param, Dropping bad and constant columns: [winner_cannes, nom_cannes]\n",
      "\n",
      "██████████████████████████████████████████████████████\n",
      "18:38:54.419: _train param, Dropping bad and constant columns: [winner_cannes, nom_cannes]\n",
      "\n",
      "| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                             </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">    aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th><th style=\"text-align: right;\">  training_time_ms</th><th style=\"text-align: right;\">  predict_time_per_row_ms</th><th>algo        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_13</td><td style=\"text-align: right;\">0.791987</td><td style=\"text-align: right;\"> 0.435541</td><td style=\"text-align: right;\">0.523313 </td><td style=\"text-align: right;\">              0.232355</td><td style=\"text-align: right;\">0.342841</td><td style=\"text-align: right;\">0.11754 </td><td style=\"text-align: right;\">             13035</td><td style=\"text-align: right;\">                 0.066777</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_9 </td><td style=\"text-align: right;\">0.745632</td><td style=\"text-align: right;\"> 0.545802</td><td style=\"text-align: right;\">0.395303 </td><td style=\"text-align: right;\">              0.28232 </td><td style=\"text-align: right;\">0.360583</td><td style=\"text-align: right;\">0.13002 </td><td style=\"text-align: right;\">             11969</td><td style=\"text-align: right;\">                 0.07269 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_10</td><td style=\"text-align: right;\">0.722339</td><td style=\"text-align: right;\"> 0.513111</td><td style=\"text-align: right;\">0.255035 </td><td style=\"text-align: right;\">              0.294899</td><td style=\"text-align: right;\">0.380841</td><td style=\"text-align: right;\">0.14504 </td><td style=\"text-align: right;\">             58032</td><td style=\"text-align: right;\">                 0.099285</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_15</td><td style=\"text-align: right;\">0.716282</td><td style=\"text-align: right;\"> 0.478913</td><td style=\"text-align: right;\">0.426337 </td><td style=\"text-align: right;\">              0.37666 </td><td style=\"text-align: right;\">0.368728</td><td style=\"text-align: right;\">0.13596 </td><td style=\"text-align: right;\">              9900</td><td style=\"text-align: right;\">                 0.070182</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_17</td><td style=\"text-align: right;\">0.664104</td><td style=\"text-align: right;\"> 0.624245</td><td style=\"text-align: right;\">0.376196 </td><td style=\"text-align: right;\">              0.382949</td><td style=\"text-align: right;\">0.368472</td><td style=\"text-align: right;\">0.135771</td><td style=\"text-align: right;\">              6812</td><td style=\"text-align: right;\">                 0.060175</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_9 </td><td style=\"text-align: right;\">0.658747</td><td style=\"text-align: right;\"> 0.585366</td><td style=\"text-align: right;\">0.388401 </td><td style=\"text-align: right;\">              0.365129</td><td style=\"text-align: right;\">0.388259</td><td style=\"text-align: right;\">0.150745</td><td style=\"text-align: right;\">             10354</td><td style=\"text-align: right;\">                 0.063284</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_19</td><td style=\"text-align: right;\">0.610762</td><td style=\"text-align: right;\"> 0.595747</td><td style=\"text-align: right;\">0.347364 </td><td style=\"text-align: right;\">              0.316212</td><td style=\"text-align: right;\">0.374992</td><td style=\"text-align: right;\">0.140619</td><td style=\"text-align: right;\">             11594</td><td style=\"text-align: right;\">                 0.06462 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_16</td><td style=\"text-align: right;\">0.581412</td><td style=\"text-align: right;\"> 1.10088 </td><td style=\"text-align: right;\">0.243106 </td><td style=\"text-align: right;\">              0.389238</td><td style=\"text-align: right;\">0.387637</td><td style=\"text-align: right;\">0.150263</td><td style=\"text-align: right;\">             19983</td><td style=\"text-align: right;\">                 0.132074</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_11</td><td style=\"text-align: right;\">0.578616</td><td style=\"text-align: right;\"> 0.52583 </td><td style=\"text-align: right;\">0.174457 </td><td style=\"text-align: right;\">              0.37072 </td><td style=\"text-align: right;\">0.386686</td><td style=\"text-align: right;\">0.149526</td><td style=\"text-align: right;\">             13040</td><td style=\"text-align: right;\">                 0.068105</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_8 </td><td style=\"text-align: right;\">0.564407</td><td style=\"text-align: right;\"> 0.725044</td><td style=\"text-align: right;\">0.22082  </td><td style=\"text-align: right;\">              0.371069</td><td style=\"text-align: right;\">0.374754</td><td style=\"text-align: right;\">0.140441</td><td style=\"text-align: right;\">             46457</td><td style=\"text-align: right;\">                 0.104383</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_11</td><td style=\"text-align: right;\">0.548567</td><td style=\"text-align: right;\"> 0.693623</td><td style=\"text-align: right;\">0.280486 </td><td style=\"text-align: right;\">              0.414396</td><td style=\"text-align: right;\">0.378795</td><td style=\"text-align: right;\">0.143486</td><td style=\"text-align: right;\">              7371</td><td style=\"text-align: right;\">                 0.068808</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_3 </td><td style=\"text-align: right;\">0.547403</td><td style=\"text-align: right;\"> 1.01079 </td><td style=\"text-align: right;\">0.362882 </td><td style=\"text-align: right;\">              0.388889</td><td style=\"text-align: right;\">0.39542 </td><td style=\"text-align: right;\">0.156357</td><td style=\"text-align: right;\">              7279</td><td style=\"text-align: right;\">                 0.056372</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_10</td><td style=\"text-align: right;\">0.546005</td><td style=\"text-align: right;\"> 0.553029</td><td style=\"text-align: right;\">0.365928 </td><td style=\"text-align: right;\">              0.367575</td><td style=\"text-align: right;\">0.358175</td><td style=\"text-align: right;\">0.128289</td><td style=\"text-align: right;\">             18495</td><td style=\"text-align: right;\">                 0.069141</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_16</td><td style=\"text-align: right;\">0.536688</td><td style=\"text-align: right;\"> 0.922376</td><td style=\"text-align: right;\">0.154017 </td><td style=\"text-align: right;\">              0.424179</td><td style=\"text-align: right;\">0.414359</td><td style=\"text-align: right;\">0.171693</td><td style=\"text-align: right;\">             14850</td><td style=\"text-align: right;\">                 0.076055</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_19</td><td style=\"text-align: right;\">0.515024</td><td style=\"text-align: right;\"> 0.660208</td><td style=\"text-align: right;\">0.178948 </td><td style=\"text-align: right;\">              0.421034</td><td style=\"text-align: right;\">0.382786</td><td style=\"text-align: right;\">0.146525</td><td style=\"text-align: right;\">             18502</td><td style=\"text-align: right;\">                 0.094777</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_1_20230518_152000              </td><td style=\"text-align: right;\">0.500582</td><td style=\"text-align: right;\"> 0.625227</td><td style=\"text-align: right;\">0.336165 </td><td style=\"text-align: right;\">              0.353249</td><td style=\"text-align: right;\">0.388208</td><td style=\"text-align: right;\">0.150705</td><td style=\"text-align: right;\">                78</td><td style=\"text-align: right;\">                 0.054884</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DRF_1_AutoML_1_20230518_152000                       </td><td style=\"text-align: right;\">0.488935</td><td style=\"text-align: right;\"> 0.605096</td><td style=\"text-align: right;\">0.128215 </td><td style=\"text-align: right;\">              0.407407</td><td style=\"text-align: right;\">0.412167</td><td style=\"text-align: right;\">0.169882</td><td style=\"text-align: right;\">               145</td><td style=\"text-align: right;\">                 0.064739</td><td>DRF         </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_12</td><td style=\"text-align: right;\">0.473096</td><td style=\"text-align: right;\"> 0.778283</td><td style=\"text-align: right;\">0.160341 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.394647</td><td style=\"text-align: right;\">0.155746</td><td style=\"text-align: right;\">             19071</td><td style=\"text-align: right;\">                 0.055571</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_5 </td><td style=\"text-align: right;\">0.47263 </td><td style=\"text-align: right;\"> 0.806584</td><td style=\"text-align: right;\">0.199521 </td><td style=\"text-align: right;\">              0.396925</td><td style=\"text-align: right;\">0.390548</td><td style=\"text-align: right;\">0.152528</td><td style=\"text-align: right;\">             53664</td><td style=\"text-align: right;\">                 0.096729</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_5 </td><td style=\"text-align: right;\">0.470068</td><td style=\"text-align: right;\"> 0.839617</td><td style=\"text-align: right;\">0.137909 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.414497</td><td style=\"text-align: right;\">0.171807</td><td style=\"text-align: right;\">             10287</td><td style=\"text-align: right;\">                 0.082514</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_8 </td><td style=\"text-align: right;\">0.437689</td><td style=\"text-align: right;\"> 0.858551</td><td style=\"text-align: right;\">0.143765 </td><td style=\"text-align: right;\">              0.426974</td><td style=\"text-align: right;\">0.401392</td><td style=\"text-align: right;\">0.161115</td><td style=\"text-align: right;\">             38936</td><td style=\"text-align: right;\">                 0.067097</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_12</td><td style=\"text-align: right;\">0.436292</td><td style=\"text-align: right;\"> 1.17835 </td><td style=\"text-align: right;\">0.136402 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.424135</td><td style=\"text-align: right;\">0.179891</td><td style=\"text-align: right;\">             19852</td><td style=\"text-align: right;\">                 0.072913</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_3 </td><td style=\"text-align: right;\">0.428372</td><td style=\"text-align: right;\"> 1.08867 </td><td style=\"text-align: right;\">0.165001 </td><td style=\"text-align: right;\">              0.419986</td><td style=\"text-align: right;\">0.416403</td><td style=\"text-align: right;\">0.173391</td><td style=\"text-align: right;\">             11663</td><td style=\"text-align: right;\">                 0.054353</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_14</td><td style=\"text-align: right;\">0.424878</td><td style=\"text-align: right;\"> 0.793529</td><td style=\"text-align: right;\">0.135115 </td><td style=\"text-align: right;\">              0.484277</td><td style=\"text-align: right;\">0.408957</td><td style=\"text-align: right;\">0.167246</td><td style=\"text-align: right;\">             13734</td><td style=\"text-align: right;\">                 0.070033</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_18</td><td style=\"text-align: right;\">0.422315</td><td style=\"text-align: right;\"> 0.698986</td><td style=\"text-align: right;\">0.132666 </td><td style=\"text-align: right;\">              0.493711</td><td style=\"text-align: right;\">0.378273</td><td style=\"text-align: right;\">0.143091</td><td style=\"text-align: right;\">              6304</td><td style=\"text-align: right;\">                 0.044456</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_7 </td><td style=\"text-align: right;\">0.41952 </td><td style=\"text-align: right;\"> 0.680188</td><td style=\"text-align: right;\">0.140618 </td><td style=\"text-align: right;\">              0.440252</td><td style=\"text-align: right;\">0.394548</td><td style=\"text-align: right;\">0.155669</td><td style=\"text-align: right;\">             21824</td><td style=\"text-align: right;\">                 0.056731</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_4 </td><td style=\"text-align: right;\">0.419287</td><td style=\"text-align: right;\"> 1.21253 </td><td style=\"text-align: right;\">0.143639 </td><td style=\"text-align: right;\">              0.496855</td><td style=\"text-align: right;\">0.411103</td><td style=\"text-align: right;\">0.169006</td><td style=\"text-align: right;\">             67043</td><td style=\"text-align: right;\">                 0.099323</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_19</td><td style=\"text-align: right;\">0.414396</td><td style=\"text-align: right;\"> 1.03341 </td><td style=\"text-align: right;\">0.121263 </td><td style=\"text-align: right;\">              0.484277</td><td style=\"text-align: right;\">0.420465</td><td style=\"text-align: right;\">0.17679 </td><td style=\"text-align: right;\">             64594</td><td style=\"text-align: right;\">                 0.11946 </td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_15         </td><td style=\"text-align: right;\">0.413464</td><td style=\"text-align: right;\"> 0.501342</td><td style=\"text-align: right;\">0.120746 </td><td style=\"text-align: right;\">              0.476939</td><td style=\"text-align: right;\">0.380071</td><td style=\"text-align: right;\">0.144454</td><td style=\"text-align: right;\">                83</td><td style=\"text-align: right;\">                 0.059647</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_14</td><td style=\"text-align: right;\">0.412066</td><td style=\"text-align: right;\"> 0.919026</td><td style=\"text-align: right;\">0.133258 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.40826 </td><td style=\"text-align: right;\">0.166676</td><td style=\"text-align: right;\">             15126</td><td style=\"text-align: right;\">                 0.084327</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_4 </td><td style=\"text-align: right;\">0.4116  </td><td style=\"text-align: right;\"> 0.934248</td><td style=\"text-align: right;\">0.118166 </td><td style=\"text-align: right;\">              0.493711</td><td style=\"text-align: right;\">0.427521</td><td style=\"text-align: right;\">0.182774</td><td style=\"text-align: right;\">             49463</td><td style=\"text-align: right;\">                 0.098904</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_9 </td><td style=\"text-align: right;\">0.410901</td><td style=\"text-align: right;\"> 0.756205</td><td style=\"text-align: right;\">0.123608 </td><td style=\"text-align: right;\">              0.496855</td><td style=\"text-align: right;\">0.389935</td><td style=\"text-align: right;\">0.152049</td><td style=\"text-align: right;\">             10955</td><td style=\"text-align: right;\">                 0.057065</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_12</td><td style=\"text-align: right;\">0.39972 </td><td style=\"text-align: right;\"> 1.10267 </td><td style=\"text-align: right;\">0.133358 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.403342</td><td style=\"text-align: right;\">0.162684</td><td style=\"text-align: right;\">             68413</td><td style=\"text-align: right;\">                 0.091221</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_1 </td><td style=\"text-align: right;\">0.393897</td><td style=\"text-align: right;\"> 1.24426 </td><td style=\"text-align: right;\">0.121836 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.437642</td><td style=\"text-align: right;\">0.191531</td><td style=\"text-align: right;\">             39400</td><td style=\"text-align: right;\">                 0.076347</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_10</td><td style=\"text-align: right;\">0.392266</td><td style=\"text-align: right;\"> 1.0185  </td><td style=\"text-align: right;\">0.18324  </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.410119</td><td style=\"text-align: right;\">0.168198</td><td style=\"text-align: right;\">             40733</td><td style=\"text-align: right;\">                 0.077296</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_15</td><td style=\"text-align: right;\">0.381551</td><td style=\"text-align: right;\"> 1.11823 </td><td style=\"text-align: right;\">0.130971 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.417633</td><td style=\"text-align: right;\">0.174417</td><td style=\"text-align: right;\">             10008</td><td style=\"text-align: right;\">                 0.058208</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_2 </td><td style=\"text-align: right;\">0.380853</td><td style=\"text-align: right;\"> 1.04229 </td><td style=\"text-align: right;\">0.120904 </td><td style=\"text-align: right;\">              0.490217</td><td style=\"text-align: right;\">0.411117</td><td style=\"text-align: right;\">0.169017</td><td style=\"text-align: right;\">              8264</td><td style=\"text-align: right;\">                 0.051352</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_2          </td><td style=\"text-align: right;\">0.369089</td><td style=\"text-align: right;\"> 0.595811</td><td style=\"text-align: right;\">0.116641 </td><td style=\"text-align: right;\">              0.496855</td><td style=\"text-align: right;\">0.400259</td><td style=\"text-align: right;\">0.160207</td><td style=\"text-align: right;\">                91</td><td style=\"text-align: right;\">                 0.05797 </td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_7 </td><td style=\"text-align: right;\">0.365013</td><td style=\"text-align: right;\"> 0.998433</td><td style=\"text-align: right;\">0.1274   </td><td style=\"text-align: right;\">              0.496855</td><td style=\"text-align: right;\">0.40448 </td><td style=\"text-align: right;\">0.163604</td><td style=\"text-align: right;\">             51643</td><td style=\"text-align: right;\">                 0.124395</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_17</td><td style=\"text-align: right;\">0.361053</td><td style=\"text-align: right;\"> 0.821705</td><td style=\"text-align: right;\">0.118646 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.378082</td><td style=\"text-align: right;\">0.142946</td><td style=\"text-align: right;\">              7965</td><td style=\"text-align: right;\">                 0.061346</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_3_AutoML_1_20230518_152000                       </td><td style=\"text-align: right;\">0.358724</td><td style=\"text-align: right;\"> 0.575933</td><td style=\"text-align: right;\">0.118056 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.388943</td><td style=\"text-align: right;\">0.151276</td><td style=\"text-align: right;\">               110</td><td style=\"text-align: right;\">                 0.055532</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_1 </td><td style=\"text-align: right;\">0.352434</td><td style=\"text-align: right;\"> 1.5234  </td><td style=\"text-align: right;\">0.116734 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.432247</td><td style=\"text-align: right;\">0.186838</td><td style=\"text-align: right;\">             62665</td><td style=\"text-align: right;\">                 0.123833</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_1 </td><td style=\"text-align: right;\">0.347077</td><td style=\"text-align: right;\"> 0.739536</td><td style=\"text-align: right;\">0.110483 </td><td style=\"text-align: right;\">              0.487072</td><td style=\"text-align: right;\">0.388521</td><td style=\"text-align: right;\">0.150949</td><td style=\"text-align: right;\">             16206</td><td style=\"text-align: right;\">                 0.054197</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_7          </td><td style=\"text-align: right;\">0.341836</td><td style=\"text-align: right;\"> 0.529719</td><td style=\"text-align: right;\">0.111203 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.385903</td><td style=\"text-align: right;\">0.148921</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">                 0.052192</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_23         </td><td style=\"text-align: right;\">0.338341</td><td style=\"text-align: right;\"> 0.566829</td><td style=\"text-align: right;\">0.110575 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.389058</td><td style=\"text-align: right;\">0.151366</td><td style=\"text-align: right;\">                95</td><td style=\"text-align: right;\">                 0.062361</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_11</td><td style=\"text-align: right;\">0.333566</td><td style=\"text-align: right;\"> 1.23946 </td><td style=\"text-align: right;\">0.122432 </td><td style=\"text-align: right;\">              0.493361</td><td style=\"text-align: right;\">0.401724</td><td style=\"text-align: right;\">0.161382</td><td style=\"text-align: right;\">              9694</td><td style=\"text-align: right;\">                 0.062654</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_16</td><td style=\"text-align: right;\">0.324715</td><td style=\"text-align: right;\"> 2.82605 </td><td style=\"text-align: right;\">0.171095 </td><td style=\"text-align: right;\">              0.432914</td><td style=\"text-align: right;\">0.405437</td><td style=\"text-align: right;\">0.164379</td><td style=\"text-align: right;\">             30628</td><td style=\"text-align: right;\">                 0.139369</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_7 </td><td style=\"text-align: right;\">0.32355 </td><td style=\"text-align: right;\"> 0.926295</td><td style=\"text-align: right;\">0.118612 </td><td style=\"text-align: right;\">              0.496855</td><td style=\"text-align: right;\">0.41619 </td><td style=\"text-align: right;\">0.173214</td><td style=\"text-align: right;\">             16591</td><td style=\"text-align: right;\">                 0.100266</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_15</td><td style=\"text-align: right;\">0.322618</td><td style=\"text-align: right;\"> 0.994901</td><td style=\"text-align: right;\">0.107185 </td><td style=\"text-align: right;\">              0.493711</td><td style=\"text-align: right;\">0.399043</td><td style=\"text-align: right;\">0.159235</td><td style=\"text-align: right;\">             13394</td><td style=\"text-align: right;\">                 0.088346</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_18         </td><td style=\"text-align: right;\">0.321686</td><td style=\"text-align: right;\"> 0.575582</td><td style=\"text-align: right;\">0.110817 </td><td style=\"text-align: right;\">              0.490566</td><td style=\"text-align: right;\">0.38911 </td><td style=\"text-align: right;\">0.151406</td><td style=\"text-align: right;\">               123</td><td style=\"text-align: right;\">                 0.07225 </td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_13</td><td style=\"text-align: right;\">0.318192</td><td style=\"text-align: right;\"> 0.854429</td><td style=\"text-align: right;\">0.119331 </td><td style=\"text-align: right;\">              0.465409</td><td style=\"text-align: right;\">0.384911</td><td style=\"text-align: right;\">0.148157</td><td style=\"text-align: right;\">             12812</td><td style=\"text-align: right;\">                 0.072808</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_35         </td><td style=\"text-align: right;\">0.317261</td><td style=\"text-align: right;\"> 0.566866</td><td style=\"text-align: right;\">0.107063 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.387136</td><td style=\"text-align: right;\">0.149874</td><td style=\"text-align: right;\">               111</td><td style=\"text-align: right;\">                 0.063636</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_12         </td><td style=\"text-align: right;\">0.315048</td><td style=\"text-align: right;\"> 0.660822</td><td style=\"text-align: right;\">0.101905 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.412265</td><td style=\"text-align: right;\">0.169962</td><td style=\"text-align: right;\">                83</td><td style=\"text-align: right;\">                 0.063138</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_10         </td><td style=\"text-align: right;\">0.314931</td><td style=\"text-align: right;\"> 0.533733</td><td style=\"text-align: right;\">0.109909 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.378575</td><td style=\"text-align: right;\">0.143319</td><td style=\"text-align: right;\">                96</td><td style=\"text-align: right;\">                 0.058557</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_9          </td><td style=\"text-align: right;\">0.309923</td><td style=\"text-align: right;\"> 0.561028</td><td style=\"text-align: right;\">0.104263 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.385827</td><td style=\"text-align: right;\">0.148863</td><td style=\"text-align: right;\">                86</td><td style=\"text-align: right;\">                 0.059427</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_13</td><td style=\"text-align: right;\">0.309341</td><td style=\"text-align: right;\"> 1.12178 </td><td style=\"text-align: right;\">0.120776 </td><td style=\"text-align: right;\">              0.496855</td><td style=\"text-align: right;\">0.391872</td><td style=\"text-align: right;\">0.153563</td><td style=\"text-align: right;\">             18302</td><td style=\"text-align: right;\">                 0.081928</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_6 </td><td style=\"text-align: right;\">0.307943</td><td style=\"text-align: right;\"> 0.79192 </td><td style=\"text-align: right;\">0.109764 </td><td style=\"text-align: right;\">              0.474843</td><td style=\"text-align: right;\">0.390542</td><td style=\"text-align: right;\">0.152523</td><td style=\"text-align: right;\">             11862</td><td style=\"text-align: right;\">                 0.067301</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_3 </td><td style=\"text-align: right;\">0.307011</td><td style=\"text-align: right;\"> 1.47618 </td><td style=\"text-align: right;\">0.129072 </td><td style=\"text-align: right;\">              0.496855</td><td style=\"text-align: right;\">0.411702</td><td style=\"text-align: right;\">0.169499</td><td style=\"text-align: right;\">             12014</td><td style=\"text-align: right;\">                 0.058877</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_2_AutoML_1_20230518_152000                       </td><td style=\"text-align: right;\">0.29979 </td><td style=\"text-align: right;\"> 0.581537</td><td style=\"text-align: right;\">0.105729 </td><td style=\"text-align: right;\">              0.493711</td><td style=\"text-align: right;\">0.390397</td><td style=\"text-align: right;\">0.152409</td><td style=\"text-align: right;\">               100</td><td style=\"text-align: right;\">                 0.058934</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_4_AutoML_1_20230518_152000                       </td><td style=\"text-align: right;\">0.288609</td><td style=\"text-align: right;\"> 0.600333</td><td style=\"text-align: right;\">0.100369 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.392185</td><td style=\"text-align: right;\">0.153809</td><td style=\"text-align: right;\">               132</td><td style=\"text-align: right;\">                 0.05673 </td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_6 </td><td style=\"text-align: right;\">0.287212</td><td style=\"text-align: right;\"> 1.10262 </td><td style=\"text-align: right;\">0.10343  </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.404244</td><td style=\"text-align: right;\">0.163413</td><td style=\"text-align: right;\">             44236</td><td style=\"text-align: right;\">                 0.108366</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_2 </td><td style=\"text-align: right;\">0.286396</td><td style=\"text-align: right;\"> 1.33243 </td><td style=\"text-align: right;\">0.130809 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.401698</td><td style=\"text-align: right;\">0.161361</td><td style=\"text-align: right;\">             13643</td><td style=\"text-align: right;\">                 0.057652</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_8 </td><td style=\"text-align: right;\">0.284184</td><td style=\"text-align: right;\"> 0.90845 </td><td style=\"text-align: right;\">0.0969542</td><td style=\"text-align: right;\">              0.484277</td><td style=\"text-align: right;\">0.394002</td><td style=\"text-align: right;\">0.155238</td><td style=\"text-align: right;\">             19954</td><td style=\"text-align: right;\">                 0.067338</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_32         </td><td style=\"text-align: right;\">0.28232 </td><td style=\"text-align: right;\"> 0.585316</td><td style=\"text-align: right;\">0.0975869</td><td style=\"text-align: right;\">              0.496855</td><td style=\"text-align: right;\">0.399796</td><td style=\"text-align: right;\">0.159837</td><td style=\"text-align: right;\">                81</td><td style=\"text-align: right;\">                 0.056552</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_2 </td><td style=\"text-align: right;\">0.281854</td><td style=\"text-align: right;\"> 1.37018 </td><td style=\"text-align: right;\">0.116682 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.416232</td><td style=\"text-align: right;\">0.173249</td><td style=\"text-align: right;\">             11190</td><td style=\"text-align: right;\">                 0.069119</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_14</td><td style=\"text-align: right;\">0.279292</td><td style=\"text-align: right;\"> 0.834969</td><td style=\"text-align: right;\">0.118262 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.400359</td><td style=\"text-align: right;\">0.160287</td><td style=\"text-align: right;\">            849991</td><td style=\"text-align: right;\">                 0.100327</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_5 </td><td style=\"text-align: right;\">0.278593</td><td style=\"text-align: right;\"> 1.40274 </td><td style=\"text-align: right;\">0.102111 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.419732</td><td style=\"text-align: right;\">0.176175</td><td style=\"text-align: right;\">             14199</td><td style=\"text-align: right;\">                 0.099683</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_13         </td><td style=\"text-align: right;\">0.278127</td><td style=\"text-align: right;\"> 0.656863</td><td style=\"text-align: right;\">0.0975721</td><td style=\"text-align: right;\">              0.496855</td><td style=\"text-align: right;\">0.4056  </td><td style=\"text-align: right;\">0.164511</td><td style=\"text-align: right;\">               120</td><td style=\"text-align: right;\">                 0.056077</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_3          </td><td style=\"text-align: right;\">0.276497</td><td style=\"text-align: right;\"> 0.544996</td><td style=\"text-align: right;\">0.104976 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.380858</td><td style=\"text-align: right;\">0.145053</td><td style=\"text-align: right;\">                87</td><td style=\"text-align: right;\">                 0.066247</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_6 </td><td style=\"text-align: right;\">0.274167</td><td style=\"text-align: right;\"> 1.07314 </td><td style=\"text-align: right;\">0.109731 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.413021</td><td style=\"text-align: right;\">0.170586</td><td style=\"text-align: right;\">             13753</td><td style=\"text-align: right;\">                 0.073315</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_22         </td><td style=\"text-align: right;\">0.273818</td><td style=\"text-align: right;\"> 0.559857</td><td style=\"text-align: right;\">0.09998  </td><td style=\"text-align: right;\">              0.496855</td><td style=\"text-align: right;\">0.382877</td><td style=\"text-align: right;\">0.146595</td><td style=\"text-align: right;\">               113</td><td style=\"text-align: right;\">                 0.046813</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_1          </td><td style=\"text-align: right;\">0.273352</td><td style=\"text-align: right;\"> 0.539461</td><td style=\"text-align: right;\">0.1      </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.381253</td><td style=\"text-align: right;\">0.145354</td><td style=\"text-align: right;\">                87</td><td style=\"text-align: right;\">                 0.074859</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_17         </td><td style=\"text-align: right;\">0.271605</td><td style=\"text-align: right;\"> 0.641473</td><td style=\"text-align: right;\">0.0976344</td><td style=\"text-align: right;\">              0.496855</td><td style=\"text-align: right;\">0.410975</td><td style=\"text-align: right;\">0.168901</td><td style=\"text-align: right;\">                85</td><td style=\"text-align: right;\">                 0.056619</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_8          </td><td style=\"text-align: right;\">0.263918</td><td style=\"text-align: right;\"> 0.648389</td><td style=\"text-align: right;\">0.0980034</td><td style=\"text-align: right;\">              0.493711</td><td style=\"text-align: right;\">0.403365</td><td style=\"text-align: right;\">0.162703</td><td style=\"text-align: right;\">               179</td><td style=\"text-align: right;\">                 0.050242</td><td>GBM         </td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20230518_152000                       </td><td style=\"text-align: right;\">0.262055</td><td style=\"text-align: right;\"> 0.491077</td><td style=\"text-align: right;\">0.101928 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.373901</td><td style=\"text-align: right;\">0.139802</td><td style=\"text-align: right;\">                31</td><td style=\"text-align: right;\">                 0.056263</td><td>GLM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_2_AutoML_1_20230518_152000_model_18</td><td style=\"text-align: right;\">0.254601</td><td style=\"text-align: right;\"> 1.18328 </td><td style=\"text-align: right;\">0.119214 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.388808</td><td style=\"text-align: right;\">0.151172</td><td style=\"text-align: right;\">              8127</td><td style=\"text-align: right;\">                 0.057762</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20230518_152000_model_4 </td><td style=\"text-align: right;\">0.245749</td><td style=\"text-align: right;\"> 1.60353 </td><td style=\"text-align: right;\">0.0949101</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.418543</td><td style=\"text-align: right;\">0.175178</td><td style=\"text-align: right;\">             15623</td><td style=\"text-align: right;\">                 0.062724</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_26         </td><td style=\"text-align: right;\">0.243652</td><td style=\"text-align: right;\"> 0.602435</td><td style=\"text-align: right;\">0.0931125</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.393246</td><td style=\"text-align: right;\">0.154642</td><td style=\"text-align: right;\">                65</td><td style=\"text-align: right;\">                 0.074318</td><td>GBM         </td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_18</td><td style=\"text-align: right;\">0.24109 </td><td style=\"text-align: right;\"> 0.893807</td><td style=\"text-align: right;\">0.0949346</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.377798</td><td style=\"text-align: right;\">0.142731</td><td style=\"text-align: right;\">              9008</td><td style=\"text-align: right;\">                 0.055091</td><td>DeepLearning</td></tr>\n",
       "<tr><td>DeepLearning_grid_3_AutoML_1_20230518_152000_model_17</td><td style=\"text-align: right;\">0.240857</td><td style=\"text-align: right;\"> 1.20755 </td><td style=\"text-align: right;\">0.124298 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.388046</td><td style=\"text-align: right;\">0.15058 </td><td style=\"text-align: right;\">             10119</td><td style=\"text-align: right;\">                 0.043909</td><td>DeepLearning</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_28         </td><td style=\"text-align: right;\">0.233986</td><td style=\"text-align: right;\"> 0.541781</td><td style=\"text-align: right;\">0.0895966</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.381409</td><td style=\"text-align: right;\">0.145472</td><td style=\"text-align: right;\">                66</td><td style=\"text-align: right;\">                 0.049938</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_5          </td><td style=\"text-align: right;\">0.231656</td><td style=\"text-align: right;\"> 0.622658</td><td style=\"text-align: right;\">0.0892537</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.403494</td><td style=\"text-align: right;\">0.162807</td><td style=\"text-align: right;\">                90</td><td style=\"text-align: right;\">                 0.045711</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_5_AutoML_1_20230518_152000                       </td><td style=\"text-align: right;\">0.209644</td><td style=\"text-align: right;\"> 0.720115</td><td style=\"text-align: right;\">0.0892811</td><td style=\"text-align: right;\">              0.496855</td><td style=\"text-align: right;\">0.425937</td><td style=\"text-align: right;\">0.181423</td><td style=\"text-align: right;\">                87</td><td style=\"text-align: right;\">                 0.046536</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_24         </td><td style=\"text-align: right;\">0.20615 </td><td style=\"text-align: right;\"> 0.551256</td><td style=\"text-align: right;\">0.0900863</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.384276</td><td style=\"text-align: right;\">0.147668</td><td style=\"text-align: right;\">                61</td><td style=\"text-align: right;\">                 0.055431</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_34         </td><td style=\"text-align: right;\">0.204403</td><td style=\"text-align: right;\"> 0.592306</td><td style=\"text-align: right;\">0.087987 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.389432</td><td style=\"text-align: right;\">0.151657</td><td style=\"text-align: right;\">                73</td><td style=\"text-align: right;\">                 0.038657</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_33         </td><td style=\"text-align: right;\">0.197764</td><td style=\"text-align: right;\"> 0.599389</td><td style=\"text-align: right;\">0.0867553</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.400767</td><td style=\"text-align: right;\">0.160614</td><td style=\"text-align: right;\">                76</td><td style=\"text-align: right;\">                 0.044318</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_21         </td><td style=\"text-align: right;\">0.194969</td><td style=\"text-align: right;\"> 0.685541</td><td style=\"text-align: right;\">0.0871129</td><td style=\"text-align: right;\">              0.490566</td><td style=\"text-align: right;\">0.414562</td><td style=\"text-align: right;\">0.171861</td><td style=\"text-align: right;\">               105</td><td style=\"text-align: right;\">                 0.047906</td><td>GBM         </td></tr>\n",
       "<tr><td>XRT_1_AutoML_1_20230518_152000                       </td><td style=\"text-align: right;\">0.171209</td><td style=\"text-align: right;\"> 0.543106</td><td style=\"text-align: right;\">0.0849223</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.391117</td><td style=\"text-align: right;\">0.152973</td><td style=\"text-align: right;\">                84</td><td style=\"text-align: right;\">                 0.058502</td><td>DRF         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_20         </td><td style=\"text-align: right;\">0.151642</td><td style=\"text-align: right;\"> 0.554223</td><td style=\"text-align: right;\">0.0825586</td><td style=\"text-align: right;\">              0.496855</td><td style=\"text-align: right;\">0.383789</td><td style=\"text-align: right;\">0.147294</td><td style=\"text-align: right;\">                54</td><td style=\"text-align: right;\">                 0.05319 </td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_25         </td><td style=\"text-align: right;\">0.14873 </td><td style=\"text-align: right;\"> 0.62924 </td><td style=\"text-align: right;\">0.0820949</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.390345</td><td style=\"text-align: right;\">0.152369</td><td style=\"text-align: right;\">                49</td><td style=\"text-align: right;\">                 0.042333</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_29         </td><td style=\"text-align: right;\">0.148148</td><td style=\"text-align: right;\"> 0.649384</td><td style=\"text-align: right;\">0.0820689</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.393572</td><td style=\"text-align: right;\">0.154899</td><td style=\"text-align: right;\">                69</td><td style=\"text-align: right;\">                 0.056214</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_4          </td><td style=\"text-align: right;\">0.136268</td><td style=\"text-align: right;\"> 0.606044</td><td style=\"text-align: right;\">0.0814398</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.38997 </td><td style=\"text-align: right;\">0.152076</td><td style=\"text-align: right;\">                85</td><td style=\"text-align: right;\">                 0.049925</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_31         </td><td style=\"text-align: right;\">0.134055</td><td style=\"text-align: right;\"> 0.587242</td><td style=\"text-align: right;\">0.0816684</td><td style=\"text-align: right;\">              0.493711</td><td style=\"text-align: right;\">0.387952</td><td style=\"text-align: right;\">0.150507</td><td style=\"text-align: right;\">                58</td><td style=\"text-align: right;\">                 0.161371</td><td>GBM         </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_1_20230518_152000_model_11         </td><td style=\"text-align: right;\">0.129397</td><td style=\"text-align: right;\"> 0.572206</td><td style=\"text-align: right;\">0.0811611</td><td style=\"text-align: right;\">              0.496855</td><td style=\"text-align: right;\">0.386062</td><td style=\"text-align: right;\">0.149044</td><td style=\"text-align: right;\">                68</td><td style=\"text-align: right;\">                 0.066926</td><td>GBM         </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[94 rows x 10 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                    auc    logloss      aucpr    mean_per_class_error      rmse       mse    training_time_ms    predict_time_per_row_ms  algo\n",
       "-----------------------------------------------------  --------  ---------  ---------  ----------------------  --------  --------  ------------------  -------------------------  ------------\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_13  0.791987   0.435541  0.523313                 0.232355  0.342841  0.11754                13035                   0.066777  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_9   0.745632   0.545802  0.395303                 0.28232   0.360583  0.13002                11969                   0.07269   DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_10  0.722339   0.513111  0.255035                 0.294899  0.380841  0.14504                58032                   0.099285  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_15  0.716282   0.478913  0.426337                 0.37666   0.368728  0.13596                 9900                   0.070182  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_17  0.664104   0.624245  0.376196                 0.382949  0.368472  0.135771                6812                   0.060175  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_9   0.658747   0.585366  0.388401                 0.365129  0.388259  0.150745               10354                   0.063284  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_19  0.610762   0.595747  0.347364                 0.316212  0.374992  0.140619               11594                   0.06462   DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_16  0.581412   1.10088   0.243106                 0.389238  0.387637  0.150263               19983                   0.132074  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_11  0.578616   0.52583   0.174457                 0.37072   0.386686  0.149526               13040                   0.068105  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_8   0.564407   0.725044  0.22082                  0.371069  0.374754  0.140441               46457                   0.104383  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_11  0.548567   0.693623  0.280486                 0.414396  0.378795  0.143486                7371                   0.068808  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_3   0.547403   1.01079   0.362882                 0.388889  0.39542   0.156357                7279                   0.056372  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_10  0.546005   0.553029  0.365928                 0.367575  0.358175  0.128289               18495                   0.069141  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_16  0.536688   0.922376  0.154017                 0.424179  0.414359  0.171693               14850                   0.076055  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_19  0.515024   0.660208  0.178948                 0.421034  0.382786  0.146525               18502                   0.094777  DeepLearning\n",
       "DeepLearning_1_AutoML_1_20230518_152000                0.500582   0.625227  0.336165                 0.353249  0.388208  0.150705                  78                   0.054884  DeepLearning\n",
       "DRF_1_AutoML_1_20230518_152000                         0.488935   0.605096  0.128215                 0.407407  0.412167  0.169882                 145                   0.064739  DRF\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_12  0.473096   0.778283  0.160341                 0.5       0.394647  0.155746               19071                   0.055571  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_5   0.47263    0.806584  0.199521                 0.396925  0.390548  0.152528               53664                   0.096729  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_5   0.470068   0.839617  0.137909                 0.5       0.414497  0.171807               10287                   0.082514  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_8   0.437689   0.858551  0.143765                 0.426974  0.401392  0.161115               38936                   0.067097  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_12  0.436292   1.17835   0.136402                 0.5       0.424135  0.179891               19852                   0.072913  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_3   0.428372   1.08867   0.165001                 0.419986  0.416403  0.173391               11663                   0.054353  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_14  0.424878   0.793529  0.135115                 0.484277  0.408957  0.167246               13734                   0.070033  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_18  0.422315   0.698986  0.132666                 0.493711  0.378273  0.143091                6304                   0.044456  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_7   0.41952    0.680188  0.140618                 0.440252  0.394548  0.155669               21824                   0.056731  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_4   0.419287   1.21253   0.143639                 0.496855  0.411103  0.169006               67043                   0.099323  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_19  0.414396   1.03341   0.121263                 0.484277  0.420465  0.17679                64594                   0.11946   DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_15           0.413464   0.501342  0.120746                 0.476939  0.380071  0.144454                  83                   0.059647  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_14  0.412066   0.919026  0.133258                 0.5       0.40826   0.166676               15126                   0.084327  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_4   0.4116     0.934248  0.118166                 0.493711  0.427521  0.182774               49463                   0.098904  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_9   0.410901   0.756205  0.123608                 0.496855  0.389935  0.152049               10955                   0.057065  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_12  0.39972    1.10267   0.133358                 0.5       0.403342  0.162684               68413                   0.091221  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_1   0.393897   1.24426   0.121836                 0.5       0.437642  0.191531               39400                   0.076347  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_10  0.392266   1.0185    0.18324                  0.5       0.410119  0.168198               40733                   0.077296  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_15  0.381551   1.11823   0.130971                 0.5       0.417633  0.174417               10008                   0.058208  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_2   0.380853   1.04229   0.120904                 0.490217  0.411117  0.169017                8264                   0.051352  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_2            0.369089   0.595811  0.116641                 0.496855  0.400259  0.160207                  91                   0.05797   GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_7   0.365013   0.998433  0.1274                   0.496855  0.40448   0.163604               51643                   0.124395  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_17  0.361053   0.821705  0.118646                 0.5       0.378082  0.142946                7965                   0.061346  DeepLearning\n",
       "GBM_3_AutoML_1_20230518_152000                         0.358724   0.575933  0.118056                 0.5       0.388943  0.151276                 110                   0.055532  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_1   0.352434   1.5234    0.116734                 0.5       0.432247  0.186838               62665                   0.123833  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_1   0.347077   0.739536  0.110483                 0.487072  0.388521  0.150949               16206                   0.054197  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_7            0.341836   0.529719  0.111203                 0.5       0.385903  0.148921                  64                   0.052192  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_23           0.338341   0.566829  0.110575                 0.5       0.389058  0.151366                  95                   0.062361  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_11  0.333566   1.23946   0.122432                 0.493361  0.401724  0.161382                9694                   0.062654  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_16  0.324715   2.82605   0.171095                 0.432914  0.405437  0.164379               30628                   0.139369  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_7   0.32355    0.926295  0.118612                 0.496855  0.41619   0.173214               16591                   0.100266  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_15  0.322618   0.994901  0.107185                 0.493711  0.399043  0.159235               13394                   0.088346  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_18           0.321686   0.575582  0.110817                 0.490566  0.38911   0.151406                 123                   0.07225   GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_13  0.318192   0.854429  0.119331                 0.465409  0.384911  0.148157               12812                   0.072808  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_35           0.317261   0.566866  0.107063                 0.5       0.387136  0.149874                 111                   0.063636  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_12           0.315048   0.660822  0.101905                 0.5       0.412265  0.169962                  83                   0.063138  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_10           0.314931   0.533733  0.109909                 0.5       0.378575  0.143319                  96                   0.058557  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_9            0.309923   0.561028  0.104263                 0.5       0.385827  0.148863                  86                   0.059427  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_13  0.309341   1.12178   0.120776                 0.496855  0.391872  0.153563               18302                   0.081928  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_6   0.307943   0.79192   0.109764                 0.474843  0.390542  0.152523               11862                   0.067301  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_3   0.307011   1.47618   0.129072                 0.496855  0.411702  0.169499               12014                   0.058877  DeepLearning\n",
       "GBM_2_AutoML_1_20230518_152000                         0.29979    0.581537  0.105729                 0.493711  0.390397  0.152409                 100                   0.058934  GBM\n",
       "GBM_4_AutoML_1_20230518_152000                         0.288609   0.600333  0.100369                 0.5       0.392185  0.153809                 132                   0.05673   GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_6   0.287212   1.10262   0.10343                  0.5       0.404244  0.163413               44236                   0.108366  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_2   0.286396   1.33243   0.130809                 0.5       0.401698  0.161361               13643                   0.057652  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_8   0.284184   0.90845   0.0969542                0.484277  0.394002  0.155238               19954                   0.067338  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_32           0.28232    0.585316  0.0975869                0.496855  0.399796  0.159837                  81                   0.056552  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_2   0.281854   1.37018   0.116682                 0.5       0.416232  0.173249               11190                   0.069119  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_14  0.279292   0.834969  0.118262                 0.5       0.400359  0.160287              849991                   0.100327  DeepLearning\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_5   0.278593   1.40274   0.102111                 0.5       0.419732  0.176175               14199                   0.099683  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_13           0.278127   0.656863  0.0975721                0.496855  0.4056    0.164511                 120                   0.056077  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_3            0.276497   0.544996  0.104976                 0.5       0.380858  0.145053                  87                   0.066247  GBM\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_6   0.274167   1.07314   0.109731                 0.5       0.413021  0.170586               13753                   0.073315  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_22           0.273818   0.559857  0.09998                  0.496855  0.382877  0.146595                 113                   0.046813  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_1            0.273352   0.539461  0.1                      0.5       0.381253  0.145354                  87                   0.074859  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_17           0.271605   0.641473  0.0976344                0.496855  0.410975  0.168901                  85                   0.056619  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_8            0.263918   0.648389  0.0980034                0.493711  0.403365  0.162703                 179                   0.050242  GBM\n",
       "GLM_1_AutoML_1_20230518_152000                         0.262055   0.491077  0.101928                 0.5       0.373901  0.139802                  31                   0.056263  GLM\n",
       "DeepLearning_grid_2_AutoML_1_20230518_152000_model_18  0.254601   1.18328   0.119214                 0.5       0.388808  0.151172                8127                   0.057762  DeepLearning\n",
       "DeepLearning_grid_1_AutoML_1_20230518_152000_model_4   0.245749   1.60353   0.0949101                0.5       0.418543  0.175178               15623                   0.062724  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_26           0.243652   0.602435  0.0931125                0.5       0.393246  0.154642                  65                   0.074318  GBM\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_18  0.24109    0.893807  0.0949346                0.5       0.377798  0.142731                9008                   0.055091  DeepLearning\n",
       "DeepLearning_grid_3_AutoML_1_20230518_152000_model_17  0.240857   1.20755   0.124298                 0.5       0.388046  0.15058                10119                   0.043909  DeepLearning\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_28           0.233986   0.541781  0.0895966                0.5       0.381409  0.145472                  66                   0.049938  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_5            0.231656   0.622658  0.0892537                0.5       0.403494  0.162807                  90                   0.045711  GBM\n",
       "GBM_5_AutoML_1_20230518_152000                         0.209644   0.720115  0.0892811                0.496855  0.425937  0.181423                  87                   0.046536  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_24           0.20615    0.551256  0.0900863                0.5       0.384276  0.147668                  61                   0.055431  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_34           0.204403   0.592306  0.087987                 0.5       0.389432  0.151657                  73                   0.038657  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_33           0.197764   0.599389  0.0867553                0.5       0.400767  0.160614                  76                   0.044318  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_21           0.194969   0.685541  0.0871129                0.490566  0.414562  0.171861                 105                   0.047906  GBM\n",
       "XRT_1_AutoML_1_20230518_152000                         0.171209   0.543106  0.0849223                0.5       0.391117  0.152973                  84                   0.058502  DRF\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_20           0.151642   0.554223  0.0825586                0.496855  0.383789  0.147294                  54                   0.05319   GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_25           0.14873    0.62924   0.0820949                0.5       0.390345  0.152369                  49                   0.042333  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_29           0.148148   0.649384  0.0820689                0.5       0.393572  0.154899                  69                   0.056214  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_4            0.136268   0.606044  0.0814398                0.5       0.38997   0.152076                  85                   0.049925  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_31           0.134055   0.587242  0.0816684                0.493711  0.387952  0.150507                  58                   0.161371  GBM\n",
       "GBM_grid_1_AutoML_1_20230518_152000_model_11           0.129397   0.572206  0.0811611                0.496855  0.386062  0.149044                  68                   0.066926  GBM\n",
       "[94 rows x 10 columns]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.automl import H2OAutoML, get_leaderboard\n",
    "\n",
    "# Import a sample binary outcome train/test set into H2O\n",
    "train1 = h2o.H2OFrame(train)\n",
    "\n",
    "# Identify predictors and response\n",
    "predictors = ['year','nom_gg_drama', 'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy',\n",
    "       'nom_pga', 'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga',\n",
    "        'nom_sag', 'winner_sag', 'nom_cannes', 'winner_cannes','nominations']\n",
    "\n",
    "x = predictors\n",
    "y = 'Oscar_win'\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train1[y] = train1[y].asfactor()\n",
    "\n",
    "# Run AutoML for 100 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=100, seed=1\n",
    "                , keep_cross_validation_predictions= True\n",
    "               , exclude_algos = ['StackedEnsemble'])\n",
    "\n",
    "aml.train(x=x, y=y, training_frame=train1)\n",
    "\n",
    "# AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "\n",
    "# Optionally edd extra model information to the leaderboard\n",
    "lb = get_leaderboard(aml, extra_columns='ALL')\n",
    "\n",
    "# Print all rows (instead of default 10 rows)\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_1_AutoML_1_20230518_152000_model_13\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 852 weights/biases, 15,0 KB, 1 313 160 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>14</td>\n",
       "<td>Input</td>\n",
       "<td>5.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>50</td>\n",
       "<td>RectifierDropout</td>\n",
       "<td>40.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0052819</td>\n",
       "<td>0.0270572</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0706238</td>\n",
       "<td>0.3019202</td>\n",
       "<td>-0.2531923</td>\n",
       "<td>0.3544667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0019572</td>\n",
       "<td>0.0036744</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0821257</td>\n",
       "<td>0.9244528</td>\n",
       "<td>-0.0111810</td>\n",
       "<td>0.3788637</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.0606066221544762\n",
       "RMSE: 0.2461841224662472\n",
       "LogLoss: 0.1987397577870827\n",
       "Mean Per-Class Error: 0.19461914744933612\n",
       "AUC: 0.9430468204053111\n",
       "AUCPR: 0.8008137032163598\n",
       "Gini: 0.8860936408106221</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35240926728521654</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>156.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0189</td>\n",
       "<td> (3.0/159.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>10.0</td>\n",
       "<td>17.0</td>\n",
       "<td>0.3704</td>\n",
       "<td> (10.0/27.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>166.0</td>\n",
       "<td>20.0</td>\n",
       "<td>0.0699</td>\n",
       "<td> (13.0/186.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3524093</td>\n",
       "<td>0.7234043</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0508160</td>\n",
       "<td>0.7668712</td>\n",
       "<td>46.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5289677</td>\n",
       "<td>0.8241758</td>\n",
       "<td>14.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5289677</td>\n",
       "<td>0.9301075</td>\n",
       "<td>14.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0231833</td>\n",
       "<td>1.0</td>\n",
       "<td>65.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3524093</td>\n",
       "<td>0.6945175</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0863697</td>\n",
       "<td>0.8518519</td>\n",
       "<td>40.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0508160</td>\n",
       "<td>0.8686233</td>\n",
       "<td>46.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>159.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>25.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>159.0</td>\n",
       "<td>149.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0231833</td>\n",
       "<td>27.0</td>\n",
       "<td>65.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9259259</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>149.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0231833</td>\n",
       "<td>1.0</td>\n",
       "<td>65.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,52 %, avg score: 12,01 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0107527</td>\n",
       "<td>1.0000000</td>\n",
       "<td>6.8888889</td>\n",
       "<td>6.8888889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.0740741</td>\n",
       "<td>588.8888889</td>\n",
       "<td>588.8888889</td>\n",
       "<td>0.0740741</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0215054</td>\n",
       "<td>0.9999959</td>\n",
       "<td>6.8888889</td>\n",
       "<td>6.8888889</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.1481481</td>\n",
       "<td>588.8888889</td>\n",
       "<td>588.8888889</td>\n",
       "<td>0.1481481</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0322581</td>\n",
       "<td>0.9998203</td>\n",
       "<td>6.8888889</td>\n",
       "<td>6.8888889</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999137</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999712</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2222222</td>\n",
       "<td>588.8888889</td>\n",
       "<td>588.8888889</td>\n",
       "<td>0.2222222</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0430108</td>\n",
       "<td>0.9945451</td>\n",
       "<td>6.8888889</td>\n",
       "<td>6.8888889</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9988702</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996960</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2962963</td>\n",
       "<td>588.8888889</td>\n",
       "<td>588.8888889</td>\n",
       "<td>0.2962963</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0537634</td>\n",
       "<td>0.9124077</td>\n",
       "<td>6.8888889</td>\n",
       "<td>6.8888889</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9858973</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9969362</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.3703704</td>\n",
       "<td>588.8888889</td>\n",
       "<td>588.8888889</td>\n",
       "<td>0.3703704</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1021505</td>\n",
       "<td>0.3525419</td>\n",
       "<td>4.5925926</td>\n",
       "<td>5.8011696</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.5578856</td>\n",
       "<td>0.8421053</td>\n",
       "<td>0.7889649</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.5925926</td>\n",
       "<td>359.2592593</td>\n",
       "<td>480.1169591</td>\n",
       "<td>0.5737247</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1505376</td>\n",
       "<td>0.2653283</td>\n",
       "<td>1.5308642</td>\n",
       "<td>4.4285714</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.3352631</td>\n",
       "<td>0.6428571</td>\n",
       "<td>0.6431321</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.6666667</td>\n",
       "<td>53.0864198</td>\n",
       "<td>342.8571429</td>\n",
       "<td>0.6037736</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2043011</td>\n",
       "<td>0.1207151</td>\n",
       "<td>2.7555556</td>\n",
       "<td>3.9883041</td>\n",
       "<td>0.4</td>\n",
       "<td>0.1676764</td>\n",
       "<td>0.5789474</td>\n",
       "<td>0.5180122</td>\n",
       "<td>0.1481481</td>\n",
       "<td>0.8148148</td>\n",
       "<td>175.5555556</td>\n",
       "<td>298.8304094</td>\n",
       "<td>0.7141859</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3010753</td>\n",
       "<td>0.0483993</td>\n",
       "<td>1.1481481</td>\n",
       "<td>3.0753968</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.0666777</td>\n",
       "<td>0.4464286</td>\n",
       "<td>0.3729404</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.9259259</td>\n",
       "<td>14.8148148</td>\n",
       "<td>207.5396825</td>\n",
       "<td>0.7309574</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4086022</td>\n",
       "<td>0.0353265</td>\n",
       "<td>0.3444444</td>\n",
       "<td>2.3567251</td>\n",
       "<td>0.05</td>\n",
       "<td>0.0404583</td>\n",
       "<td>0.3421053</td>\n",
       "<td>0.2854451</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.9629630</td>\n",
       "<td>-65.5555556</td>\n",
       "<td>135.6725146</td>\n",
       "<td>0.6484976</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5053763</td>\n",
       "<td>0.0157897</td>\n",
       "<td>0.3827160</td>\n",
       "<td>1.9787234</td>\n",
       "<td>0.0555556</td>\n",
       "<td>0.0247685</td>\n",
       "<td>0.2872340</td>\n",
       "<td>0.2355283</td>\n",
       "<td>0.0370370</td>\n",
       "<td>1.0</td>\n",
       "<td>-61.7283951</td>\n",
       "<td>97.8723404</td>\n",
       "<td>0.5786164</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6021505</td>\n",
       "<td>0.0042550</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6607143</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0080156</td>\n",
       "<td>0.2410714</td>\n",
       "<td>0.1989638</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.0714286</td>\n",
       "<td>0.4654088</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6989247</td>\n",
       "<td>0.0023426</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4307692</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0029021</td>\n",
       "<td>0.2076923</td>\n",
       "<td>0.1718168</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.0769231</td>\n",
       "<td>0.3522013</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8010753</td>\n",
       "<td>0.0000810</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2483221</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005099</td>\n",
       "<td>0.1812081</td>\n",
       "<td>0.1499723</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.8322148</td>\n",
       "<td>0.2327044</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8978495</td>\n",
       "<td>0.0000007</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1137725</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000212</td>\n",
       "<td>0.1616766</td>\n",
       "<td>0.1338099</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.3772455</td>\n",
       "<td>0.1194969</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.1451613</td>\n",
       "<td>0.1201411</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.11754000967735893\n",
       "RMSE: 0.34284108516535605\n",
       "LogLoss: 0.43554125490004575\n",
       "Mean Per-Class Error: 0.23235499650593988\n",
       "AUC: 0.791986955508968\n",
       "AUCPR: 0.5233127899825332\n",
       "Gini: 0.583973911017936</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.18970386837654063</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>144.0</td>\n",
       "<td>15.0</td>\n",
       "<td>0.0943</td>\n",
       "<td> (15.0/159.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>10.0</td>\n",
       "<td>17.0</td>\n",
       "<td>0.3704</td>\n",
       "<td> (10.0/27.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>154.0</td>\n",
       "<td>32.0</td>\n",
       "<td>0.1344</td>\n",
       "<td> (25.0/186.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.1897039</td>\n",
       "<td>0.5762712</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1897039</td>\n",
       "<td>0.6071429</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9415002</td>\n",
       "<td>0.6349206</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9415002</td>\n",
       "<td>0.8924731</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999998</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0032229</td>\n",
       "<td>1.0</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999998</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1897039</td>\n",
       "<td>0.4996136</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0606926</td>\n",
       "<td>0.7037037</td>\n",
       "<td>53.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1897039</td>\n",
       "<td>0.7676450</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999998</td>\n",
       "<td>159.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999998</td>\n",
       "<td>26.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000008</td>\n",
       "<td>159.0</td>\n",
       "<td>179.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0032229</td>\n",
       "<td>27.0</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999998</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999998</td>\n",
       "<td>0.9629630</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000008</td>\n",
       "<td>1.0</td>\n",
       "<td>179.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0032229</td>\n",
       "<td>1.0</td>\n",
       "<td>142.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 14,52 %, avg score: 13,99 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0107527</td>\n",
       "<td>0.9999811</td>\n",
       "<td>6.8888889</td>\n",
       "<td>6.8888889</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999998</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999998</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.0740741</td>\n",
       "<td>588.8888889</td>\n",
       "<td>588.8888889</td>\n",
       "<td>0.0740741</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0215054</td>\n",
       "<td>0.9993527</td>\n",
       "<td>6.8888889</td>\n",
       "<td>6.8888889</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999777</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999887</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.1481481</td>\n",
       "<td>588.8888889</td>\n",
       "<td>588.8888889</td>\n",
       "<td>0.1481481</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0322581</td>\n",
       "<td>0.9854080</td>\n",
       "<td>3.4444444</td>\n",
       "<td>5.7407407</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9985298</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.9995024</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.1851852</td>\n",
       "<td>244.4444444</td>\n",
       "<td>474.0740741</td>\n",
       "<td>0.1788959</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0430108</td>\n",
       "<td>0.9497110</td>\n",
       "<td>6.8888889</td>\n",
       "<td>6.0277778</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9651555</td>\n",
       "<td>0.875</td>\n",
       "<td>0.9909157</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2592593</td>\n",
       "<td>588.8888889</td>\n",
       "<td>502.7777778</td>\n",
       "<td>0.2529700</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0537634</td>\n",
       "<td>0.9192653</td>\n",
       "<td>3.4444444</td>\n",
       "<td>5.5111111</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9331563</td>\n",
       "<td>0.8</td>\n",
       "<td>0.9793638</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.2962963</td>\n",
       "<td>244.4444444</td>\n",
       "<td>451.1111111</td>\n",
       "<td>0.2837177</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1021505</td>\n",
       "<td>0.6285782</td>\n",
       "<td>0.0</td>\n",
       "<td>2.9005848</td>\n",
       "<td>0.0</td>\n",
       "<td>0.7645958</td>\n",
       "<td>0.4210526</td>\n",
       "<td>0.8776316</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2962963</td>\n",
       "<td>-100.0</td>\n",
       "<td>190.0584795</td>\n",
       "<td>0.2271139</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1505376</td>\n",
       "<td>0.2736724</td>\n",
       "<td>4.5925926</td>\n",
       "<td>3.4444444</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.4320210</td>\n",
       "<td>0.5</td>\n",
       "<td>0.7343996</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.5185185</td>\n",
       "<td>359.2592593</td>\n",
       "<td>244.4444444</td>\n",
       "<td>0.4304682</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2043011</td>\n",
       "<td>0.1509563</td>\n",
       "<td>2.0666667</td>\n",
       "<td>3.0818713</td>\n",
       "<td>0.3</td>\n",
       "<td>0.1847457</td>\n",
       "<td>0.4473684</td>\n",
       "<td>0.5897539</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.6296296</td>\n",
       "<td>106.6666667</td>\n",
       "<td>208.1871345</td>\n",
       "<td>0.4975542</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3010753</td>\n",
       "<td>0.0580568</td>\n",
       "<td>0.7654321</td>\n",
       "<td>2.3373016</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.0975445</td>\n",
       "<td>0.3392857</td>\n",
       "<td>0.4315437</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.7037037</td>\n",
       "<td>-23.4567901</td>\n",
       "<td>133.7301587</td>\n",
       "<td>0.4709993</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4032258</td>\n",
       "<td>0.0342205</td>\n",
       "<td>0.0</td>\n",
       "<td>1.7451852</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0433447</td>\n",
       "<td>0.2533333</td>\n",
       "<td>0.3332000</td>\n",
       "<td>0.0</td>\n",
       "<td>0.7037037</td>\n",
       "<td>-100.0</td>\n",
       "<td>74.5185185</td>\n",
       "<td>0.3515024</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0198965</td>\n",
       "<td>1.1481481</td>\n",
       "<td>1.6296296</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.0280413</td>\n",
       "<td>0.2365591</td>\n",
       "<td>0.2741370</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.8148148</td>\n",
       "<td>14.8148148</td>\n",
       "<td>62.9629630</td>\n",
       "<td>0.3682739</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6021505</td>\n",
       "<td>0.0107042</td>\n",
       "<td>0.7251462</td>\n",
       "<td>1.4761905</td>\n",
       "<td>0.1052632</td>\n",
       "<td>0.0140386</td>\n",
       "<td>0.2142857</td>\n",
       "<td>0.2300132</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.8888889</td>\n",
       "<td>-27.4853801</td>\n",
       "<td>47.6190476</td>\n",
       "<td>0.3354298</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6989247</td>\n",
       "<td>0.0066404</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2717949</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0081230</td>\n",
       "<td>0.1846154</td>\n",
       "<td>0.1992899</td>\n",
       "<td>0.0</td>\n",
       "<td>0.8888889</td>\n",
       "<td>-100.0</td>\n",
       "<td>27.1794872</td>\n",
       "<td>0.2222222</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8010753</td>\n",
       "<td>0.0032229</td>\n",
       "<td>1.0877193</td>\n",
       "<td>1.2483221</td>\n",
       "<td>0.1578947</td>\n",
       "<td>0.0048099</td>\n",
       "<td>0.1812081</td>\n",
       "<td>0.1744904</td>\n",
       "<td>0.1111111</td>\n",
       "<td>1.0</td>\n",
       "<td>8.7719298</td>\n",
       "<td>24.8322148</td>\n",
       "<td>0.2327044</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8978495</td>\n",
       "<td>0.0002952</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1137725</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0014884</td>\n",
       "<td>0.1616766</td>\n",
       "<td>0.1558435</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.3772455</td>\n",
       "<td>0.1194969</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>7.9e-07</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001041</td>\n",
       "<td>0.1451613</td>\n",
       "<td>0.1399347</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.7790896</td>\n",
       "<td>0.1870809</td>\n",
       "<td>0.8684211</td>\n",
       "<td>0.5405405</td>\n",
       "<td>0.972973</td>\n",
       "<td>0.6216216</td>\n",
       "<td>0.8918919</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.6687955</td>\n",
       "<td>0.1405028</td>\n",
       "<td>0.8666667</td>\n",
       "<td>0.6214285</td>\n",
       "<td>0.6714286</td>\n",
       "<td>0.7058824</td>\n",
       "<td>0.4785714</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.2209104</td>\n",
       "<td>0.1870809</td>\n",
       "<td>0.1315790</td>\n",
       "<td>0.4594594</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.3783784</td>\n",
       "<td>0.1081081</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>8.2</td>\n",
       "<td>6.9065185</td>\n",
       "<td>5.0</td>\n",
       "<td>17.0</td>\n",
       "<td>1.0</td>\n",
       "<td>14.0</td>\n",
       "<td>4.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.4603295</td>\n",
       "<td>0.3526573</td>\n",
       "<td>0.8510638</td>\n",
       "<td>0.1282051</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.2112676</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.4710682</td>\n",
       "<td>0.282976</td>\n",
       "<td>0.8648649</td>\n",
       "<td>0.1904762</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.3</td>\n",
       "<td>0.3333333</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.5477909</td>\n",
       "<td>0.1996527</td>\n",
       "<td>0.8791209</td>\n",
       "<td>0.3703704</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.5172414</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>4.1222224</td>\n",
       "<td>8.08924</td>\n",
       "<td>2.1111112</td>\n",
       "<td>0.0</td>\n",
       "<td>18.5</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.4337158</td>\n",
       "<td>0.2180643</td>\n",
       "<td>0.7732567</td>\n",
       "<td>0.5186943</td>\n",
       "<td>0.2228640</td>\n",
       "<td>0.3125070</td>\n",
       "<td>0.3412567</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.4094958</td>\n",
       "<td>0.1496116</td>\n",
       "<td>0.15</td>\n",
       "<td>0.4857143</td>\n",
       "<td>0.5</td>\n",
       "<td>0.4117647</td>\n",
       "<td>0.5</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.4583264</td>\n",
       "<td>0.2393736</td>\n",
       "<td>0.7378648</td>\n",
       "<td>0.2326700</td>\n",
       "<td>0.6972167</td>\n",
       "<td>0.3221897</td>\n",
       "<td>0.3016908</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.7755696</td>\n",
       "<td>0.0608935</td>\n",
       "<td>0.8694444</td>\n",
       "<td>0.7571428</td>\n",
       "<td>0.75</td>\n",
       "<td>0.7941176</td>\n",
       "<td>0.7071428</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.2244304</td>\n",
       "<td>0.0608935</td>\n",
       "<td>0.1305556</td>\n",
       "<td>0.2428571</td>\n",
       "<td>0.25</td>\n",
       "<td>0.2058824</td>\n",
       "<td>0.2928571</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1170378</td>\n",
       "<td>0.0683103</td>\n",
       "<td>0.2104473</td>\n",
       "<td>0.1639352</td>\n",
       "<td>0.0432085</td>\n",
       "<td>0.0774701</td>\n",
       "<td>0.0901279</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.3296252</td>\n",
       "<td>0.3430624</td>\n",
       "<td>0.8397061</td>\n",
       "<td>0.0649010</td>\n",
       "<td>0.5305471</td>\n",
       "<td>0.1231285</td>\n",
       "<td>0.0898432</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.4747678</td>\n",
       "<td>0.4143794</td>\n",
       "<td>0.8421053</td>\n",
       "<td>0.1052632</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1764706</td>\n",
       "<td>0.25</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>-0.5395364</td>\n",
       "<td>1.0053506</td>\n",
       "<td>0.1558726</td>\n",
       "<td>-2.206105</td>\n",
       "<td>0.1549644</td>\n",
       "<td>-0.0397704</td>\n",
       "<td>-0.7626436</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.7777778</td>\n",
       "<td>0.2576005</td>\n",
       "<td>0.8888889</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.3300097</td>\n",
       "<td>0.1008178</td>\n",
       "<td>0.4587453</td>\n",
       "<td>0.4048892</td>\n",
       "<td>0.2078666</td>\n",
       "<td>0.2783345</td>\n",
       "<td>0.3002130</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.7733613</td>\n",
       "<td>0.2112404</td>\n",
       "<td>0.85</td>\n",
       "<td>0.5142857</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5882353</td>\n",
       "<td>0.9142857</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-10.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-10 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-10 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-10 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table th,\n",
       "#h2o-table-10 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2023-05-18 15:35:20</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-18 15:35:20</td>\n",
       "<td>14 min 57.881 sec</td>\n",
       "<td>77500 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>1</td>\n",
       "<td>1860.0</td>\n",
       "<td>0.3281038</td>\n",
       "<td>0.4167286</td>\n",
       "<td>0.1324640</td>\n",
       "<td>0.8086420</td>\n",
       "<td>0.4972985</td>\n",
       "<td>6.8888889</td>\n",
       "<td>0.1129032</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-18 15:35:25</td>\n",
       "<td>15 min  2.890 sec</td>\n",
       "<td>87865 obs/sec</td>\n",
       "<td>2370.0</td>\n",
       "<td>237</td>\n",
       "<td>440820.0</td>\n",
       "<td>0.2488482</td>\n",
       "<td>0.2048569</td>\n",
       "<td>0.5009615</td>\n",
       "<td>0.9367575</td>\n",
       "<td>0.7875639</td>\n",
       "<td>6.8888889</td>\n",
       "<td>0.0698925</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-18 15:35:30</td>\n",
       "<td>15 min  7.891 sec</td>\n",
       "<td>98158 obs/sec</td>\n",
       "<td>5280.0</td>\n",
       "<td>528</td>\n",
       "<td>982080.0</td>\n",
       "<td>0.2480757</td>\n",
       "<td>0.2025354</td>\n",
       "<td>0.5040550</td>\n",
       "<td>0.9439786</td>\n",
       "<td>0.7986576</td>\n",
       "<td>6.8888889</td>\n",
       "<td>0.0752688</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2023-05-18 15:35:33</td>\n",
       "<td>15 min 10.849 sec</td>\n",
       "<td>101425 obs/sec</td>\n",
       "<td>7060.0</td>\n",
       "<td>706</td>\n",
       "<td>1313160.0</td>\n",
       "<td>0.2461841</td>\n",
       "<td>0.1987398</td>\n",
       "<td>0.5115894</td>\n",
       "<td>0.9430468</td>\n",
       "<td>0.8008137</td>\n",
       "<td>6.8888889</td>\n",
       "<td>0.0698925</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-11.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-11 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-11 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-11 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table th,\n",
       "#h2o-table-11 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>winner_sag</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1255337</td></tr>\n",
       "<tr><td>winner_gg_drama</td>\n",
       "<td>0.8694185</td>\n",
       "<td>0.8694185</td>\n",
       "<td>0.1091413</td></tr>\n",
       "<tr><td>nominations</td>\n",
       "<td>0.8031203</td>\n",
       "<td>0.8031203</td>\n",
       "<td>0.1008186</td></tr>\n",
       "<tr><td>winner_dga</td>\n",
       "<td>0.6849936</td>\n",
       "<td>0.6849936</td>\n",
       "<td>0.0859898</td></tr>\n",
       "<tr><td>winner_pga</td>\n",
       "<td>0.6611996</td>\n",
       "<td>0.6611996</td>\n",
       "<td>0.0830028</td></tr>\n",
       "<tr><td>nom_gg_drama</td>\n",
       "<td>0.6321517</td>\n",
       "<td>0.6321517</td>\n",
       "<td>0.0793563</td></tr>\n",
       "<tr><td>nom_bafta</td>\n",
       "<td>0.4765725</td>\n",
       "<td>0.4765725</td>\n",
       "<td>0.0598259</td></tr>\n",
       "<tr><td>winner_bafta</td>\n",
       "<td>0.4700401</td>\n",
       "<td>0.4700401</td>\n",
       "<td>0.0590059</td></tr>\n",
       "<tr><td>nom_dga</td>\n",
       "<td>0.4239600</td>\n",
       "<td>0.4239600</td>\n",
       "<td>0.0532213</td></tr>\n",
       "<tr><td>year</td>\n",
       "<td>0.4210126</td>\n",
       "<td>0.4210126</td>\n",
       "<td>0.0528513</td></tr>\n",
       "<tr><td>nom_sag</td>\n",
       "<td>0.4021040</td>\n",
       "<td>0.4021040</td>\n",
       "<td>0.0504776</td></tr>\n",
       "<tr><td>nom_pga</td>\n",
       "<td>0.3885119</td>\n",
       "<td>0.3885119</td>\n",
       "<td>0.0487713</td></tr>\n",
       "<tr><td>winner_gg_comedy</td>\n",
       "<td>0.3673862</td>\n",
       "<td>0.3673862</td>\n",
       "<td>0.0461193</td></tr>\n",
       "<tr><td>nom_gg_comedy</td>\n",
       "<td>0.3655189</td>\n",
       "<td>0.3655189</td>\n",
       "<td>0.0458849</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_grid_1_AutoML_1_20230518_152000_model_13\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting Oscar_win, 2-class classification, bernoulli distribution, CrossEntropy loss, 852 weights/biases, 15,0 KB, 1 313 160 training samples, mini-batch size 1\n",
       "    layer    units    type              dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight           weight_rms           mean_bias              bias_rms\n",
       "--  -------  -------  ----------------  ---------  ----  ----  ---------------------  ---------------------  ----------  --------------------  -------------------  ---------------------  -------------------\n",
       "    1        14       Input             5.0\n",
       "    2        50       RectifierDropout  40.0       0.0   0.0   0.0052818747279837095  0.027057208120822906   0.0         0.07062382860942827   0.30192017555236816  -0.2531922840566988    0.35446667671203613\n",
       "    3        2        Softmax                      0.0   0.0   0.0019571759249083697  0.0036744242534041405  0.0         -0.08212572288699448  0.9244527816772461   -0.011181012423209513  0.37886369228363037\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.0606066221544762\n",
       "RMSE: 0.2461841224662472\n",
       "LogLoss: 0.1987397577870827\n",
       "Mean Per-Class Error: 0.19461914744933612\n",
       "AUC: 0.9430468204053111\n",
       "AUCPR: 0.8008137032163598\n",
       "Gini: 0.8860936408106221\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35240926728521654\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      156  3    0.0189   (3.0/159.0)\n",
       "1      10   17   0.3704   (10.0/27.0)\n",
       "Total  166  20   0.0699   (13.0/186.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.352409     0.723404  18\n",
       "max f2                       0.050816     0.766871  46\n",
       "max f0point5                 0.528968     0.824176  14\n",
       "max accuracy                 0.528968     0.930108  14\n",
       "max precision                1            1         0\n",
       "max recall                   0.0231833    1         65\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.352409     0.694518  18\n",
       "max min_per_class_accuracy   0.0863697    0.851852  40\n",
       "max mean_per_class_accuracy  0.050816     0.868623  46\n",
       "max tns                      1            159       0\n",
       "max fns                      1            25        0\n",
       "max fps                      2.38047e-13  159       149\n",
       "max tps                      0.0231833    27        65\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.925926  0\n",
       "max fpr                      2.38047e-13  1         149\n",
       "max tpr                      0.0231833    1         65\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,52 %, avg score: 12,01 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0107527                   1                  6.88889   6.88889            1                1            1                           1                   0.0740741       0.0740741                  588.889   588.889            0.0740741\n",
       "2        0.0215054                   0.999996           6.88889   6.88889            1                1            1                           1                   0.0740741       0.148148                   588.889   588.889            0.148148\n",
       "3        0.0322581                   0.99982            6.88889   6.88889            1                0.999914     1                           0.999971            0.0740741       0.222222                   588.889   588.889            0.222222\n",
       "4        0.0430108                   0.994545           6.88889   6.88889            1                0.99887      1                           0.999696            0.0740741       0.296296                   588.889   588.889            0.296296\n",
       "5        0.0537634                   0.912408           6.88889   6.88889            1                0.985897     1                           0.996936            0.0740741       0.37037                    588.889   588.889            0.37037\n",
       "6        0.102151                    0.352542           4.59259   5.80117            0.666667         0.557886     0.842105                    0.788965            0.222222        0.592593                   359.259   480.117            0.573725\n",
       "7        0.150538                    0.265328           1.53086   4.42857            0.222222         0.335263     0.642857                    0.643132            0.0740741       0.666667                   53.0864   342.857            0.603774\n",
       "8        0.204301                    0.120715           2.75556   3.9883             0.4              0.167676     0.578947                    0.518012            0.148148        0.814815                   175.556   298.83             0.714186\n",
       "9        0.301075                    0.0483993          1.14815   3.0754             0.166667         0.0666777    0.446429                    0.37294             0.111111        0.925926                   14.8148   207.54             0.730957\n",
       "10       0.408602                    0.0353265          0.344444  2.35673            0.05             0.0404583    0.342105                    0.285445            0.037037        0.962963                   -65.5556  135.673            0.648498\n",
       "11       0.505376                    0.0157897          0.382716  1.97872            0.0555556        0.0247685    0.287234                    0.235528            0.037037        1                          -61.7284  97.8723            0.578616\n",
       "12       0.602151                    0.00425502         0         1.66071            0                0.00801563   0.241071                    0.198964            0               1                          -100      66.0714            0.465409\n",
       "13       0.698925                    0.00234262         0         1.43077            0                0.00290209   0.207692                    0.171817            0               1                          -100      43.0769            0.352201\n",
       "14       0.801075                    8.09615e-05        0         1.24832            0                0.000509935  0.181208                    0.149972            0               1                          -100      24.8322            0.232704\n",
       "15       0.897849                    6.99288e-07        0         1.11377            0                2.11804e-05  0.161677                    0.13381             0               1                          -100      11.3772            0.119497\n",
       "16       1                           2.38047e-13        0         1                  0                1.2665e-07   0.145161                    0.120141            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.11754000967735893\n",
       "RMSE: 0.34284108516535605\n",
       "LogLoss: 0.43554125490004575\n",
       "Mean Per-Class Error: 0.23235499650593988\n",
       "AUC: 0.791986955508968\n",
       "AUCPR: 0.5233127899825332\n",
       "Gini: 0.583973911017936\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.18970386837654063\n",
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      144  15   0.0943   (15.0/159.0)\n",
       "1      10   17   0.3704   (10.0/27.0)\n",
       "Total  154  32   0.1344   (25.0/186.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.189704     0.576271  31\n",
       "max f2                       0.189704     0.607143  31\n",
       "max f0point5                 0.9415       0.634921  8\n",
       "max accuracy                 0.9415       0.892473  8\n",
       "max precision                1            1         0\n",
       "max recall                   0.00322294   1         142\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.189704     0.499614  31\n",
       "max min_per_class_accuracy   0.0606926    0.703704  53\n",
       "max mean_per_class_accuracy  0.189704     0.767645  31\n",
       "max tns                      1            159       0\n",
       "max fns                      1            26        0\n",
       "max fps                      7.92974e-07  159       179\n",
       "max tps                      0.00322294   27        142\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.962963  0\n",
       "max fpr                      7.92974e-07  1         179\n",
       "max tpr                      0.00322294   1         142\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 14,52 %, avg score: 13,99 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0107527                   0.999981           6.88889   6.88889            1                1            1                           1                   0.0740741       0.0740741                  588.889   588.889            0.0740741\n",
       "2        0.0215054                   0.999353           6.88889   6.88889            1                0.999978     1                           0.999989            0.0740741       0.148148                   588.889   588.889            0.148148\n",
       "3        0.0322581                   0.985408           3.44444   5.74074            0.5              0.99853      0.833333                    0.999502            0.037037        0.185185                   244.444   474.074            0.178896\n",
       "4        0.0430108                   0.949711           6.88889   6.02778            1                0.965156     0.875                       0.990916            0.0740741       0.259259                   588.889   502.778            0.25297\n",
       "5        0.0537634                   0.919265           3.44444   5.51111            0.5              0.933156     0.8                         0.979364            0.037037        0.296296                   244.444   451.111            0.283718\n",
       "6        0.102151                    0.628578           0         2.90058            0                0.764596     0.421053                    0.877632            0               0.296296                   -100      190.058            0.227114\n",
       "7        0.150538                    0.273672           4.59259   3.44444            0.666667         0.432021     0.5                         0.7344              0.222222        0.518519                   359.259   244.444            0.430468\n",
       "8        0.204301                    0.150956           2.06667   3.08187            0.3              0.184746     0.447368                    0.589754            0.111111        0.62963                    106.667   208.187            0.497554\n",
       "9        0.301075                    0.0580568          0.765432  2.3373             0.111111         0.0975445    0.339286                    0.431544            0.0740741       0.703704                   -23.4568  133.73             0.470999\n",
       "10       0.403226                    0.0342205          0         1.74519            0                0.0433447    0.253333                    0.3332              0               0.703704                   -100      74.5185            0.351502\n",
       "11       0.5                         0.0198965          1.14815   1.62963            0.166667         0.0280413    0.236559                    0.274137            0.111111        0.814815                   14.8148   62.963             0.368274\n",
       "12       0.602151                    0.0107042          0.725146  1.47619            0.105263         0.0140386    0.214286                    0.230013            0.0740741       0.888889                   -27.4854  47.619             0.33543\n",
       "13       0.698925                    0.00664042         0         1.27179            0                0.00812298   0.184615                    0.19929             0               0.888889                   -100      27.1795            0.222222\n",
       "14       0.801075                    0.00322294         1.08772   1.24832            0.157895         0.00480989   0.181208                    0.17449             0.111111        1                          8.77193   24.8322            0.232704\n",
       "15       0.897849                    0.00029524         0         1.11377            0                0.00148843   0.161677                    0.155844            0               1                          -100      11.3772            0.119497\n",
       "16       1                           7.9e-07            0         1                  0                0.000104138  0.145161                    0.139935            0               1                          -100      0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean       sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.77909    0.187081   0.868421      0.54054       0.972973      0.621622      0.891892\n",
       "auc                      0.668795   0.140503   0.866667      0.621429      0.671429      0.705882      0.478571\n",
       "err                      0.22091    0.187081   0.131579      0.459459      0.027027      0.378378      0.108108\n",
       "err_count                8.2        6.90652    5             17            1             14            4\n",
       "f0point5                 0.46033    0.352657   0.851064      0.128205      0.833333      0.211268      0.277778\n",
       "f1                       0.471068   0.282976   0.864865      0.190476      0.666667      0.3           0.333333\n",
       "f2                       0.547791   0.199653   0.879121      0.37037       0.555556      0.517241      0.416667\n",
       "lift_top_group           4.12222    8.08924    2.11111       0             18.5          0             0\n",
       "logloss                  0.433716   0.218064   0.773257      0.518694      0.222864      0.312507      0.341257\n",
       "max_per_class_error      0.409496   0.149612   0.15          0.485714      0.5           0.411765      0.5\n",
       "mcc                      0.458326   0.239374   0.737865      0.23267       0.697217      0.32219       0.301691\n",
       "mean_per_class_accuracy  0.77557    0.0608935  0.869444      0.757143      0.75          0.794118      0.707143\n",
       "mean_per_class_error     0.22443    0.0608935  0.130556      0.242857      0.25          0.205882      0.292857\n",
       "mse                      0.117038   0.0683103  0.210447      0.163935      0.0432085     0.0774701     0.0901279\n",
       "pr_auc                   0.329625   0.343062   0.839706      0.064901      0.530547      0.123128      0.0898432\n",
       "precision                0.474768   0.414379   0.842105      0.105263      1             0.176471      0.25\n",
       "r2                       -0.539536  1.00535    0.155873      -2.2061       0.154964      -0.0397704    -0.762644\n",
       "recall                   0.777778   0.257601   0.888889      1             0.5           1             0.5\n",
       "rmse                     0.33001    0.100818   0.458745      0.404889      0.207867      0.278335      0.300213\n",
       "specificity              0.773361   0.21124    0.85          0.514286      1             0.588235      0.914286\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration           training_speed    epochs    iterations    samples      training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  -----------------  ----------------  --------  ------------  -----------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2023-05-18 15:35:20  0.000 sec                            0         0             0            nan              nan                 nan            nan             nan                nan              nan\n",
       "    2023-05-18 15:35:20  14 min 57.881 sec  77500 obs/sec     10        1             1860         0.328104         0.416729            0.132464       0.808642        0.497298           6.88889          0.112903\n",
       "    2023-05-18 15:35:25  15 min  2.890 sec  87865 obs/sec     2370      237           440820       0.248848         0.204857            0.500961       0.936758        0.787564           6.88889          0.0698925\n",
       "    2023-05-18 15:35:30  15 min  7.891 sec  98158 obs/sec     5280      528           982080       0.248076         0.202535            0.504055       0.943979        0.798658           6.88889          0.0752688\n",
       "    2023-05-18 15:35:33  15 min 10.849 sec  101425 obs/sec    7060      706           1.31316e+06  0.246184         0.19874             0.511589       0.943047        0.800814           6.88889          0.0698925\n",
       "\n",
       "Variable Importances: \n",
       "variable          relative_importance    scaled_importance    percentage\n",
       "----------------  ---------------------  -------------------  ------------\n",
       "winner_sag        1                      1                    0.125534\n",
       "winner_gg_drama   0.869419               0.869419             0.109141\n",
       "nominations       0.80312                0.80312              0.100819\n",
       "winner_dga        0.684994               0.684994             0.0859898\n",
       "winner_pga        0.6612                 0.6612               0.0830028\n",
       "nom_gg_drama      0.632152               0.632152             0.0793563\n",
       "nom_bafta         0.476572               0.476572             0.0598259\n",
       "winner_bafta      0.47004                0.47004              0.0590059\n",
       "nom_dga           0.42396                0.42396              0.0532213\n",
       "year              0.421013               0.421013             0.0528513\n",
       "nom_sag           0.402104               0.402104             0.0504776\n",
       "nom_pga           0.388512               0.388512             0.0487713\n",
       "winner_gg_comedy  0.367386               0.367386             0.0461193\n",
       "nom_gg_comedy     0.365519               0.365519             0.0458849\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model = aml.leader\n",
    "top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Aleksandra Czaplak\\\\Desktop\\\\oscars_ml\\\\oscar_predictions\\\\basic_model\\\\DeepLearning_grid_1_AutoML_1_20230518_152000_model_13'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.save_model(top_model, './basic_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.as_data_frame().to_csv('./basic_model/leaderboard.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Predict on 2019's films\n",
    "test = full_table.loc[(full_table['year'] == 2019)]\n",
    "\n",
    "# Import a binary outcome train/test set into H2O\n",
    "test = h2o.H2OFrame(test)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost prediction progress: |████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">      p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.872341</td><td style=\"text-align: right;\">0.127659</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.871212</td><td style=\"text-align: right;\">0.128788</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.871916</td><td style=\"text-align: right;\">0.128084</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.871639</td><td style=\"text-align: right;\">0.128361</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.872341</td><td style=\"text-align: right;\">0.127659</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.872341</td><td style=\"text-align: right;\">0.127659</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.508026</td><td style=\"text-align: right;\">0.491974</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.871212</td><td style=\"text-align: right;\">0.128788</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.805078</td><td style=\"text-align: right;\">0.194922</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = top_model.predict(test)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred'] = preds['predict']\n",
    "test['probA'] = preds['p1']\n",
    "test_pd = test.as_data_frame(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>probA</th>\n",
       "      <th>%_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1917 (2019 film)</td>\n",
       "      <td>0.491974</td>\n",
       "      <td>31.061029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Parasite (2019 film)</td>\n",
       "      <td>0.194922</td>\n",
       "      <td>12.306475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Irishman</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>8.131125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Once Upon a Time in Hollywood</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>8.131125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joker (2019 film)</td>\n",
       "      <td>0.128361</td>\n",
       "      <td>8.104137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jojo Rabbit</td>\n",
       "      <td>0.128084</td>\n",
       "      <td>8.086673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ford v Ferrari</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>8.059812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Women (2019 film)</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>8.059812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Marriage Story</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>8.059812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            film     probA  %_confidence\n",
       "6               1917 (2019 film)  0.491974     31.061029\n",
       "8           Parasite (2019 film)  0.194922     12.306475\n",
       "1                   The Irishman  0.128788      8.131125\n",
       "7  Once Upon a Time in Hollywood  0.128788      8.131125\n",
       "3              Joker (2019 film)  0.128361      8.104137\n",
       "2                    Jojo Rabbit  0.128084      8.086673\n",
       "0                 Ford v Ferrari  0.127659      8.059812\n",
       "4       Little Women (2019 film)  0.127659      8.059812\n",
       "5                 Marriage Story  0.127659      8.059812"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rankings = test_pd[['film','probA']].sort_values('probA', ascending = False)\n",
    "final_rankings['%_confidence'] = final_rankings['probA']/final_rankings['probA'].sum() * 100\n",
    "final_rankings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And the Oscar goes to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And the Oscar goes to...\n",
      "🎉🏆1917🏆🎉\n"
     ]
    }
   ],
   "source": [
    "bp_winner = np.array(final_rankings.reset_index())[0][1].split('(')[0].strip()\n",
    "print(f'And the Oscar goes to...\\n🎉🏆{bp_winner}🏆🎉')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
